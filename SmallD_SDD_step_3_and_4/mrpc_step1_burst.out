Hostname: b-31-111
Python is:
/scratch/zz3645/conda_envs/nlp_env/bin/python
Python 3.10.19
CUDA visible devices: 0
Torch Seed Specified with rank: 0
Dataset: mrpc_emb
Dataset Path: ./scripts
Namespace(seed=0, mp_distributed=False, world_size=1, rank=0, dist_url='tcp://224.66.41.62:23456', dist_backend='nccl', workers=0, gpu=None, root='./scripts', dataset='mrpc_emb', arch='text_mlp', lr=0.001, inner_optim='Adam', outer_optim='Adam', inner_lr=0.001, label_lr_scale=1, num_per_class=5, batch_per_class=5, task_sampler_nc=2, window=20, minwindow=0, totwindow=20, num_train_eval=4, train_y=False, batch_size=200, eps=1e-08, wd=0, test_freq=5, print_freq=20, start_epoch=0, epochs=100, ddtype='standard', cctype=0, zca=False, wandb=False, clip_coef=0.9, fname='mrpc_mlp_ipc5', name='mrpc_step1_greene', comp_aug=False, comp_aug_real=False, syn_strategy='none', real_strategy='none', ckptname='none', limit_train=False, load_ckpt=False, complete_random=False, distributed=False, data_root='./scripts/mrpc_emb')
==> Preparing data..
mrpc_emb
None None
Dataset: number of classes: 2
Training set size: 3668
Image size: channel 1, height 768, width 1
Synthetic images, not_single False, keys []
==> Building model..
Initialized data with size, x: torch.Size([10, 768]), y:torch.Size([10])
TextMLP(
  (fc1): Linear(in_features=768, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=2, bias=True)
)
use data parallel only
GPU_0_using curriculum 20 with window 20
The current update step is 19
GPU_0_using curriculum 20 with window 20
The current update step is 38
GPU_0_using curriculum 20 with window 20
The current update step is 57
GPU_0_using curriculum 20 with window 20
The current update step is 76
GPU_0_using curriculum 20 with window 20
The current update step is 95
The current seed is 9231632523751190985
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.118
 *   Acc@1 69.057
 *   Acc@1 69.118
 *   Acc@1 68.948
 *   Acc@1 69.118
 *   Acc@1 68.866
 *   Acc@1 69.118
 *   Acc@1 68.757
 *   Acc@1 70.833
 *   Acc@1 71.347
 *   Acc@1 70.343
 *   Acc@1 71.210
 *   Acc@1 70.588
 *   Acc@1 71.238
 *   Acc@1 70.588
 *   Acc@1 71.183
 *   Acc@1 69.853
 *   Acc@1 70.638
 *   Acc@1 69.853
 *   Acc@1 70.883
 *   Acc@1 70.343
 *   Acc@1 70.856
 *   Acc@1 70.588
 *   Acc@1 70.883
 *   Acc@1 70.098
 *   Acc@1 71.320
 *   Acc@1 70.588
 *   Acc@1 71.047
 *   Acc@1 70.588
 *   Acc@1 71.265
 *   Acc@1 70.098
 *   Acc@1 71.565
Training for 300 epoch: 69.97549019607843
Training for 600 epoch: 69.97549019607843
Training for 1000 epoch: 70.1593137254902
Training for 3000 epoch: 70.09803921568627
Training for 300 epoch: 70.590239912759
Training for 600 epoch: 70.52208287895311
Training for 1000 epoch: 70.55616139585605
Training for 3000 epoch: 70.59705561613958
[[69.97549019607843, 69.97549019607843, 70.1593137254902, 70.09803921568627], [70.590239912759, 70.52208287895311, 70.55616139585605, 70.59705561613958]]
train loss 0.5681600635678323, epoch 4, best loss 0.5681600635678323, best_epoch 4
GPU_0_using curriculum 20 with window 20
The current update step is 114
GPU_0_using curriculum 20 with window 20
The current update step is 133
GPU_0_using curriculum 20 with window 20
The current update step is 152
GPU_0_using curriculum 20 with window 20
The current update step is 171
GPU_0_using curriculum 20 with window 20
The current update step is 190
The current seed is 3442175070289942178
The current lr is: 0.001
Testing Results:
 *   Acc@1 68.137
 *   Acc@1 72.410
 *   Acc@1 68.382
 *   Acc@1 72.465
 *   Acc@1 68.382
 *   Acc@1 72.437
 *   Acc@1 68.137
 *   Acc@1 72.465
 *   Acc@1 69.363
 *   Acc@1 72.574
 *   Acc@1 69.853
 *   Acc@1 72.601
 *   Acc@1 69.853
 *   Acc@1 72.519
 *   Acc@1 69.608
 *   Acc@1 72.683
 *   Acc@1 69.363
 *   Acc@1 72.574
 *   Acc@1 69.363
 *   Acc@1 72.437
 *   Acc@1 69.363
 *   Acc@1 72.437
 *   Acc@1 69.363
 *   Acc@1 72.465
 *   Acc@1 69.363
 *   Acc@1 72.710
 *   Acc@1 69.363
 *   Acc@1 72.601
 *   Acc@1 69.363
 *   Acc@1 72.764
 *   Acc@1 69.363
 *   Acc@1 72.383
Training for 300 epoch: 69.05637254901961
Training for 600 epoch: 69.24019607843138
Training for 1000 epoch: 69.24019607843138
Training for 3000 epoch: 69.11764705882354
Training for 300 epoch: 72.56679389312977
Training for 600 epoch: 72.52589967284624
Training for 1000 epoch: 72.53953107960741
Training for 3000 epoch: 72.49863685932388
[[69.05637254901961, 69.24019607843138, 69.24019607843138, 69.11764705882354], [72.56679389312977, 72.52589967284624, 72.53953107960741, 72.49863685932388]]
train loss 0.716051825780255, epoch 9, best loss 0.5681600635678323, best_epoch 4
GPU_0_using curriculum 20 with window 20
The current update step is 209
GPU_0_using curriculum 20 with window 20
The current update step is 228
GPU_0_using curriculum 20 with window 20
The current update step is 247
GPU_0_using curriculum 20 with window 20
The current update step is 266
GPU_0_using curriculum 20 with window 20
The current update step is 285
The current seed is 122799979858656781
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.118
 *   Acc@1 73.173
 *   Acc@1 69.118
 *   Acc@1 73.201
 *   Acc@1 68.873
 *   Acc@1 73.173
 *   Acc@1 68.873
 *   Acc@1 73.173
 *   Acc@1 69.853
 *   Acc@1 73.255
 *   Acc@1 69.853
 *   Acc@1 73.310
 *   Acc@1 69.608
 *   Acc@1 73.310
 *   Acc@1 69.363
 *   Acc@1 73.255
 *   Acc@1 68.627
 *   Acc@1 73.201
 *   Acc@1 68.873
 *   Acc@1 73.119
 *   Acc@1 68.873
 *   Acc@1 73.037
 *   Acc@1 69.118
 *   Acc@1 73.119
 *   Acc@1 68.873
 *   Acc@1 73.010
 *   Acc@1 68.382
 *   Acc@1 72.983
 *   Acc@1 68.382
 *   Acc@1 72.955
 *   Acc@1 68.627
 *   Acc@1 72.874
Training for 300 epoch: 69.11764705882354
Training for 600 epoch: 69.05637254901961
Training for 1000 epoch: 68.93382352941177
Training for 3000 epoch: 68.99509803921569
Training for 300 epoch: 73.159760087241
Training for 600 epoch: 73.15294438386042
Training for 1000 epoch: 73.11886586695746
Training for 3000 epoch: 73.10523446019629
[[69.11764705882354, 69.05637254901961, 68.93382352941177, 68.99509803921569], [73.159760087241, 73.15294438386042, 73.11886586695746, 73.10523446019629]]
train loss 0.5933925729801507, epoch 14, best loss 0.5681600635678323, best_epoch 4
GPU_0_using curriculum 20 with window 20
The current update step is 304
GPU_0_using curriculum 20 with window 20
The current update step is 323
GPU_0_using curriculum 20 with window 20
The current update step is 342
GPU_0_using curriculum 20 with window 20
The current update step is 361
GPU_0_using curriculum 20 with window 20
The current update step is 380
The current seed is 15182640897694313871
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.363
 *   Acc@1 73.255
 *   Acc@1 69.363
 *   Acc@1 73.255
 *   Acc@1 69.363
 *   Acc@1 73.255
 *   Acc@1 69.363
 *   Acc@1 73.064
 *   Acc@1 69.608
 *   Acc@1 73.037
 *   Acc@1 69.363
 *   Acc@1 72.983
 *   Acc@1 69.363
 *   Acc@1 73.010
 *   Acc@1 69.363
 *   Acc@1 73.037
 *   Acc@1 70.588
 *   Acc@1 73.228
 *   Acc@1 70.833
 *   Acc@1 73.146
 *   Acc@1 70.588
 *   Acc@1 73.201
 *   Acc@1 70.098
 *   Acc@1 73.255
 *   Acc@1 68.873
 *   Acc@1 73.037
 *   Acc@1 69.118
 *   Acc@1 73.092
 *   Acc@1 69.118
 *   Acc@1 73.173
 *   Acc@1 68.873
 *   Acc@1 73.201
Training for 300 epoch: 69.6078431372549
Training for 600 epoch: 69.66911764705883
Training for 1000 epoch: 69.6078431372549
Training for 3000 epoch: 69.42401960784314
Training for 300 epoch: 73.13931297709922
Training for 600 epoch: 73.11886586695746
Training for 1000 epoch: 73.159760087241
Training for 3000 epoch: 73.13931297709922
[[69.6078431372549, 69.66911764705883, 69.6078431372549, 69.42401960784314], [73.13931297709922, 73.11886586695746, 73.159760087241, 73.13931297709922]]
train loss 0.5030150361513493, epoch 19, best loss 0.5030150361513493, best_epoch 19
GPU_0_using curriculum 20 with window 20
The current update step is 399
GPU_0_using curriculum 20 with window 20
The current update step is 418
GPU_0_using curriculum 20 with window 20
The current update step is 437
GPU_0_using curriculum 20 with window 20
The current update step is 456
GPU_0_using curriculum 20 with window 20
The current update step is 475
The current seed is 6503243798846740693
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.098
 *   Acc@1 73.255
 *   Acc@1 69.608
 *   Acc@1 73.255
 *   Acc@1 69.363
 *   Acc@1 73.310
 *   Acc@1 69.118
 *   Acc@1 73.337
 *   Acc@1 71.324
 *   Acc@1 73.282
 *   Acc@1 71.324
 *   Acc@1 73.310
 *   Acc@1 71.324
 *   Acc@1 73.228
 *   Acc@1 71.324
 *   Acc@1 73.473
 *   Acc@1 71.078
 *   Acc@1 73.419
 *   Acc@1 70.833
 *   Acc@1 73.391
 *   Acc@1 70.833
 *   Acc@1 73.501
 *   Acc@1 70.588
 *   Acc@1 73.173
 *   Acc@1 70.343
 *   Acc@1 72.928
 *   Acc@1 70.343
 *   Acc@1 73.010
 *   Acc@1 70.343
 *   Acc@1 73.037
 *   Acc@1 70.343
 *   Acc@1 73.119
Training for 300 epoch: 70.7107843137255
Training for 600 epoch: 70.52696078431373
Training for 1000 epoch: 70.4656862745098
Training for 3000 epoch: 70.34313725490196
Training for 300 epoch: 73.22110141766629
Training for 600 epoch: 73.24154852780806
Training for 1000 epoch: 73.26881134133042
Training for 3000 epoch: 73.275627044711
[[70.7107843137255, 70.52696078431373, 70.4656862745098, 70.34313725490196], [73.22110141766629, 73.24154852780806, 73.26881134133042, 73.275627044711]]
train loss 0.5592960221946824, epoch 24, best loss 0.5030150361513493, best_epoch 19
GPU_0_using curriculum 20 with window 20
The current update step is 494
GPU_0_using curriculum 20 with window 20
The current update step is 513
GPU_0_using curriculum 20 with window 20
The current update step is 532
GPU_0_using curriculum 20 with window 20
The current update step is 551
GPU_0_using curriculum 20 with window 20
The current update step is 570
The current seed is 16903087246125609875
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.853
 *   Acc@1 73.337
 *   Acc@1 69.853
 *   Acc@1 73.337
 *   Acc@1 69.853
 *   Acc@1 73.419
 *   Acc@1 69.608
 *   Acc@1 73.473
 *   Acc@1 69.853
 *   Acc@1 73.473
 *   Acc@1 69.853
 *   Acc@1 73.391
 *   Acc@1 69.608
 *   Acc@1 73.473
 *   Acc@1 69.608
 *   Acc@1 73.391
 *   Acc@1 69.608
 *   Acc@1 73.282
 *   Acc@1 69.608
 *   Acc@1 73.282
 *   Acc@1 69.608
 *   Acc@1 73.310
 *   Acc@1 69.608
 *   Acc@1 73.255
 *   Acc@1 69.853
 *   Acc@1 73.201
 *   Acc@1 69.118
 *   Acc@1 73.337
 *   Acc@1 69.118
 *   Acc@1 73.419
 *   Acc@1 69.608
 *   Acc@1 73.337
Training for 300 epoch: 69.79166666666667
Training for 600 epoch: 69.6078431372549
Training for 1000 epoch: 69.54656862745098
Training for 3000 epoch: 69.6078431372549
Training for 300 epoch: 73.32333696837513
Training for 600 epoch: 73.33696837513631
Training for 1000 epoch: 73.4051254089422
Training for 3000 epoch: 73.36423118865866
[[69.79166666666667, 69.6078431372549, 69.54656862745098, 69.6078431372549], [73.32333696837513, 73.33696837513631, 73.4051254089422, 73.36423118865866]]
train loss 0.4948551178368513, epoch 29, best loss 0.4948551178368513, best_epoch 29
GPU_0_using curriculum 20 with window 20
The current update step is 589
GPU_0_using curriculum 20 with window 20
The current update step is 608
GPU_0_using curriculum 20 with window 20
The current update step is 627
GPU_0_using curriculum 20 with window 20
The current update step is 646
GPU_0_using curriculum 20 with window 20
The current update step is 665
The current seed is 12763629731896148753
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.363
 *   Acc@1 73.800
 *   Acc@1 69.118
 *   Acc@1 73.664
 *   Acc@1 68.382
 *   Acc@1 73.555
 *   Acc@1 68.873
 *   Acc@1 73.473
 *   Acc@1 70.098
 *   Acc@1 73.473
 *   Acc@1 69.608
 *   Acc@1 73.419
 *   Acc@1 69.608
 *   Acc@1 73.419
 *   Acc@1 69.608
 *   Acc@1 73.446
 *   Acc@1 69.118
 *   Acc@1 73.719
 *   Acc@1 69.118
 *   Acc@1 73.664
 *   Acc@1 69.118
 *   Acc@1 73.691
 *   Acc@1 69.363
 *   Acc@1 73.746
 *   Acc@1 69.853
 *   Acc@1 73.446
 *   Acc@1 69.363
 *   Acc@1 73.337
 *   Acc@1 69.118
 *   Acc@1 73.173
 *   Acc@1 69.118
 *   Acc@1 73.092
Training for 300 epoch: 69.6078431372549
Training for 600 epoch: 69.3014705882353
Training for 1000 epoch: 69.05637254901961
Training for 3000 epoch: 69.24019607843138
Training for 300 epoch: 73.60959651035986
Training for 600 epoch: 73.5209923664122
Training for 1000 epoch: 73.45965103598691
Training for 3000 epoch: 73.43920392584513
[[69.6078431372549, 69.3014705882353, 69.05637254901961, 69.24019607843138], [73.60959651035986, 73.5209923664122, 73.45965103598691, 73.43920392584513]]
train loss 0.4356485100517876, epoch 34, best loss 0.4356485100517876, best_epoch 34
GPU_0_using curriculum 20 with window 20
The current update step is 684
GPU_0_using curriculum 20 with window 20
The current update step is 703
GPU_0_using curriculum 20 with window 20
The current update step is 722
GPU_0_using curriculum 20 with window 20
The current update step is 741
GPU_0_using curriculum 20 with window 20
The current update step is 760
The current seed is 736976928115311211
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.588
 *   Acc@1 73.610
 *   Acc@1 70.588
 *   Acc@1 73.528
 *   Acc@1 70.588
 *   Acc@1 73.691
 *   Acc@1 70.833
 *   Acc@1 73.828
 *   Acc@1 70.098
 *   Acc@1 73.664
 *   Acc@1 70.343
 *   Acc@1 73.719
 *   Acc@1 70.343
 *   Acc@1 73.637
 *   Acc@1 70.588
 *   Acc@1 73.746
 *   Acc@1 71.324
 *   Acc@1 73.555
 *   Acc@1 71.078
 *   Acc@1 73.473
 *   Acc@1 70.833
 *   Acc@1 73.473
 *   Acc@1 70.833
 *   Acc@1 73.391
 *   Acc@1 70.098
 *   Acc@1 73.746
 *   Acc@1 70.098
 *   Acc@1 73.773
 *   Acc@1 70.098
 *   Acc@1 73.800
 *   Acc@1 70.343
 *   Acc@1 73.828
Training for 300 epoch: 70.52696078431373
Training for 600 epoch: 70.52696078431373
Training for 1000 epoch: 70.4656862745098
Training for 3000 epoch: 70.64950980392157
Training for 300 epoch: 73.64367502726282
Training for 600 epoch: 73.62322791712104
Training for 1000 epoch: 73.6504907306434
Training for 3000 epoch: 73.69820065430753
[[70.52696078431373, 70.52696078431373, 70.4656862745098, 70.64950980392157], [73.64367502726282, 73.62322791712104, 73.6504907306434, 73.69820065430753]]
train loss 0.5209464135060784, epoch 39, best loss 0.4356485100517876, best_epoch 34
GPU_0_using curriculum 20 with window 20
The current update step is 779
GPU_0_using curriculum 20 with window 20
The current update step is 798
GPU_0_using curriculum 20 with window 20
The current update step is 817
GPU_0_using curriculum 20 with window 20
The current update step is 836
GPU_0_using curriculum 20 with window 20
The current update step is 855
The current seed is 15769933720568070495
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.608
 *   Acc@1 74.455
 *   Acc@1 69.363
 *   Acc@1 74.019
 *   Acc@1 69.363
 *   Acc@1 74.073
 *   Acc@1 68.873
 *   Acc@1 74.019
 *   Acc@1 69.608
 *   Acc@1 73.937
 *   Acc@1 69.363
 *   Acc@1 73.800
 *   Acc@1 69.363
 *   Acc@1 73.855
 *   Acc@1 69.363
 *   Acc@1 73.773
 *   Acc@1 69.363
 *   Acc@1 73.446
 *   Acc@1 69.118
 *   Acc@1 73.419
 *   Acc@1 69.118
 *   Acc@1 73.255
 *   Acc@1 68.873
 *   Acc@1 73.337
 *   Acc@1 68.873
 *   Acc@1 74.237
 *   Acc@1 69.363
 *   Acc@1 73.909
 *   Acc@1 68.627
 *   Acc@1 73.937
 *   Acc@1 69.363
 *   Acc@1 73.855
Training for 300 epoch: 69.36274509803921
Training for 600 epoch: 69.30147058823529
Training for 1000 epoch: 69.11764705882354
Training for 3000 epoch: 69.11764705882354
Training for 300 epoch: 74.0185387131952
Training for 600 epoch: 73.78680479825518
Training for 1000 epoch: 73.7799890948746
Training for 3000 epoch: 73.74591057797164
[[69.36274509803921, 69.30147058823529, 69.11764705882354, 69.11764705882354], [74.0185387131952, 73.78680479825518, 73.7799890948746, 73.74591057797164]]
train loss 0.42162859901347105, epoch 44, best loss 0.42162859901347105, best_epoch 44
GPU_0_using curriculum 20 with window 20
The current update step is 874
GPU_0_using curriculum 20 with window 20
The current update step is 893
GPU_0_using curriculum 20 with window 20
The current update step is 912
GPU_0_using curriculum 20 with window 20
The current update step is 931
GPU_0_using curriculum 20 with window 20
The current update step is 950
The current seed is 15799574370485724796
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.343
 *   Acc@1 73.882
 *   Acc@1 70.098
 *   Acc@1 73.664
 *   Acc@1 70.098
 *   Acc@1 73.664
 *   Acc@1 70.343
 *   Acc@1 73.719
 *   Acc@1 69.118
 *   Acc@1 73.964
 *   Acc@1 69.118
 *   Acc@1 74.073
 *   Acc@1 69.608
 *   Acc@1 74.046
 *   Acc@1 69.363
 *   Acc@1 73.964
 *   Acc@1 70.343
 *   Acc@1 73.937
 *   Acc@1 69.853
 *   Acc@1 73.964
 *   Acc@1 69.853
 *   Acc@1 73.991
 *   Acc@1 69.853
 *   Acc@1 74.100
 *   Acc@1 70.343
 *   Acc@1 74.237
 *   Acc@1 69.853
 *   Acc@1 74.155
 *   Acc@1 70.098
 *   Acc@1 74.209
 *   Acc@1 69.853
 *   Acc@1 74.237
Training for 300 epoch: 70.03676470588235
Training for 600 epoch: 69.73039215686275
Training for 1000 epoch: 69.9142156862745
Training for 3000 epoch: 69.8529411764706
Training for 300 epoch: 74.00490730643402
Training for 600 epoch: 73.96401308615049
Training for 1000 epoch: 73.97764449291166
Training for 3000 epoch: 74.00490730643402
[[70.03676470588235, 69.73039215686275, 69.9142156862745, 69.8529411764706], [74.00490730643402, 73.96401308615049, 73.97764449291166, 74.00490730643402]]
train loss 0.41715967239184365, epoch 49, best loss 0.41715967239184365, best_epoch 49
GPU_0_using curriculum 20 with window 20
The current update step is 969
GPU_0_using curriculum 20 with window 20
The current update step is 988
GPU_0_using curriculum 20 with window 20
The current update step is 1007
GPU_0_using curriculum 20 with window 20
The current update step is 1026
GPU_0_using curriculum 20 with window 20
The current update step is 1045
The current seed is 9302796488722881271
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.098
 *   Acc@1 74.019
 *   Acc@1 70.098
 *   Acc@1 74.073
 *   Acc@1 70.098
 *   Acc@1 74.046
 *   Acc@1 69.853
 *   Acc@1 74.046
 *   Acc@1 70.833
 *   Acc@1 74.373
 *   Acc@1 70.588
 *   Acc@1 74.400
 *   Acc@1 70.098
 *   Acc@1 74.264
 *   Acc@1 70.098
 *   Acc@1 74.155
 *   Acc@1 70.098
 *   Acc@1 74.100
 *   Acc@1 70.098
 *   Acc@1 74.128
 *   Acc@1 70.098
 *   Acc@1 74.046
 *   Acc@1 69.853
 *   Acc@1 73.991
 *   Acc@1 70.098
 *   Acc@1 74.128
 *   Acc@1 70.098
 *   Acc@1 74.155
 *   Acc@1 70.098
 *   Acc@1 74.155
 *   Acc@1 69.853
 *   Acc@1 74.019
Training for 300 epoch: 70.28186274509804
Training for 600 epoch: 70.22058823529412
Training for 1000 epoch: 70.09803921568627
Training for 3000 epoch: 69.91421568627452
Training for 300 epoch: 74.15485278080698
Training for 600 epoch: 74.18893129770993
Training for 1000 epoch: 74.12758996728462
Training for 3000 epoch: 74.05261723009815
[[70.28186274509804, 70.22058823529412, 70.09803921568627, 69.91421568627452], [74.15485278080698, 74.18893129770993, 74.12758996728462, 74.05261723009815]]
train loss 0.4120574632868772, epoch 54, best loss 0.4120574632868772, best_epoch 54
GPU_0_using curriculum 20 with window 20
The current update step is 1064
GPU_0_using curriculum 20 with window 20
The current update step is 1083
GPU_0_using curriculum 20 with window 20
The current update step is 1102
GPU_0_using curriculum 20 with window 20
The current update step is 1121
GPU_0_using curriculum 20 with window 20
The current update step is 1140
The current seed is 9010449955735870668
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.608
 *   Acc@1 74.155
 *   Acc@1 69.363
 *   Acc@1 74.209
 *   Acc@1 69.363
 *   Acc@1 74.291
 *   Acc@1 70.343
 *   Acc@1 73.964
 *   Acc@1 70.343
 *   Acc@1 73.800
 *   Acc@1 69.608
 *   Acc@1 73.501
 *   Acc@1 69.608
 *   Acc@1 73.228
 *   Acc@1 69.608
 *   Acc@1 72.928
 *   Acc@1 69.853
 *   Acc@1 74.073
 *   Acc@1 70.098
 *   Acc@1 73.664
 *   Acc@1 69.608
 *   Acc@1 73.473
 *   Acc@1 70.343
 *   Acc@1 73.037
 *   Acc@1 69.853
 *   Acc@1 73.800
 *   Acc@1 69.608
 *   Acc@1 73.719
 *   Acc@1 69.608
 *   Acc@1 73.691
 *   Acc@1 69.608
 *   Acc@1 73.664
Training for 300 epoch: 69.91421568627452
Training for 600 epoch: 69.66911764705883
Training for 1000 epoch: 69.54656862745098
Training for 3000 epoch: 69.97549019607843
Training for 300 epoch: 73.95719738276989
Training for 600 epoch: 73.773173391494
Training for 1000 epoch: 73.67093784078517
Training for 3000 epoch: 73.39830970556162
[[69.91421568627452, 69.66911764705883, 69.54656862745098, 69.97549019607843], [73.95719738276989, 73.773173391494, 73.67093784078517, 73.39830970556162]]
train loss 0.3953729951297184, epoch 59, best loss 0.3953729951297184, best_epoch 59
GPU_0_using curriculum 20 with window 20
The current update step is 1159
GPU_0_using curriculum 20 with window 20
The current update step is 1178
GPU_0_using curriculum 20 with window 20
The current update step is 1197
GPU_0_using curriculum 20 with window 20
The current update step is 1216
GPU_0_using curriculum 20 with window 20
The current update step is 1235
The current seed is 5095224922215548630
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.588
 *   Acc@1 73.882
 *   Acc@1 70.343
 *   Acc@1 73.746
 *   Acc@1 70.098
 *   Acc@1 73.419
 *   Acc@1 69.608
 *   Acc@1 73.092
 *   Acc@1 70.098
 *   Acc@1 74.264
 *   Acc@1 70.098
 *   Acc@1 74.427
 *   Acc@1 70.098
 *   Acc@1 74.373
 *   Acc@1 69.853
 *   Acc@1 74.019
 *   Acc@1 69.853
 *   Acc@1 73.582
 *   Acc@1 69.608
 *   Acc@1 73.228
 *   Acc@1 69.608
 *   Acc@1 73.092
 *   Acc@1 69.363
 *   Acc@1 72.792
 *   Acc@1 69.853
 *   Acc@1 73.746
 *   Acc@1 69.608
 *   Acc@1 73.146
 *   Acc@1 69.363
 *   Acc@1 72.819
 *   Acc@1 69.118
 *   Acc@1 72.246
Training for 300 epoch: 70.09803921568628
Training for 600 epoch: 69.91421568627452
Training for 1000 epoch: 69.79166666666667
Training for 3000 epoch: 69.48529411764706
Training for 300 epoch: 73.86859323882224
Training for 600 epoch: 73.63685932388222
Training for 1000 epoch: 73.42557251908397
Training for 3000 epoch: 73.03707742639041
[[70.09803921568628, 69.91421568627452, 69.79166666666667, 69.48529411764706], [73.86859323882224, 73.63685932388222, 73.42557251908397, 73.03707742639041]]
train loss 0.35402649527287666, epoch 64, best loss 0.35402649527287666, best_epoch 64
GPU_0_using curriculum 20 with window 20
The current update step is 1254
GPU_0_using curriculum 20 with window 20
The current update step is 1273
GPU_0_using curriculum 20 with window 20
The current update step is 1292
GPU_0_using curriculum 20 with window 20
The current update step is 1311
GPU_0_using curriculum 20 with window 20
The current update step is 1330
The current seed is 7169259551776921705
The current lr is: 0.001
Testing Results:
 *   Acc@1 72.304
 *   Acc@1 73.582
 *   Acc@1 72.549
 *   Acc@1 73.555
 *   Acc@1 72.794
 *   Acc@1 73.582
 *   Acc@1 73.039
 *   Acc@1 73.746
 *   Acc@1 72.059
 *   Acc@1 73.719
 *   Acc@1 72.304
 *   Acc@1 73.909
 *   Acc@1 72.304
 *   Acc@1 73.855
 *   Acc@1 71.569
 *   Acc@1 73.909
 *   Acc@1 69.853
 *   Acc@1 74.100
 *   Acc@1 69.608
 *   Acc@1 74.209
 *   Acc@1 69.608
 *   Acc@1 74.155
 *   Acc@1 70.098
 *   Acc@1 74.291
 *   Acc@1 72.549
 *   Acc@1 73.855
 *   Acc@1 72.304
 *   Acc@1 73.800
 *   Acc@1 71.814
 *   Acc@1 73.746
 *   Acc@1 72.059
 *   Acc@1 73.800
Training for 300 epoch: 71.69117647058825
Training for 600 epoch: 71.69117647058823
Training for 1000 epoch: 71.62990196078431
Training for 3000 epoch: 71.69117647058823
Training for 300 epoch: 73.81406761177753
Training for 600 epoch: 73.86859323882224
Training for 1000 epoch: 73.8345147219193
Training for 3000 epoch: 73.93675027262813
[[71.69117647058825, 71.69117647058823, 71.62990196078431, 71.69117647058823], [73.81406761177753, 73.86859323882224, 73.8345147219193, 73.93675027262813]]
train loss 0.28922241659694825, epoch 69, best loss 0.28922241659694825, best_epoch 69
GPU_0_using curriculum 20 with window 20
The current update step is 1349
GPU_0_using curriculum 20 with window 20
The current update step is 1368
GPU_0_using curriculum 20 with window 20
The current update step is 1387
GPU_0_using curriculum 20 with window 20
The current update step is 1406
GPU_0_using curriculum 20 with window 20
The current update step is 1425
The current seed is 8442496294806265931
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.343
 *   Acc@1 74.646
 *   Acc@1 70.098
 *   Acc@1 74.591
 *   Acc@1 70.343
 *   Acc@1 74.482
 *   Acc@1 70.098
 *   Acc@1 74.318
 *   Acc@1 71.569
 *   Acc@1 74.182
 *   Acc@1 70.098
 *   Acc@1 74.427
 *   Acc@1 70.343
 *   Acc@1 74.509
 *   Acc@1 69.853
 *   Acc@1 74.782
 *   Acc@1 70.098
 *   Acc@1 74.291
 *   Acc@1 70.343
 *   Acc@1 74.318
 *   Acc@1 70.588
 *   Acc@1 74.400
 *   Acc@1 70.343
 *   Acc@1 74.209
 *   Acc@1 69.363
 *   Acc@1 74.400
 *   Acc@1 69.853
 *   Acc@1 74.291
 *   Acc@1 70.098
 *   Acc@1 74.155
 *   Acc@1 70.343
 *   Acc@1 74.237
Training for 300 epoch: 70.34313725490196
Training for 600 epoch: 70.09803921568627
Training for 1000 epoch: 70.34313725490196
Training for 3000 epoch: 70.1593137254902
Training for 300 epoch: 74.37977099236642
Training for 600 epoch: 74.40703380588877
Training for 1000 epoch: 74.386586695747
Training for 3000 epoch: 74.386586695747
[[70.34313725490196, 70.09803921568627, 70.34313725490196, 70.1593137254902], [74.37977099236642, 74.40703380588877, 74.386586695747, 74.386586695747]]
train loss 0.32756623482756164, epoch 74, best loss 0.28922241659694825, best_epoch 69
GPU_0_using curriculum 20 with window 20
The current update step is 1444
GPU_0_using curriculum 20 with window 20
The current update step is 1463
GPU_0_using curriculum 20 with window 20
The current update step is 1482
GPU_0_using curriculum 20 with window 20
The current update step is 1501
GPU_0_using curriculum 20 with window 20
The current update step is 1520
The current seed is 6992186602591354822
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.363
 *   Acc@1 72.028
 *   Acc@1 69.118
 *   Acc@1 71.947
 *   Acc@1 69.118
 *   Acc@1 72.056
 *   Acc@1 68.382
 *   Acc@1 71.838
 *   Acc@1 70.098
 *   Acc@1 74.019
 *   Acc@1 69.608
 *   Acc@1 73.964
 *   Acc@1 69.118
 *   Acc@1 73.882
 *   Acc@1 70.343
 *   Acc@1 73.146
 *   Acc@1 70.588
 *   Acc@1 73.501
 *   Acc@1 70.343
 *   Acc@1 73.255
 *   Acc@1 69.853
 *   Acc@1 73.173
 *   Acc@1 70.588
 *   Acc@1 72.846
 *   Acc@1 70.098
 *   Acc@1 73.037
 *   Acc@1 70.588
 *   Acc@1 72.465
 *   Acc@1 70.098
 *   Acc@1 72.246
 *   Acc@1 69.853
 *   Acc@1 71.947
Training for 300 epoch: 70.03676470588235
Training for 600 epoch: 69.91421568627452
Training for 1000 epoch: 69.546568627451
Training for 3000 epoch: 69.79166666666667
Training for 300 epoch: 73.14612868047982
Training for 600 epoch: 72.90757906215921
Training for 1000 epoch: 72.83942202835333
Training for 3000 epoch: 72.44411123227917
[[70.03676470588235, 69.91421568627452, 69.546568627451, 69.79166666666667], [73.14612868047982, 72.90757906215921, 72.83942202835333, 72.44411123227917]]
train loss 0.27092470724294077, epoch 79, best loss 0.27092470724294077, best_epoch 79
GPU_0_using curriculum 20 with window 20
The current update step is 1539
GPU_0_using curriculum 20 with window 20
The current update step is 1558
GPU_0_using curriculum 20 with window 20
The current update step is 1577
GPU_0_using curriculum 20 with window 20
The current update step is 1596
GPU_0_using curriculum 20 with window 20
The current update step is 1615
The current seed is 12340261918471005341
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.853
 *   Acc@1 73.882
 *   Acc@1 69.853
 *   Acc@1 73.582
 *   Acc@1 69.608
 *   Acc@1 73.719
 *   Acc@1 68.627
 *   Acc@1 73.582
 *   Acc@1 69.118
 *   Acc@1 73.310
 *   Acc@1 69.363
 *   Acc@1 73.173
 *   Acc@1 69.608
 *   Acc@1 72.928
 *   Acc@1 69.363
 *   Acc@1 72.519
 *   Acc@1 69.608
 *   Acc@1 73.964
 *   Acc@1 69.118
 *   Acc@1 74.019
 *   Acc@1 69.608
 *   Acc@1 73.882
 *   Acc@1 69.853
 *   Acc@1 74.019
 *   Acc@1 69.118
 *   Acc@1 72.110
 *   Acc@1 68.627
 *   Acc@1 71.974
 *   Acc@1 68.627
 *   Acc@1 71.892
 *   Acc@1 68.873
 *   Acc@1 71.701
Training for 300 epoch: 69.42401960784315
Training for 600 epoch: 69.24019607843138
Training for 1000 epoch: 69.36274509803921
Training for 3000 epoch: 69.17892156862746
Training for 300 epoch: 73.31652126499455
Training for 600 epoch: 73.18702290076335
Training for 1000 epoch: 73.10523446019629
Training for 3000 epoch: 72.95528898582334
[[69.42401960784315, 69.24019607843138, 69.36274509803921, 69.17892156862746], [73.31652126499455, 73.18702290076335, 73.10523446019629, 72.95528898582334]]
train loss 0.26588764770470374, epoch 84, best loss 0.26588764770470374, best_epoch 84
GPU_0_using curriculum 20 with window 20
The current update step is 1634
GPU_0_using curriculum 20 with window 20
The current update step is 1653
GPU_0_using curriculum 20 with window 20
The current update step is 1672
GPU_0_using curriculum 20 with window 20
The current update step is 1691
GPU_0_using curriculum 20 with window 20
The current update step is 1710
The current seed is 15657508008122010253
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.588
 *   Acc@1 74.618
 *   Acc@1 70.588
 *   Acc@1 74.727
 *   Acc@1 70.343
 *   Acc@1 74.782
 *   Acc@1 70.343
 *   Acc@1 74.755
 *   Acc@1 69.853
 *   Acc@1 74.809
 *   Acc@1 69.608
 *   Acc@1 74.782
 *   Acc@1 69.853
 *   Acc@1 74.673
 *   Acc@1 71.324
 *   Acc@1 74.673
 *   Acc@1 69.608
 *   Acc@1 73.855
 *   Acc@1 69.853
 *   Acc@1 73.773
 *   Acc@1 69.608
 *   Acc@1 73.528
 *   Acc@1 70.098
 *   Acc@1 73.446
 *   Acc@1 70.588
 *   Acc@1 74.128
 *   Acc@1 70.588
 *   Acc@1 74.400
 *   Acc@1 70.588
 *   Acc@1 74.400
 *   Acc@1 69.853
 *   Acc@1 74.046
Training for 300 epoch: 70.1593137254902
Training for 600 epoch: 70.1593137254902
Training for 1000 epoch: 70.09803921568627
Training for 3000 epoch: 70.40441176470588
Training for 300 epoch: 74.35250817884406
Training for 600 epoch: 74.42066521264994
Training for 1000 epoch: 74.34569247546347
Training for 3000 epoch: 74.22982551799345
[[70.1593137254902, 70.1593137254902, 70.09803921568627, 70.40441176470588], [74.35250817884406, 74.42066521264994, 74.34569247546347, 74.22982551799345]]
train loss 0.26226633896842, epoch 89, best loss 0.26226633896842, best_epoch 89
GPU_0_using curriculum 20 with window 20
The current update step is 1729
GPU_0_using curriculum 20 with window 20
The current update step is 1748
GPU_0_using curriculum 20 with window 20
The current update step is 1767
GPU_0_using curriculum 20 with window 20
The current update step is 1786
GPU_0_using curriculum 20 with window 20
The current update step is 1805
The current seed is 10647826155379418764
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.078
 *   Acc@1 73.719
 *   Acc@1 70.833
 *   Acc@1 73.555
 *   Acc@1 70.833
 *   Acc@1 73.637
 *   Acc@1 70.098
 *   Acc@1 73.501
 *   Acc@1 70.588
 *   Acc@1 72.874
 *   Acc@1 69.118
 *   Acc@1 72.764
 *   Acc@1 69.363
 *   Acc@1 72.574
 *   Acc@1 69.363
 *   Acc@1 72.383
 *   Acc@1 69.608
 *   Acc@1 74.537
 *   Acc@1 69.608
 *   Acc@1 74.373
 *   Acc@1 69.608
 *   Acc@1 74.128
 *   Acc@1 69.608
 *   Acc@1 74.100
 *   Acc@1 70.343
 *   Acc@1 72.983
 *   Acc@1 70.833
 *   Acc@1 72.928
 *   Acc@1 70.833
 *   Acc@1 72.764
 *   Acc@1 70.833
 *   Acc@1 72.465
Training for 300 epoch: 70.40441176470588
Training for 600 epoch: 70.09803921568627
Training for 1000 epoch: 70.1593137254902
Training for 3000 epoch: 69.97549019607843
Training for 300 epoch: 73.5278080697928
Training for 600 epoch: 73.40512540894221
Training for 1000 epoch: 73.27562704471102
Training for 3000 epoch: 73.11205016357688
[[70.40441176470588, 70.09803921568627, 70.1593137254902, 69.97549019607843], [73.5278080697928, 73.40512540894221, 73.27562704471102, 73.11205016357688]]
train loss 0.1844234881575261, epoch 94, best loss 0.1844234881575261, best_epoch 94
GPU_0_using curriculum 20 with window 20
The current update step is 1824
GPU_0_using curriculum 20 with window 20
The current update step is 1843
GPU_0_using curriculum 20 with window 20
The current update step is 1862
GPU_0_using curriculum 20 with window 20
The current update step is 1881
GPU_0_using curriculum 20 with window 20
The current update step is 1900
The current seed is 1405601561233297233
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.853
 *   Acc@1 74.537
 *   Acc@1 70.098
 *   Acc@1 74.673
 *   Acc@1 70.098
 *   Acc@1 74.455
 *   Acc@1 70.833
 *   Acc@1 74.509
 *   Acc@1 70.343
 *   Acc@1 72.465
 *   Acc@1 70.098
 *   Acc@1 72.165
 *   Acc@1 70.098
 *   Acc@1 72.056
 *   Acc@1 68.873
 *   Acc@1 71.510
 *   Acc@1 69.608
 *   Acc@1 73.909
 *   Acc@1 69.608
 *   Acc@1 73.337
 *   Acc@1 70.098
 *   Acc@1 72.983
 *   Acc@1 70.098
 *   Acc@1 71.974
 *   Acc@1 70.833
 *   Acc@1 74.400
 *   Acc@1 70.833
 *   Acc@1 74.400
 *   Acc@1 70.833
 *   Acc@1 74.400
 *   Acc@1 70.588
 *   Acc@1 74.100
Training for 300 epoch: 70.1593137254902
Training for 600 epoch: 70.1593137254902
Training for 1000 epoch: 70.28186274509804
Training for 3000 epoch: 70.09803921568627
Training for 300 epoch: 73.82769901853871
Training for 600 epoch: 73.64367502726282
Training for 1000 epoch: 73.47328244274809
Training for 3000 epoch: 73.02344601962923
[[70.1593137254902, 70.1593137254902, 70.28186274509804, 70.09803921568627], [73.82769901853871, 73.64367502726282, 73.47328244274809, 73.02344601962923]]
train loss 0.18229890462811407, epoch 99, best loss 0.18229890462811407, best_epoch 99
=== Final results:
{'acc': 71.69117647058825, 'test': [71.69117647058825, 71.69117647058823, 71.62990196078431, 71.69117647058823], 'train': [71.69117647058825, 71.69117647058823, 71.62990196078431, 71.69117647058823], 'ind': 0, 'epoch': 70, 'data': array([[-0.03258682, -0.04683308, -0.02463481, ..., -0.03059905,
         0.0199838 ,  0.01967429],
       [-0.06493881, -0.04281371, -0.00407828, ...,  0.00176906,
        -0.00261644,  0.0172939 ],
       [-0.01799166, -0.05812058,  0.00376102, ..., -0.04667432,
         0.01688176, -0.00510959],
       ...,
       [ 0.03138882,  0.0376123 , -0.00926032, ...,  0.02906617,
        -0.04234861, -0.00369329],
       [-0.01037638,  0.07624773,  0.04373475, ...,  0.11530223,
        -0.0119875 , -0.00264104],
       [ 0.05071146,  0.0699067 ,  0.02539499, ...,  0.08246567,
        -0.06855646, -0.07605637]], shape=(10, 768), dtype=float32)}
