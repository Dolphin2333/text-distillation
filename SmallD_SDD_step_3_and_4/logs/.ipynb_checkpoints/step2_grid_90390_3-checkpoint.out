Hostname: b-31-164
Python:
/scratch/zz3645/conda_envs/nlp_env/bin/python
Python 3.10.19
CUDA visible devices: 0
Task ID: 3
Config: IPC=1, window=20, seed=0
Torch Seed Specified with rank: 0
Dataset: mrpc_emb
Dataset Path: ./scripts
Namespace(seed=0, mp_distributed=False, world_size=1, rank=0, dist_url='tcp://224.66.41.62:23456', dist_backend='nccl', workers=0, gpu=None, root='./scripts', dataset='mrpc_emb', arch='text_mlp', lr=0.001, inner_optim='Adam', outer_optim='Adam', inner_lr=0.001, label_lr_scale=1, num_per_class=1, batch_per_class=1, task_sampler_nc=2, window=20, minwindow=0, totwindow=20, num_train_eval=4, train_y=False, batch_size=200, eps=1e-08, wd=0, test_freq=5, print_freq=20, start_epoch=0, epochs=100, ddtype='standard', cctype=0, zca=False, wandb=False, clip_coef=0.9, fname='mrpc_mlp_ipc1_w20_seed0', name='mrpc_step2_ipc1_w20_seed0', comp_aug=False, comp_aug_real=False, syn_strategy='none', real_strategy='none', ckptname='none', limit_train=False, load_ckpt=False, complete_random=False, distributed=False, data_root='./scripts/mrpc_emb')
==> Preparing data..
mrpc_emb
None None
Dataset: number of classes: 2
Training set size: 3668
Image size: channel 1, height 768, width 1
Synthetic images, not_single False, keys []
==> Building model..
Initialized data with size, x: torch.Size([2, 768]), y:torch.Size([2])
TextMLP(
  (fc1): Linear(in_features=768, out_features=64, bias=True)
  (fc2): Linear(in_features=64, out_features=2, bias=True)
)
use data parallel only
GPU_0_using curriculum 20 with window 20
The current update step is 19
GPU_0_using curriculum 20 with window 20
The current update step is 38
GPU_0_using curriculum 20 with window 20
The current update step is 57
GPU_0_using curriculum 20 with window 20
The current update step is 76
GPU_0_using curriculum 20 with window 20
The current update step is 95
The current seed is 5136362422073005632
The current lr is: 0.001
Testing Results:
 *   Acc@1 68.627
 *   Acc@1 68.239
 *   Acc@1 68.627
 *   Acc@1 68.239
 *   Acc@1 68.627
 *   Acc@1 68.293
 *   Acc@1 68.627
 *   Acc@1 68.348
 *   Acc@1 68.873
 *   Acc@1 68.402
 *   Acc@1 68.873
 *   Acc@1 68.375
 *   Acc@1 68.873
 *   Acc@1 68.375
 *   Acc@1 68.873
 *   Acc@1 68.375
 *   Acc@1 68.627
 *   Acc@1 68.239
 *   Acc@1 68.627
 *   Acc@1 68.321
 *   Acc@1 68.627
 *   Acc@1 68.348
 *   Acc@1 68.627
 *   Acc@1 68.348
 *   Acc@1 68.627
 *   Acc@1 68.184
 *   Acc@1 68.627
 *   Acc@1 68.212
 *   Acc@1 68.627
 *   Acc@1 68.293
 *   Acc@1 68.627
 *   Acc@1 68.293
Training for 300 epoch: 68.68872549019608
Training for 600 epoch: 68.68872549019608
Training for 1000 epoch: 68.68872549019608
Training for 3000 epoch: 68.68872549019608
Training for 300 epoch: 68.2660850599782
Training for 600 epoch: 68.28653217011995
Training for 1000 epoch: 68.3274263904035
Training for 3000 epoch: 68.34105779716467
[[68.68872549019608, 68.68872549019608, 68.68872549019608, 68.68872549019608], [68.2660850599782, 68.28653217011995, 68.3274263904035, 68.34105779716467]]
train loss 0.9802046508539464, epoch 4, best loss 0.9802046508539464, best_epoch 4
GPU_0_using curriculum 20 with window 20
The current update step is 114
GPU_0_using curriculum 20 with window 20
The current update step is 133
GPU_0_using curriculum 20 with window 20
The current update step is 152
GPU_0_using curriculum 20 with window 20
The current update step is 171
GPU_0_using curriculum 20 with window 20
The current update step is 190
The current seed is 16559185894677112698
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.098
 *   Acc@1 70.529
 *   Acc@1 70.098
 *   Acc@1 70.502
 *   Acc@1 70.098
 *   Acc@1 70.502
 *   Acc@1 70.098
 *   Acc@1 70.529
 *   Acc@1 70.343
 *   Acc@1 70.665
 *   Acc@1 70.343
 *   Acc@1 70.665
 *   Acc@1 70.343
 *   Acc@1 70.692
 *   Acc@1 70.098
 *   Acc@1 70.665
 *   Acc@1 71.078
 *   Acc@1 71.183
 *   Acc@1 70.098
 *   Acc@1 71.020
 *   Acc@1 70.588
 *   Acc@1 71.020
 *   Acc@1 70.588
 *   Acc@1 70.992
 *   Acc@1 70.098
 *   Acc@1 70.692
 *   Acc@1 70.098
 *   Acc@1 70.638
 *   Acc@1 70.098
 *   Acc@1 70.611
 *   Acc@1 70.343
 *   Acc@1 70.720
Training for 300 epoch: 70.40441176470588
Training for 600 epoch: 70.1593137254902
Training for 1000 epoch: 70.28186274509804
Training for 3000 epoch: 70.28186274509804
Training for 300 epoch: 70.7674482006543
Training for 600 epoch: 70.70610687022901
Training for 1000 epoch: 70.70610687022901
Training for 3000 epoch: 70.72655398037078
[[70.40441176470588, 70.1593137254902, 70.28186274509804, 70.28186274509804], [70.7674482006543, 70.70610687022901, 70.70610687022901, 70.72655398037078]]
train loss 0.6354225728348011, epoch 9, best loss 0.6354225728348011, best_epoch 9
GPU_0_using curriculum 20 with window 20
The current update step is 209
GPU_0_using curriculum 20 with window 20
The current update step is 228
GPU_0_using curriculum 20 with window 20
The current update step is 247
GPU_0_using curriculum 20 with window 20
The current update step is 266
GPU_0_using curriculum 20 with window 20
The current update step is 285
The current seed is 4083945476876017361
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.853
 *   Acc@1 70.938
 *   Acc@1 69.608
 *   Acc@1 71.020
 *   Acc@1 69.608
 *   Acc@1 71.020
 *   Acc@1 69.608
 *   Acc@1 70.938
 *   Acc@1 70.343
 *   Acc@1 71.129
 *   Acc@1 70.343
 *   Acc@1 71.074
 *   Acc@1 70.098
 *   Acc@1 71.020
 *   Acc@1 70.098
 *   Acc@1 70.938
 *   Acc@1 69.853
 *   Acc@1 71.047
 *   Acc@1 70.343
 *   Acc@1 71.129
 *   Acc@1 70.098
 *   Acc@1 71.020
 *   Acc@1 70.098
 *   Acc@1 71.347
 *   Acc@1 70.343
 *   Acc@1 70.611
 *   Acc@1 70.588
 *   Acc@1 70.583
 *   Acc@1 70.833
 *   Acc@1 70.556
 *   Acc@1 70.833
 *   Acc@1 70.447
Training for 300 epoch: 70.09803921568627
Training for 600 epoch: 70.22058823529412
Training for 1000 epoch: 70.1593137254902
Training for 3000 epoch: 70.1593137254902
Training for 300 epoch: 70.93102508178845
Training for 600 epoch: 70.95147219193021
Training for 1000 epoch: 70.90376226826609
Training for 3000 epoch: 70.91739367502727
[[70.09803921568627, 70.22058823529412, 70.1593137254902, 70.1593137254902], [70.93102508178845, 70.95147219193021, 70.90376226826609, 70.91739367502727]]
train loss 0.8906721517589906, epoch 14, best loss 0.6354225728348011, best_epoch 9
GPU_0_using curriculum 20 with window 20
The current update step is 304
GPU_0_using curriculum 20 with window 20
The current update step is 323
GPU_0_using curriculum 20 with window 20
The current update step is 342
GPU_0_using curriculum 20 with window 20
The current update step is 361
GPU_0_using curriculum 20 with window 20
The current update step is 380
The current seed is 17452852734523453368
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.363
 *   Acc@1 72.301
 *   Acc@1 69.363
 *   Acc@1 72.301
 *   Acc@1 69.363
 *   Acc@1 72.301
 *   Acc@1 69.608
 *   Acc@1 72.165
 *   Acc@1 70.588
 *   Acc@1 71.783
 *   Acc@1 70.343
 *   Acc@1 71.810
 *   Acc@1 70.343
 *   Acc@1 71.838
 *   Acc@1 69.853
 *   Acc@1 71.919
 *   Acc@1 70.098
 *   Acc@1 71.456
 *   Acc@1 69.853
 *   Acc@1 71.456
 *   Acc@1 70.098
 *   Acc@1 71.292
 *   Acc@1 70.343
 *   Acc@1 71.210
 *   Acc@1 70.343
 *   Acc@1 71.647
 *   Acc@1 70.343
 *   Acc@1 71.756
 *   Acc@1 70.343
 *   Acc@1 71.783
 *   Acc@1 70.343
 *   Acc@1 71.701
Training for 300 epoch: 70.09803921568627
Training for 600 epoch: 69.97549019607843
Training for 1000 epoch: 70.03676470588235
Training for 3000 epoch: 70.03676470588235
Training for 300 epoch: 71.79661941112323
Training for 600 epoch: 71.83069792802618
Training for 1000 epoch: 71.80343511450381
Training for 3000 epoch: 71.74890948745912
[[70.09803921568627, 69.97549019607843, 70.03676470588235, 70.03676470588235], [71.79661941112323, 71.83069792802618, 71.80343511450381, 71.74890948745912]]
train loss 0.7380477102918219, epoch 19, best loss 0.6354225728348011, best_epoch 9
GPU_0_using curriculum 20 with window 20
The current update step is 399
GPU_0_using curriculum 20 with window 20
The current update step is 418
GPU_0_using curriculum 20 with window 20
The current update step is 437
GPU_0_using curriculum 20 with window 20
The current update step is 456
GPU_0_using curriculum 20 with window 20
The current update step is 475
The current seed is 17283816814682857501
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.853
 *   Acc@1 71.865
 *   Acc@1 70.098
 *   Acc@1 71.892
 *   Acc@1 70.098
 *   Acc@1 71.865
 *   Acc@1 70.833
 *   Acc@1 71.865
 *   Acc@1 69.363
 *   Acc@1 72.219
 *   Acc@1 69.853
 *   Acc@1 72.083
 *   Acc@1 69.853
 *   Acc@1 72.056
 *   Acc@1 70.098
 *   Acc@1 72.083
 *   Acc@1 70.343
 *   Acc@1 72.083
 *   Acc@1 70.588
 *   Acc@1 72.083
 *   Acc@1 70.588
 *   Acc@1 72.056
 *   Acc@1 70.588
 *   Acc@1 72.110
 *   Acc@1 69.363
 *   Acc@1 72.356
 *   Acc@1 69.363
 *   Acc@1 72.383
 *   Acc@1 69.118
 *   Acc@1 72.410
 *   Acc@1 69.118
 *   Acc@1 72.546
Training for 300 epoch: 69.73039215686275
Training for 600 epoch: 69.97549019607843
Training for 1000 epoch: 69.9142156862745
Training for 3000 epoch: 70.1593137254902
Training for 300 epoch: 72.1305888767721
Training for 600 epoch: 72.11014176663032
Training for 1000 epoch: 72.09651035986914
Training for 3000 epoch: 72.15103598691385
[[69.73039215686275, 69.97549019607843, 69.9142156862745, 70.1593137254902], [72.1305888767721, 72.11014176663032, 72.09651035986914, 72.15103598691385]]
train loss 0.5498638139426253, epoch 24, best loss 0.5498638139426253, best_epoch 24
GPU_0_using curriculum 20 with window 20
The current update step is 494
GPU_0_using curriculum 20 with window 20
The current update step is 513
GPU_0_using curriculum 20 with window 20
The current update step is 532
GPU_0_using curriculum 20 with window 20
The current update step is 551
GPU_0_using curriculum 20 with window 20
The current update step is 570
The current seed is 8784302401318680484
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.853
 *   Acc@1 72.574
 *   Acc@1 69.608
 *   Acc@1 72.519
 *   Acc@1 69.608
 *   Acc@1 72.465
 *   Acc@1 70.343
 *   Acc@1 72.928
 *   Acc@1 70.098
 *   Acc@1 72.356
 *   Acc@1 70.098
 *   Acc@1 72.328
 *   Acc@1 70.098
 *   Acc@1 72.356
 *   Acc@1 69.853
 *   Acc@1 72.356
 *   Acc@1 69.608
 *   Acc@1 72.465
 *   Acc@1 69.118
 *   Acc@1 72.356
 *   Acc@1 68.627
 *   Acc@1 72.274
 *   Acc@1 69.118
 *   Acc@1 72.274
 *   Acc@1 69.853
 *   Acc@1 72.328
 *   Acc@1 70.098
 *   Acc@1 72.356
 *   Acc@1 70.098
 *   Acc@1 72.383
 *   Acc@1 70.098
 *   Acc@1 72.328
Training for 300 epoch: 69.8529411764706
Training for 600 epoch: 69.73039215686273
Training for 1000 epoch: 69.60784313725489
Training for 3000 epoch: 69.85294117647058
Training for 300 epoch: 72.43047982551799
Training for 600 epoch: 72.38958560523447
Training for 1000 epoch: 72.3691384950927
Training for 3000 epoch: 72.47137404580153
[[69.8529411764706, 69.73039215686273, 69.60784313725489, 69.85294117647058], [72.43047982551799, 72.38958560523447, 72.3691384950927, 72.47137404580153]]
train loss 0.538841118144365, epoch 29, best loss 0.538841118144365, best_epoch 29
GPU_0_using curriculum 20 with window 20
The current update step is 589
GPU_0_using curriculum 20 with window 20
The current update step is 608
GPU_0_using curriculum 20 with window 20
The current update step is 627
GPU_0_using curriculum 20 with window 20
The current update step is 646
GPU_0_using curriculum 20 with window 20
The current update step is 665
The current seed is 6177930419798099917
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.324
 *   Acc@1 72.328
 *   Acc@1 71.078
 *   Acc@1 72.328
 *   Acc@1 71.324
 *   Acc@1 72.274
 *   Acc@1 71.814
 *   Acc@1 71.838
 *   Acc@1 71.078
 *   Acc@1 72.383
 *   Acc@1 72.059
 *   Acc@1 72.137
 *   Acc@1 72.059
 *   Acc@1 71.756
 *   Acc@1 71.814
 *   Acc@1 71.456
 *   Acc@1 70.588
 *   Acc@1 72.546
 *   Acc@1 71.324
 *   Acc@1 72.437
 *   Acc@1 71.078
 *   Acc@1 72.028
 *   Acc@1 72.059
 *   Acc@1 71.565
 *   Acc@1 69.853
 *   Acc@1 73.146
 *   Acc@1 69.608
 *   Acc@1 73.173
 *   Acc@1 69.853
 *   Acc@1 73.201
 *   Acc@1 69.853
 *   Acc@1 73.282
Training for 300 epoch: 70.7107843137255
Training for 600 epoch: 71.0171568627451
Training for 1000 epoch: 71.07843137254902
Training for 3000 epoch: 71.38480392156863
Training for 300 epoch: 72.60087241003272
Training for 600 epoch: 72.51908396946564
Training for 1000 epoch: 72.31461286804799
Training for 3000 epoch: 72.03516902944384
[[70.7107843137255, 71.0171568627451, 71.07843137254902, 71.38480392156863], [72.60087241003272, 72.51908396946564, 72.31461286804799, 72.03516902944384]]
train loss 0.4435350473730489, epoch 34, best loss 0.4435350473730489, best_epoch 34
GPU_0_using curriculum 20 with window 20
The current update step is 684
GPU_0_using curriculum 20 with window 20
The current update step is 703
GPU_0_using curriculum 20 with window 20
The current update step is 722
GPU_0_using curriculum 20 with window 20
The current update step is 741
GPU_0_using curriculum 20 with window 20
The current update step is 760
The current seed is 4027318701773690757
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.118
 *   Acc@1 73.092
 *   Acc@1 69.118
 *   Acc@1 73.010
 *   Acc@1 69.118
 *   Acc@1 73.064
 *   Acc@1 69.363
 *   Acc@1 73.037
 *   Acc@1 69.363
 *   Acc@1 73.037
 *   Acc@1 69.363
 *   Acc@1 73.282
 *   Acc@1 69.608
 *   Acc@1 73.173
 *   Acc@1 69.853
 *   Acc@1 72.983
 *   Acc@1 69.853
 *   Acc@1 72.983
 *   Acc@1 69.608
 *   Acc@1 72.901
 *   Acc@1 69.608
 *   Acc@1 72.874
 *   Acc@1 69.608
 *   Acc@1 72.737
 *   Acc@1 70.833
 *   Acc@1 73.092
 *   Acc@1 70.588
 *   Acc@1 72.928
 *   Acc@1 70.343
 *   Acc@1 73.037
 *   Acc@1 70.098
 *   Acc@1 72.764
Training for 300 epoch: 69.79166666666667
Training for 600 epoch: 69.66911764705884
Training for 1000 epoch: 69.66911764705884
Training for 3000 epoch: 69.73039215686273
Training for 300 epoch: 73.05070883315157
Training for 600 epoch: 73.03026172300982
Training for 1000 epoch: 73.0370774263904
Training for 3000 epoch: 72.88031624863686
[[69.79166666666667, 69.66911764705884, 69.66911764705884, 69.73039215686273], [73.05070883315157, 73.03026172300982, 73.0370774263904, 72.88031624863686]]
train loss 0.348561988564588, epoch 39, best loss 0.348561988564588, best_epoch 39
GPU_0_using curriculum 20 with window 20
The current update step is 779
GPU_0_using curriculum 20 with window 20
The current update step is 798
GPU_0_using curriculum 20 with window 20
The current update step is 817
GPU_0_using curriculum 20 with window 20
The current update step is 836
GPU_0_using curriculum 20 with window 20
The current update step is 855
The current seed is 7932845928846775860
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.098
 *   Acc@1 73.201
 *   Acc@1 69.363
 *   Acc@1 72.983
 *   Acc@1 69.608
 *   Acc@1 73.010
 *   Acc@1 69.608
 *   Acc@1 72.846
 *   Acc@1 70.588
 *   Acc@1 72.764
 *   Acc@1 70.588
 *   Acc@1 72.846
 *   Acc@1 70.343
 *   Acc@1 72.874
 *   Acc@1 70.343
 *   Acc@1 72.846
 *   Acc@1 69.608
 *   Acc@1 73.282
 *   Acc@1 69.853
 *   Acc@1 72.928
 *   Acc@1 69.118
 *   Acc@1 73.146
 *   Acc@1 68.873
 *   Acc@1 71.919
 *   Acc@1 70.098
 *   Acc@1 73.010
 *   Acc@1 69.853
 *   Acc@1 73.010
 *   Acc@1 69.853
 *   Acc@1 72.955
 *   Acc@1 69.853
 *   Acc@1 73.010
Training for 300 epoch: 70.09803921568627
Training for 600 epoch: 69.91421568627452
Training for 1000 epoch: 69.73039215686275
Training for 3000 epoch: 69.66911764705883
Training for 300 epoch: 73.06434023991275
Training for 600 epoch: 72.94165757906217
Training for 1000 epoch: 72.99618320610688
Training for 3000 epoch: 72.65539803707742
[[70.09803921568627, 69.91421568627452, 69.73039215686275, 69.66911764705883], [73.06434023991275, 72.94165757906217, 72.99618320610688, 72.65539803707742]]
train loss 0.5402837265018808, epoch 44, best loss 0.348561988564588, best_epoch 39
GPU_0_using curriculum 20 with window 20
The current update step is 874
GPU_0_using curriculum 20 with window 20
The current update step is 893
GPU_0_using curriculum 20 with window 20
The current update step is 912
GPU_0_using curriculum 20 with window 20
The current update step is 931
GPU_0_using curriculum 20 with window 20
The current update step is 950
The current seed is 7068654777809209232
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.098
 *   Acc@1 73.092
 *   Acc@1 70.098
 *   Acc@1 73.146
 *   Acc@1 70.098
 *   Acc@1 73.119
 *   Acc@1 70.098
 *   Acc@1 73.119
 *   Acc@1 70.098
 *   Acc@1 72.901
 *   Acc@1 69.608
 *   Acc@1 73.255
 *   Acc@1 69.118
 *   Acc@1 72.928
 *   Acc@1 69.363
 *   Acc@1 72.083
 *   Acc@1 70.588
 *   Acc@1 72.983
 *   Acc@1 70.833
 *   Acc@1 72.628
 *   Acc@1 71.569
 *   Acc@1 72.356
 *   Acc@1 72.304
 *   Acc@1 71.892
 *   Acc@1 69.608
 *   Acc@1 73.064
 *   Acc@1 69.608
 *   Acc@1 73.146
 *   Acc@1 69.363
 *   Acc@1 73.201
 *   Acc@1 69.363
 *   Acc@1 73.119
Training for 300 epoch: 70.09803921568627
Training for 600 epoch: 70.03676470588235
Training for 1000 epoch: 70.03676470588235
Training for 3000 epoch: 70.28186274509804
Training for 300 epoch: 73.00981461286804
Training for 600 epoch: 73.04389312977099
Training for 1000 epoch: 72.90076335877862
Training for 3000 epoch: 72.55316248636859
[[70.09803921568627, 70.03676470588235, 70.03676470588235, 70.28186274509804], [73.00981461286804, 73.04389312977099, 72.90076335877862, 72.55316248636859]]
train loss 0.4661780338705951, epoch 49, best loss 0.348561988564588, best_epoch 39
GPU_0_using curriculum 20 with window 20
The current update step is 969
GPU_0_using curriculum 20 with window 20
The current update step is 988
GPU_0_using curriculum 20 with window 20
The current update step is 1007
GPU_0_using curriculum 20 with window 20
The current update step is 1026
GPU_0_using curriculum 20 with window 20
The current update step is 1045
The current seed is 10209928736662065680
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.608
 *   Acc@1 73.310
 *   Acc@1 69.608
 *   Acc@1 73.391
 *   Acc@1 69.853
 *   Acc@1 73.337
 *   Acc@1 69.363
 *   Acc@1 73.391
 *   Acc@1 69.608
 *   Acc@1 73.228
 *   Acc@1 70.833
 *   Acc@1 73.173
 *   Acc@1 70.098
 *   Acc@1 73.119
 *   Acc@1 69.363
 *   Acc@1 73.282
 *   Acc@1 71.814
 *   Acc@1 72.683
 *   Acc@1 72.059
 *   Acc@1 72.628
 *   Acc@1 72.059
 *   Acc@1 72.628
 *   Acc@1 71.814
 *   Acc@1 72.437
 *   Acc@1 69.363
 *   Acc@1 73.255
 *   Acc@1 69.363
 *   Acc@1 73.173
 *   Acc@1 69.853
 *   Acc@1 72.955
 *   Acc@1 69.608
 *   Acc@1 72.983
Training for 300 epoch: 70.09803921568627
Training for 600 epoch: 70.4656862745098
Training for 1000 epoch: 70.4656862745098
Training for 3000 epoch: 70.03676470588235
Training for 300 epoch: 73.11886586695746
Training for 600 epoch: 73.09160305343511
Training for 1000 epoch: 73.00981461286804
Training for 3000 epoch: 73.02344601962922
[[70.09803921568627, 70.4656862745098, 70.4656862745098, 70.03676470588235], [73.11886586695746, 73.09160305343511, 73.00981461286804, 73.02344601962922]]
train loss 0.3668012445469589, epoch 54, best loss 0.348561988564588, best_epoch 39
GPU_0_using curriculum 20 with window 20
The current update step is 1064
GPU_0_using curriculum 20 with window 20
The current update step is 1083
GPU_0_using curriculum 20 with window 20
The current update step is 1102
GPU_0_using curriculum 20 with window 20
The current update step is 1121
GPU_0_using curriculum 20 with window 20
The current update step is 1140
The current seed is 13387528451248387941
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.608
 *   Acc@1 73.255
 *   Acc@1 70.098
 *   Acc@1 73.255
 *   Acc@1 70.343
 *   Acc@1 73.228
 *   Acc@1 69.608
 *   Acc@1 73.201
 *   Acc@1 69.608
 *   Acc@1 73.037
 *   Acc@1 70.098
 *   Acc@1 73.310
 *   Acc@1 70.098
 *   Acc@1 73.310
 *   Acc@1 69.853
 *   Acc@1 73.092
 *   Acc@1 69.118
 *   Acc@1 73.119
 *   Acc@1 69.118
 *   Acc@1 73.201
 *   Acc@1 69.363
 *   Acc@1 73.173
 *   Acc@1 69.363
 *   Acc@1 73.146
 *   Acc@1 68.627
 *   Acc@1 73.337
 *   Acc@1 69.608
 *   Acc@1 73.173
 *   Acc@1 69.608
 *   Acc@1 73.119
 *   Acc@1 70.098
 *   Acc@1 73.364
Training for 300 epoch: 69.24019607843138
Training for 600 epoch: 69.73039215686275
Training for 1000 epoch: 69.8529411764706
Training for 3000 epoch: 69.73039215686273
Training for 300 epoch: 73.18702290076335
Training for 600 epoch: 73.23473282442748
Training for 1000 epoch: 73.20747001090513
Training for 3000 epoch: 73.20065430752453
[[69.24019607843138, 69.73039215686275, 69.8529411764706, 69.73039215686273], [73.18702290076335, 73.23473282442748, 73.20747001090513, 73.20065430752453]]
train loss 0.4222626529447125, epoch 59, best loss 0.348561988564588, best_epoch 39
GPU_0_using curriculum 20 with window 20
The current update step is 1159
GPU_0_using curriculum 20 with window 20
The current update step is 1178
GPU_0_using curriculum 20 with window 20
The current update step is 1197
GPU_0_using curriculum 20 with window 20
The current update step is 1216
GPU_0_using curriculum 20 with window 20
The current update step is 1235
The current seed is 7494508785112603723
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.853
 *   Acc@1 73.173
 *   Acc@1 69.853
 *   Acc@1 73.146
 *   Acc@1 69.853
 *   Acc@1 73.228
 *   Acc@1 70.098
 *   Acc@1 73.255
 *   Acc@1 71.569
 *   Acc@1 72.683
 *   Acc@1 71.569
 *   Acc@1 72.846
 *   Acc@1 70.098
 *   Acc@1 73.173
 *   Acc@1 69.608
 *   Acc@1 73.364
 *   Acc@1 70.588
 *   Acc@1 73.419
 *   Acc@1 70.588
 *   Acc@1 73.446
 *   Acc@1 70.343
 *   Acc@1 73.201
 *   Acc@1 71.078
 *   Acc@1 72.846
 *   Acc@1 69.608
 *   Acc@1 73.337
 *   Acc@1 69.608
 *   Acc@1 73.364
 *   Acc@1 69.853
 *   Acc@1 73.310
 *   Acc@1 70.098
 *   Acc@1 73.146
Training for 300 epoch: 70.40441176470588
Training for 600 epoch: 70.40441176470588
Training for 1000 epoch: 70.03676470588235
Training for 3000 epoch: 70.22058823529412
Training for 300 epoch: 73.15294438386042
Training for 600 epoch: 73.20065430752453
Training for 1000 epoch: 73.22791712104689
Training for 3000 epoch: 73.15294438386042
[[70.40441176470588, 70.40441176470588, 70.03676470588235, 70.22058823529412], [73.15294438386042, 73.20065430752453, 73.22791712104689, 73.15294438386042]]
train loss 0.40731836353289524, epoch 64, best loss 0.348561988564588, best_epoch 39
GPU_0_using curriculum 20 with window 20
The current update step is 1254
GPU_0_using curriculum 20 with window 20
The current update step is 1273
GPU_0_using curriculum 20 with window 20
The current update step is 1292
GPU_0_using curriculum 20 with window 20
The current update step is 1311
GPU_0_using curriculum 20 with window 20
The current update step is 1330
The current seed is 17928624225385738524
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.078
 *   Acc@1 72.710
 *   Acc@1 70.833
 *   Acc@1 72.955
 *   Acc@1 70.588
 *   Acc@1 73.255
 *   Acc@1 70.343
 *   Acc@1 73.391
 *   Acc@1 70.588
 *   Acc@1 73.010
 *   Acc@1 69.363
 *   Acc@1 73.119
 *   Acc@1 69.118
 *   Acc@1 72.601
 *   Acc@1 68.627
 *   Acc@1 72.028
 *   Acc@1 70.098
 *   Acc@1 73.337
 *   Acc@1 70.098
 *   Acc@1 73.310
 *   Acc@1 69.853
 *   Acc@1 73.282
 *   Acc@1 70.343
 *   Acc@1 73.337
 *   Acc@1 69.608
 *   Acc@1 73.419
 *   Acc@1 69.608
 *   Acc@1 73.228
 *   Acc@1 69.608
 *   Acc@1 73.201
 *   Acc@1 70.343
 *   Acc@1 73.337
Training for 300 epoch: 70.34313725490196
Training for 600 epoch: 69.97549019607843
Training for 1000 epoch: 69.79166666666667
Training for 3000 epoch: 69.9142156862745
Training for 300 epoch: 73.11886586695746
Training for 600 epoch: 73.15294438386042
Training for 1000 epoch: 73.08478735005451
Training for 3000 epoch: 73.02344601962922
[[70.34313725490196, 69.97549019607843, 69.79166666666667, 69.9142156862745], [73.11886586695746, 73.15294438386042, 73.08478735005451, 73.02344601962922]]
train loss 0.37019465166583837, epoch 69, best loss 0.348561988564588, best_epoch 39
GPU_0_using curriculum 20 with window 20
The current update step is 1349
GPU_0_using curriculum 20 with window 20
The current update step is 1368
GPU_0_using curriculum 20 with window 20
The current update step is 1387
GPU_0_using curriculum 20 with window 20
The current update step is 1406
GPU_0_using curriculum 20 with window 20
The current update step is 1425
The current seed is 6439900122620948789
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.343
 *   Acc@1 73.146
 *   Acc@1 69.853
 *   Acc@1 73.228
 *   Acc@1 69.363
 *   Acc@1 73.146
 *   Acc@1 69.118
 *   Acc@1 73.092
 *   Acc@1 70.343
 *   Acc@1 72.983
 *   Acc@1 70.098
 *   Acc@1 73.037
 *   Acc@1 70.343
 *   Acc@1 73.146
 *   Acc@1 70.588
 *   Acc@1 72.955
 *   Acc@1 69.608
 *   Acc@1 73.664
 *   Acc@1 69.608
 *   Acc@1 73.691
 *   Acc@1 69.608
 *   Acc@1 73.746
 *   Acc@1 69.608
 *   Acc@1 73.637
 *   Acc@1 70.343
 *   Acc@1 73.501
 *   Acc@1 70.588
 *   Acc@1 73.310
 *   Acc@1 71.078
 *   Acc@1 72.846
 *   Acc@1 72.059
 *   Acc@1 72.792
Training for 300 epoch: 70.1593137254902
Training for 600 epoch: 70.03676470588235
Training for 1000 epoch: 70.09803921568627
Training for 3000 epoch: 70.34313725490196
Training for 300 epoch: 73.32333696837513
Training for 600 epoch: 73.31652126499455
Training for 1000 epoch: 73.2211014176663
Training for 3000 epoch: 73.11886586695746
[[70.1593137254902, 70.03676470588235, 70.09803921568627, 70.34313725490196], [73.32333696837513, 73.31652126499455, 73.2211014176663, 73.11886586695746]]
train loss 0.4511102996969691, epoch 74, best loss 0.348561988564588, best_epoch 39
GPU_0_using curriculum 20 with window 20
The current update step is 1444
GPU_0_using curriculum 20 with window 20
The current update step is 1463
GPU_0_using curriculum 20 with window 20
The current update step is 1482
GPU_0_using curriculum 20 with window 20
The current update step is 1501
GPU_0_using curriculum 20 with window 20
The current update step is 1520
The current seed is 480937430078073806
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.343
 *   Acc@1 73.828
 *   Acc@1 69.853
 *   Acc@1 73.364
 *   Acc@1 70.588
 *   Acc@1 73.582
 *   Acc@1 71.078
 *   Acc@1 73.092
 *   Acc@1 69.608
 *   Acc@1 73.419
 *   Acc@1 70.343
 *   Acc@1 73.473
 *   Acc@1 69.853
 *   Acc@1 73.446
 *   Acc@1 70.098
 *   Acc@1 73.419
 *   Acc@1 70.098
 *   Acc@1 73.719
 *   Acc@1 70.098
 *   Acc@1 73.828
 *   Acc@1 70.098
 *   Acc@1 73.773
 *   Acc@1 70.098
 *   Acc@1 73.691
 *   Acc@1 69.853
 *   Acc@1 73.037
 *   Acc@1 68.873
 *   Acc@1 72.655
 *   Acc@1 68.137
 *   Acc@1 72.546
 *   Acc@1 65.686
 *   Acc@1 70.774
Training for 300 epoch: 69.97549019607843
Training for 600 epoch: 69.79166666666666
Training for 1000 epoch: 69.66911764705883
Training for 3000 epoch: 69.24019607843138
Training for 300 epoch: 73.50054525627044
Training for 600 epoch: 73.33015267175573
Training for 1000 epoch: 73.33696837513631
Training for 3000 epoch: 72.74400218102508
[[69.97549019607843, 69.79166666666666, 69.66911764705883, 69.24019607843138], [73.50054525627044, 73.33015267175573, 73.33696837513631, 72.74400218102508]]
train loss 0.2602085766901497, epoch 79, best loss 0.2602085766901497, best_epoch 79
GPU_0_using curriculum 20 with window 20
The current update step is 1539
GPU_0_using curriculum 20 with window 20
The current update step is 1558
GPU_0_using curriculum 20 with window 20
The current update step is 1577
GPU_0_using curriculum 20 with window 20
The current update step is 1596
GPU_0_using curriculum 20 with window 20
The current update step is 1615
The current seed is 2159581110403347322
The current lr is: 0.001
Testing Results:
 *   Acc@1 72.304
 *   Acc@1 73.064
 *   Acc@1 72.304
 *   Acc@1 72.874
 *   Acc@1 72.794
 *   Acc@1 72.710
 *   Acc@1 72.059
 *   Acc@1 72.410
 *   Acc@1 71.078
 *   Acc@1 73.337
 *   Acc@1 71.814
 *   Acc@1 72.874
 *   Acc@1 72.059
 *   Acc@1 72.710
 *   Acc@1 72.059
 *   Acc@1 72.056
 *   Acc@1 71.078
 *   Acc@1 73.146
 *   Acc@1 71.569
 *   Acc@1 73.092
 *   Acc@1 72.549
 *   Acc@1 72.983
 *   Acc@1 72.794
 *   Acc@1 72.628
 *   Acc@1 70.343
 *   Acc@1 73.746
 *   Acc@1 70.098
 *   Acc@1 73.746
 *   Acc@1 70.098
 *   Acc@1 73.664
 *   Acc@1 70.343
 *   Acc@1 73.664
Training for 300 epoch: 71.20098039215685
Training for 600 epoch: 71.44607843137254
Training for 1000 epoch: 71.875
Training for 3000 epoch: 71.81372549019608
Training for 300 epoch: 73.32333696837513
Training for 600 epoch: 73.14612868047982
Training for 1000 epoch: 73.01663031624864
Training for 3000 epoch: 72.68947655398037
[[71.20098039215685, 71.44607843137254, 71.875, 71.81372549019608], [73.32333696837513, 73.14612868047982, 73.01663031624864, 72.68947655398037]]
train loss 0.321485161618812, epoch 84, best loss 0.2602085766901497, best_epoch 79
GPU_0_using curriculum 20 with window 20
The current update step is 1634
GPU_0_using curriculum 20 with window 20
The current update step is 1653
GPU_0_using curriculum 20 with window 20
The current update step is 1672
GPU_0_using curriculum 20 with window 20
The current update step is 1691
GPU_0_using curriculum 20 with window 20
The current update step is 1710
The current seed is 15230757971154856497
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.833
 *   Acc@1 73.582
 *   Acc@1 71.324
 *   Acc@1 73.201
 *   Acc@1 72.059
 *   Acc@1 72.955
 *   Acc@1 72.059
 *   Acc@1 72.165
 *   Acc@1 69.853
 *   Acc@1 73.719
 *   Acc@1 70.098
 *   Acc@1 73.719
 *   Acc@1 70.343
 *   Acc@1 73.773
 *   Acc@1 69.608
 *   Acc@1 73.800
 *   Acc@1 70.343
 *   Acc@1 73.746
 *   Acc@1 70.343
 *   Acc@1 73.746
 *   Acc@1 70.343
 *   Acc@1 73.800
 *   Acc@1 70.343
 *   Acc@1 73.691
 *   Acc@1 72.549
 *   Acc@1 72.955
 *   Acc@1 72.304
 *   Acc@1 72.874
 *   Acc@1 72.304
 *   Acc@1 72.737
 *   Acc@1 72.304
 *   Acc@1 72.628
Training for 300 epoch: 70.89460784313725
Training for 600 epoch: 71.0171568627451
Training for 1000 epoch: 71.26225490196079
Training for 3000 epoch: 71.07843137254902
Training for 300 epoch: 73.50054525627044
Training for 600 epoch: 73.38467829880044
Training for 1000 epoch: 73.31652126499455
Training for 3000 epoch: 73.07115594329335
[[70.89460784313725, 71.0171568627451, 71.26225490196079, 71.07843137254902], [73.50054525627044, 73.38467829880044, 73.31652126499455, 73.07115594329335]]
train loss 0.45382886026521807, epoch 89, best loss 0.2602085766901497, best_epoch 79
GPU_0_using curriculum 20 with window 20
The current update step is 1729
GPU_0_using curriculum 20 with window 20
The current update step is 1748
GPU_0_using curriculum 20 with window 20
The current update step is 1767
GPU_0_using curriculum 20 with window 20
The current update step is 1786
GPU_0_using curriculum 20 with window 20
The current update step is 1805
The current seed is 16330726185362410835
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.343
 *   Acc@1 73.228
 *   Acc@1 69.853
 *   Acc@1 73.282
 *   Acc@1 69.608
 *   Acc@1 73.337
 *   Acc@1 69.118
 *   Acc@1 73.173
 *   Acc@1 69.853
 *   Acc@1 73.555
 *   Acc@1 70.098
 *   Acc@1 73.582
 *   Acc@1 70.098
 *   Acc@1 73.473
 *   Acc@1 70.343
 *   Acc@1 73.364
 *   Acc@1 70.098
 *   Acc@1 72.955
 *   Acc@1 70.343
 *   Acc@1 72.983
 *   Acc@1 70.343
 *   Acc@1 73.010
 *   Acc@1 69.608
 *   Acc@1 73.092
 *   Acc@1 70.833
 *   Acc@1 73.473
 *   Acc@1 70.833
 *   Acc@1 73.582
 *   Acc@1 70.588
 *   Acc@1 73.637
 *   Acc@1 70.588
 *   Acc@1 73.664
Training for 300 epoch: 70.28186274509804
Training for 600 epoch: 70.28186274509804
Training for 1000 epoch: 70.1593137254902
Training for 3000 epoch: 69.9142156862745
Training for 300 epoch: 73.30288985823336
Training for 600 epoch: 73.35741548527807
Training for 1000 epoch: 73.36423118865866
Training for 3000 epoch: 73.32333696837513
[[70.28186274509804, 70.28186274509804, 70.1593137254902, 69.9142156862745], [73.30288985823336, 73.35741548527807, 73.36423118865866, 73.32333696837513]]
train loss 0.3381167220900337, epoch 94, best loss 0.2602085766901497, best_epoch 79
GPU_0_using curriculum 20 with window 20
The current update step is 1824
GPU_0_using curriculum 20 with window 20
The current update step is 1843
GPU_0_using curriculum 20 with window 20
The current update step is 1862
GPU_0_using curriculum 20 with window 20
The current update step is 1881
GPU_0_using curriculum 20 with window 20
The current update step is 1900
The current seed is 7728698213951347209
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.588
 *   Acc@1 73.828
 *   Acc@1 70.833
 *   Acc@1 73.773
 *   Acc@1 70.343
 *   Acc@1 73.800
 *   Acc@1 72.059
 *   Acc@1 73.364
 *   Acc@1 70.343
 *   Acc@1 73.773
 *   Acc@1 70.343
 *   Acc@1 73.746
 *   Acc@1 70.343
 *   Acc@1 73.773
 *   Acc@1 70.588
 *   Acc@1 73.800
 *   Acc@1 70.098
 *   Acc@1 73.719
 *   Acc@1 70.343
 *   Acc@1 73.446
 *   Acc@1 70.343
 *   Acc@1 73.746
 *   Acc@1 70.098
 *   Acc@1 73.719
 *   Acc@1 70.098
 *   Acc@1 73.610
 *   Acc@1 70.098
 *   Acc@1 73.473
 *   Acc@1 69.853
 *   Acc@1 73.501
 *   Acc@1 70.833
 *   Acc@1 73.092
Training for 300 epoch: 70.28186274509804
Training for 600 epoch: 70.40441176470588
Training for 1000 epoch: 70.22058823529412
Training for 3000 epoch: 70.89460784313725
Training for 300 epoch: 73.73227917121046
Training for 600 epoch: 73.60959651035986
Training for 1000 epoch: 73.70501635768811
Training for 3000 epoch: 73.49372955288985
[[70.28186274509804, 70.40441176470588, 70.22058823529412, 70.89460784313725], [73.73227917121046, 73.60959651035986, 73.70501635768811, 73.49372955288985]]
train loss 0.28983424475564823, epoch 99, best loss 0.2602085766901497, best_epoch 79
=== Final results:
{'acc': 71.875, 'test': [71.20098039215685, 71.44607843137254, 71.875, 71.81372549019608], 'train': [71.20098039215685, 71.44607843137254, 71.875, 71.81372549019608], 'ind': 2, 'epoch': 85, 'data': array([[-0.03241424, -0.10253858, -0.1272321 , ...,  0.05575713,
         0.04783189,  0.01858114],
       [ 0.04418611,  0.09421633, -0.00847758, ..., -0.06301079,
        -0.09269539, -0.07628612]], shape=(2, 768), dtype=float32)}
Training exit code: 0
Found checkpoint: grad_save_init_IPC_1_no_curr_unroll_20mrpc_mlp_ipc1_w20_seed0.pth
Using device: cuda
Loading validation data from ./scripts/mrpc_emb...
Val set shape: x=(408, 768), y=(408,)
Loading synthetic data from grad_save_init_IPC_1_no_curr_unroll_20mrpc_mlp_ipc1_w20_seed0.pth...
Synthetic set shape: X=(2, 768), y=(2,)
Training fresh TextMLP on synthetic set and evaluating on real MRPC val...
[Epoch 200/1000] train_loss=0.0010 val_acc=69.12%
[Epoch 400/1000] train_loss=0.0003 val_acc=69.85%
[Epoch 600/1000] train_loss=0.0001 val_acc=70.34%
[Epoch 800/1000] train_loss=0.0001 val_acc=70.34%
[Epoch 1000/1000] train_loss=0.0001 val_acc=70.10%

=== FINAL DISTILLED-SET ACCURACY ON MRPC VAL: 70.10% ===
Eval exit code: 0
