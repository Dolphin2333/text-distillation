Torch Seed Specified with rank: 0
Dataset: agnews_emb
Dataset Path: ./scripts
Namespace(seed=0, mp_distributed=False, world_size=1, rank=0, dist_url='tcp://224.66.41.62:23456', dist_backend='nccl', workers=0, gpu=None, root='./scripts', dataset='agnews_emb', arch='text_transformer', width=256, lr=0.001, inner_optim='Adam', outer_optim='Adam', inner_lr=0.001, label_lr_scale=1, num_per_class=10, batch_per_class=8, task_sampler_nc=4, window=20, minwindow=0, totwindow=40, num_train_eval=2, train_y=False, batch_size=2048, eps=1e-08, wd=0, test_freq=5, print_freq=20, start_epoch=0, epochs=200, ddtype='standard', cctype=0, zca=False, wandb=False, clip_coef=0.9, fname='out_tf_ratbptt_ipc10_s2_w20t40_ep200', out_dir='./checkpoints', name='agnews_tf_ratbptt_s2_w20t40_ep200', comp_aug=False, comp_aug_real=False, syn_strategy='none', real_strategy='none', ckptname='none', limit_train=False, load_ckpt=False, complete_random=False, boost_dd=False, boost_init_from='none', boost_beta=1.0, stage=2, distributed=False, data_root='./scripts/agnews_emb')
==> Preparing data..
None None
Dataset: number of classes: 4
Training set size: 120000
Image size: channel 1, height 768, width 1
Synthetic images, not_single False, keys []
==> Building model..
Initialized data with size, x: torch.Size([40, 768]), y:torch.Size([40])
TextTransformer(
  (input_proj): Linear(in_features=192, out_features=256, bias=True)
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=1024, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=1024, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (cls_head): Linear(in_features=256, out_features=4, bias=True)
)
use data parallel only
GPU_0_using curriculum 20 with window 20
Epoch: [0][20/59]	Time  1.604 ( 1.683)	Data  0.024 ( 0.029)	InnerLoop  0.670 ( 0.733)	Loss 3.0048e+00 (3.7561e+00)	Acc@1  38.72 ( 33.27)
Epoch: [0][40/59]	Time  1.598 ( 1.650)	Data  0.025 ( 0.029)	InnerLoop  0.673 ( 0.709)	Loss 1.7469e+00 (2.8238e+00)	Acc@1  46.48 ( 38.01)
The current update step is 59
GPU_0_using curriculum 20 with window 20
Epoch: [1][20/59]	Time  1.592 ( 1.598)	Data  0.021 ( 0.028)	InnerLoop  0.670 ( 0.678)	Loss 1.3732e+00 (1.4665e+00)	Acc@1  52.34 ( 48.59)
Epoch: [1][40/59]	Time  1.598 ( 1.602)	Data  0.022 ( 0.027)	InnerLoop  0.673 ( 0.680)	Loss 1.4387e+00 (1.4338e+00)	Acc@1  48.05 ( 48.78)
The current update step is 118
GPU_0_using curriculum 20 with window 20
Epoch: [2][20/59]	Time  1.588 ( 1.601)	Data  0.020 ( 0.020)	InnerLoop  0.667 ( 0.686)	Loss 8.9722e-01 (1.0603e+00)	Acc@1  65.72 ( 58.53)
Epoch: [2][40/59]	Time  1.616 ( 1.610)	Data  0.023 ( 0.024)	InnerLoop  0.679 ( 0.687)	Loss 1.0393e+00 (1.0784e+00)	Acc@1  50.98 ( 58.04)
The current update step is 177
GPU_0_using curriculum 20 with window 20
Epoch: [3][20/59]	Time  1.680 ( 1.589)	Data  0.022 ( 0.033)	InnerLoop  0.772 ( 0.671)	Loss 8.5226e-01 (9.1438e-01)	Acc@1  68.51 ( 64.21)
Epoch: [3][40/59]	Time  1.570 ( 1.591)	Data  0.019 ( 0.030)	InnerLoop  0.664 ( 0.673)	Loss 8.8369e-01 (9.0017e-01)	Acc@1  67.38 ( 65.56)
The current update step is 236
GPU_0_using curriculum 20 with window 20
Epoch: [4][20/59]	Time  1.682 ( 1.591)	Data  0.143 ( 0.033)	InnerLoop  0.658 ( 0.672)	Loss 7.5953e-01 (9.3750e-01)	Acc@1  72.41 ( 65.74)
Epoch: [4][40/59]	Time  1.573 ( 1.588)	Data  0.019 ( 0.027)	InnerLoop  0.663 ( 0.675)	Loss 8.8339e-01 (8.9557e-01)	Acc@1  66.50 ( 67.01)
The current update step is 295
The current seed is 14826795661483761642
The current lr is: 0.001
Testing Results:
 *   Acc@1 62.316
 *   Acc@1 62.682
 *   Acc@1 61.750
 *   Acc@1 61.703
 *   Acc@1 62.513
 *   Acc@1 62.489
 *   Acc@1 64.118
 *   Acc@1 64.159
 *   Acc@1 65.197
 *   Acc@1 65.210
 *   Acc@1 64.592
 *   Acc@1 64.744
Training for 300 epoch: 63.21710526315789
Training for 600 epoch: 63.473684210526315
Training for 1000 epoch: 63.55263157894737
Training for 300 epoch: 63.42041666666667
Training for 600 epoch: 63.45625
Training for 1000 epoch: 63.616666666666674
[[63.21710526315789, 63.473684210526315, 63.55263157894737], [63.42041666666667, 63.45625, 63.616666666666674]]
train loss 0.8006332093556722, epoch 4, best loss 0.8006332093556722, best_epoch 4
GPU_0_using curriculum 20 with window 20
Epoch: [5][20/59]	Time  1.572 ( 1.592)	Data  0.025 ( 0.027)	InnerLoop  0.669 ( 0.679)	Loss 7.6159e-01 (1.0935e+00)	Acc@1  71.83 ( 62.63)
Epoch: [5][40/59]	Time  1.596 ( 1.595)	Data  0.022 ( 0.024)	InnerLoop  0.669 ( 0.681)	Loss 7.2069e-01 (1.0484e+00)	Acc@1  72.75 ( 63.87)
The current update step is 354
GPU_0_using curriculum 20 with window 20
Epoch: [6][20/59]	Time  1.620 ( 1.599)	Data  0.025 ( 0.022)	InnerLoop  0.689 ( 0.685)	Loss 9.3674e-01 (8.7201e-01)	Acc@1  65.28 ( 67.66)
Epoch: [6][40/59]	Time  1.596 ( 1.619)	Data  0.023 ( 0.029)	InnerLoop  0.676 ( 0.690)	Loss 8.7223e-01 (8.6723e-01)	Acc@1  69.34 ( 68.14)
The current update step is 413
GPU_0_using curriculum 20 with window 20
Epoch: [7][20/59]	Time  1.614 ( 1.630)	Data  0.025 ( 0.037)	InnerLoop  0.683 ( 0.688)	Loss 6.5523e-01 (8.2129e-01)	Acc@1  74.32 ( 70.43)
Epoch: [7][40/59]	Time  1.582 ( 1.629)	Data  0.022 ( 0.033)	InnerLoop  0.666 ( 0.693)	Loss 6.4316e-01 (7.9900e-01)	Acc@1  76.76 ( 71.59)
The current update step is 472
GPU_0_using curriculum 20 with window 20
Epoch: [8][20/59]	Time  1.563 ( 1.574)	Data  0.024 ( 0.035)	InnerLoop  0.660 ( 0.662)	Loss 7.1778e-01 (8.3147e-01)	Acc@1  71.53 ( 71.13)
Epoch: [8][40/59]	Time  1.546 ( 1.595)	Data  0.022 ( 0.029)	InnerLoop  0.651 ( 0.683)	Loss 6.6875e-01 (8.1428e-01)	Acc@1  76.17 ( 71.67)
The current update step is 531
GPU_0_using curriculum 20 with window 20
Epoch: [9][20/59]	Time  1.521 ( 1.543)	Data  0.019 ( 0.032)	InnerLoop  0.648 ( 0.652)	Loss 7.7738e-01 (7.4881e-01)	Acc@1  69.82 ( 72.45)
Epoch: [9][40/59]	Time  1.645 ( 1.546)	Data  0.022 ( 0.027)	InnerLoop  0.773 ( 0.662)	Loss 7.0404e-01 (7.7018e-01)	Acc@1  75.24 ( 71.91)
The current update step is 590
The current seed is 3082768395583422061
The current lr is: 0.001
Testing Results:
 *   Acc@1 57.513
 *   Acc@1 57.391
 *   Acc@1 57.789
 *   Acc@1 58.463
 *   Acc@1 56.934
 *   Acc@1 56.713
 *   Acc@1 73.776
 *   Acc@1 74.166
 *   Acc@1 73.171
 *   Acc@1 73.149
 *   Acc@1 73.066
 *   Acc@1 72.912
Training for 300 epoch: 65.64473684210526
Training for 600 epoch: 65.48026315789474
Training for 1000 epoch: 65.0
Training for 300 epoch: 65.77833333333334
Training for 600 epoch: 65.80625
Training for 1000 epoch: 64.8125
[[65.64473684210526, 65.48026315789474, 65.0], [65.77833333333334, 65.80625, 64.8125]]
train loss 0.5052383096377054, epoch 9, best loss 0.5052383096377054, best_epoch 9
GPU_0_using curriculum 20 with window 20
Epoch: [10][20/59]	Time  1.613 ( 1.544)	Data  0.018 ( 0.027)	InnerLoop  0.757 ( 0.670)	Loss 8.4884e-01 (7.3400e-01)	Acc@1  67.68 ( 74.06)
Epoch: [10][40/59]	Time  1.495 ( 1.527)	Data  0.020 ( 0.023)	InnerLoop  0.634 ( 0.660)	Loss 9.0357e-01 (7.3318e-01)	Acc@1  66.06 ( 73.95)
The current update step is 649
GPU_0_using curriculum 20 with window 20
Epoch: [11][20/59]	Time  1.510 ( 1.518)	Data  0.019 ( 0.033)	InnerLoop  0.653 ( 0.646)	Loss 6.0795e-01 (6.6750e-01)	Acc@1  78.71 ( 76.35)
Epoch: [11][40/59]	Time  1.602 ( 1.517)	Data  0.020 ( 0.029)	InnerLoop  0.748 ( 0.649)	Loss 6.4942e-01 (7.3645e-01)	Acc@1  75.24 ( 74.69)
The current update step is 708
GPU_0_using curriculum 20 with window 20
Epoch: [12][20/59]	Time  1.493 ( 1.504)	Data  0.021 ( 0.026)	InnerLoop  0.633 ( 0.645)	Loss 1.1738e+00 (8.8697e-01)	Acc@1  62.06 ( 69.42)
Epoch: [12][40/59]	Time  1.485 ( 1.508)	Data  0.019 ( 0.026)	InnerLoop  0.632 ( 0.647)	Loss 8.6447e-01 (8.5774e-01)	Acc@1  68.36 ( 70.08)
The current update step is 767
GPU_0_using curriculum 20 with window 20
Epoch: [13][20/59]	Time  1.493 ( 1.507)	Data  0.018 ( 0.032)	InnerLoop  0.637 ( 0.640)	Loss 7.7340e-01 (7.4429e-01)	Acc@1  69.73 ( 73.27)
Epoch: [13][40/59]	Time  1.492 ( 1.509)	Data  0.017 ( 0.029)	InnerLoop  0.637 ( 0.645)	Loss 7.6798e-01 (7.3315e-01)	Acc@1  70.36 ( 73.75)
The current update step is 826
GPU_0_using curriculum 20 with window 20
Epoch: [14][20/59]	Time  1.502 ( 1.548)	Data  0.021 ( 0.034)	InnerLoop  0.634 ( 0.660)	Loss 1.0954e+00 (8.5044e-01)	Acc@1  66.94 ( 70.54)
Epoch: [14][40/59]	Time  1.481 ( 1.529)	Data  0.021 ( 0.030)	InnerLoop  0.625 ( 0.653)	Loss 6.8761e-01 (7.7046e-01)	Acc@1  76.42 ( 72.91)
The current update step is 885
The current seed is 9188926701626041167
The current lr is: 0.001
Testing Results:
 *   Acc@1 67.013
 *   Acc@1 67.931
 *   Acc@1 64.342
 *   Acc@1 65.035
 *   Acc@1 62.724
 *   Acc@1 63.409
 *   Acc@1 60.053
 *   Acc@1 60.320
 *   Acc@1 56.750
 *   Acc@1 56.638
 *   Acc@1 54.632
 *   Acc@1 55.070
Training for 300 epoch: 63.5328947368421
Training for 600 epoch: 60.546052631578945
Training for 1000 epoch: 58.67763157894737
Training for 300 epoch: 64.12541666666667
Training for 600 epoch: 60.83625
Training for 1000 epoch: 59.23958333333333
[[63.5328947368421, 60.546052631578945, 58.67763157894737], [64.12541666666667, 60.83625, 59.23958333333333]]
train loss 0.7445761014620463, epoch 14, best loss 0.5052383096377054, best_epoch 9
GPU_0_using curriculum 20 with window 20
Epoch: [15][20/59]	Time  1.510 ( 1.501)	Data  0.021 ( 0.019)	InnerLoop  0.639 ( 0.648)	Loss 8.7471e-01 (7.0705e-01)	Acc@1  72.71 ( 74.93)
Epoch: [15][40/59]	Time  1.601 ( 1.505)	Data  0.140 ( 0.026)	InnerLoop  0.626 ( 0.643)	Loss 7.2922e-01 (7.6435e-01)	Acc@1  73.49 ( 73.18)
The current update step is 944
GPU_0_using curriculum 20 with window 20
Epoch: [16][20/59]	Time  1.501 ( 1.503)	Data  0.021 ( 0.032)	InnerLoop  0.636 ( 0.637)	Loss 7.8656e-01 (7.8438e-01)	Acc@1  70.51 ( 71.75)
Epoch: [16][40/59]	Time  1.495 ( 1.508)	Data  0.018 ( 0.028)	InnerLoop  0.636 ( 0.642)	Loss 7.0229e-01 (7.2534e-01)	Acc@1  73.83 ( 73.71)
The current update step is 1003
GPU_0_using curriculum 20 with window 20
Epoch: [17][20/59]	Time  1.501 ( 1.509)	Data  0.021 ( 0.032)	InnerLoop  0.636 ( 0.637)	Loss 7.7695e-01 (7.0049e-01)	Acc@1  72.02 ( 73.76)
Epoch: [17][40/59]	Time  1.600 ( 1.510)	Data  0.021 ( 0.026)	InnerLoop  0.742 ( 0.645)	Loss 5.3260e-01 (7.1456e-01)	Acc@1  79.93 ( 74.16)
The current update step is 1062
GPU_0_using curriculum 20 with window 20
Epoch: [18][20/59]	Time  1.504 ( 1.502)	Data  0.020 ( 0.025)	InnerLoop  0.639 ( 0.641)	Loss 6.9566e-01 (6.9161e-01)	Acc@1  71.44 ( 74.72)
Epoch: [18][40/59]	Time  1.647 ( 1.514)	Data  0.021 ( 0.022)	InnerLoop  0.763 ( 0.652)	Loss 6.6190e-01 (7.2539e-01)	Acc@1  75.73 ( 73.93)
The current update step is 1121
GPU_0_using curriculum 20 with window 20
Epoch: [19][20/59]	Time  1.491 ( 1.511)	Data  0.017 ( 0.025)	InnerLoop  0.635 ( 0.643)	Loss 6.3995e-01 (7.8101e-01)	Acc@1  75.98 ( 71.34)
Epoch: [19][40/59]	Time  1.611 ( 1.511)	Data  0.019 ( 0.022)	InnerLoop  0.754 ( 0.649)	Loss 5.3395e-01 (7.3640e-01)	Acc@1  80.42 ( 73.19)
The current update step is 1180
The current seed is 12891728362568216395
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.132
 *   Acc@1 70.641
 *   Acc@1 70.447
 *   Acc@1 69.828
 *   Acc@1 70.974
 *   Acc@1 70.414
 *   Acc@1 72.829
 *   Acc@1 72.138
 *   Acc@1 69.013
 *   Acc@1 69.202
 *   Acc@1 68.553
 *   Acc@1 68.607
Training for 300 epoch: 71.98026315789474
Training for 600 epoch: 69.73026315789474
Training for 1000 epoch: 69.76315789473685
Training for 300 epoch: 71.38958333333333
Training for 600 epoch: 69.515
Training for 1000 epoch: 69.51041666666667
[[71.98026315789474, 69.73026315789474, 69.76315789473685], [71.38958333333333, 69.515, 69.51041666666667]]
train loss 0.5097480787277222, epoch 19, best loss 0.5052383096377054, best_epoch 9
GPU_0_using curriculum 20 with window 20
Epoch: [20][20/59]	Time  1.603 ( 1.508)	Data  0.020 ( 0.026)	InnerLoop  0.745 ( 0.648)	Loss 6.3055e-01 (6.9305e-01)	Acc@1  77.98 ( 74.48)
Epoch: [20][40/59]	Time  1.522 ( 1.515)	Data  0.022 ( 0.023)	InnerLoop  0.649 ( 0.652)	Loss 6.3344e-01 (6.9789e-01)	Acc@1  75.83 ( 74.74)
The current update step is 1239
GPU_0_using curriculum 20 with window 20
Epoch: [21][20/59]	Time  1.491 ( 1.505)	Data  0.018 ( 0.032)	InnerLoop  0.631 ( 0.637)	Loss 5.8465e-01 (7.4274e-01)	Acc@1  75.98 ( 71.99)
Epoch: [21][40/59]	Time  1.615 ( 1.509)	Data  0.020 ( 0.029)	InnerLoop  0.761 ( 0.643)	Loss 6.1162e-01 (7.2532e-01)	Acc@1  76.66 ( 73.03)
The current update step is 1298
GPU_0_using curriculum 20 with window 20
Epoch: [22][20/59]	Time  1.489 ( 1.512)	Data  0.020 ( 0.027)	InnerLoop  0.632 ( 0.644)	Loss 8.1303e-01 (7.1487e-01)	Acc@1  73.19 ( 73.89)
Epoch: [22][40/59]	Time  1.488 ( 1.512)	Data  0.020 ( 0.026)	InnerLoop  0.633 ( 0.646)	Loss 5.9598e-01 (6.7879e-01)	Acc@1  77.10 ( 75.04)
The current update step is 1357
GPU_0_using curriculum 20 with window 20
Epoch: [23][20/59]	Time  1.487 ( 1.539)	Data  0.020 ( 0.035)	InnerLoop  0.631 ( 0.653)	Loss 6.3853e-01 (6.9445e-01)	Acc@1  75.59 ( 74.12)
Epoch: [23][40/59]	Time  1.486 ( 1.525)	Data  0.017 ( 0.030)	InnerLoop  0.631 ( 0.649)	Loss 6.4351e-01 (6.8900e-01)	Acc@1  75.83 ( 74.51)
The current update step is 1416
GPU_0_using curriculum 20 with window 20
Epoch: [24][20/59]	Time  1.495 ( 1.504)	Data  0.021 ( 0.031)	InnerLoop  0.628 ( 0.635)	Loss 5.4423e-01 (6.4623e-01)	Acc@1  81.54 ( 76.85)
Epoch: [24][40/59]	Time  1.487 ( 1.507)	Data  0.019 ( 0.029)	InnerLoop  0.633 ( 0.639)	Loss 5.4489e-01 (6.8136e-01)	Acc@1  80.13 ( 75.79)
The current update step is 1475
The current seed is 5842613761569088366
The current lr is: 0.001
Testing Results:
 *   Acc@1 62.158
 *   Acc@1 62.046
 *   Acc@1 55.303
 *   Acc@1 55.141
 *   Acc@1 52.553
 *   Acc@1 52.749
 *   Acc@1 71.158
 *   Acc@1 71.409
 *   Acc@1 71.066
 *   Acc@1 70.656
 *   Acc@1 69.855
 *   Acc@1 69.862
Training for 300 epoch: 66.65789473684211
Training for 600 epoch: 63.18421052631579
Training for 1000 epoch: 61.203947368421055
Training for 300 epoch: 66.72749999999999
Training for 600 epoch: 62.89833333333333
Training for 1000 epoch: 61.30583333333333
[[66.65789473684211, 63.18421052631579, 61.203947368421055], [66.72749999999999, 62.89833333333333, 61.30583333333333]]
train loss 0.45709108980496727, epoch 24, best loss 0.45709108980496727, best_epoch 24
GPU_0_using curriculum 20 with window 20
Epoch: [25][20/59]	Time  1.481 ( 1.504)	Data  0.021 ( 0.019)	InnerLoop  0.624 ( 0.647)	Loss 7.4505e-01 (6.4827e-01)	Acc@1  72.22 ( 75.88)
Epoch: [25][40/59]	Time  1.620 ( 1.525)	Data  0.147 ( 0.026)	InnerLoop  0.630 ( 0.653)	Loss 5.8040e-01 (6.9654e-01)	Acc@1  78.03 ( 74.75)
The current update step is 1534
GPU_0_using curriculum 20 with window 20
Epoch: [26][20/59]	Time  1.486 ( 1.502)	Data  0.021 ( 0.032)	InnerLoop  0.627 ( 0.634)	Loss 6.1022e-01 (6.7827e-01)	Acc@1  78.86 ( 75.15)
Epoch: [26][40/59]	Time  1.499 ( 1.508)	Data  0.020 ( 0.029)	InnerLoop  0.636 ( 0.642)	Loss 6.1033e-01 (6.6197e-01)	Acc@1  78.08 ( 75.83)
The current update step is 1593
GPU_0_using curriculum 20 with window 20
Epoch: [27][20/59]	Time  1.493 ( 1.508)	Data  0.022 ( 0.031)	InnerLoop  0.633 ( 0.637)	Loss 6.6848e-01 (8.0026e-01)	Acc@1  77.29 ( 69.55)
Epoch: [27][40/59]	Time  1.604 ( 1.512)	Data  0.022 ( 0.025)	InnerLoop  0.741 ( 0.647)	Loss 5.6816e-01 (7.5054e-01)	Acc@1  80.22 ( 72.25)
The current update step is 1652
GPU_0_using curriculum 20 with window 20
Epoch: [28][20/59]	Time  1.489 ( 1.504)	Data  0.017 ( 0.025)	InnerLoop  0.631 ( 0.644)	Loss 7.1789e-01 (6.7503e-01)	Acc@1  75.00 ( 75.81)
Epoch: [28][40/59]	Time  1.666 ( 1.511)	Data  0.025 ( 0.022)	InnerLoop  0.784 ( 0.650)	Loss 5.9073e-01 (6.8326e-01)	Acc@1  77.49 ( 74.92)
The current update step is 1711
GPU_0_using curriculum 20 with window 20
Epoch: [29][20/59]	Time  1.495 ( 1.507)	Data  0.019 ( 0.025)	InnerLoop  0.641 ( 0.644)	Loss 5.1236e-01 (6.7612e-01)	Acc@1  81.30 ( 75.47)
Epoch: [29][40/59]	Time  1.601 ( 1.509)	Data  0.020 ( 0.022)	InnerLoop  0.749 ( 0.650)	Loss 6.3762e-01 (7.2295e-01)	Acc@1  76.95 ( 74.21)
The current update step is 1770
The current seed is 803436711918824045
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.750
 *   Acc@1 70.472
 *   Acc@1 65.803
 *   Acc@1 65.814
 *   Acc@1 63.803
 *   Acc@1 63.707
 *   Acc@1 75.000
 *   Acc@1 75.065
 *   Acc@1 72.513
 *   Acc@1 72.765
 *   Acc@1 71.750
 *   Acc@1 71.741
Training for 300 epoch: 72.375
Training for 600 epoch: 69.15789473684211
Training for 1000 epoch: 67.77631578947368
Training for 300 epoch: 72.76833333333333
Training for 600 epoch: 69.28958333333333
Training for 1000 epoch: 67.72375
[[72.375, 69.15789473684211, 67.77631578947368], [72.76833333333333, 69.28958333333333, 67.72375]]
train loss 0.3885827513535817, epoch 29, best loss 0.3885827513535817, best_epoch 29
GPU_0_using curriculum 20 with window 20
Epoch: [30][20/59]	Time  1.613 ( 1.509)	Data  0.019 ( 0.026)	InnerLoop  0.755 ( 0.649)	Loss 1.0109e+00 (6.9591e-01)	Acc@1  65.77 ( 74.50)
Epoch: [30][40/59]	Time  1.490 ( 1.509)	Data  0.019 ( 0.023)	InnerLoop  0.638 ( 0.651)	Loss 8.9432e-01 (6.9570e-01)	Acc@1  69.43 ( 74.70)
The current update step is 1829
GPU_0_using curriculum 20 with window 20
Epoch: [31][20/59]	Time  1.488 ( 1.512)	Data  0.021 ( 0.033)	InnerLoop  0.630 ( 0.640)	Loss 7.0760e-01 (6.8923e-01)	Acc@1  73.63 ( 74.46)
Epoch: [31][40/59]	Time  1.613 ( 1.513)	Data  0.019 ( 0.030)	InnerLoop  0.747 ( 0.645)	Loss 5.2601e-01 (6.7007e-01)	Acc@1  82.28 ( 75.42)
The current update step is 1888
GPU_0_using curriculum 20 with window 20
Epoch: [32][20/59]	Time  1.485 ( 1.500)	Data  0.019 ( 0.026)	InnerLoop  0.629 ( 0.640)	Loss 5.9029e-01 (7.0887e-01)	Acc@1  78.27 ( 74.36)
Epoch: [32][40/59]	Time  1.560 ( 1.520)	Data  0.024 ( 0.027)	InnerLoop  0.684 ( 0.652)	Loss 5.6846e-01 (6.7617e-01)	Acc@1  78.71 ( 75.55)
The current update step is 1947
GPU_0_using curriculum 20 with window 20
Epoch: [33][20/59]	Time  1.486 ( 1.501)	Data  0.020 ( 0.032)	InnerLoop  0.629 ( 0.636)	Loss 5.9662e-01 (6.4110e-01)	Acc@1  78.71 ( 76.92)
Epoch: [33][40/59]	Time  1.496 ( 1.504)	Data  0.017 ( 0.029)	InnerLoop  0.637 ( 0.639)	Loss 6.4012e-01 (6.5440e-01)	Acc@1  77.98 ( 76.23)
The current update step is 2006
GPU_0_using curriculum 20 with window 20
Epoch: [34][20/59]	Time  1.484 ( 1.508)	Data  0.017 ( 0.032)	InnerLoop  0.631 ( 0.640)	Loss 5.2398e-01 (6.3438e-01)	Acc@1  81.84 ( 77.26)
Epoch: [34][40/59]	Time  1.511 ( 1.509)	Data  0.021 ( 0.029)	InnerLoop  0.644 ( 0.643)	Loss 5.8302e-01 (6.4238e-01)	Acc@1  78.86 ( 76.72)
The current update step is 2065
The current seed is 7283809937541444524
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.355
 *   Acc@1 76.804
 *   Acc@1 74.855
 *   Acc@1 75.009
 *   Acc@1 73.026
 *   Acc@1 73.496
 *   Acc@1 74.895
 *   Acc@1 74.957
 *   Acc@1 71.342
 *   Acc@1 71.555
 *   Acc@1 70.171
 *   Acc@1 70.252
Training for 300 epoch: 75.625
Training for 600 epoch: 73.09868421052632
Training for 1000 epoch: 71.59868421052632
Training for 300 epoch: 75.88083333333333
Training for 600 epoch: 73.28208333333333
Training for 1000 epoch: 71.87375
[[75.625, 73.09868421052632, 71.59868421052632], [75.88083333333333, 73.28208333333333, 71.87375]]
train loss 0.4302893067677816, epoch 34, best loss 0.3885827513535817, best_epoch 29
GPU_0_using curriculum 20 with window 20
Epoch: [35][20/59]	Time  1.498 ( 1.538)	Data  0.021 ( 0.020)	InnerLoop  0.631 ( 0.665)	Loss 6.1111e-01 (6.7640e-01)	Acc@1  78.96 ( 75.37)
Epoch: [35][40/59]	Time  1.617 ( 1.526)	Data  0.146 ( 0.026)	InnerLoop  0.633 ( 0.654)	Loss 5.3314e-01 (6.5457e-01)	Acc@1  82.42 ( 76.27)
The current update step is 2124
GPU_0_using curriculum 20 with window 20
Epoch: [36][20/59]	Time  1.487 ( 1.505)	Data  0.020 ( 0.032)	InnerLoop  0.632 ( 0.638)	Loss 5.9080e-01 (6.4362e-01)	Acc@1  77.25 ( 76.39)
Epoch: [36][40/59]	Time  1.484 ( 1.509)	Data  0.019 ( 0.028)	InnerLoop  0.630 ( 0.644)	Loss 6.4356e-01 (6.3578e-01)	Acc@1  77.54 ( 76.59)
The current update step is 2183
GPU_0_using curriculum 20 with window 20
Epoch: [37][20/59]	Time  1.498 ( 1.530)	Data  0.019 ( 0.033)	InnerLoop  0.639 ( 0.648)	Loss 6.3877e-01 (7.0194e-01)	Acc@1  77.83 ( 75.69)
Epoch: [37][40/59]	Time  1.617 ( 1.524)	Data  0.019 ( 0.027)	InnerLoop  0.754 ( 0.652)	Loss 1.1485e+00 (6.8531e-01)	Acc@1  54.93 ( 75.23)
The current update step is 2242
GPU_0_using curriculum 20 with window 20
Epoch: [38][20/59]	Time  1.489 ( 1.500)	Data  0.020 ( 0.025)	InnerLoop  0.634 ( 0.640)	Loss 4.8958e-01 (6.1754e-01)	Acc@1  82.37 ( 77.44)
Epoch: [38][40/59]	Time  1.603 ( 1.504)	Data  0.021 ( 0.022)	InnerLoop  0.747 ( 0.647)	Loss 6.0859e-01 (6.2528e-01)	Acc@1  79.59 ( 77.47)
The current update step is 2301
GPU_0_using curriculum 20 with window 20
Epoch: [39][20/59]	Time  1.586 ( 1.521)	Data  0.023 ( 0.026)	InnerLoop  0.685 ( 0.652)	Loss 7.6271e-01 (6.2034e-01)	Acc@1  69.29 ( 76.87)
Epoch: [39][40/59]	Time  1.606 ( 1.528)	Data  0.022 ( 0.024)	InnerLoop  0.746 ( 0.660)	Loss 5.6070e-01 (6.3766e-01)	Acc@1  80.52 ( 76.77)
The current update step is 2360
The current seed is 4637062617251299205
The current lr is: 0.001
Testing Results:
 *   Acc@1 66.039
 *   Acc@1 66.499
 *   Acc@1 60.197
 *   Acc@1 60.435
 *   Acc@1 57.684
 *   Acc@1 57.926
 *   Acc@1 76.145
 *   Acc@1 76.463
 *   Acc@1 75.697
 *   Acc@1 76.741
 *   Acc@1 75.395
 *   Acc@1 75.916
Training for 300 epoch: 71.09210526315789
Training for 600 epoch: 67.94736842105263
Training for 1000 epoch: 66.53947368421052
Training for 300 epoch: 71.48125
Training for 600 epoch: 68.58791666666667
Training for 1000 epoch: 66.92083333333333
[[71.09210526315789, 67.94736842105263, 66.53947368421052], [71.48125, 68.58791666666667, 66.92083333333333]]
train loss 0.32023745470047, epoch 39, best loss 0.32023745470047, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [40][20/59]	Time  1.623 ( 1.548)	Data  0.020 ( 0.026)	InnerLoop  0.761 ( 0.670)	Loss 7.1936e-01 (7.1158e-01)	Acc@1  72.12 ( 74.54)
Epoch: [40][40/59]	Time  1.474 ( 1.530)	Data  0.019 ( 0.023)	InnerLoop  0.628 ( 0.662)	Loss 8.1617e-01 (6.8498e-01)	Acc@1  71.44 ( 75.25)
The current update step is 2419
GPU_0_using curriculum 20 with window 20
Epoch: [41][20/59]	Time  1.477 ( 1.501)	Data  0.019 ( 0.032)	InnerLoop  0.628 ( 0.636)	Loss 5.6989e-01 (7.4040e-01)	Acc@1  79.20 ( 73.79)
Epoch: [41][40/59]	Time  1.598 ( 1.520)	Data  0.018 ( 0.029)	InnerLoop  0.741 ( 0.649)	Loss 7.6561e-01 (7.2585e-01)	Acc@1  70.46 ( 74.10)
The current update step is 2478
GPU_0_using curriculum 20 with window 20
Epoch: [42][20/59]	Time  1.478 ( 1.501)	Data  0.018 ( 0.025)	InnerLoop  0.628 ( 0.642)	Loss 4.8286e-01 (6.7848e-01)	Acc@1  83.54 ( 75.56)
Epoch: [42][40/59]	Time  1.490 ( 1.504)	Data  0.020 ( 0.025)	InnerLoop  0.630 ( 0.645)	Loss 8.5805e-01 (6.7686e-01)	Acc@1  69.29 ( 75.35)
The current update step is 2537
GPU_0_using curriculum 20 with window 20
Epoch: [43][20/59]	Time  1.520 ( 1.502)	Data  0.018 ( 0.032)	InnerLoop  0.638 ( 0.636)	Loss 5.3057e-01 (6.2542e-01)	Acc@1  80.37 ( 77.28)
Epoch: [43][40/59]	Time  1.495 ( 1.516)	Data  0.019 ( 0.029)	InnerLoop  0.642 ( 0.646)	Loss 5.3845e-01 (6.4448e-01)	Acc@1  81.74 ( 76.60)
The current update step is 2596
GPU_0_using curriculum 20 with window 20
Epoch: [44][20/59]	Time  1.524 ( 1.506)	Data  0.022 ( 0.032)	InnerLoop  0.633 ( 0.638)	Loss 1.0455e+00 (6.6021e-01)	Acc@1  66.80 ( 76.28)
Epoch: [44][40/59]	Time  1.489 ( 1.509)	Data  0.019 ( 0.029)	InnerLoop  0.636 ( 0.642)	Loss 7.8289e-01 (6.5746e-01)	Acc@1  71.88 ( 76.32)
The current update step is 2655
The current seed is 9700895800008037130
The current lr is: 0.001
Testing Results:
 *   Acc@1 78.697
 *   Acc@1 78.942
 *   Acc@1 77.132
 *   Acc@1 77.289
 *   Acc@1 76.237
 *   Acc@1 76.356
 *   Acc@1 69.461
 *   Acc@1 69.585
 *   Acc@1 66.934
 *   Acc@1 66.630
 *   Acc@1 65.816
 *   Acc@1 65.832
Training for 300 epoch: 74.07894736842105
Training for 600 epoch: 72.03289473684211
Training for 1000 epoch: 71.02631578947368
Training for 300 epoch: 74.26333333333332
Training for 600 epoch: 71.95958333333334
Training for 1000 epoch: 71.09416666666667
[[74.07894736842105, 72.03289473684211, 71.02631578947368], [74.26333333333332, 71.95958333333334, 71.09416666666667]]
train loss 0.5374467659314474, epoch 44, best loss 0.32023745470047, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [45][20/59]	Time  1.487 ( 1.498)	Data  0.020 ( 0.019)	InnerLoop  0.629 ( 0.645)	Loss 7.3824e-01 (7.5888e-01)	Acc@1  74.12 ( 72.34)
Epoch: [45][40/59]	Time  1.609 ( 1.514)	Data  0.142 ( 0.026)	InnerLoop  0.635 ( 0.650)	Loss 6.1549e-01 (6.9495e-01)	Acc@1  78.91 ( 74.44)
The current update step is 2714
GPU_0_using curriculum 20 with window 20
Epoch: [46][20/59]	Time  1.488 ( 1.501)	Data  0.021 ( 0.032)	InnerLoop  0.625 ( 0.636)	Loss 5.5406e-01 (6.8606e-01)	Acc@1  79.79 ( 74.96)
Epoch: [46][40/59]	Time  1.481 ( 1.507)	Data  0.020 ( 0.029)	InnerLoop  0.625 ( 0.642)	Loss 9.5065e-01 (6.8227e-01)	Acc@1  66.31 ( 74.75)
The current update step is 2773
GPU_0_using curriculum 20 with window 20
Epoch: [47][20/59]	Time  1.494 ( 1.532)	Data  0.020 ( 0.033)	InnerLoop  0.638 ( 0.652)	Loss 5.9290e-01 (7.0837e-01)	Acc@1  78.81 ( 73.40)
Epoch: [47][40/59]	Time  1.600 ( 1.520)	Data  0.019 ( 0.026)	InnerLoop  0.749 ( 0.653)	Loss 7.5633e-01 (6.8728e-01)	Acc@1  72.85 ( 74.62)
The current update step is 2832
GPU_0_using curriculum 20 with window 20
Epoch: [48][20/59]	Time  1.493 ( 1.501)	Data  0.019 ( 0.025)	InnerLoop  0.634 ( 0.642)	Loss 5.6462e-01 (6.0869e-01)	Acc@1  78.22 ( 77.45)
Epoch: [48][40/59]	Time  1.602 ( 1.507)	Data  0.018 ( 0.023)	InnerLoop  0.749 ( 0.649)	Loss 6.1314e-01 (6.0708e-01)	Acc@1  77.98 ( 77.58)
The current update step is 2891
GPU_0_using curriculum 20 with window 20
Epoch: [49][20/59]	Time  1.479 ( 1.519)	Data  0.018 ( 0.026)	InnerLoop  0.626 ( 0.650)	Loss 7.2083e-01 (7.4754e-01)	Acc@1  69.87 ( 72.17)
Epoch: [49][40/59]	Time  1.602 ( 1.517)	Data  0.019 ( 0.023)	InnerLoop  0.741 ( 0.653)	Loss 7.1360e-01 (7.1543e-01)	Acc@1  74.66 ( 73.24)
The current update step is 2950
The current seed is 11319620161971338135
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.158
 *   Acc@1 71.280
 *   Acc@1 66.105
 *   Acc@1 66.303
 *   Acc@1 63.474
 *   Acc@1 63.258
 *   Acc@1 49.658
 *   Acc@1 50.086
 *   Acc@1 49.513
 *   Acc@1 50.045
 *   Acc@1 49.618
 *   Acc@1 49.865
Training for 300 epoch: 60.40789473684211
Training for 600 epoch: 57.809210526315795
Training for 1000 epoch: 56.546052631578945
Training for 300 epoch: 60.68291666666667
Training for 600 epoch: 58.174166666666665
Training for 1000 epoch: 56.56125
[[60.40789473684211, 57.809210526315795, 56.546052631578945], [60.68291666666667, 58.174166666666665, 56.56125]]
train loss 0.8582734344800313, epoch 49, best loss 0.32023745470047, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [50][20/59]	Time  1.605 ( 1.505)	Data  0.019 ( 0.026)	InnerLoop  0.754 ( 0.647)	Loss 5.6057e-01 (6.5782e-01)	Acc@1  78.76 ( 75.46)
Epoch: [50][40/59]	Time  1.585 ( 1.516)	Data  0.023 ( 0.023)	InnerLoop  0.679 ( 0.653)	Loss 7.3551e-01 (6.5199e-01)	Acc@1  69.97 ( 75.59)
The current update step is 3009
GPU_0_using curriculum 20 with window 20
Epoch: [51][20/59]	Time  1.483 ( 1.502)	Data  0.021 ( 0.032)	InnerLoop  0.631 ( 0.637)	Loss 9.8076e-01 (7.6068e-01)	Acc@1  65.82 ( 70.99)
Epoch: [51][40/59]	Time  1.593 ( 1.505)	Data  0.019 ( 0.029)	InnerLoop  0.743 ( 0.642)	Loss 7.1212e-01 (7.3672e-01)	Acc@1  69.24 ( 71.96)
The current update step is 3068
GPU_0_using curriculum 20 with window 20
Epoch: [52][20/59]	Time  1.516 ( 1.514)	Data  0.019 ( 0.026)	InnerLoop  0.654 ( 0.649)	Loss 6.2558e-01 (6.5003e-01)	Acc@1  77.49 ( 76.09)
Epoch: [52][40/59]	Time  1.487 ( 1.514)	Data  0.019 ( 0.026)	InnerLoop  0.630 ( 0.649)	Loss 5.8273e-01 (6.7164e-01)	Acc@1  77.73 ( 74.95)
The current update step is 3127
GPU_0_using curriculum 20 with window 20
Epoch: [53][20/59]	Time  1.476 ( 1.497)	Data  0.021 ( 0.032)	InnerLoop  0.622 ( 0.634)	Loss 7.1567e-01 (6.4440e-01)	Acc@1  75.15 ( 76.12)
Epoch: [53][40/59]	Time  1.499 ( 1.499)	Data  0.019 ( 0.029)	InnerLoop  0.634 ( 0.638)	Loss 5.7667e-01 (6.5860e-01)	Acc@1  76.95 ( 75.85)
The current update step is 3186
GPU_0_using curriculum 20 with window 20
Epoch: [54][20/59]	Time  1.490 ( 1.508)	Data  0.020 ( 0.033)	InnerLoop  0.639 ( 0.638)	Loss 6.8296e-01 (6.7734e-01)	Acc@1  72.17 ( 75.05)
Epoch: [54][40/59]	Time  1.487 ( 1.506)	Data  0.017 ( 0.029)	InnerLoop  0.632 ( 0.641)	Loss 5.2264e-01 (6.5396e-01)	Acc@1  80.91 ( 75.62)
The current update step is 3245
The current seed is 1033952424449809710
The current lr is: 0.001
Testing Results:
 *   Acc@1 67.303
 *   Acc@1 67.891
 *   Acc@1 67.829
 *   Acc@1 67.978
 *   Acc@1 68.895
 *   Acc@1 69.031
 *   Acc@1 67.461
 *   Acc@1 67.805
 *   Acc@1 60.974
 *   Acc@1 61.742
 *   Acc@1 59.158
 *   Acc@1 59.944
Training for 300 epoch: 67.38157894736842
Training for 600 epoch: 64.40131578947368
Training for 1000 epoch: 64.02631578947368
Training for 300 epoch: 67.84791666666666
Training for 600 epoch: 64.86
Training for 1000 epoch: 64.4875
[[67.38157894736842, 64.40131578947368, 64.02631578947368], [67.84791666666666, 64.86, 64.4875]]
train loss 0.6075644879976908, epoch 54, best loss 0.32023745470047, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [55][20/59]	Time  1.491 ( 1.510)	Data  0.022 ( 0.020)	InnerLoop  0.629 ( 0.652)	Loss 9.1360e-01 (6.3279e-01)	Acc@1  70.36 ( 77.13)
Epoch: [55][40/59]	Time  1.604 ( 1.511)	Data  0.141 ( 0.026)	InnerLoop  0.625 ( 0.647)	Loss 8.7943e-01 (6.3846e-01)	Acc@1  68.26 ( 76.82)
The current update step is 3304
GPU_0_using curriculum 20 with window 20
Epoch: [56][20/59]	Time  1.506 ( 1.507)	Data  0.022 ( 0.032)	InnerLoop  0.630 ( 0.639)	Loss 6.6334e-01 (6.6009e-01)	Acc@1  77.15 ( 76.12)
Epoch: [56][40/59]	Time  1.489 ( 1.523)	Data  0.021 ( 0.030)	InnerLoop  0.633 ( 0.651)	Loss 7.1493e-01 (6.8037e-01)	Acc@1  74.12 ( 75.06)
The current update step is 3363
GPU_0_using curriculum 20 with window 20
Epoch: [57][20/59]	Time  1.491 ( 1.500)	Data  0.020 ( 0.031)	InnerLoop  0.633 ( 0.636)	Loss 5.8094e-01 (6.5839e-01)	Acc@1  79.05 ( 75.58)
Epoch: [57][40/59]	Time  1.604 ( 1.506)	Data  0.019 ( 0.025)	InnerLoop  0.744 ( 0.646)	Loss 6.1490e-01 (6.7224e-01)	Acc@1  76.95 ( 74.93)
The current update step is 3422
GPU_0_using curriculum 20 with window 20
Epoch: [58][20/59]	Time  1.504 ( 1.508)	Data  0.018 ( 0.025)	InnerLoop  0.639 ( 0.646)	Loss 6.2045e-01 (6.9018e-01)	Acc@1  79.05 ( 74.27)
Epoch: [58][40/59]	Time  1.593 ( 1.510)	Data  0.018 ( 0.022)	InnerLoop  0.742 ( 0.651)	Loss 5.3360e-01 (6.6815e-01)	Acc@1  80.71 ( 75.18)
The current update step is 3481
GPU_0_using curriculum 20 with window 20
Epoch: [59][20/59]	Time  1.489 ( 1.503)	Data  0.018 ( 0.026)	InnerLoop  0.631 ( 0.643)	Loss 6.4149e-01 (6.4040e-01)	Acc@1  75.29 ( 76.22)
Epoch: [59][40/59]	Time  1.611 ( 1.510)	Data  0.019 ( 0.022)	InnerLoop  0.749 ( 0.650)	Loss 5.7242e-01 (6.8345e-01)	Acc@1  79.10 ( 75.20)
The current update step is 3540
The current seed is 15559982164930735683
The current lr is: 0.001
Testing Results:
 *   Acc@1 65.658
 *   Acc@1 65.926
 *   Acc@1 63.368
 *   Acc@1 63.047
 *   Acc@1 62.158
 *   Acc@1 61.844
 *   Acc@1 76.039
 *   Acc@1 75.926
 *   Acc@1 74.513
 *   Acc@1 74.975
 *   Acc@1 73.776
 *   Acc@1 73.849
Training for 300 epoch: 70.84868421052632
Training for 600 epoch: 68.9407894736842
Training for 1000 epoch: 67.96710526315789
Training for 300 epoch: 70.92583333333333
Training for 600 epoch: 69.01083333333332
Training for 1000 epoch: 67.84666666666666
[[70.84868421052632, 68.9407894736842, 67.96710526315789], [70.92583333333333, 69.01083333333332, 67.84666666666666]]
train loss 0.3224215689500173, epoch 59, best loss 0.32023745470047, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [60][20/59]	Time  1.602 ( 1.509)	Data  0.018 ( 0.025)	InnerLoop  0.750 ( 0.651)	Loss 6.8209e-01 (6.7850e-01)	Acc@1  75.15 ( 75.41)
Epoch: [60][40/59]	Time  1.484 ( 1.507)	Data  0.019 ( 0.022)	InnerLoop  0.628 ( 0.650)	Loss 9.6658e-01 (6.7664e-01)	Acc@1  66.60 ( 75.34)
The current update step is 3599
GPU_0_using curriculum 20 with window 20
Epoch: [61][20/59]	Time  1.491 ( 1.515)	Data  0.019 ( 0.033)	InnerLoop  0.633 ( 0.641)	Loss 6.1761e-01 (6.5995e-01)	Acc@1  78.52 ( 75.95)
Epoch: [61][40/59]	Time  1.642 ( 1.515)	Data  0.021 ( 0.029)	InnerLoop  0.773 ( 0.645)	Loss 6.8926e-01 (6.9762e-01)	Acc@1  73.78 ( 74.93)
The current update step is 3658
GPU_0_using curriculum 20 with window 20
Epoch: [62][20/59]	Time  1.488 ( 1.529)	Data  0.020 ( 0.027)	InnerLoop  0.632 ( 0.657)	Loss 8.3248e-01 (6.2096e-01)	Acc@1  72.02 ( 76.75)
Epoch: [62][40/59]	Time  1.492 ( 1.520)	Data  0.018 ( 0.026)	InnerLoop  0.637 ( 0.653)	Loss 5.6132e-01 (6.4134e-01)	Acc@1  80.71 ( 76.48)
The current update step is 3717
GPU_0_using curriculum 20 with window 20
Epoch: [63][20/59]	Time  1.512 ( 1.518)	Data  0.022 ( 0.033)	InnerLoop  0.643 ( 0.643)	Loss 4.9753e-01 (6.4255e-01)	Acc@1  82.76 ( 76.91)
Epoch: [63][40/59]	Time  1.485 ( 1.517)	Data  0.018 ( 0.030)	InnerLoop  0.633 ( 0.647)	Loss 6.1503e-01 (6.7153e-01)	Acc@1  79.49 ( 75.65)
The current update step is 3776
GPU_0_using curriculum 20 with window 20
Epoch: [64][20/59]	Time  1.492 ( 1.508)	Data  0.020 ( 0.033)	InnerLoop  0.631 ( 0.639)	Loss 6.5657e-01 (6.8647e-01)	Acc@1  77.98 ( 75.57)
Epoch: [64][40/59]	Time  1.499 ( 1.509)	Data  0.018 ( 0.029)	InnerLoop  0.640 ( 0.642)	Loss 5.2697e-01 (7.1753e-01)	Acc@1  82.18 ( 74.67)
The current update step is 3835
The current seed is 9531865212551237712
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.158
 *   Acc@1 71.358
 *   Acc@1 66.789
 *   Acc@1 67.264
 *   Acc@1 64.842
 *   Acc@1 65.414
 *   Acc@1 73.553
 *   Acc@1 73.557
 *   Acc@1 70.908
 *   Acc@1 71.048
 *   Acc@1 70.816
 *   Acc@1 70.976
Training for 300 epoch: 72.35526315789474
Training for 600 epoch: 68.84868421052632
Training for 1000 epoch: 67.82894736842104
Training for 300 epoch: 72.45708333333334
Training for 600 epoch: 69.15625
Training for 1000 epoch: 68.195
[[72.35526315789474, 68.84868421052632, 67.82894736842104], [72.45708333333334, 69.15625, 68.195]]
train loss 0.344387380361557, epoch 64, best loss 0.32023745470047, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [65][20/59]	Time  1.494 ( 1.504)	Data  0.021 ( 0.019)	InnerLoop  0.634 ( 0.648)	Loss 5.8577e-01 (6.2889e-01)	Acc@1  79.93 ( 76.90)
Epoch: [65][40/59]	Time  1.605 ( 1.508)	Data  0.139 ( 0.025)	InnerLoop  0.632 ( 0.646)	Loss 5.9071e-01 (6.4689e-01)	Acc@1  80.81 ( 75.98)
The current update step is 3894
GPU_0_using curriculum 20 with window 20
Epoch: [66][20/59]	Time  1.480 ( 1.503)	Data  0.023 ( 0.032)	InnerLoop  0.623 ( 0.638)	Loss 6.0322e-01 (6.4632e-01)	Acc@1  73.88 ( 74.96)
Epoch: [66][40/59]	Time  1.495 ( 1.507)	Data  0.018 ( 0.029)	InnerLoop  0.632 ( 0.644)	Loss 6.7542e-01 (6.4168e-01)	Acc@1  76.12 ( 75.53)
The current update step is 3953
GPU_0_using curriculum 20 with window 20
Epoch: [67][20/59]	Time  1.484 ( 1.541)	Data  0.019 ( 0.033)	InnerLoop  0.629 ( 0.658)	Loss 6.6647e-01 (6.4992e-01)	Acc@1  73.78 ( 76.21)
Epoch: [67][40/59]	Time  1.598 ( 1.527)	Data  0.019 ( 0.026)	InnerLoop  0.744 ( 0.658)	Loss 8.6607e-01 (6.6525e-01)	Acc@1  69.43 ( 75.92)
The current update step is 4012
GPU_0_using curriculum 20 with window 20
Epoch: [68][20/59]	Time  1.571 ( 1.520)	Data  0.020 ( 0.027)	InnerLoop  0.671 ( 0.651)	Loss 7.0947e-01 (6.1246e-01)	Acc@1  71.97 ( 77.03)
Epoch: [68][40/59]	Time  1.623 ( 1.526)	Data  0.020 ( 0.024)	InnerLoop  0.764 ( 0.659)	Loss 7.3671e-01 (6.4318e-01)	Acc@1  71.34 ( 75.83)
The current update step is 4071
GPU_0_using curriculum 20 with window 20
Epoch: [69][20/59]	Time  1.480 ( 1.501)	Data  0.018 ( 0.025)	InnerLoop  0.626 ( 0.641)	Loss 6.7040e-01 (6.5673e-01)	Acc@1  78.03 ( 75.31)
Epoch: [69][40/59]	Time  1.606 ( 1.505)	Data  0.020 ( 0.022)	InnerLoop  0.752 ( 0.648)	Loss 5.4058e-01 (6.4874e-01)	Acc@1  79.30 ( 75.89)
The current update step is 4130
The current seed is 5601375935446643558
The current lr is: 0.001
Testing Results:
 *   Acc@1 75.934
 *   Acc@1 76.113
 *   Acc@1 71.961
 *   Acc@1 71.930
 *   Acc@1 70.750
 *   Acc@1 70.966
 *   Acc@1 76.237
 *   Acc@1 76.111
 *   Acc@1 73.961
 *   Acc@1 74.403
 *   Acc@1 71.816
 *   Acc@1 71.919
Training for 300 epoch: 76.08552631578948
Training for 600 epoch: 72.96052631578948
Training for 1000 epoch: 71.28289473684211
Training for 300 epoch: 76.11208333333333
Training for 600 epoch: 73.16625
Training for 1000 epoch: 71.4425
[[76.08552631578948, 72.96052631578948, 71.28289473684211], [76.11208333333333, 73.16625, 71.4425]]
train loss 0.3817283867518107, epoch 69, best loss 0.32023745470047, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [70][20/59]	Time  1.606 ( 1.517)	Data  0.022 ( 0.026)	InnerLoop  0.748 ( 0.653)	Loss 5.4055e-01 (5.9009e-01)	Acc@1  81.74 ( 77.92)
Epoch: [70][40/59]	Time  1.500 ( 1.512)	Data  0.021 ( 0.023)	InnerLoop  0.636 ( 0.651)	Loss 6.4976e-01 (6.1664e-01)	Acc@1  77.25 ( 77.14)
The current update step is 4189
GPU_0_using curriculum 20 with window 20
Epoch: [71][20/59]	Time  1.485 ( 1.498)	Data  0.019 ( 0.032)	InnerLoop  0.630 ( 0.633)	Loss 6.2264e-01 (6.5843e-01)	Acc@1  78.42 ( 75.63)
Epoch: [71][40/59]	Time  1.698 ( 1.508)	Data  0.024 ( 0.029)	InnerLoop  0.795 ( 0.642)	Loss 5.5019e-01 (6.5012e-01)	Acc@1  78.81 ( 76.08)
The current update step is 4248
GPU_0_using curriculum 20 with window 20
Epoch: [72][20/59]	Time  1.483 ( 1.507)	Data  0.018 ( 0.026)	InnerLoop  0.626 ( 0.644)	Loss 6.9567e-01 (5.9642e-01)	Acc@1  71.63 ( 77.99)
Epoch: [72][40/59]	Time  1.485 ( 1.508)	Data  0.019 ( 0.025)	InnerLoop  0.630 ( 0.645)	Loss 5.0720e-01 (6.0737e-01)	Acc@1  81.79 ( 78.10)
The current update step is 4307
GPU_0_using curriculum 20 with window 20
Epoch: [73][20/59]	Time  1.522 ( 1.510)	Data  0.022 ( 0.032)	InnerLoop  0.643 ( 0.638)	Loss 9.1601e-01 (6.6139e-01)	Acc@1  70.56 ( 76.78)
Epoch: [73][40/59]	Time  1.478 ( 1.516)	Data  0.018 ( 0.029)	InnerLoop  0.624 ( 0.645)	Loss 5.5209e-01 (6.4463e-01)	Acc@1  79.10 ( 76.62)
The current update step is 4366
GPU_0_using curriculum 20 with window 20
Epoch: [74][20/59]	Time  1.477 ( 1.504)	Data  0.018 ( 0.031)	InnerLoop  0.626 ( 0.637)	Loss 5.9882e-01 (6.4673e-01)	Acc@1  78.32 ( 75.59)
Epoch: [74][40/59]	Time  1.527 ( 1.504)	Data  0.021 ( 0.029)	InnerLoop  0.638 ( 0.639)	Loss 5.0138e-01 (6.2310e-01)	Acc@1  82.37 ( 76.63)
The current update step is 4425
The current seed is 11666119079870732429
The current lr is: 0.001
Testing Results:
 *   Acc@1 60.474
 *   Acc@1 60.187
 *   Acc@1 57.158
 *   Acc@1 56.589
 *   Acc@1 56.263
 *   Acc@1 55.913
 *   Acc@1 78.066
 *   Acc@1 78.062
 *   Acc@1 74.579
 *   Acc@1 74.845
 *   Acc@1 71.974
 *   Acc@1 71.657
Training for 300 epoch: 69.26973684210526
Training for 600 epoch: 65.86842105263158
Training for 1000 epoch: 64.11842105263158
Training for 300 epoch: 69.12416666666667
Training for 600 epoch: 65.71708333333333
Training for 1000 epoch: 63.78458333333333
[[69.26973684210526, 65.86842105263158, 64.11842105263158], [69.12416666666667, 65.71708333333333, 63.78458333333333]]
train loss 0.40812929889361066, epoch 74, best loss 0.32023745470047, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [75][20/59]	Time  1.484 ( 1.502)	Data  0.021 ( 0.019)	InnerLoop  0.630 ( 0.650)	Loss 7.4403e-01 (6.4455e-01)	Acc@1  70.41 ( 77.02)
Epoch: [75][40/59]	Time  1.610 ( 1.506)	Data  0.140 ( 0.025)	InnerLoop  0.628 ( 0.646)	Loss 8.8129e-01 (6.4146e-01)	Acc@1  71.58 ( 76.67)
The current update step is 4484
GPU_0_using curriculum 20 with window 20
Epoch: [76][20/59]	Time  1.471 ( 1.506)	Data  0.020 ( 0.032)	InnerLoop  0.620 ( 0.637)	Loss 4.9065e-01 (6.2335e-01)	Acc@1  82.57 ( 77.43)
Epoch: [76][40/59]	Time  1.484 ( 1.507)	Data  0.018 ( 0.028)	InnerLoop  0.629 ( 0.642)	Loss 6.6205e-01 (6.2461e-01)	Acc@1  76.32 ( 77.29)
The current update step is 4543
GPU_0_using curriculum 20 with window 20
Epoch: [77][20/59]	Time  1.490 ( 1.515)	Data  0.022 ( 0.032)	InnerLoop  0.628 ( 0.642)	Loss 5.9925e-01 (6.1826e-01)	Acc@1  75.83 ( 77.60)
Epoch: [77][40/59]	Time  1.629 ( 1.513)	Data  0.018 ( 0.026)	InnerLoop  0.755 ( 0.648)	Loss 7.2766e-01 (6.5554e-01)	Acc@1  72.22 ( 76.43)
The current update step is 4602
GPU_0_using curriculum 20 with window 20
Epoch: [78][20/59]	Time  1.479 ( 1.500)	Data  0.016 ( 0.025)	InnerLoop  0.630 ( 0.642)	Loss 5.1335e-01 (6.4699e-01)	Acc@1  81.20 ( 76.04)
Epoch: [78][40/59]	Time  1.619 ( 1.505)	Data  0.019 ( 0.022)	InnerLoop  0.755 ( 0.648)	Loss 6.3022e-01 (6.4224e-01)	Acc@1  78.42 ( 76.17)
The current update step is 4661
GPU_0_using curriculum 20 with window 20
Epoch: [79][20/59]	Time  1.482 ( 1.530)	Data  0.021 ( 0.027)	InnerLoop  0.627 ( 0.658)	Loss 4.8249e-01 (6.2120e-01)	Acc@1  82.57 ( 76.83)
Epoch: [79][40/59]	Time  1.613 ( 1.520)	Data  0.020 ( 0.023)	InnerLoop  0.753 ( 0.656)	Loss 5.1988e-01 (6.2362e-01)	Acc@1  81.10 ( 76.86)
The current update step is 4720
The current seed is 9545665891072596840
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.816
 *   Acc@1 73.985
 *   Acc@1 70.276
 *   Acc@1 70.485
 *   Acc@1 69.934
 *   Acc@1 70.001
 *   Acc@1 72.132
 *   Acc@1 72.103
 *   Acc@1 70.711
 *   Acc@1 71.052
 *   Acc@1 71.842
 *   Acc@1 72.017
Training for 300 epoch: 72.97368421052632
Training for 600 epoch: 70.49342105263159
Training for 1000 epoch: 70.88815789473685
Training for 300 epoch: 73.04416666666667
Training for 600 epoch: 70.76875
Training for 1000 epoch: 71.00916666666666
[[72.97368421052632, 70.49342105263159, 70.88815789473685], [73.04416666666667, 70.76875, 71.00916666666666]]
train loss 0.43738392038345336, epoch 79, best loss 0.32023745470047, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [80][20/59]	Time  1.603 ( 1.506)	Data  0.019 ( 0.025)	InnerLoop  0.752 ( 0.646)	Loss 6.7184e-01 (6.3171e-01)	Acc@1  73.19 ( 76.26)
Epoch: [80][40/59]	Time  1.496 ( 1.508)	Data  0.020 ( 0.023)	InnerLoop  0.639 ( 0.649)	Loss 5.6600e-01 (6.6146e-01)	Acc@1  81.30 ( 75.57)
The current update step is 4779
GPU_0_using curriculum 20 with window 20
Epoch: [81][20/59]	Time  1.482 ( 1.506)	Data  0.021 ( 0.033)	InnerLoop  0.632 ( 0.637)	Loss 6.1359e-01 (6.0626e-01)	Acc@1  78.37 ( 77.72)
Epoch: [81][40/59]	Time  1.608 ( 1.510)	Data  0.020 ( 0.029)	InnerLoop  0.754 ( 0.643)	Loss 5.3422e-01 (6.1517e-01)	Acc@1  81.49 ( 77.34)
The current update step is 4838
GPU_0_using curriculum 20 with window 20
Epoch: [82][20/59]	Time  1.490 ( 1.509)	Data  0.020 ( 0.026)	InnerLoop  0.635 ( 0.647)	Loss 5.9357e-01 (5.9578e-01)	Acc@1  78.32 ( 78.66)
Epoch: [82][40/59]	Time  1.484 ( 1.510)	Data  0.019 ( 0.026)	InnerLoop  0.626 ( 0.648)	Loss 1.0102e+00 (6.1249e-01)	Acc@1  67.92 ( 78.20)
The current update step is 4897
GPU_0_using curriculum 20 with window 20
Epoch: [83][20/59]	Time  1.492 ( 1.505)	Data  0.019 ( 0.032)	InnerLoop  0.637 ( 0.638)	Loss 7.9894e-01 (6.1207e-01)	Acc@1  70.36 ( 77.46)
Epoch: [83][40/59]	Time  1.485 ( 1.508)	Data  0.017 ( 0.029)	InnerLoop  0.631 ( 0.641)	Loss 5.1538e-01 (6.3150e-01)	Acc@1  82.28 ( 76.86)
The current update step is 4956
GPU_0_using curriculum 20 with window 20
Epoch: [84][20/59]	Time  1.483 ( 1.502)	Data  0.020 ( 0.031)	InnerLoop  0.629 ( 0.638)	Loss 9.2343e-01 (6.1577e-01)	Acc@1  66.16 ( 77.43)
Epoch: [84][40/59]	Time  1.502 ( 1.511)	Data  0.020 ( 0.029)	InnerLoop  0.641 ( 0.644)	Loss 6.4769e-01 (6.1115e-01)	Acc@1  72.90 ( 77.68)
The current update step is 5015
The current seed is 17935809008890061864
The current lr is: 0.001
Testing Results:
 *   Acc@1 72.513
 *   Acc@1 72.816
 *   Acc@1 71.632
 *   Acc@1 72.029
 *   Acc@1 70.592
 *   Acc@1 70.998
 *   Acc@1 71.368
 *   Acc@1 71.536
 *   Acc@1 68.724
 *   Acc@1 68.948
 *   Acc@1 66.855
 *   Acc@1 67.201
Training for 300 epoch: 71.9407894736842
Training for 600 epoch: 70.17763157894737
Training for 1000 epoch: 68.72368421052632
Training for 300 epoch: 72.17583333333333
Training for 600 epoch: 70.48875000000001
Training for 1000 epoch: 69.09916666666666
[[71.9407894736842, 70.17763157894737, 68.72368421052632], [72.17583333333333, 70.48875000000001, 69.09916666666666]]
train loss 0.50269007174174, epoch 84, best loss 0.32023745470047, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [85][20/59]	Time  1.487 ( 1.501)	Data  0.021 ( 0.019)	InnerLoop  0.630 ( 0.647)	Loss 5.2860e-01 (6.0468e-01)	Acc@1  81.74 ( 77.81)
Epoch: [85][40/59]	Time  1.596 ( 1.506)	Data  0.141 ( 0.026)	InnerLoop  0.625 ( 0.645)	Loss 5.2799e-01 (5.9450e-01)	Acc@1  82.18 ( 78.34)
The current update step is 5074
GPU_0_using curriculum 20 with window 20
Epoch: [86][20/59]	Time  1.473 ( 1.508)	Data  0.021 ( 0.033)	InnerLoop  0.622 ( 0.638)	Loss 9.3707e-01 (6.4393e-01)	Acc@1  67.68 ( 76.52)
Epoch: [86][40/59]	Time  1.483 ( 1.510)	Data  0.019 ( 0.029)	InnerLoop  0.632 ( 0.644)	Loss 7.7876e-01 (6.3667e-01)	Acc@1  72.46 ( 76.61)
The current update step is 5133
GPU_0_using curriculum 20 with window 20
Epoch: [87][20/59]	Time  1.483 ( 1.509)	Data  0.019 ( 0.032)	InnerLoop  0.628 ( 0.640)	Loss 7.5094e-01 (6.4273e-01)	Acc@1  70.75 ( 75.16)
Epoch: [87][40/59]	Time  1.618 ( 1.514)	Data  0.020 ( 0.026)	InnerLoop  0.755 ( 0.650)	Loss 6.0817e-01 (6.4017e-01)	Acc@1  77.98 ( 75.40)
The current update step is 5192
GPU_0_using curriculum 20 with window 20
Epoch: [88][20/59]	Time  1.474 ( 1.513)	Data  0.020 ( 0.026)	InnerLoop  0.624 ( 0.648)	Loss 5.3284e-01 (6.5396e-01)	Acc@1  79.69 ( 75.75)
Epoch: [88][40/59]	Time  1.605 ( 1.520)	Data  0.023 ( 0.023)	InnerLoop  0.749 ( 0.656)	Loss 7.0190e-01 (6.5048e-01)	Acc@1  74.32 ( 76.18)
The current update step is 5251
GPU_0_using curriculum 20 with window 20
Epoch: [89][20/59]	Time  1.484 ( 1.499)	Data  0.019 ( 0.026)	InnerLoop  0.630 ( 0.640)	Loss 6.0592e-01 (6.4680e-01)	Acc@1  78.03 ( 76.68)
Epoch: [89][40/59]	Time  1.593 ( 1.504)	Data  0.021 ( 0.023)	InnerLoop  0.739 ( 0.647)	Loss 6.8065e-01 (6.5294e-01)	Acc@1  70.31 ( 76.40)
The current update step is 5310
The current seed is 6758244616572454522
The current lr is: 0.001
Testing Results:
 *   Acc@1 75.658
 *   Acc@1 75.837
 *   Acc@1 75.276
 *   Acc@1 75.844
 *   Acc@1 76.000
 *   Acc@1 76.254
 *   Acc@1 77.500
 *   Acc@1 77.652
 *   Acc@1 74.776
 *   Acc@1 74.657
 *   Acc@1 73.013
 *   Acc@1 72.871
Training for 300 epoch: 76.57894736842105
Training for 600 epoch: 75.02631578947368
Training for 1000 epoch: 74.50657894736841
Training for 300 epoch: 76.74416666666667
Training for 600 epoch: 75.25083333333333
Training for 1000 epoch: 74.5625
[[76.57894736842105, 75.02631578947368, 74.50657894736841], [76.74416666666667, 75.25083333333333, 74.5625]]
train loss 0.4023461541652679, epoch 89, best loss 0.32023745470047, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [90][20/59]	Time  1.601 ( 1.505)	Data  0.018 ( 0.025)	InnerLoop  0.744 ( 0.646)	Loss 6.9014e-01 (6.4314e-01)	Acc@1  75.39 ( 76.50)
Epoch: [90][40/59]	Time  1.547 ( 1.513)	Data  0.023 ( 0.023)	InnerLoop  0.670 ( 0.652)	Loss 5.1672e-01 (6.1058e-01)	Acc@1  80.86 ( 77.53)
The current update step is 5369
GPU_0_using curriculum 20 with window 20
Epoch: [91][20/59]	Time  1.503 ( 1.512)	Data  0.019 ( 0.032)	InnerLoop  0.636 ( 0.639)	Loss 6.3049e-01 (6.1280e-01)	Acc@1  76.81 ( 77.71)
Epoch: [91][40/59]	Time  1.625 ( 1.521)	Data  0.022 ( 0.029)	InnerLoop  0.757 ( 0.649)	Loss 5.0084e-01 (6.2010e-01)	Acc@1  81.69 ( 77.08)
The current update step is 5428
GPU_0_using curriculum 20 with window 20
Epoch: [92][20/59]	Time  1.491 ( 1.507)	Data  0.020 ( 0.026)	InnerLoop  0.631 ( 0.645)	Loss 6.3685e-01 (6.2892e-01)	Acc@1  76.17 ( 77.19)
Epoch: [92][40/59]	Time  1.491 ( 1.510)	Data  0.017 ( 0.026)	InnerLoop  0.632 ( 0.647)	Loss 6.3789e-01 (6.2113e-01)	Acc@1  76.51 ( 77.31)
The current update step is 5487
GPU_0_using curriculum 20 with window 20
Epoch: [93][20/59]	Time  1.491 ( 1.511)	Data  0.021 ( 0.033)	InnerLoop  0.633 ( 0.639)	Loss 5.4733e-01 (6.4878e-01)	Acc@1  79.74 ( 75.98)
Epoch: [93][40/59]	Time  1.501 ( 1.514)	Data  0.018 ( 0.029)	InnerLoop  0.638 ( 0.644)	Loss 5.9613e-01 (6.5339e-01)	Acc@1  77.88 ( 75.75)
The current update step is 5546
GPU_0_using curriculum 20 with window 20
Epoch: [94][20/59]	Time  1.493 ( 1.512)	Data  0.021 ( 0.032)	InnerLoop  0.633 ( 0.640)	Loss 5.1699e-01 (6.0295e-01)	Acc@1  82.03 ( 78.01)
Epoch: [94][40/59]	Time  1.500 ( 1.512)	Data  0.019 ( 0.029)	InnerLoop  0.641 ( 0.644)	Loss 6.3609e-01 (6.1394e-01)	Acc@1  76.22 ( 77.58)
The current update step is 5605
The current seed is 1118712896345798043
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.855
 *   Acc@1 72.651
 *   Acc@1 66.553
 *   Acc@1 67.536
 *   Acc@1 66.553
 *   Acc@1 66.854
 *   Acc@1 77.737
 *   Acc@1 78.333
 *   Acc@1 78.816
 *   Acc@1 79.295
 *   Acc@1 79.276
 *   Acc@1 79.794
Training for 300 epoch: 74.79605263157896
Training for 600 epoch: 72.68421052631578
Training for 1000 epoch: 72.91447368421052
Training for 300 epoch: 75.49208333333334
Training for 600 epoch: 73.41541666666666
Training for 1000 epoch: 73.32416666666667
[[74.79605263157896, 72.68421052631578, 72.91447368421052], [75.49208333333334, 73.41541666666666, 73.32416666666667]]
train loss 0.29038397626876833, epoch 94, best loss 0.29038397626876833, best_epoch 94
GPU_0_using curriculum 20 with window 20
Epoch: [95][20/59]	Time  1.485 ( 1.507)	Data  0.021 ( 0.019)	InnerLoop  0.631 ( 0.650)	Loss 5.3152e-01 (6.1966e-01)	Acc@1  80.22 ( 77.12)
Epoch: [95][40/59]	Time  1.613 ( 1.524)	Data  0.141 ( 0.026)	InnerLoop  0.627 ( 0.654)	Loss 5.9374e-01 (6.0292e-01)	Acc@1  76.61 ( 77.84)
The current update step is 5664
GPU_0_using curriculum 20 with window 20
Epoch: [96][20/59]	Time  1.527 ( 1.514)	Data  0.023 ( 0.031)	InnerLoop  0.648 ( 0.642)	Loss 5.5886e-01 (6.0132e-01)	Acc@1  78.81 ( 77.48)
Epoch: [96][40/59]	Time  1.561 ( 1.530)	Data  0.023 ( 0.029)	InnerLoop  0.673 ( 0.654)	Loss 9.3282e-01 (6.2603e-01)	Acc@1  66.02 ( 76.60)
The current update step is 5723
GPU_0_using curriculum 20 with window 20
Epoch: [97][20/59]	Time  1.495 ( 1.505)	Data  0.021 ( 0.032)	InnerLoop  0.634 ( 0.635)	Loss 5.4664e-01 (6.1444e-01)	Acc@1  79.54 ( 77.73)
Epoch: [97][40/59]	Time  1.605 ( 1.509)	Data  0.021 ( 0.026)	InnerLoop  0.744 ( 0.645)	Loss 5.1305e-01 (6.2662e-01)	Acc@1  82.28 ( 77.04)
The current update step is 5782
GPU_0_using curriculum 20 with window 20
Epoch: [98][20/59]	Time  1.500 ( 1.513)	Data  0.019 ( 0.025)	InnerLoop  0.638 ( 0.650)	Loss 5.7157e-01 (5.9724e-01)	Acc@1  79.10 ( 78.02)
Epoch: [98][40/59]	Time  1.593 ( 1.513)	Data  0.020 ( 0.023)	InnerLoop  0.739 ( 0.652)	Loss 7.0335e-01 (6.1864e-01)	Acc@1  74.37 ( 77.08)
The current update step is 5841
GPU_0_using curriculum 20 with window 20
Epoch: [99][20/59]	Time  1.507 ( 1.516)	Data  0.017 ( 0.026)	InnerLoop  0.642 ( 0.648)	Loss 5.2742e-01 (5.7876e-01)	Acc@1  81.64 ( 78.33)
Epoch: [99][40/59]	Time  1.615 ( 1.517)	Data  0.018 ( 0.022)	InnerLoop  0.752 ( 0.654)	Loss 4.8355e-01 (5.8967e-01)	Acc@1  83.25 ( 78.04)
The current update step is 5900
The current seed is 797826917809573134
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.868
 *   Acc@1 72.834
 *   Acc@1 70.592
 *   Acc@1 71.704
 *   Acc@1 70.092
 *   Acc@1 70.554
 *   Acc@1 81.105
 *   Acc@1 81.442
 *   Acc@1 81.132
 *   Acc@1 81.268
 *   Acc@1 80.487
 *   Acc@1 80.899
Training for 300 epoch: 76.48684210526315
Training for 600 epoch: 75.86184210526315
Training for 1000 epoch: 75.28947368421052
Training for 300 epoch: 77.13833333333332
Training for 600 epoch: 76.48625
Training for 1000 epoch: 75.72666666666666
[[76.48684210526315, 75.86184210526315, 75.28947368421052], [77.13833333333332, 76.48625, 75.72666666666666]]
train loss 0.2888210260550181, epoch 99, best loss 0.2888210260550181, best_epoch 99
GPU_0_using curriculum 20 with window 20
Epoch: [100][20/59]	Time  1.619 ( 1.519)	Data  0.017 ( 0.026)	InnerLoop  0.760 ( 0.654)	Loss 5.8112e-01 (6.1293e-01)	Acc@1  79.15 ( 77.01)
Epoch: [100][40/59]	Time  1.494 ( 1.518)	Data  0.018 ( 0.023)	InnerLoop  0.642 ( 0.654)	Loss 8.3775e-01 (6.1296e-01)	Acc@1  68.60 ( 77.02)
The current update step is 5959
GPU_0_using curriculum 20 with window 20
Epoch: [101][20/59]	Time  1.486 ( 1.499)	Data  0.018 ( 0.031)	InnerLoop  0.636 ( 0.633)	Loss 6.1096e-01 (6.2954e-01)	Acc@1  78.52 ( 77.09)
Epoch: [101][40/59]	Time  1.605 ( 1.507)	Data  0.021 ( 0.028)	InnerLoop  0.745 ( 0.642)	Loss 5.1960e-01 (6.0094e-01)	Acc@1  81.45 ( 77.87)
The current update step is 6018
GPU_0_using curriculum 20 with window 20
Epoch: [102][20/59]	Time  1.488 ( 1.504)	Data  0.019 ( 0.026)	InnerLoop  0.634 ( 0.641)	Loss 5.2291e-01 (6.2331e-01)	Acc@1  81.84 ( 77.23)
Epoch: [102][40/59]	Time  1.490 ( 1.511)	Data  0.019 ( 0.026)	InnerLoop  0.634 ( 0.647)	Loss 5.4048e-01 (6.2273e-01)	Acc@1  80.91 ( 76.87)
The current update step is 6077
GPU_0_using curriculum 20 with window 20
Epoch: [103][20/59]	Time  1.544 ( 1.504)	Data  0.019 ( 0.032)	InnerLoop  0.659 ( 0.637)	Loss 5.4158e-01 (5.8227e-01)	Acc@1  78.91 ( 78.33)
Epoch: [103][40/59]	Time  1.477 ( 1.518)	Data  0.019 ( 0.030)	InnerLoop  0.623 ( 0.647)	Loss 1.0377e+00 (6.0751e-01)	Acc@1  57.37 ( 77.41)
The current update step is 6136
GPU_0_using curriculum 20 with window 20
Epoch: [104][20/59]	Time  1.499 ( 1.527)	Data  0.021 ( 0.033)	InnerLoop  0.644 ( 0.650)	Loss 1.5785e+00 (7.7249e-01)	Acc@1  54.59 ( 71.67)
Epoch: [104][40/59]	Time  1.496 ( 1.516)	Data  0.020 ( 0.029)	InnerLoop  0.636 ( 0.647)	Loss 8.2922e-01 (7.1495e-01)	Acc@1  62.70 ( 73.47)
The current update step is 6195
The current seed is 12819041187648467594
The current lr is: 0.001
Testing Results:
 *   Acc@1 75.553
 *   Acc@1 75.778
 *   Acc@1 74.553
 *   Acc@1 75.277
 *   Acc@1 73.789
 *   Acc@1 74.257
 *   Acc@1 67.789
 *   Acc@1 67.805
 *   Acc@1 67.316
 *   Acc@1 67.573
 *   Acc@1 67.158
 *   Acc@1 67.417
Training for 300 epoch: 71.67105263157895
Training for 600 epoch: 70.93421052631578
Training for 1000 epoch: 70.47368421052632
Training for 300 epoch: 71.79125
Training for 600 epoch: 71.42500000000001
Training for 1000 epoch: 70.83708333333334
[[71.67105263157895, 70.93421052631578, 70.47368421052632], [71.79125, 71.42500000000001, 70.83708333333334]]
train loss 0.4140723898251851, epoch 104, best loss 0.2888210260550181, best_epoch 99
GPU_0_using curriculum 20 with window 20
Epoch: [105][20/59]	Time  1.492 ( 1.513)	Data  0.021 ( 0.020)	InnerLoop  0.627 ( 0.654)	Loss 8.4449e-01 (6.1983e-01)	Acc@1  70.90 ( 77.11)
Epoch: [105][40/59]	Time  1.623 ( 1.517)	Data  0.138 ( 0.026)	InnerLoop  0.647 ( 0.651)	Loss 5.6520e-01 (6.0897e-01)	Acc@1  77.83 ( 77.43)
The current update step is 6254
GPU_0_using curriculum 20 with window 20
Epoch: [106][20/59]	Time  1.479 ( 1.503)	Data  0.019 ( 0.032)	InnerLoop  0.628 ( 0.637)	Loss 5.8576e-01 (6.3602e-01)	Acc@1  79.20 ( 76.67)
Epoch: [106][40/59]	Time  1.502 ( 1.512)	Data  0.020 ( 0.029)	InnerLoop  0.638 ( 0.645)	Loss 5.3138e-01 (6.3875e-01)	Acc@1  80.13 ( 76.49)
The current update step is 6313
GPU_0_using curriculum 20 with window 20
Epoch: [107][20/59]	Time  1.494 ( 1.500)	Data  0.020 ( 0.032)	InnerLoop  0.635 ( 0.634)	Loss 8.2270e-01 (6.8060e-01)	Acc@1  70.65 ( 75.46)
Epoch: [107][40/59]	Time  1.603 ( 1.506)	Data  0.021 ( 0.026)	InnerLoop  0.749 ( 0.645)	Loss 5.0652e-01 (6.5847e-01)	Acc@1  81.98 ( 75.67)
The current update step is 6372
GPU_0_using curriculum 20 with window 20
Epoch: [108][20/59]	Time  1.500 ( 1.519)	Data  0.020 ( 0.027)	InnerLoop  0.632 ( 0.649)	Loss 5.0340e-01 (5.9422e-01)	Acc@1  81.15 ( 77.21)
Epoch: [108][40/59]	Time  1.608 ( 1.520)	Data  0.020 ( 0.023)	InnerLoop  0.754 ( 0.655)	Loss 6.9430e-01 (6.0335e-01)	Acc@1  76.81 ( 77.44)
The current update step is 6431
GPU_0_using curriculum 20 with window 20
Epoch: [109][20/59]	Time  1.499 ( 1.501)	Data  0.019 ( 0.025)	InnerLoop  0.637 ( 0.642)	Loss 6.4881e-01 (6.0592e-01)	Acc@1  75.68 ( 77.69)
Epoch: [109][40/59]	Time  1.605 ( 1.520)	Data  0.019 ( 0.022)	InnerLoop  0.749 ( 0.657)	Loss 6.1332e-01 (6.2109e-01)	Acc@1  77.49 ( 77.41)
The current update step is 6490
The current seed is 4774780471941868309
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.145
 *   Acc@1 76.599
 *   Acc@1 75.526
 *   Acc@1 76.112
 *   Acc@1 75.092
 *   Acc@1 75.620
 *   Acc@1 73.816
 *   Acc@1 74.262
 *   Acc@1 70.171
 *   Acc@1 70.417
 *   Acc@1 69.039
 *   Acc@1 69.858
Training for 300 epoch: 74.98026315789474
Training for 600 epoch: 72.84868421052632
Training for 1000 epoch: 72.0657894736842
Training for 300 epoch: 75.43041666666667
Training for 600 epoch: 73.26416666666667
Training for 1000 epoch: 72.73916666666668
[[74.98026315789474, 72.84868421052632, 72.0657894736842], [75.43041666666667, 73.26416666666667, 72.73916666666668]]
train loss 0.401258665339152, epoch 109, best loss 0.2888210260550181, best_epoch 99
GPU_0_using curriculum 20 with window 20
Epoch: [110][20/59]	Time  1.598 ( 1.506)	Data  0.019 ( 0.025)	InnerLoop  0.743 ( 0.648)	Loss 5.5162e-01 (6.4109e-01)	Acc@1  81.25 ( 76.92)
Epoch: [110][40/59]	Time  1.494 ( 1.513)	Data  0.020 ( 0.022)	InnerLoop  0.633 ( 0.653)	Loss 5.3695e-01 (6.1582e-01)	Acc@1  81.64 ( 77.73)
The current update step is 6549
GPU_0_using curriculum 20 with window 20
Epoch: [111][20/59]	Time  1.511 ( 1.508)	Data  0.019 ( 0.032)	InnerLoop  0.640 ( 0.640)	Loss 5.7300e-01 (6.2894e-01)	Acc@1  78.76 ( 76.87)
Epoch: [111][40/59]	Time  1.599 ( 1.524)	Data  0.019 ( 0.030)	InnerLoop  0.744 ( 0.652)	Loss 5.8710e-01 (6.1683e-01)	Acc@1  78.81 ( 77.72)
The current update step is 6608
GPU_0_using curriculum 20 with window 20
Epoch: [112][20/59]	Time  1.488 ( 1.505)	Data  0.020 ( 0.025)	InnerLoop  0.632 ( 0.645)	Loss 5.9491e-01 (6.0192e-01)	Acc@1  79.20 ( 78.34)
Epoch: [112][40/59]	Time  1.559 ( 1.522)	Data  0.021 ( 0.025)	InnerLoop  0.654 ( 0.653)	Loss 5.3881e-01 (6.3141e-01)	Acc@1  81.30 ( 77.56)
The current update step is 6667
GPU_0_using curriculum 20 with window 20
Epoch: [113][20/59]	Time  1.487 ( 1.502)	Data  0.020 ( 0.033)	InnerLoop  0.632 ( 0.638)	Loss 6.9004e-01 (6.1764e-01)	Acc@1  73.44 ( 77.21)
Epoch: [113][40/59]	Time  1.512 ( 1.506)	Data  0.018 ( 0.029)	InnerLoop  0.640 ( 0.642)	Loss 1.0936e+00 (6.2600e-01)	Acc@1  64.45 ( 77.25)
The current update step is 6726
GPU_0_using curriculum 20 with window 20
Epoch: [114][20/59]	Time  1.498 ( 1.509)	Data  0.020 ( 0.032)	InnerLoop  0.638 ( 0.640)	Loss 5.8529e-01 (6.1914e-01)	Acc@1  78.61 ( 77.93)
Epoch: [114][40/59]	Time  1.505 ( 1.514)	Data  0.020 ( 0.030)	InnerLoop  0.643 ( 0.645)	Loss 7.4577e-01 (6.0598e-01)	Acc@1  72.41 ( 77.96)
The current update step is 6785
The current seed is 389188118381751490
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.316
 *   Acc@1 76.844
 *   Acc@1 72.658
 *   Acc@1 73.224
 *   Acc@1 70.684
 *   Acc@1 71.203
 *   Acc@1 75.487
 *   Acc@1 76.503
 *   Acc@1 73.961
 *   Acc@1 75.058
 *   Acc@1 72.855
 *   Acc@1 73.722
Training for 300 epoch: 75.90131578947368
Training for 600 epoch: 73.3092105263158
Training for 1000 epoch: 71.76973684210526
Training for 300 epoch: 76.67375
Training for 600 epoch: 74.14125
Training for 1000 epoch: 72.46208333333334
[[75.90131578947368, 73.3092105263158, 71.76973684210526], [76.67375, 74.14125, 72.46208333333334]]
train loss 0.42436798408826193, epoch 114, best loss 0.2888210260550181, best_epoch 99
GPU_0_using curriculum 20 with window 20
Epoch: [115][20/59]	Time  1.545 ( 1.506)	Data  0.024 ( 0.020)	InnerLoop  0.668 ( 0.651)	Loss 6.8070e-01 (6.0456e-01)	Acc@1  75.20 ( 77.94)
Epoch: [115][40/59]	Time  1.613 ( 1.513)	Data  0.141 ( 0.026)	InnerLoop  0.629 ( 0.650)	Loss 5.4145e-01 (6.0107e-01)	Acc@1  80.18 ( 77.89)
The current update step is 6844
GPU_0_using curriculum 20 with window 20
Epoch: [116][20/59]	Time  1.477 ( 1.499)	Data  0.019 ( 0.031)	InnerLoop  0.624 ( 0.634)	Loss 5.7131e-01 (6.1142e-01)	Acc@1  78.12 ( 78.03)
Epoch: [116][40/59]	Time  1.490 ( 1.504)	Data  0.020 ( 0.028)	InnerLoop  0.635 ( 0.641)	Loss 5.6435e-01 (6.2034e-01)	Acc@1  78.96 ( 77.75)
The current update step is 6903
GPU_0_using curriculum 20 with window 20
Epoch: [117][20/59]	Time  1.502 ( 1.512)	Data  0.020 ( 0.033)	InnerLoop  0.638 ( 0.641)	Loss 5.4870e-01 (5.7085e-01)	Acc@1  80.18 ( 79.17)
Epoch: [117][40/59]	Time  1.636 ( 1.515)	Data  0.021 ( 0.026)	InnerLoop  0.763 ( 0.649)	Loss 5.6903e-01 (5.9010e-01)	Acc@1  80.22 ( 78.19)
The current update step is 6962
GPU_0_using curriculum 20 with window 20
Epoch: [118][20/59]	Time  1.493 ( 1.503)	Data  0.017 ( 0.025)	InnerLoop  0.638 ( 0.643)	Loss 5.6377e-01 (5.8752e-01)	Acc@1  80.27 ( 78.02)
Epoch: [118][40/59]	Time  1.602 ( 1.506)	Data  0.019 ( 0.022)	InnerLoop  0.742 ( 0.648)	Loss 4.8298e-01 (5.7415e-01)	Acc@1  82.62 ( 78.81)
The current update step is 7021
GPU_0_using curriculum 20 with window 20
Epoch: [119][20/59]	Time  1.511 ( 1.511)	Data  0.019 ( 0.025)	InnerLoop  0.651 ( 0.648)	Loss 6.7792e-01 (5.9687e-01)	Acc@1  73.58 ( 78.96)
Epoch: [119][40/59]	Time  1.643 ( 1.520)	Data  0.020 ( 0.023)	InnerLoop  0.780 ( 0.656)	Loss 5.3512e-01 (6.1466e-01)	Acc@1  81.15 ( 78.12)
The current update step is 7080
The current seed is 16530038745958567860
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.829
 *   Acc@1 72.495
 *   Acc@1 68.632
 *   Acc@1 68.787
 *   Acc@1 66.842
 *   Acc@1 67.554
 *   Acc@1 73.053
 *   Acc@1 73.516
 *   Acc@1 67.539
 *   Acc@1 67.184
 *   Acc@1 62.553
 *   Acc@1 62.964
Training for 300 epoch: 72.44078947368422
Training for 600 epoch: 68.08552631578948
Training for 1000 epoch: 64.69736842105263
Training for 300 epoch: 73.00541666666666
Training for 600 epoch: 67.98583333333333
Training for 1000 epoch: 65.25916666666666
[[72.44078947368422, 68.08552631578948, 64.69736842105263], [73.00541666666666, 67.98583333333333, 65.25916666666666]]
train loss 0.5740750924428304, epoch 119, best loss 0.2888210260550181, best_epoch 99
GPU_0_using curriculum 20 with window 20
Epoch: [120][20/59]	Time  1.618 ( 1.515)	Data  0.017 ( 0.025)	InnerLoop  0.762 ( 0.653)	Loss 5.8631e-01 (6.1759e-01)	Acc@1  79.25 ( 77.44)
Epoch: [120][40/59]	Time  1.487 ( 1.519)	Data  0.020 ( 0.023)	InnerLoop  0.633 ( 0.655)	Loss 6.1713e-01 (5.9014e-01)	Acc@1  79.20 ( 78.30)
The current update step is 7139
GPU_0_using curriculum 20 with window 20
Epoch: [121][20/59]	Time  1.492 ( 1.514)	Data  0.021 ( 0.032)	InnerLoop  0.634 ( 0.642)	Loss 5.0457e-01 (5.9358e-01)	Acc@1  81.84 ( 78.62)
Epoch: [121][40/59]	Time  1.602 ( 1.512)	Data  0.020 ( 0.029)	InnerLoop  0.747 ( 0.644)	Loss 6.7079e-01 (5.9402e-01)	Acc@1  73.73 ( 78.27)
The current update step is 7198
GPU_0_using curriculum 20 with window 20
Epoch: [122][20/59]	Time  1.479 ( 1.515)	Data  0.019 ( 0.027)	InnerLoop  0.622 ( 0.647)	Loss 5.7755e-01 (5.8000e-01)	Acc@1  79.54 ( 78.43)
Epoch: [122][40/59]	Time  1.496 ( 1.519)	Data  0.022 ( 0.026)	InnerLoop  0.632 ( 0.651)	Loss 7.4974e-01 (5.9487e-01)	Acc@1  75.20 ( 78.34)
The current update step is 7257
GPU_0_using curriculum 20 with window 20
Epoch: [123][20/59]	Time  1.494 ( 1.525)	Data  0.021 ( 0.034)	InnerLoop  0.627 ( 0.647)	Loss 4.9263e-01 (5.6478e-01)	Acc@1  81.30 ( 79.59)
Epoch: [123][40/59]	Time  1.511 ( 1.522)	Data  0.021 ( 0.030)	InnerLoop  0.645 ( 0.648)	Loss 5.2807e-01 (5.7648e-01)	Acc@1  80.96 ( 79.19)
The current update step is 7316
GPU_0_using curriculum 20 with window 20
Epoch: [124][20/59]	Time  1.474 ( 1.496)	Data  0.020 ( 0.032)	InnerLoop  0.623 ( 0.632)	Loss 5.0422e-01 (5.9271e-01)	Acc@1  81.79 ( 78.13)
Epoch: [124][40/59]	Time  1.476 ( 1.492)	Data  0.019 ( 0.028)	InnerLoop  0.627 ( 0.634)	Loss 5.7102e-01 (6.0578e-01)	Acc@1  79.93 ( 77.79)
The current update step is 7375
The current seed is 525020218827279491
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.974
 *   Acc@1 77.408
 *   Acc@1 77.711
 *   Acc@1 77.498
 *   Acc@1 77.487
 *   Acc@1 77.965
 *   Acc@1 80.000
 *   Acc@1 80.223
 *   Acc@1 77.934
 *   Acc@1 78.230
 *   Acc@1 76.289
 *   Acc@1 76.676
Training for 300 epoch: 78.48684210526315
Training for 600 epoch: 77.82236842105263
Training for 1000 epoch: 76.88815789473685
Training for 300 epoch: 78.81583333333333
Training for 600 epoch: 77.86416666666668
Training for 1000 epoch: 77.32041666666666
[[78.48684210526315, 77.82236842105263, 76.88815789473685], [78.81583333333333, 77.86416666666668, 77.32041666666666]]
train loss 0.3170895551363627, epoch 124, best loss 0.2888210260550181, best_epoch 99
GPU_0_using curriculum 20 with window 20
Epoch: [125][20/59]	Time  1.474 ( 1.500)	Data  0.018 ( 0.018)	InnerLoop  0.622 ( 0.645)	Loss 6.2682e-01 (5.6142e-01)	Acc@1  79.30 ( 79.73)
Epoch: [125][40/59]	Time  1.587 ( 1.499)	Data  0.133 ( 0.024)	InnerLoop  0.623 ( 0.641)	Loss 5.4641e-01 (5.7698e-01)	Acc@1  80.03 ( 79.07)
The current update step is 7434
GPU_0_using curriculum 20 with window 20
Epoch: [126][20/59]	Time  1.469 ( 1.489)	Data  0.020 ( 0.030)	InnerLoop  0.618 ( 0.628)	Loss 5.1461e-01 (5.6126e-01)	Acc@1  81.69 ( 79.79)
Epoch: [126][40/59]	Time  1.477 ( 1.492)	Data  0.020 ( 0.028)	InnerLoop  0.623 ( 0.634)	Loss 5.1118e-01 (5.7836e-01)	Acc@1  80.42 ( 79.22)
The current update step is 7493
GPU_0_using curriculum 20 with window 20
Epoch: [127][20/59]	Time  1.492 ( 1.490)	Data  0.021 ( 0.031)	InnerLoop  0.627 ( 0.628)	Loss 5.2930e-01 (6.4144e-01)	Acc@1  81.05 ( 76.81)
Epoch: [127][40/59]	Time  1.586 ( 1.495)	Data  0.020 ( 0.025)	InnerLoop  0.730 ( 0.638)	Loss 5.4637e-01 (6.3278e-01)	Acc@1  80.32 ( 76.84)
The current update step is 7552
GPU_0_using curriculum 20 with window 20
Epoch: [128][20/59]	Time  1.472 ( 1.488)	Data  0.017 ( 0.024)	InnerLoop  0.620 ( 0.634)	Loss 4.8934e-01 (6.1662e-01)	Acc@1  81.30 ( 77.65)
Epoch: [128][40/59]	Time  1.617 ( 1.493)	Data  0.022 ( 0.021)	InnerLoop  0.752 ( 0.640)	Loss 6.4829e-01 (5.8833e-01)	Acc@1  74.12 ( 78.57)
The current update step is 7611
GPU_0_using curriculum 20 with window 20
Epoch: [129][20/59]	Time  1.472 ( 1.495)	Data  0.017 ( 0.024)	InnerLoop  0.623 ( 0.638)	Loss 8.2391e-01 (5.4826e-01)	Acc@1  68.85 ( 80.21)
Epoch: [129][40/59]	Time  1.594 ( 1.498)	Data  0.019 ( 0.022)	InnerLoop  0.740 ( 0.643)	Loss 4.5227e-01 (5.7236e-01)	Acc@1  83.59 ( 79.16)
The current update step is 7670
The current seed is 13230806271364594250
The current lr is: 0.001
Testing Results:
 *   Acc@1 79.039
 *   Acc@1 79.507
 *   Acc@1 73.026
 *   Acc@1 73.724
 *   Acc@1 68.842
 *   Acc@1 68.729
 *   Acc@1 80.934
 *   Acc@1 81.312
 *   Acc@1 80.513
 *   Acc@1 80.901
 *   Acc@1 80.250
 *   Acc@1 80.601
Training for 300 epoch: 79.98684210526315
Training for 600 epoch: 76.76973684210526
Training for 1000 epoch: 74.54605263157895
Training for 300 epoch: 80.40916666666666
Training for 600 epoch: 77.3125
Training for 1000 epoch: 74.66499999999999
[[79.98684210526315, 76.76973684210526, 74.54605263157895], [80.40916666666666, 77.3125, 74.66499999999999]]
train loss 0.2882022131125132, epoch 129, best loss 0.2882022131125132, best_epoch 129
GPU_0_using curriculum 20 with window 20
Epoch: [130][20/59]	Time  1.600 ( 1.498)	Data  0.017 ( 0.024)	InnerLoop  0.746 ( 0.643)	Loss 6.0849e-01 (6.0211e-01)	Acc@1  78.91 ( 78.19)
Epoch: [130][40/59]	Time  1.480 ( 1.500)	Data  0.020 ( 0.022)	InnerLoop  0.625 ( 0.645)	Loss 4.9352e-01 (5.8176e-01)	Acc@1  82.08 ( 78.91)
The current update step is 7729
GPU_0_using curriculum 20 with window 20
Epoch: [131][20/59]	Time  1.488 ( 1.493)	Data  0.021 ( 0.031)	InnerLoop  0.629 ( 0.631)	Loss 4.9505e-01 (5.6719e-01)	Acc@1  83.30 ( 79.58)
Epoch: [131][40/59]	Time  1.612 ( 1.500)	Data  0.020 ( 0.028)	InnerLoop  0.748 ( 0.638)	Loss 4.7142e-01 (5.6866e-01)	Acc@1  84.33 ( 79.51)
The current update step is 7788
GPU_0_using curriculum 20 with window 20
Epoch: [132][20/59]	Time  1.486 ( 1.502)	Data  0.019 ( 0.026)	InnerLoop  0.632 ( 0.642)	Loss 7.3724e-01 (5.7692e-01)	Acc@1  78.37 ( 79.59)
Epoch: [132][40/59]	Time  1.481 ( 1.504)	Data  0.019 ( 0.025)	InnerLoop  0.624 ( 0.643)	Loss 6.0893e-01 (6.0407e-01)	Acc@1  74.17 ( 78.31)
The current update step is 7847
GPU_0_using curriculum 20 with window 20
Epoch: [133][20/59]	Time  1.547 ( 1.546)	Data  0.021 ( 0.034)	InnerLoop  0.664 ( 0.657)	Loss 8.9732e-01 (6.7572e-01)	Acc@1  68.51 ( 75.76)
Epoch: [133][40/59]	Time  1.530 ( 1.551)	Data  0.019 ( 0.031)	InnerLoop  0.652 ( 0.662)	Loss 5.5035e-01 (6.2904e-01)	Acc@1  79.88 ( 77.17)
The current update step is 7906
GPU_0_using curriculum 20 with window 20
Epoch: [134][20/59]	Time  1.478 ( 1.492)	Data  0.021 ( 0.030)	InnerLoop  0.625 ( 0.631)	Loss 8.4622e-01 (6.5900e-01)	Acc@1  70.36 ( 75.76)
Epoch: [134][40/59]	Time  1.467 ( 1.492)	Data  0.017 ( 0.027)	InnerLoop  0.623 ( 0.633)	Loss 5.8218e-01 (6.5671e-01)	Acc@1  79.54 ( 75.94)
The current update step is 7965
The current seed is 12094142164303754398
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.526
 *   Acc@1 77.501
 *   Acc@1 76.868
 *   Acc@1 76.786
 *   Acc@1 76.303
 *   Acc@1 76.158
 *   Acc@1 68.342
 *   Acc@1 68.407
 *   Acc@1 66.000
 *   Acc@1 65.984
 *   Acc@1 64.513
 *   Acc@1 64.732
Training for 300 epoch: 72.93421052631578
Training for 600 epoch: 71.43421052631578
Training for 1000 epoch: 70.40789473684211
Training for 300 epoch: 72.95375
Training for 600 epoch: 71.38499999999999
Training for 1000 epoch: 70.445
[[72.93421052631578, 71.43421052631578, 70.40789473684211], [72.95375, 71.38499999999999, 70.445]]
train loss 0.5983763564745586, epoch 134, best loss 0.2882022131125132, best_epoch 129
GPU_0_using curriculum 20 with window 20
Epoch: [135][20/59]	Time  1.473 ( 1.489)	Data  0.020 ( 0.018)	InnerLoop  0.624 ( 0.641)	Loss 6.8843e-01 (6.5244e-01)	Acc@1  73.05 ( 76.12)
Epoch: [135][40/59]	Time  1.594 ( 1.493)	Data  0.135 ( 0.024)	InnerLoop  0.627 ( 0.638)	Loss 6.5448e-01 (6.4923e-01)	Acc@1  75.29 ( 75.91)
The current update step is 8024
GPU_0_using curriculum 20 with window 20
Epoch: [136][20/59]	Time  1.479 ( 1.490)	Data  0.018 ( 0.030)	InnerLoop  0.625 ( 0.628)	Loss 9.6598e-01 (6.2074e-01)	Acc@1  62.21 ( 77.01)
Epoch: [136][40/59]	Time  1.473 ( 1.494)	Data  0.019 ( 0.027)	InnerLoop  0.622 ( 0.635)	Loss 5.7475e-01 (6.1500e-01)	Acc@1  77.49 ( 77.45)
The current update step is 8083
GPU_0_using curriculum 20 with window 20
Epoch: [137][20/59]	Time  1.492 ( 1.488)	Data  0.019 ( 0.030)	InnerLoop  0.626 ( 0.627)	Loss 6.7778e-01 (6.3718e-01)	Acc@1  75.88 ( 76.20)
Epoch: [137][40/59]	Time  1.613 ( 1.494)	Data  0.020 ( 0.025)	InnerLoop  0.748 ( 0.637)	Loss 5.6479e-01 (6.1638e-01)	Acc@1  78.52 ( 77.06)
The current update step is 8142
GPU_0_using curriculum 20 with window 20
Epoch: [138][20/59]	Time  1.473 ( 1.492)	Data  0.017 ( 0.025)	InnerLoop  0.622 ( 0.637)	Loss 5.4681e-01 (5.9021e-01)	Acc@1  80.42 ( 78.18)
Epoch: [138][40/59]	Time  1.606 ( 1.497)	Data  0.017 ( 0.021)	InnerLoop  0.749 ( 0.644)	Loss 5.8436e-01 (5.9047e-01)	Acc@1  78.08 ( 78.07)
The current update step is 8201
GPU_0_using curriculum 20 with window 20
Epoch: [139][20/59]	Time  1.477 ( 1.488)	Data  0.018 ( 0.025)	InnerLoop  0.625 ( 0.634)	Loss 6.0620e-01 (6.4145e-01)	Acc@1  78.27 ( 76.01)
Epoch: [139][40/59]	Time  1.587 ( 1.494)	Data  0.019 ( 0.022)	InnerLoop  0.736 ( 0.641)	Loss 5.5975e-01 (6.3960e-01)	Acc@1  80.81 ( 76.13)
The current update step is 8260
The current seed is 15254956379923632161
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.553
 *   Acc@1 73.336
 *   Acc@1 72.092
 *   Acc@1 72.397
 *   Acc@1 71.092
 *   Acc@1 71.343
 *   Acc@1 80.053
 *   Acc@1 80.103
 *   Acc@1 79.105
 *   Acc@1 79.309
 *   Acc@1 78.355
 *   Acc@1 79.058
Training for 300 epoch: 76.80263157894737
Training for 600 epoch: 75.59868421052632
Training for 1000 epoch: 74.72368421052632
Training for 300 epoch: 76.71958333333333
Training for 600 epoch: 75.85333333333332
Training for 1000 epoch: 75.20083333333334
[[76.80263157894737, 75.59868421052632, 74.72368421052632], [76.71958333333333, 75.85333333333332, 75.20083333333334]]
train loss 0.3200273945013682, epoch 139, best loss 0.2882022131125132, best_epoch 129
GPU_0_using curriculum 20 with window 20
Epoch: [140][20/59]	Time  1.597 ( 1.497)	Data  0.018 ( 0.024)	InnerLoop  0.747 ( 0.643)	Loss 6.4377e-01 (5.8826e-01)	Acc@1  72.61 ( 78.35)
Epoch: [140][40/59]	Time  1.493 ( 1.499)	Data  0.017 ( 0.022)	InnerLoop  0.630 ( 0.644)	Loss 5.5936e-01 (6.2199e-01)	Acc@1  79.10 ( 77.24)
The current update step is 8319
GPU_0_using curriculum 20 with window 20
Epoch: [141][20/59]	Time  1.472 ( 1.491)	Data  0.017 ( 0.031)	InnerLoop  0.623 ( 0.630)	Loss 5.8373e-01 (5.9331e-01)	Acc@1  78.32 ( 78.12)
Epoch: [141][40/59]	Time  1.582 ( 1.494)	Data  0.017 ( 0.028)	InnerLoop  0.734 ( 0.636)	Loss 5.9491e-01 (6.0988e-01)	Acc@1  75.15 ( 77.31)
The current update step is 8378
GPU_0_using curriculum 20 with window 20
Epoch: [142][20/59]	Time  1.472 ( 1.488)	Data  0.018 ( 0.025)	InnerLoop  0.625 ( 0.633)	Loss 6.0000e-01 (6.1220e-01)	Acc@1  78.37 ( 77.18)
Epoch: [142][40/59]	Time  1.477 ( 1.493)	Data  0.018 ( 0.025)	InnerLoop  0.627 ( 0.637)	Loss 6.0747e-01 (6.0835e-01)	Acc@1  77.98 ( 77.23)
The current update step is 8437
GPU_0_using curriculum 20 with window 20
Epoch: [143][20/59]	Time  1.472 ( 1.490)	Data  0.017 ( 0.030)	InnerLoop  0.622 ( 0.629)	Loss 6.0793e-01 (6.1143e-01)	Acc@1  77.93 ( 77.54)
Epoch: [143][40/59]	Time  1.483 ( 1.493)	Data  0.018 ( 0.027)	InnerLoop  0.624 ( 0.632)	Loss 7.7677e-01 (6.0511e-01)	Acc@1  68.80 ( 77.66)
The current update step is 8496
GPU_0_using curriculum 20 with window 20
Epoch: [144][20/59]	Time  1.487 ( 1.492)	Data  0.019 ( 0.030)	InnerLoop  0.628 ( 0.629)	Loss 6.5081e-01 (6.1118e-01)	Acc@1  76.27 ( 77.17)
Epoch: [144][40/59]	Time  1.482 ( 1.493)	Data  0.020 ( 0.027)	InnerLoop  0.629 ( 0.633)	Loss 5.0442e-01 (5.9034e-01)	Acc@1  81.98 ( 78.16)
The current update step is 8555
The current seed is 11988297259576079271
The current lr is: 0.001
Testing Results:
 *   Acc@1 74.776
 *   Acc@1 75.332
 *   Acc@1 73.474
 *   Acc@1 74.025
 *   Acc@1 72.197
 *   Acc@1 73.058
 *   Acc@1 80.263
 *   Acc@1 80.380
 *   Acc@1 78.737
 *   Acc@1 79.346
 *   Acc@1 78.421
 *   Acc@1 78.538
Training for 300 epoch: 77.51973684210526
Training for 600 epoch: 76.10526315789474
Training for 1000 epoch: 75.30921052631578
Training for 300 epoch: 77.85624999999999
Training for 600 epoch: 76.68541666666667
Training for 1000 epoch: 75.79833333333333
[[77.51973684210526, 76.10526315789474, 75.30921052631578], [77.85624999999999, 76.68541666666667, 75.79833333333333]]
train loss 0.31799328548113504, epoch 144, best loss 0.2882022131125132, best_epoch 129
GPU_0_using curriculum 20 with window 20
Epoch: [145][20/59]	Time  1.504 ( 1.493)	Data  0.018 ( 0.018)	InnerLoop  0.645 ( 0.645)	Loss 5.8598e-01 (5.5043e-01)	Acc@1  78.86 ( 79.64)
Epoch: [145][40/59]	Time  1.580 ( 1.496)	Data  0.131 ( 0.024)	InnerLoop  0.620 ( 0.640)	Loss 6.4475e-01 (5.7535e-01)	Acc@1  75.39 ( 79.03)
The current update step is 8614
GPU_0_using curriculum 20 with window 20
Epoch: [146][20/59]	Time  1.478 ( 1.488)	Data  0.020 ( 0.031)	InnerLoop  0.627 ( 0.629)	Loss 5.3861e-01 (5.5722e-01)	Acc@1  79.00 ( 79.62)
Epoch: [146][40/59]	Time  1.484 ( 1.495)	Data  0.020 ( 0.028)	InnerLoop  0.635 ( 0.637)	Loss 4.3595e-01 (5.5232e-01)	Acc@1  85.21 ( 79.58)
The current update step is 8673
GPU_0_using curriculum 20 with window 20
Epoch: [147][20/59]	Time  1.471 ( 1.487)	Data  0.018 ( 0.031)	InnerLoop  0.619 ( 0.628)	Loss 6.7749e-01 (5.5016e-01)	Acc@1  74.85 ( 79.78)
Epoch: [147][40/59]	Time  1.588 ( 1.492)	Data  0.019 ( 0.025)	InnerLoop  0.738 ( 0.637)	Loss 6.3977e-01 (5.4460e-01)	Acc@1  74.71 ( 79.97)
The current update step is 8732
GPU_0_using curriculum 20 with window 20
Epoch: [148][20/59]	Time  1.468 ( 1.487)	Data  0.020 ( 0.026)	InnerLoop  0.621 ( 0.633)	Loss 9.6505e-01 (6.1132e-01)	Acc@1  64.60 ( 77.52)
Epoch: [148][40/59]	Time  1.586 ( 1.491)	Data  0.021 ( 0.022)	InnerLoop  0.738 ( 0.640)	Loss 6.6665e-01 (5.9285e-01)	Acc@1  74.95 ( 78.11)
The current update step is 8791
GPU_0_using curriculum 20 with window 20
Epoch: [149][20/59]	Time  1.475 ( 1.487)	Data  0.019 ( 0.024)	InnerLoop  0.621 ( 0.634)	Loss 5.0383e-01 (5.9057e-01)	Acc@1  80.66 ( 78.64)
Epoch: [149][40/59]	Time  1.601 ( 1.495)	Data  0.018 ( 0.021)	InnerLoop  0.746 ( 0.642)	Loss 4.9997e-01 (5.8247e-01)	Acc@1  81.69 ( 78.97)
The current update step is 8850
The current seed is 17477691574266382665
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.434
 *   Acc@1 73.452
 *   Acc@1 71.592
 *   Acc@1 71.388
 *   Acc@1 69.342
 *   Acc@1 69.317
 *   Acc@1 80.066
 *   Acc@1 80.436
 *   Acc@1 78.342
 *   Acc@1 78.377
 *   Acc@1 76.487
 *   Acc@1 76.661
Training for 300 epoch: 76.75
Training for 600 epoch: 74.96710526315789
Training for 1000 epoch: 72.91447368421052
Training for 300 epoch: 76.94375
Training for 600 epoch: 74.8825
Training for 1000 epoch: 72.98916666666666
[[76.75, 74.96710526315789, 72.91447368421052], [76.94375, 74.8825, 72.98916666666666]]
train loss 0.3596062717437744, epoch 149, best loss 0.2882022131125132, best_epoch 129
GPU_0_using curriculum 20 with window 20
Epoch: [150][20/59]	Time  1.592 ( 1.493)	Data  0.018 ( 0.024)	InnerLoop  0.737 ( 0.641)	Loss 7.7952e-01 (6.4374e-01)	Acc@1  73.93 ( 76.70)
Epoch: [150][40/59]	Time  1.474 ( 1.492)	Data  0.020 ( 0.021)	InnerLoop  0.622 ( 0.641)	Loss 5.9799e-01 (6.2053e-01)	Acc@1  78.47 ( 77.37)
The current update step is 8909
GPU_0_using curriculum 20 with window 20
Epoch: [151][20/59]	Time  1.477 ( 1.493)	Data  0.020 ( 0.031)	InnerLoop  0.622 ( 0.631)	Loss 4.9122e-01 (5.7526e-01)	Acc@1  83.06 ( 78.92)
Epoch: [151][40/59]	Time  1.585 ( 1.494)	Data  0.020 ( 0.028)	InnerLoop  0.735 ( 0.635)	Loss 6.0986e-01 (5.9343e-01)	Acc@1  76.86 ( 78.01)
The current update step is 8968
GPU_0_using curriculum 20 with window 20
Epoch: [152][20/59]	Time  1.469 ( 1.487)	Data  0.017 ( 0.024)	InnerLoop  0.623 ( 0.634)	Loss 5.9783e-01 (5.6679e-01)	Acc@1  77.88 ( 78.97)
Epoch: [152][40/59]	Time  1.472 ( 1.495)	Data  0.018 ( 0.025)	InnerLoop  0.625 ( 0.639)	Loss 5.2287e-01 (5.7168e-01)	Acc@1  81.69 ( 78.97)
The current update step is 9027
GPU_0_using curriculum 20 with window 20
Epoch: [153][20/59]	Time  1.476 ( 1.495)	Data  0.019 ( 0.032)	InnerLoop  0.624 ( 0.631)	Loss 5.0938e-01 (6.0635e-01)	Acc@1  80.57 ( 78.01)
Epoch: [153][40/59]	Time  1.480 ( 1.495)	Data  0.018 ( 0.028)	InnerLoop  0.627 ( 0.634)	Loss 5.9164e-01 (5.9312e-01)	Acc@1  78.71 ( 78.38)
The current update step is 9086
GPU_0_using curriculum 20 with window 20
Epoch: [154][20/59]	Time  1.490 ( 1.494)	Data  0.020 ( 0.031)	InnerLoop  0.626 ( 0.631)	Loss 5.2229e-01 (5.5416e-01)	Acc@1  80.76 ( 79.67)
Epoch: [154][40/59]	Time  1.481 ( 1.495)	Data  0.018 ( 0.028)	InnerLoop  0.627 ( 0.634)	Loss 8.0700e-01 (5.7666e-01)	Acc@1  69.73 ( 78.52)
The current update step is 9145
The current seed is 12630822937928917747
The current lr is: 0.001
Testing Results:
 *   Acc@1 80.974
 *   Acc@1 81.203
 *   Acc@1 80.934
 *   Acc@1 81.378
 *   Acc@1 79.487
 *   Acc@1 79.903
 *   Acc@1 80.184
 *   Acc@1 80.952
 *   Acc@1 77.987
 *   Acc@1 78.912
 *   Acc@1 75.776
 *   Acc@1 76.660
Training for 300 epoch: 80.57894736842105
Training for 600 epoch: 79.46052631578948
Training for 1000 epoch: 77.63157894736842
Training for 300 epoch: 81.0775
Training for 600 epoch: 80.145
Training for 1000 epoch: 78.28166666666667
[[80.57894736842105, 79.46052631578948, 77.63157894736842], [81.0775, 80.145, 78.28166666666667]]
train loss 0.3515445474624634, epoch 154, best loss 0.2882022131125132, best_epoch 129
GPU_0_using curriculum 20 with window 20
Epoch: [155][20/59]	Time  1.480 ( 1.497)	Data  0.020 ( 0.019)	InnerLoop  0.627 ( 0.645)	Loss 5.4697e-01 (5.7299e-01)	Acc@1  79.93 ( 78.95)
Epoch: [155][40/59]	Time  1.595 ( 1.500)	Data  0.135 ( 0.025)	InnerLoop  0.629 ( 0.642)	Loss 5.6460e-01 (6.0093e-01)	Acc@1  80.18 ( 77.56)
The current update step is 9204
GPU_0_using curriculum 20 with window 20
Epoch: [156][20/59]	Time  1.478 ( 1.497)	Data  0.022 ( 0.031)	InnerLoop  0.626 ( 0.632)	Loss 6.1013e-01 (6.0194e-01)	Acc@1  76.95 ( 77.43)
Epoch: [156][40/59]	Time  1.473 ( 1.498)	Data  0.018 ( 0.028)	InnerLoop  0.623 ( 0.637)	Loss 5.5495e-01 (5.9613e-01)	Acc@1  78.86 ( 77.88)
The current update step is 9263
GPU_0_using curriculum 20 with window 20
Epoch: [157][20/59]	Time  1.479 ( 1.496)	Data  0.021 ( 0.031)	InnerLoop  0.626 ( 0.631)	Loss 5.9115e-01 (5.4699e-01)	Acc@1  75.83 ( 80.02)
Epoch: [157][40/59]	Time  1.589 ( 1.499)	Data  0.020 ( 0.025)	InnerLoop  0.741 ( 0.641)	Loss 5.9799e-01 (5.5451e-01)	Acc@1  77.05 ( 79.66)
The current update step is 9322
GPU_0_using curriculum 20 with window 20
Epoch: [158][20/59]	Time  1.467 ( 1.491)	Data  0.017 ( 0.025)	InnerLoop  0.618 ( 0.636)	Loss 5.4181e-01 (5.8317e-01)	Acc@1  77.05 ( 78.91)
Epoch: [158][40/59]	Time  1.594 ( 1.498)	Data  0.018 ( 0.021)	InnerLoop  0.742 ( 0.644)	Loss 5.7975e-01 (6.0814e-01)	Acc@1  79.44 ( 77.76)
The current update step is 9381
GPU_0_using curriculum 20 with window 20
Epoch: [159][20/59]	Time  1.472 ( 1.511)	Data  0.018 ( 0.027)	InnerLoop  0.625 ( 0.644)	Loss 6.4776e-01 (5.8698e-01)	Acc@1  75.44 ( 78.12)
Epoch: [159][40/59]	Time  1.597 ( 1.505)	Data  0.021 ( 0.023)	InnerLoop  0.741 ( 0.646)	Loss 5.2681e-01 (5.9466e-01)	Acc@1  80.42 ( 77.81)
The current update step is 9440
The current seed is 5946859230898540340
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.421
 *   Acc@1 71.529
 *   Acc@1 68.342
 *   Acc@1 68.426
 *   Acc@1 65.671
 *   Acc@1 65.727
 *   Acc@1 76.921
 *   Acc@1 77.454
 *   Acc@1 76.368
 *   Acc@1 76.427
 *   Acc@1 75.934
 *   Acc@1 75.729
Training for 300 epoch: 74.17105263157895
Training for 600 epoch: 72.35526315789474
Training for 1000 epoch: 70.80263157894737
Training for 300 epoch: 74.49166666666667
Training for 600 epoch: 72.42666666666666
Training for 1000 epoch: 70.72791666666667
[[74.17105263157895, 72.35526315789474, 70.80263157894737], [74.49166666666667, 72.42666666666666, 70.72791666666667]]
train loss 0.4168970225175222, epoch 159, best loss 0.2882022131125132, best_epoch 129
GPU_0_using curriculum 20 with window 20
Epoch: [160][20/59]	Time  1.591 ( 1.513)	Data  0.019 ( 0.026)	InnerLoop  0.742 ( 0.650)	Loss 5.0353e-01 (5.8545e-01)	Acc@1  80.47 ( 78.52)
Epoch: [160][40/59]	Time  1.482 ( 1.506)	Data  0.021 ( 0.023)	InnerLoop  0.625 ( 0.647)	Loss 5.5005e-01 (5.7939e-01)	Acc@1  80.76 ( 79.09)
The current update step is 9499
GPU_0_using curriculum 20 with window 20
Epoch: [161][20/59]	Time  1.529 ( 1.553)	Data  0.020 ( 0.034)	InnerLoop  0.655 ( 0.661)	Loss 5.4438e-01 (5.7308e-01)	Acc@1  79.49 ( 79.03)
Epoch: [161][40/59]	Time  1.585 ( 1.541)	Data  0.019 ( 0.030)	InnerLoop  0.735 ( 0.660)	Loss 5.1648e-01 (5.8527e-01)	Acc@1  81.49 ( 78.76)
The current update step is 9558
GPU_0_using curriculum 20 with window 20
Epoch: [162][20/59]	Time  1.471 ( 1.491)	Data  0.019 ( 0.026)	InnerLoop  0.625 ( 0.636)	Loss 5.2931e-01 (6.2122e-01)	Acc@1  79.83 ( 77.27)
Epoch: [162][40/59]	Time  1.497 ( 1.495)	Data  0.021 ( 0.025)	InnerLoop  0.633 ( 0.639)	Loss 5.4175e-01 (6.0463e-01)	Acc@1  80.71 ( 78.12)
The current update step is 9617
GPU_0_using curriculum 20 with window 20
Epoch: [163][20/59]	Time  1.520 ( 1.549)	Data  0.019 ( 0.035)	InnerLoop  0.650 ( 0.658)	Loss 5.9094e-01 (5.6077e-01)	Acc@1  77.69 ( 79.28)
Epoch: [163][40/59]	Time  1.520 ( 1.549)	Data  0.022 ( 0.031)	InnerLoop  0.644 ( 0.663)	Loss 5.1835e-01 (5.5513e-01)	Acc@1  81.59 ( 79.72)
The current update step is 9676
GPU_0_using curriculum 20 with window 20
Epoch: [164][20/59]	Time  1.531 ( 1.550)	Data  0.023 ( 0.034)	InnerLoop  0.658 ( 0.663)	Loss 6.1838e-01 (5.8888e-01)	Acc@1  75.34 ( 78.28)
Epoch: [164][40/59]	Time  1.536 ( 1.552)	Data  0.020 ( 0.031)	InnerLoop  0.660 ( 0.666)	Loss 7.2239e-01 (5.9397e-01)	Acc@1  76.32 ( 78.19)
The current update step is 9735
The current seed is 1235562800420329125
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.000
 *   Acc@1 70.358
 *   Acc@1 67.895
 *   Acc@1 68.209
 *   Acc@1 65.579
 *   Acc@1 65.883
 *   Acc@1 75.342
 *   Acc@1 75.200
 *   Acc@1 71.882
 *   Acc@1 71.660
 *   Acc@1 69.013
 *   Acc@1 68.976
Training for 300 epoch: 72.67105263157895
Training for 600 epoch: 69.88815789473685
Training for 1000 epoch: 67.29605263157895
Training for 300 epoch: 72.77916666666667
Training for 600 epoch: 69.93458333333334
Training for 1000 epoch: 67.42958333333334
[[72.67105263157895, 69.88815789473685, 67.29605263157895], [72.77916666666667, 69.93458333333334, 67.42958333333334]]
train loss 0.6506085302352905, epoch 164, best loss 0.2882022131125132, best_epoch 129
GPU_0_using curriculum 20 with window 20
Epoch: [165][20/59]	Time  1.511 ( 1.535)	Data  0.022 ( 0.021)	InnerLoop  0.641 ( 0.666)	Loss 5.7019e-01 (6.4192e-01)	Acc@1  78.86 ( 76.77)
Epoch: [165][40/59]	Time  1.628 ( 1.540)	Data  0.145 ( 0.027)	InnerLoop  0.635 ( 0.661)	Loss 6.0791e-01 (6.1376e-01)	Acc@1  79.35 ( 77.53)
The current update step is 9794
GPU_0_using curriculum 20 with window 20
Epoch: [166][20/59]	Time  1.466 ( 1.498)	Data  0.019 ( 0.032)	InnerLoop  0.617 ( 0.634)	Loss 5.3450e-01 (5.7835e-01)	Acc@1  80.13 ( 78.78)
Epoch: [166][40/59]	Time  1.480 ( 1.498)	Data  0.018 ( 0.028)	InnerLoop  0.629 ( 0.638)	Loss 5.6973e-01 (5.7792e-01)	Acc@1  76.86 ( 78.92)
The current update step is 9853
GPU_0_using curriculum 20 with window 20
Epoch: [167][20/59]	Time  1.478 ( 1.495)	Data  0.018 ( 0.031)	InnerLoop  0.625 ( 0.632)	Loss 5.0680e-01 (5.6538e-01)	Acc@1  82.47 ( 78.88)
Epoch: [167][40/59]	Time  1.584 ( 1.498)	Data  0.020 ( 0.025)	InnerLoop  0.737 ( 0.642)	Loss 5.7757e-01 (5.6665e-01)	Acc@1  78.71 ( 79.20)
The current update step is 9912
GPU_0_using curriculum 20 with window 20
Epoch: [168][20/59]	Time  1.464 ( 1.488)	Data  0.018 ( 0.024)	InnerLoop  0.618 ( 0.635)	Loss 4.8082e-01 (5.7328e-01)	Acc@1  82.71 ( 79.11)
Epoch: [168][40/59]	Time  1.592 ( 1.494)	Data  0.019 ( 0.021)	InnerLoop  0.740 ( 0.642)	Loss 5.4272e-01 (5.7631e-01)	Acc@1  79.93 ( 79.09)
The current update step is 9971
GPU_0_using curriculum 20 with window 20
Epoch: [169][20/59]	Time  1.487 ( 1.492)	Data  0.019 ( 0.025)	InnerLoop  0.631 ( 0.637)	Loss 5.7120e-01 (5.6245e-01)	Acc@1  79.44 ( 79.22)
Epoch: [169][40/59]	Time  1.595 ( 1.494)	Data  0.017 ( 0.022)	InnerLoop  0.745 ( 0.643)	Loss 5.3110e-01 (5.6028e-01)	Acc@1  80.32 ( 79.40)
The current update step is 10030
The current seed is 4414056890674481953
The current lr is: 0.001
Testing Results:
 *   Acc@1 80.474
 *   Acc@1 80.844
 *   Acc@1 77.974
 *   Acc@1 78.456
 *   Acc@1 75.053
 *   Acc@1 75.251
 *   Acc@1 73.487
 *   Acc@1 73.515
 *   Acc@1 68.789
 *   Acc@1 68.996
 *   Acc@1 66.421
 *   Acc@1 66.359
Training for 300 epoch: 76.98026315789474
Training for 600 epoch: 73.38157894736841
Training for 1000 epoch: 70.73684210526315
Training for 300 epoch: 77.17958333333334
Training for 600 epoch: 73.72583333333333
Training for 1000 epoch: 70.805
[[76.98026315789474, 73.38157894736841, 70.73684210526315], [77.17958333333334, 73.72583333333333, 70.805]]
train loss 0.7241909904162089, epoch 169, best loss 0.2882022131125132, best_epoch 129
GPU_0_using curriculum 20 with window 20
Epoch: [170][20/59]	Time  1.611 ( 1.501)	Data  0.017 ( 0.025)	InnerLoop  0.753 ( 0.646)	Loss 6.4088e-01 (5.5706e-01)	Acc@1  77.49 ( 79.80)
Epoch: [170][40/59]	Time  1.482 ( 1.501)	Data  0.020 ( 0.022)	InnerLoop  0.632 ( 0.646)	Loss 5.5939e-01 (5.4950e-01)	Acc@1  77.69 ( 79.86)
The current update step is 10089
GPU_0_using curriculum 20 with window 20
Epoch: [171][20/59]	Time  1.472 ( 1.489)	Data  0.019 ( 0.031)	InnerLoop  0.625 ( 0.630)	Loss 6.7887e-01 (5.4927e-01)	Acc@1  77.10 ( 80.33)
Epoch: [171][40/59]	Time  1.585 ( 1.494)	Data  0.018 ( 0.028)	InnerLoop  0.733 ( 0.637)	Loss 6.1263e-01 (5.5532e-01)	Acc@1  77.88 ( 79.97)
The current update step is 10148
GPU_0_using curriculum 20 with window 20
Epoch: [172][20/59]	Time  1.473 ( 1.490)	Data  0.019 ( 0.025)	InnerLoop  0.628 ( 0.637)	Loss 5.9723e-01 (5.6331e-01)	Acc@1  79.64 ( 79.50)
Epoch: [172][40/59]	Time  1.473 ( 1.494)	Data  0.018 ( 0.025)	InnerLoop  0.622 ( 0.640)	Loss 5.7994e-01 (5.5824e-01)	Acc@1  78.08 ( 79.73)
The current update step is 10207
GPU_0_using curriculum 20 with window 20
Epoch: [173][20/59]	Time  1.475 ( 1.496)	Data  0.017 ( 0.031)	InnerLoop  0.623 ( 0.633)	Loss 5.3843e-01 (5.3774e-01)	Acc@1  78.42 ( 80.30)
Epoch: [173][40/59]	Time  1.483 ( 1.497)	Data  0.018 ( 0.028)	InnerLoop  0.627 ( 0.636)	Loss 5.6120e-01 (5.5080e-01)	Acc@1  79.15 ( 79.82)
The current update step is 10266
GPU_0_using curriculum 20 with window 20
Epoch: [174][20/59]	Time  1.482 ( 1.491)	Data  0.019 ( 0.030)	InnerLoop  0.628 ( 0.632)	Loss 5.0350e-01 (5.3340e-01)	Acc@1  81.10 ( 80.74)
Epoch: [174][40/59]	Time  1.486 ( 1.493)	Data  0.019 ( 0.027)	InnerLoop  0.626 ( 0.634)	Loss 5.1581e-01 (5.5016e-01)	Acc@1  82.13 ( 80.01)
The current update step is 10325
The current seed is 6078711259915537312
The current lr is: 0.001
Testing Results:
 *   Acc@1 81.224
 *   Acc@1 81.445
 *   Acc@1 78.566
 *   Acc@1 78.733
 *   Acc@1 75.618
 *   Acc@1 75.882
 *   Acc@1 69.921
 *   Acc@1 70.342
 *   Acc@1 65.237
 *   Acc@1 65.653
 *   Acc@1 63.605
 *   Acc@1 64.123
Training for 300 epoch: 75.57236842105263
Training for 600 epoch: 71.90131578947368
Training for 1000 epoch: 69.61184210526315
Training for 300 epoch: 75.89333333333333
Training for 600 epoch: 72.19333333333333
Training for 1000 epoch: 70.0025
[[75.57236842105263, 71.90131578947368, 69.61184210526315], [75.89333333333333, 72.19333333333333, 70.0025]]
train loss 0.6586049760182698, epoch 174, best loss 0.2882022131125132, best_epoch 129
GPU_0_using curriculum 20 with window 20
Epoch: [175][20/59]	Time  1.471 ( 1.490)	Data  0.020 ( 0.018)	InnerLoop  0.624 ( 0.642)	Loss 6.0452e-01 (5.3593e-01)	Acc@1  78.86 ( 80.63)
Epoch: [175][40/59]	Time  1.584 ( 1.494)	Data  0.135 ( 0.025)	InnerLoop  0.619 ( 0.639)	Loss 6.6210e-01 (5.5931e-01)	Acc@1  76.03 ( 79.59)
The current update step is 10384
GPU_0_using curriculum 20 with window 20
Epoch: [176][20/59]	Time  1.494 ( 1.497)	Data  0.021 ( 0.031)	InnerLoop  0.631 ( 0.633)	Loss 5.0121e-01 (5.4905e-01)	Acc@1  82.08 ( 79.82)
Epoch: [176][40/59]	Time  1.467 ( 1.499)	Data  0.017 ( 0.028)	InnerLoop  0.623 ( 0.639)	Loss 5.2948e-01 (5.6668e-01)	Acc@1  80.32 ( 79.23)
The current update step is 10443
GPU_0_using curriculum 20 with window 20
Epoch: [177][20/59]	Time  1.484 ( 1.491)	Data  0.020 ( 0.031)	InnerLoop  0.628 ( 0.630)	Loss 5.9889e-01 (5.9546e-01)	Acc@1  77.29 ( 78.45)
Epoch: [177][40/59]	Time  1.592 ( 1.496)	Data  0.017 ( 0.025)	InnerLoop  0.742 ( 0.640)	Loss 8.9982e-01 (5.9986e-01)	Acc@1  70.17 ( 78.16)
The current update step is 10502
GPU_0_using curriculum 20 with window 20
Epoch: [178][20/59]	Time  1.465 ( 1.488)	Data  0.018 ( 0.024)	InnerLoop  0.619 ( 0.635)	Loss 5.3768e-01 (5.9641e-01)	Acc@1  81.54 ( 77.85)
Epoch: [178][40/59]	Time  1.598 ( 1.493)	Data  0.018 ( 0.021)	InnerLoop  0.748 ( 0.641)	Loss 5.7820e-01 (5.7332e-01)	Acc@1  78.03 ( 78.88)
The current update step is 10561
GPU_0_using curriculum 20 with window 20
Epoch: [179][20/59]	Time  1.492 ( 1.494)	Data  0.022 ( 0.025)	InnerLoop  0.635 ( 0.637)	Loss 5.6610e-01 (5.6229e-01)	Acc@1  79.30 ( 79.18)
Epoch: [179][40/59]	Time  1.590 ( 1.497)	Data  0.017 ( 0.022)	InnerLoop  0.742 ( 0.643)	Loss 6.1610e-01 (5.5375e-01)	Acc@1  76.42 ( 79.52)
The current update step is 10620
The current seed is 16161637717780240232
The current lr is: 0.001
Testing Results:
 *   Acc@1 75.908
 *   Acc@1 76.131
 *   Acc@1 72.289
 *   Acc@1 72.794
 *   Acc@1 69.737
 *   Acc@1 70.103
 *   Acc@1 81.842
 *   Acc@1 81.917
 *   Acc@1 80.368
 *   Acc@1 80.279
 *   Acc@1 79.197
 *   Acc@1 79.032
Training for 300 epoch: 78.875
Training for 600 epoch: 76.32894736842104
Training for 1000 epoch: 74.46710526315789
Training for 300 epoch: 79.02375
Training for 600 epoch: 76.53666666666666
Training for 1000 epoch: 74.5675
[[78.875, 76.32894736842104, 74.46710526315789], [79.02375, 76.53666666666666, 74.5675]]
train loss 0.38515727570851643, epoch 179, best loss 0.2882022131125132, best_epoch 129
GPU_0_using curriculum 20 with window 20
Epoch: [180][20/59]	Time  1.591 ( 1.497)	Data  0.017 ( 0.024)	InnerLoop  0.741 ( 0.643)	Loss 5.3052e-01 (5.3436e-01)	Acc@1  80.22 ( 79.88)
Epoch: [180][40/59]	Time  1.473 ( 1.494)	Data  0.017 ( 0.021)	InnerLoop  0.628 ( 0.642)	Loss 5.0858e-01 (5.5661e-01)	Acc@1  81.49 ( 79.29)
The current update step is 10679
GPU_0_using curriculum 20 with window 20
Epoch: [181][20/59]	Time  1.472 ( 1.490)	Data  0.019 ( 0.031)	InnerLoop  0.622 ( 0.629)	Loss 5.7697e-01 (5.4229e-01)	Acc@1  79.00 ( 79.71)
Epoch: [181][40/59]	Time  1.592 ( 1.493)	Data  0.018 ( 0.028)	InnerLoop  0.738 ( 0.635)	Loss 5.2713e-01 (5.5754e-01)	Acc@1  79.69 ( 79.54)
The current update step is 10738
GPU_0_using curriculum 20 with window 20
Epoch: [182][20/59]	Time  1.464 ( 1.496)	Data  0.018 ( 0.025)	InnerLoop  0.621 ( 0.638)	Loss 4.7134e-01 (5.6363e-01)	Acc@1  83.40 ( 79.42)
Epoch: [182][40/59]	Time  1.476 ( 1.496)	Data  0.018 ( 0.025)	InnerLoop  0.627 ( 0.639)	Loss 4.7491e-01 (5.4974e-01)	Acc@1  83.35 ( 79.79)
The current update step is 10797
GPU_0_using curriculum 20 with window 20
Epoch: [183][20/59]	Time  1.472 ( 1.491)	Data  0.017 ( 0.030)	InnerLoop  0.624 ( 0.631)	Loss 6.3637e-01 (5.4117e-01)	Acc@1  76.90 ( 80.37)
Epoch: [183][40/59]	Time  1.477 ( 1.494)	Data  0.018 ( 0.027)	InnerLoop  0.628 ( 0.634)	Loss 5.3163e-01 (5.3629e-01)	Acc@1  81.30 ( 80.43)
The current update step is 10856
GPU_0_using curriculum 20 with window 20
Epoch: [184][20/59]	Time  1.478 ( 1.489)	Data  0.020 ( 0.031)	InnerLoop  0.628 ( 0.630)	Loss 4.9018e-01 (5.6732e-01)	Acc@1  82.28 ( 79.42)
Epoch: [184][40/59]	Time  1.472 ( 1.490)	Data  0.019 ( 0.028)	InnerLoop  0.625 ( 0.633)	Loss 7.5394e-01 (5.5146e-01)	Acc@1  75.88 ( 79.91)
The current update step is 10915
The current seed is 1596335701260857971
The current lr is: 0.001
Testing Results:
 *   Acc@1 72.605
 *   Acc@1 73.257
 *   Acc@1 69.421
 *   Acc@1 69.948
 *   Acc@1 67.118
 *   Acc@1 67.448
 *   Acc@1 77.934
 *   Acc@1 78.074
 *   Acc@1 73.224
 *   Acc@1 73.475
 *   Acc@1 69.039
 *   Acc@1 69.445
Training for 300 epoch: 75.26973684210526
Training for 600 epoch: 71.32236842105263
Training for 1000 epoch: 68.07894736842104
Training for 300 epoch: 75.66541666666666
Training for 600 epoch: 71.71125
Training for 1000 epoch: 68.44624999999999
[[75.26973684210526, 71.32236842105263, 68.07894736842104], [75.66541666666666, 71.71125, 68.44624999999999]]
train loss 0.5205939476331075, epoch 184, best loss 0.2882022131125132, best_epoch 129
GPU_0_using curriculum 20 with window 20
Epoch: [185][20/59]	Time  1.487 ( 1.491)	Data  0.020 ( 0.018)	InnerLoop  0.626 ( 0.642)	Loss 6.2535e-01 (5.6364e-01)	Acc@1  75.39 ( 79.62)
Epoch: [185][40/59]	Time  1.586 ( 1.494)	Data  0.133 ( 0.024)	InnerLoop  0.618 ( 0.639)	Loss 5.3409e-01 (5.6766e-01)	Acc@1  80.86 ( 79.52)
The current update step is 10974
GPU_0_using curriculum 20 with window 20
Epoch: [186][20/59]	Time  1.479 ( 1.487)	Data  0.020 ( 0.030)	InnerLoop  0.626 ( 0.628)	Loss 5.5283e-01 (5.7366e-01)	Acc@1  79.44 ( 79.58)
Epoch: [186][40/59]	Time  1.462 ( 1.492)	Data  0.018 ( 0.027)	InnerLoop  0.620 ( 0.635)	Loss 5.5966e-01 (5.6570e-01)	Acc@1  79.35 ( 79.90)
The current update step is 11033
GPU_0_using curriculum 20 with window 20
Epoch: [187][20/59]	Time  1.472 ( 1.485)	Data  0.019 ( 0.031)	InnerLoop  0.628 ( 0.626)	Loss 7.4283e-01 (5.6514e-01)	Acc@1  72.90 ( 79.54)
Epoch: [187][40/59]	Time  1.581 ( 1.490)	Data  0.019 ( 0.025)	InnerLoop  0.739 ( 0.636)	Loss 5.1754e-01 (5.5379e-01)	Acc@1  81.35 ( 79.90)
The current update step is 11092
GPU_0_using curriculum 20 with window 20
Epoch: [188][20/59]	Time  1.472 ( 1.490)	Data  0.019 ( 0.025)	InnerLoop  0.623 ( 0.636)	Loss 6.3636e-01 (5.7229e-01)	Acc@1  76.61 ( 79.36)
Epoch: [188][40/59]	Time  1.592 ( 1.493)	Data  0.020 ( 0.021)	InnerLoop  0.738 ( 0.641)	Loss 6.8372e-01 (5.8006e-01)	Acc@1  74.80 ( 79.00)
The current update step is 11151
GPU_0_using curriculum 20 with window 20
Epoch: [189][20/59]	Time  1.473 ( 1.489)	Data  0.018 ( 0.024)	InnerLoop  0.629 ( 0.637)	Loss 5.9259e-01 (5.5293e-01)	Acc@1  79.35 ( 79.66)
Epoch: [189][40/59]	Time  1.592 ( 1.493)	Data  0.018 ( 0.021)	InnerLoop  0.738 ( 0.643)	Loss 5.2470e-01 (5.4364e-01)	Acc@1  81.49 ( 80.30)
The current update step is 11210
The current seed is 16102699578982215709
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.868
 *   Acc@1 77.835
 *   Acc@1 75.382
 *   Acc@1 75.948
 *   Acc@1 73.671
 *   Acc@1 74.078
 *   Acc@1 81.368
 *   Acc@1 81.672
 *   Acc@1 80.263
 *   Acc@1 80.787
 *   Acc@1 79.829
 *   Acc@1 79.877
Training for 300 epoch: 79.11842105263158
Training for 600 epoch: 77.82236842105263
Training for 1000 epoch: 76.75
Training for 300 epoch: 79.75375
Training for 600 epoch: 78.36708333333334
Training for 1000 epoch: 76.97791666666666
[[79.11842105263158, 77.82236842105263, 76.75], [79.75375, 78.36708333333334, 76.97791666666666]]
train loss 0.36080595328013104, epoch 189, best loss 0.2882022131125132, best_epoch 189
GPU_0_using curriculum 20 with window 20
Epoch: [190][20/59]	Time  1.584 ( 1.490)	Data  0.017 ( 0.024)	InnerLoop  0.736 ( 0.638)	Loss 7.2220e-01 (5.9799e-01)	Acc@1  74.32 ( 78.72)
Epoch: [190][40/59]	Time  1.466 ( 1.490)	Data  0.020 ( 0.021)	InnerLoop  0.619 ( 0.639)	Loss 6.5170e-01 (5.8830e-01)	Acc@1  77.59 ( 78.85)
The current update step is 11269
GPU_0_using curriculum 20 with window 20
Epoch: [191][20/59]	Time  1.474 ( 1.487)	Data  0.019 ( 0.031)	InnerLoop  0.624 ( 0.627)	Loss 5.0502e-01 (5.6554e-01)	Acc@1  81.59 ( 79.71)
Epoch: [191][40/59]	Time  1.590 ( 1.493)	Data  0.017 ( 0.028)	InnerLoop  0.741 ( 0.636)	Loss 4.9678e-01 (5.5396e-01)	Acc@1  82.03 ( 80.04)
The current update step is 11328
GPU_0_using curriculum 20 with window 20
Epoch: [192][20/59]	Time  1.469 ( 1.487)	Data  0.019 ( 0.025)	InnerLoop  0.624 ( 0.634)	Loss 4.7669e-01 (5.3885e-01)	Acc@1  83.84 ( 80.45)
Epoch: [192][40/59]	Time  1.489 ( 1.491)	Data  0.019 ( 0.025)	InnerLoop  0.633 ( 0.638)	Loss 5.6443e-01 (5.4373e-01)	Acc@1  81.25 ( 80.49)
The current update step is 11387
GPU_0_using curriculum 20 with window 20
Epoch: [193][20/59]	Time  1.475 ( 1.487)	Data  0.018 ( 0.030)	InnerLoop  0.624 ( 0.627)	Loss 5.6540e-01 (5.5791e-01)	Acc@1  79.83 ( 79.82)
Epoch: [193][40/59]	Time  1.465 ( 1.488)	Data  0.016 ( 0.027)	InnerLoop  0.622 ( 0.631)	Loss 5.1587e-01 (5.6381e-01)	Acc@1  81.54 ( 79.60)
The current update step is 11446
GPU_0_using curriculum 20 with window 20
Epoch: [194][20/59]	Time  1.467 ( 1.489)	Data  0.017 ( 0.030)	InnerLoop  0.624 ( 0.630)	Loss 5.3399e-01 (5.3968e-01)	Acc@1  80.86 ( 80.42)
Epoch: [194][40/59]	Time  1.476 ( 1.489)	Data  0.017 ( 0.027)	InnerLoop  0.622 ( 0.633)	Loss 5.1430e-01 (5.7783e-01)	Acc@1  80.71 ( 79.17)
The current update step is 11505
The current seed is 9707588001248672842
The current lr is: 0.001
Testing Results:
 *   Acc@1 79.645
 *   Acc@1 79.691
 *   Acc@1 72.342
 *   Acc@1 72.711
 *   Acc@1 65.566
 *   Acc@1 66.270
 *   Acc@1 82.342
 *   Acc@1 82.776
 *   Acc@1 82.026
 *   Acc@1 82.385
 *   Acc@1 81.934
 *   Acc@1 82.022
Training for 300 epoch: 80.99342105263158
Training for 600 epoch: 77.18421052631578
Training for 1000 epoch: 73.75
Training for 300 epoch: 81.23333333333333
Training for 600 epoch: 77.54791666666667
Training for 1000 epoch: 74.14625
[[80.99342105263158, 77.18421052631578, 73.75], [81.23333333333333, 77.54791666666667, 74.14625]]
train loss 0.2849658932685852, epoch 194, best loss 0.2849658932685852, best_epoch 194
GPU_0_using curriculum 20 with window 20
Epoch: [195][20/59]	Time  1.474 ( 1.488)	Data  0.019 ( 0.019)	InnerLoop  0.621 ( 0.640)	Loss 4.9448e-01 (5.6396e-01)	Acc@1  82.96 ( 79.25)
Epoch: [195][40/59]	Time  1.590 ( 1.491)	Data  0.143 ( 0.025)	InnerLoop  0.621 ( 0.636)	Loss 5.0390e-01 (5.6363e-01)	Acc@1  81.40 ( 79.34)
The current update step is 11564
GPU_0_using curriculum 20 with window 20
Epoch: [196][20/59]	Time  1.473 ( 1.486)	Data  0.021 ( 0.030)	InnerLoop  0.619 ( 0.627)	Loss 4.6767e-01 (5.4134e-01)	Acc@1  82.28 ( 80.52)
Epoch: [196][40/59]	Time  1.493 ( 1.494)	Data  0.018 ( 0.027)	InnerLoop  0.628 ( 0.635)	Loss 4.9491e-01 (5.3820e-01)	Acc@1  81.45 ( 80.59)
The current update step is 11623
GPU_0_using curriculum 20 with window 20
Epoch: [197][20/59]	Time  1.479 ( 1.493)	Data  0.018 ( 0.030)	InnerLoop  0.626 ( 0.632)	Loss 7.2007e-01 (5.8929e-01)	Acc@1  76.27 ( 78.81)
Epoch: [197][40/59]	Time  1.589 ( 1.496)	Data  0.017 ( 0.024)	InnerLoop  0.739 ( 0.640)	Loss 5.1449e-01 (5.5539e-01)	Acc@1  81.59 ( 79.97)
The current update step is 11682
GPU_0_using curriculum 20 with window 20
Epoch: [198][20/59]	Time  1.472 ( 1.489)	Data  0.018 ( 0.024)	InnerLoop  0.624 ( 0.636)	Loss 5.7151e-01 (5.2984e-01)	Acc@1  78.32 ( 81.07)
Epoch: [198][40/59]	Time  1.608 ( 1.494)	Data  0.021 ( 0.022)	InnerLoop  0.751 ( 0.642)	Loss 5.1176e-01 (5.4050e-01)	Acc@1  80.91 ( 80.52)
The current update step is 11741
GPU_0_using curriculum 20 with window 20
Epoch: [199][20/59]	Time  1.483 ( 1.491)	Data  0.020 ( 0.025)	InnerLoop  0.630 ( 0.637)	Loss 5.7880e-01 (5.3553e-01)	Acc@1  79.88 ( 80.33)
Epoch: [199][40/59]	Time  1.613 ( 1.494)	Data  0.020 ( 0.021)	InnerLoop  0.752 ( 0.642)	Loss 6.5132e-01 (5.5679e-01)	Acc@1  77.64 ( 79.43)
The current update step is 11800
The current seed is 8842646518793031207
The current lr is: 0.001
Testing Results:
 *   Acc@1 80.855
 *   Acc@1 80.731
 *   Acc@1 79.579
 *   Acc@1 79.939
 *   Acc@1 78.803
 *   Acc@1 78.951
 *   Acc@1 73.329
 *   Acc@1 73.873
 *   Acc@1 73.145
 *   Acc@1 73.567
 *   Acc@1 72.539
 *   Acc@1 73.261
Training for 300 epoch: 77.09210526315789
Training for 600 epoch: 76.36184210526315
Training for 1000 epoch: 75.67105263157895
Training for 300 epoch: 77.30208333333334
Training for 600 epoch: 76.75333333333333
Training for 1000 epoch: 76.10583333333334
[[77.09210526315789, 76.36184210526315, 75.67105263157895], [77.30208333333334, 76.75333333333333, 76.10583333333334]]
train loss 0.4698213123321533, epoch 199, best loss 0.2849658932685852, best_epoch 194
=== Final results:
{'acc': 80.99342105263158, 'test': [80.99342105263158, 77.18421052631578, 73.75], 'train': [80.99342105263158, 77.18421052631578, 73.75], 'ind': 0, 'epoch': 195, 'data': array([[-0.08986609, -0.05857462, -0.049861  , ..., -0.021443  ,
         0.02584685, -0.1128976 ],
       [ 0.0898763 , -0.02881539,  0.03534324, ..., -0.0481244 ,
         0.0002243 ,  0.12427827],
       [-0.04048903,  0.12405844, -0.03931024, ..., -0.03440378,
        -0.00399968,  0.0043323 ],
       ...,
       [-0.05524886,  0.14726414, -0.02209581, ..., -0.03622314,
         0.03950078, -0.0157069 ],
       [-0.16822185,  0.04734216, -0.10528845, ..., -0.11552206,
         0.04193616, -0.04949257],
       [-0.08224791,  0.05426656, -0.05562815, ..., -0.0496689 ,
        -0.01461236, -0.12643078]], shape=(40, 768), dtype=float32)}
