Torch Seed Specified with rank: 0
Dataset: agnews_emb
Dataset Path: ./scripts
Namespace(seed=0, mp_distributed=False, world_size=1, rank=0, dist_url='tcp://224.66.41.62:23456', dist_backend='nccl', workers=0, gpu=None, root='./scripts', dataset='agnews_emb', arch='text_transformer', width=256, lr=0.0012, inner_optim='Adam', outer_optim='Adam', inner_lr=0.001, label_lr_scale=1, num_per_class=20, batch_per_class=12, task_sampler_nc=5, window=20, minwindow=0, totwindow=40, num_train_eval=2, train_y=False, batch_size=3072, eps=1e-08, wd=0, test_freq=5, print_freq=20, start_epoch=0, epochs=170, ddtype='standard', cctype=0, zca=False, wandb=False, clip_coef=0.9, fname='out_tf_ratbptt_ipc20_s3_w20t40', out_dir='./checkpoints', name='agnews_tf_ratbptt_s3_w20t40', comp_aug=False, comp_aug_real=False, syn_strategy='none', real_strategy='none', ckptname='none', limit_train=False, load_ckpt=False, complete_random=False, boost_dd=False, boost_init_from='none', boost_beta=1.0, stage=3, distributed=False, data_root='./scripts/agnews_emb')
==> Preparing data..
None None
Dataset: number of classes: 4
Training set size: 120000
Image size: channel 1, height 768, width 1
Synthetic images, not_single False, keys []
==> Building model..
Initialized data with size, x: torch.Size([80, 768]), y:torch.Size([80])
TextTransformer(
  (input_proj): Linear(in_features=192, out_features=256, bias=True)
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=1024, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=1024, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (cls_head): Linear(in_features=256, out_features=4, bias=True)
)
use data parallel only
GPU_0_using curriculum 20 with window 20
Epoch: [0][20/40]	Time  1.639 ( 1.709)	Data  0.030 ( 0.046)	InnerLoop  0.684 ( 0.742)	Loss 2.9913e+00 (3.3640e+00)	Acc@1  40.01 ( 34.47)
Epoch: [0][40/40]	Time  1.717 ( 1.676)	Data  0.012 ( 0.044)	InnerLoop  0.817 ( 0.721)	Loss 1.2330e+00 (2.6059e+00)	Acc@1  56.77 ( 42.58)
The current update step is 40
GPU_0_using curriculum 20 with window 20
Epoch: [1][20/40]	Time  1.612 ( 1.630)	Data  0.034 ( 0.044)	InnerLoop  0.677 ( 0.689)	Loss 2.3877e+00 (1.7100e+00)	Acc@1  44.63 ( 50.14)
Epoch: [1][40/40]	Time  1.580 ( 1.631)	Data  0.013 ( 0.041)	InnerLoop  0.679 ( 0.689)	Loss 1.3816e+00 (1.6033e+00)	Acc@1  53.65 ( 51.82)
The current update step is 80
GPU_0_using curriculum 20 with window 20
Epoch: [2][20/40]	Time  1.735 ( 1.643)	Data  0.035 ( 0.052)	InnerLoop  0.808 ( 0.691)	Loss 9.6331e-01 (1.5155e+00)	Acc@1  67.48 ( 56.83)
Epoch: [2][40/40]	Time  1.561 ( 1.635)	Data  0.013 ( 0.048)	InnerLoop  0.667 ( 0.687)	Loss 8.7655e-01 (1.6226e+00)	Acc@1  69.27 ( 53.50)
The current update step is 120
GPU_0_using curriculum 20 with window 20
Epoch: [3][20/40]	Time  1.572 ( 1.598)	Data  0.031 ( 0.049)	InnerLoop  0.659 ( 0.664)	Loss 7.6713e-01 (1.2843e+00)	Acc@1  71.74 ( 59.48)
Epoch: [3][40/40]	Time  1.545 ( 1.601)	Data  0.013 ( 0.043)	InnerLoop  0.656 ( 0.672)	Loss 9.3744e-01 (1.1857e+00)	Acc@1  71.35 ( 60.62)
The current update step is 160
GPU_0_using curriculum 20 with window 20
Epoch: [4][20/40]	Time  1.596 ( 1.629)	Data  0.035 ( 0.046)	InnerLoop  0.665 ( 0.690)	Loss 8.5814e-01 (1.4308e+00)	Acc@1  68.49 ( 55.54)
Epoch: [4][40/40]	Time  1.544 ( 1.617)	Data  0.010 ( 0.044)	InnerLoop  0.662 ( 0.682)	Loss 1.2267e+00 (1.2953e+00)	Acc@1  56.77 ( 59.26)
The current update step is 200
The current seed is 10971026752066930356
The current lr is: 0.001
Testing Results:
 *   Acc@1 57.329
 *   Acc@1 56.389
 *   Acc@1 53.645
 *   Acc@1 53.421
 *   Acc@1 52.684
 *   Acc@1 52.136
 *   Acc@1 51.276
 *   Acc@1 51.662
 *   Acc@1 53.895
 *   Acc@1 54.643
 *   Acc@1 55.039
 *   Acc@1 55.602
Training for 300 epoch: 54.30263157894737
Training for 600 epoch: 53.76973684210526
Training for 1000 epoch: 53.86184210526316
Training for 300 epoch: 54.02541666666667
Training for 600 epoch: 54.03208333333333
Training for 1000 epoch: 53.869166666666665
[[54.30263157894737, 53.76973684210526, 53.86184210526316], [54.02541666666667, 54.03208333333333, 53.869166666666665]]
train loss 0.9152910251617432, epoch 4, best loss 0.9152910251617432, best_epoch 4
GPU_0_using curriculum 20 with window 20
Epoch: [5][20/40]	Time  1.578 ( 1.590)	Data  0.033 ( 0.043)	InnerLoop  0.657 ( 0.668)	Loss 9.2602e-01 (1.0972e+00)	Acc@1  68.33 ( 64.16)
Epoch: [5][40/40]	Time  1.513 ( 1.588)	Data  0.009 ( 0.039)	InnerLoop  0.640 ( 0.671)	Loss 8.3398e-01 (1.0150e+00)	Acc@1  71.35 ( 65.93)
The current update step is 240
GPU_0_using curriculum 20 with window 20
Epoch: [6][20/40]	Time  1.535 ( 1.563)	Data  0.034 ( 0.049)	InnerLoop  0.651 ( 0.657)	Loss 7.6640e-01 (8.8066e-01)	Acc@1  69.73 ( 69.23)
Epoch: [6][40/40]	Time  1.517 ( 1.563)	Data  0.013 ( 0.045)	InnerLoop  0.633 ( 0.658)	Loss 6.1742e-01 (8.7913e-01)	Acc@1  76.04 ( 69.06)
The current update step is 280
GPU_0_using curriculum 20 with window 20
Epoch: [7][20/40]	Time  1.638 ( 1.551)	Data  0.029 ( 0.042)	InnerLoop  0.770 ( 0.657)	Loss 8.6921e-01 (7.2976e-01)	Acc@1  69.50 ( 73.76)
Epoch: [7][40/40]	Time  1.516 ( 1.552)	Data  0.012 ( 0.042)	InnerLoop  0.661 ( 0.657)	Loss 6.6261e-01 (8.0164e-01)	Acc@1  77.08 ( 71.55)
The current update step is 320
GPU_0_using curriculum 20 with window 20
Epoch: [8][20/40]	Time  1.523 ( 1.546)	Data  0.035 ( 0.037)	InnerLoop  0.634 ( 0.663)	Loss 9.0034e-01 (8.4025e-01)	Acc@1  68.85 ( 70.95)
Epoch: [8][40/40]	Time  1.514 ( 1.557)	Data  0.013 ( 0.040)	InnerLoop  0.643 ( 0.667)	Loss 7.0926e-01 (8.3465e-01)	Acc@1  70.31 ( 70.83)
The current update step is 360
GPU_0_using curriculum 20 with window 20
Epoch: [9][20/40]	Time  1.502 ( 1.543)	Data  0.032 ( 0.044)	InnerLoop  0.635 ( 0.657)	Loss 9.0898e-01 (8.2285e-01)	Acc@1  65.46 ( 70.56)
Epoch: [9][40/40]	Time  1.492 ( 1.541)	Data  0.013 ( 0.040)	InnerLoop  0.649 ( 0.659)	Loss 6.1745e-01 (7.7382e-01)	Acc@1  75.52 ( 72.38)
The current update step is 400
The current seed is 13531316977060794233
The current lr is: 0.001
Testing Results:
 *   Acc@1 72.329
 *   Acc@1 72.752
 *   Acc@1 71.289
 *   Acc@1 71.971
 *   Acc@1 71.618
 *   Acc@1 71.772
 *   Acc@1 53.776
 *   Acc@1 54.227
 *   Acc@1 57.816
 *   Acc@1 58.302
 *   Acc@1 59.579
 *   Acc@1 60.058
Training for 300 epoch: 63.05263157894737
Training for 600 epoch: 64.55263157894737
Training for 1000 epoch: 65.59868421052632
Training for 300 epoch: 63.48958333333333
Training for 600 epoch: 65.13625
Training for 1000 epoch: 65.91541666666666
[[63.05263157894737, 64.55263157894737, 65.59868421052632], [63.48958333333333, 65.13625, 65.91541666666666]]
train loss 0.7693927115440369, epoch 9, best loss 0.7693927115440369, best_epoch 9
GPU_0_using curriculum 20 with window 20
Epoch: [10][20/40]	Time  1.508 ( 1.548)	Data  0.030 ( 0.044)	InnerLoop  0.636 ( 0.658)	Loss 6.3900e-01 (8.7033e-01)	Acc@1  77.54 ( 71.77)
Epoch: [10][40/40]	Time  1.506 ( 1.559)	Data  0.014 ( 0.041)	InnerLoop  0.641 ( 0.666)	Loss 6.6792e-01 (8.3195e-01)	Acc@1  72.40 ( 71.90)
The current update step is 440
GPU_0_using curriculum 20 with window 20
Epoch: [11][20/40]	Time  1.609 ( 1.543)	Data  0.028 ( 0.050)	InnerLoop  0.748 ( 0.654)	Loss 6.2313e-01 (7.0445e-01)	Acc@1  77.25 ( 75.20)
Epoch: [11][40/40]	Time  1.487 ( 1.535)	Data  0.013 ( 0.046)	InnerLoop  0.632 ( 0.651)	Loss 1.0904e+00 (7.7261e-01)	Acc@1  63.54 ( 72.77)
The current update step is 480
GPU_0_using curriculum 20 with window 20
Epoch: [12][20/40]	Time  1.489 ( 1.520)	Data  0.032 ( 0.049)	InnerLoop  0.627 ( 0.639)	Loss 7.1570e-01 (7.0562e-01)	Acc@1  73.40 ( 74.19)
Epoch: [12][40/40]	Time  1.483 ( 1.522)	Data  0.012 ( 0.042)	InnerLoop  0.646 ( 0.645)	Loss 8.8328e-01 (7.3096e-01)	Acc@1  70.83 ( 73.80)
The current update step is 520
GPU_0_using curriculum 20 with window 20
Epoch: [13][20/40]	Time  1.494 ( 1.528)	Data  0.034 ( 0.042)	InnerLoop  0.632 ( 0.649)	Loss 5.7847e-01 (7.6693e-01)	Acc@1  79.39 ( 72.46)
Epoch: [13][40/40]	Time  1.493 ( 1.526)	Data  0.012 ( 0.041)	InnerLoop  0.654 ( 0.648)	Loss 7.7119e-01 (7.9269e-01)	Acc@1  73.96 ( 71.73)
The current update step is 560
GPU_0_using curriculum 20 with window 20
Epoch: [14][20/40]	Time  1.536 ( 1.523)	Data  0.030 ( 0.043)	InnerLoop  0.658 ( 0.647)	Loss 5.1316e-01 (7.5166e-01)	Acc@1  80.57 ( 72.81)
Epoch: [14][40/40]	Time  1.460 ( 1.523)	Data  0.011 ( 0.041)	InnerLoop  0.623 ( 0.647)	Loss 7.5303e-01 (7.1876e-01)	Acc@1  73.96 ( 73.90)
The current update step is 600
The current seed is 15858775740962744933
The current lr is: 0.001
Testing Results:
 *   Acc@1 78.276
 *   Acc@1 78.278
 *   Acc@1 75.776
 *   Acc@1 76.138
 *   Acc@1 75.461
 *   Acc@1 75.173
 *   Acc@1 69.487
 *   Acc@1 69.608
 *   Acc@1 65.421
 *   Acc@1 65.067
 *   Acc@1 63.737
 *   Acc@1 63.823
Training for 300 epoch: 73.88157894736842
Training for 600 epoch: 70.59868421052632
Training for 1000 epoch: 69.59868421052632
Training for 300 epoch: 73.9425
Training for 600 epoch: 70.60208333333333
Training for 1000 epoch: 69.49833333333333
[[73.88157894736842, 70.59868421052632, 69.59868421052632], [73.9425, 70.60208333333333, 69.49833333333333]]
train loss 0.475559872341156, epoch 14, best loss 0.475559872341156, best_epoch 14
GPU_0_using curriculum 20 with window 20
Epoch: [15][20/40]	Time  1.479 ( 1.516)	Data  0.030 ( 0.040)	InnerLoop  0.621 ( 0.643)	Loss 7.3575e-01 (7.3241e-01)	Acc@1  74.97 ( 73.37)
Epoch: [15][40/40]	Time  1.460 ( 1.513)	Data  0.013 ( 0.041)	InnerLoop  0.620 ( 0.640)	Loss 7.0606e-01 (7.1223e-01)	Acc@1  68.75 ( 74.18)
The current update step is 640
GPU_0_using curriculum 20 with window 20
Epoch: [16][20/40]	Time  1.501 ( 1.510)	Data  0.029 ( 0.047)	InnerLoop  0.627 ( 0.628)	Loss 6.8593e-01 (7.1057e-01)	Acc@1  77.12 ( 74.46)
Epoch: [16][40/40]	Time  1.631 ( 1.523)	Data  0.012 ( 0.041)	InnerLoop  0.758 ( 0.645)	Loss 1.0111e+00 (7.3865e-01)	Acc@1  61.98 ( 73.25)
The current update step is 680
GPU_0_using curriculum 20 with window 20
Epoch: [17][20/40]	Time  1.489 ( 1.577)	Data  0.028 ( 0.044)	InnerLoop  0.616 ( 0.670)	Loss 8.0563e-01 (7.1525e-01)	Acc@1  67.55 ( 73.34)
Epoch: [17][40/40]	Time  1.470 ( 1.549)	Data  0.011 ( 0.042)	InnerLoop  0.625 ( 0.656)	Loss 7.8780e-01 (7.7687e-01)	Acc@1  75.00 ( 71.71)
The current update step is 720
GPU_0_using curriculum 20 with window 20
Epoch: [18][20/40]	Time  1.505 ( 1.526)	Data  0.029 ( 0.047)	InnerLoop  0.648 ( 0.643)	Loss 6.2316e-01 (7.2447e-01)	Acc@1  78.12 ( 72.74)
Epoch: [18][40/40]	Time  1.457 ( 1.521)	Data  0.010 ( 0.043)	InnerLoop  0.624 ( 0.641)	Loss 9.4628e-01 (7.5061e-01)	Acc@1  65.10 ( 71.69)
The current update step is 760
GPU_0_using curriculum 20 with window 20
Epoch: [19][20/40]	Time  1.627 ( 1.518)	Data  0.029 ( 0.041)	InnerLoop  0.735 ( 0.643)	Loss 7.5351e-01 (7.8484e-01)	Acc@1  70.74 ( 69.58)
Epoch: [19][40/40]	Time  1.464 ( 1.516)	Data  0.013 ( 0.041)	InnerLoop  0.626 ( 0.641)	Loss 8.9178e-01 (7.7633e-01)	Acc@1  67.71 ( 71.08)
The current update step is 800
The current seed is 2231676200279275443
The current lr is: 0.001
Testing Results:
 *   Acc@1 64.553
 *   Acc@1 65.591
 *   Acc@1 61.605
 *   Acc@1 62.020
 *   Acc@1 59.829
 *   Acc@1 60.021
 *   Acc@1 64.447
 *   Acc@1 64.641
 *   Acc@1 60.013
 *   Acc@1 60.753
 *   Acc@1 59.684
 *   Acc@1 60.093
Training for 300 epoch: 64.5
Training for 600 epoch: 60.809210526315795
Training for 1000 epoch: 59.756578947368425
Training for 300 epoch: 65.11583333333334
Training for 600 epoch: 61.38666666666667
Training for 1000 epoch: 60.05666666666667
[[64.5, 60.809210526315795, 59.756578947368425], [65.11583333333334, 61.38666666666667, 60.05666666666667]]
train loss 0.4703999847412109, epoch 19, best loss 0.4703999847412109, best_epoch 19
GPU_0_using curriculum 20 with window 20
Epoch: [20][20/40]	Time  1.486 ( 1.515)	Data  0.027 ( 0.034)	InnerLoop  0.618 ( 0.645)	Loss 6.6580e-01 (7.1191e-01)	Acc@1  72.79 ( 72.75)
Epoch: [20][40/40]	Time  1.498 ( 1.520)	Data  0.013 ( 0.037)	InnerLoop  0.638 ( 0.647)	Loss 7.0829e-01 (7.1378e-01)	Acc@1  75.00 ( 73.49)
The current update step is 840
GPU_0_using curriculum 20 with window 20
Epoch: [21][20/40]	Time  1.501 ( 1.529)	Data  0.029 ( 0.036)	InnerLoop  0.636 ( 0.650)	Loss 7.5997e-01 (6.7889e-01)	Acc@1  69.14 ( 73.77)
Epoch: [21][40/40]	Time  1.534 ( 1.533)	Data  0.013 ( 0.039)	InnerLoop  0.621 ( 0.649)	Loss 7.8192e-01 (7.0517e-01)	Acc@1  67.19 ( 73.15)
The current update step is 880
GPU_0_using curriculum 20 with window 20
Epoch: [22][20/40]	Time  1.610 ( 1.513)	Data  0.030 ( 0.041)	InnerLoop  0.751 ( 0.644)	Loss 6.5944e-01 (6.7027e-01)	Acc@1  75.03 ( 74.66)
Epoch: [22][40/40]	Time  1.461 ( 1.516)	Data  0.014 ( 0.041)	InnerLoop  0.625 ( 0.643)	Loss 7.2131e-01 (7.1081e-01)	Acc@1  72.92 ( 73.96)
The current update step is 920
GPU_0_using curriculum 20 with window 20
Epoch: [23][20/40]	Time  1.485 ( 1.508)	Data  0.029 ( 0.036)	InnerLoop  0.627 ( 0.646)	Loss 5.5521e-01 (6.8271e-01)	Acc@1  80.11 ( 74.45)
Epoch: [23][40/40]	Time  1.468 ( 1.517)	Data  0.012 ( 0.038)	InnerLoop  0.632 ( 0.649)	Loss 5.8977e-01 (6.8481e-01)	Acc@1  78.65 ( 74.00)
The current update step is 960
GPU_0_using curriculum 20 with window 20
Epoch: [24][20/40]	Time  1.507 ( 1.518)	Data  0.030 ( 0.041)	InnerLoop  0.630 ( 0.638)	Loss 5.6363e-01 (6.5040e-01)	Acc@1  78.06 ( 75.42)
Epoch: [24][40/40]	Time  1.484 ( 1.521)	Data  0.011 ( 0.038)	InnerLoop  0.650 ( 0.645)	Loss 5.9142e-01 (6.7233e-01)	Acc@1  77.08 ( 74.72)
The current update step is 1000
The current seed is 2750118643827080716
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.421
 *   Acc@1 76.801
 *   Acc@1 74.566
 *   Acc@1 74.478
 *   Acc@1 71.605
 *   Acc@1 72.061
 *   Acc@1 78.724
 *   Acc@1 78.891
 *   Acc@1 77.671
 *   Acc@1 77.805
 *   Acc@1 76.329
 *   Acc@1 76.793
Training for 300 epoch: 77.57236842105263
Training for 600 epoch: 76.11842105263158
Training for 1000 epoch: 73.96710526315789
Training for 300 epoch: 77.84583333333333
Training for 600 epoch: 76.14166666666668
Training for 1000 epoch: 74.42666666666668
[[77.57236842105263, 76.11842105263158, 73.96710526315789], [77.84583333333333, 76.14166666666668, 74.42666666666668]]
train loss 0.3234549364566803, epoch 24, best loss 0.3234549364566803, best_epoch 24
GPU_0_using curriculum 20 with window 20
Epoch: [25][20/40]	Time  1.524 ( 1.541)	Data  0.032 ( 0.043)	InnerLoop  0.643 ( 0.656)	Loss 6.8985e-01 (6.7546e-01)	Acc@1  76.73 ( 76.01)
Epoch: [25][40/40]	Time  1.476 ( 1.541)	Data  0.011 ( 0.040)	InnerLoop  0.640 ( 0.659)	Loss 5.4030e-01 (6.6103e-01)	Acc@1  82.81 ( 76.04)
The current update step is 1040
GPU_0_using curriculum 20 with window 20
Epoch: [26][20/40]	Time  1.652 ( 1.543)	Data  0.029 ( 0.048)	InnerLoop  0.779 ( 0.652)	Loss 8.5337e-01 (6.8221e-01)	Acc@1  70.35 ( 75.33)
Epoch: [26][40/40]	Time  1.511 ( 1.536)	Data  0.012 ( 0.045)	InnerLoop  0.663 ( 0.650)	Loss 5.7039e-01 (6.5768e-01)	Acc@1  76.04 ( 75.92)
The current update step is 1080
GPU_0_using curriculum 20 with window 20
Epoch: [27][20/40]	Time  1.543 ( 1.545)	Data  0.036 ( 0.051)	InnerLoop  0.661 ( 0.650)	Loss 8.8512e-01 (7.2721e-01)	Acc@1  71.88 ( 74.48)
Epoch: [27][40/40]	Time  1.529 ( 1.553)	Data  0.016 ( 0.044)	InnerLoop  0.644 ( 0.658)	Loss 9.6728e-01 (6.9152e-01)	Acc@1  67.71 ( 75.47)
The current update step is 1120
GPU_0_using curriculum 20 with window 20
Epoch: [28][20/40]	Time  1.547 ( 1.541)	Data  0.028 ( 0.043)	InnerLoop  0.668 ( 0.656)	Loss 5.9574e-01 (6.9529e-01)	Acc@1  80.24 ( 74.65)
Epoch: [28][40/40]	Time  1.475 ( 1.532)	Data  0.013 ( 0.041)	InnerLoop  0.641 ( 0.650)	Loss 5.2399e-01 (6.5278e-01)	Acc@1  84.90 ( 76.09)
The current update step is 1160
GPU_0_using curriculum 20 with window 20
Epoch: [29][20/40]	Time  1.481 ( 1.511)	Data  0.030 ( 0.041)	InnerLoop  0.625 ( 0.640)	Loss 5.9574e-01 (7.0822e-01)	Acc@1  78.09 ( 74.25)
Epoch: [29][40/40]	Time  1.502 ( 1.523)	Data  0.012 ( 0.042)	InnerLoop  0.633 ( 0.648)	Loss 5.2229e-01 (6.9118e-01)	Acc@1  80.21 ( 74.89)
The current update step is 1200
The current seed is 16784342763521730249
The current lr is: 0.001
Testing Results:
 *   Acc@1 78.013
 *   Acc@1 78.721
 *   Acc@1 77.145
 *   Acc@1 78.147
 *   Acc@1 76.618
 *   Acc@1 77.404
 *   Acc@1 71.947
 *   Acc@1 72.267
 *   Acc@1 72.355
 *   Acc@1 72.597
 *   Acc@1 72.618
 *   Acc@1 72.799
Training for 300 epoch: 74.98026315789474
Training for 600 epoch: 74.75
Training for 1000 epoch: 74.61842105263158
Training for 300 epoch: 75.49375
Training for 600 epoch: 75.37208333333334
Training for 1000 epoch: 75.10166666666666
[[74.98026315789474, 74.75, 74.61842105263158], [75.49375, 75.37208333333334, 75.10166666666666]]
train loss 0.39222610206604, epoch 29, best loss 0.3234549364566803, best_epoch 24
GPU_0_using curriculum 20 with window 20
Epoch: [30][20/40]	Time  1.490 ( 1.522)	Data  0.028 ( 0.041)	InnerLoop  0.628 ( 0.647)	Loss 8.4546e-01 (6.5670e-01)	Acc@1  66.05 ( 75.97)
Epoch: [30][40/40]	Time  1.479 ( 1.521)	Data  0.014 ( 0.041)	InnerLoop  0.635 ( 0.647)	Loss 6.1342e-01 (6.5034e-01)	Acc@1  79.17 ( 76.46)
The current update step is 1240
GPU_0_using curriculum 20 with window 20
Epoch: [31][20/40]	Time  1.480 ( 1.520)	Data  0.027 ( 0.046)	InnerLoop  0.625 ( 0.639)	Loss 5.7489e-01 (6.6570e-01)	Acc@1  78.55 ( 76.06)
Epoch: [31][40/40]	Time  1.575 ( 1.520)	Data  0.012 ( 0.040)	InnerLoop  0.742 ( 0.646)	Loss 5.2951e-01 (6.6013e-01)	Acc@1  80.21 ( 75.93)
The current update step is 1280
GPU_0_using curriculum 20 with window 20
Epoch: [32][20/40]	Time  1.496 ( 1.514)	Data  0.027 ( 0.041)	InnerLoop  0.640 ( 0.641)	Loss 7.0749e-01 (6.9029e-01)	Acc@1  74.61 ( 74.55)
Epoch: [32][40/40]	Time  1.480 ( 1.515)	Data  0.012 ( 0.041)	InnerLoop  0.625 ( 0.642)	Loss 5.5569e-01 (6.6014e-01)	Acc@1  76.04 ( 75.88)
The current update step is 1320
GPU_0_using curriculum 20 with window 20
Epoch: [33][20/40]	Time  1.508 ( 1.524)	Data  0.029 ( 0.048)	InnerLoop  0.649 ( 0.643)	Loss 8.0747e-01 (6.8180e-01)	Acc@1  70.90 ( 75.85)
Epoch: [33][40/40]	Time  1.524 ( 1.535)	Data  0.012 ( 0.045)	InnerLoop  0.659 ( 0.650)	Loss 5.4828e-01 (7.1135e-01)	Acc@1  83.33 ( 74.95)
The current update step is 1360
GPU_0_using curriculum 20 with window 20
Epoch: [34][20/40]	Time  1.600 ( 1.581)	Data  0.033 ( 0.046)	InnerLoop  0.743 ( 0.681)	Loss 9.1540e-01 (6.9155e-01)	Acc@1  65.95 ( 75.13)
Epoch: [34][40/40]	Time  1.467 ( 1.548)	Data  0.012 ( 0.043)	InnerLoop  0.629 ( 0.662)	Loss 6.6169e-01 (6.6671e-01)	Acc@1  78.12 ( 75.87)
The current update step is 1400
The current seed is 2183645782937958555
The current lr is: 0.001
Testing Results:
 *   Acc@1 79.816
 *   Acc@1 80.282
 *   Acc@1 78.539
 *   Acc@1 78.985
 *   Acc@1 77.329
 *   Acc@1 77.966
 *   Acc@1 75.526
 *   Acc@1 76.091
 *   Acc@1 73.724
 *   Acc@1 73.877
 *   Acc@1 72.895
 *   Acc@1 73.360
Training for 300 epoch: 77.67105263157895
Training for 600 epoch: 76.13157894736841
Training for 1000 epoch: 75.11184210526315
Training for 300 epoch: 78.18625
Training for 600 epoch: 76.43083333333334
Training for 1000 epoch: 75.66291666666666
[[77.67105263157895, 76.13157894736841, 75.11184210526315], [78.18625, 76.43083333333334, 75.66291666666666]]
train loss 0.3461305863857269, epoch 34, best loss 0.3234549364566803, best_epoch 24
GPU_0_using curriculum 20 with window 20
Epoch: [35][20/40]	Time  1.488 ( 1.521)	Data  0.032 ( 0.036)	InnerLoop  0.620 ( 0.651)	Loss 6.1083e-01 (6.6616e-01)	Acc@1  77.41 ( 76.01)
Epoch: [35][40/40]	Time  1.483 ( 1.522)	Data  0.012 ( 0.039)	InnerLoop  0.639 ( 0.651)	Loss 7.7814e-01 (6.7640e-01)	Acc@1  71.88 ( 75.85)
The current update step is 1440
GPU_0_using curriculum 20 with window 20
Epoch: [36][20/40]	Time  1.487 ( 1.521)	Data  0.030 ( 0.036)	InnerLoop  0.631 ( 0.654)	Loss 1.4193e+00 (7.7353e-01)	Acc@1  58.11 ( 73.81)
Epoch: [36][40/40]	Time  1.479 ( 1.518)	Data  0.014 ( 0.039)	InnerLoop  0.620 ( 0.649)	Loss 7.5851e-01 (7.3512e-01)	Acc@1  71.88 ( 73.96)
The current update step is 1480
GPU_0_using curriculum 20 with window 20
Epoch: [37][20/40]	Time  1.595 ( 1.512)	Data  0.031 ( 0.042)	InnerLoop  0.735 ( 0.644)	Loss 6.8665e-01 (6.9517e-01)	Acc@1  74.45 ( 74.79)
Epoch: [37][40/40]	Time  1.465 ( 1.513)	Data  0.011 ( 0.042)	InnerLoop  0.624 ( 0.641)	Loss 8.7158e-01 (6.7422e-01)	Acc@1  71.35 ( 75.19)
The current update step is 1520
GPU_0_using curriculum 20 with window 20
Epoch: [38][20/40]	Time  1.496 ( 1.514)	Data  0.028 ( 0.036)	InnerLoop  0.633 ( 0.648)	Loss 1.1840e+00 (7.6993e-01)	Acc@1  52.28 ( 73.04)
Epoch: [38][40/40]	Time  1.456 ( 1.518)	Data  0.012 ( 0.039)	InnerLoop  0.620 ( 0.647)	Loss 7.1123e-01 (7.3120e-01)	Acc@1  70.83 ( 73.99)
The current update step is 1560
GPU_0_using curriculum 20 with window 20
Epoch: [39][20/40]	Time  1.490 ( 1.512)	Data  0.029 ( 0.042)	InnerLoop  0.634 ( 0.637)	Loss 6.2244e-01 (6.3120e-01)	Acc@1  76.89 ( 76.80)
Epoch: [39][40/40]	Time  1.475 ( 1.510)	Data  0.013 ( 0.038)	InnerLoop  0.626 ( 0.639)	Loss 9.6500e-01 (6.3697e-01)	Acc@1  61.46 ( 76.25)
The current update step is 1600
The current seed is 16805016812526727868
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.566
 *   Acc@1 70.301
 *   Acc@1 68.197
 *   Acc@1 68.672
 *   Acc@1 66.276
 *   Acc@1 66.947
 *   Acc@1 75.789
 *   Acc@1 76.037
 *   Acc@1 76.158
 *   Acc@1 76.659
 *   Acc@1 75.947
 *   Acc@1 76.534
Training for 300 epoch: 72.67763157894737
Training for 600 epoch: 72.17763157894737
Training for 1000 epoch: 71.11184210526315
Training for 300 epoch: 73.16916666666665
Training for 600 epoch: 72.66541666666666
Training for 1000 epoch: 71.74041666666668
[[72.67763157894737, 72.17763157894737, 71.11184210526315], [73.16916666666665, 72.66541666666666, 71.74041666666668]]
train loss 0.3038037651538849, epoch 39, best loss 0.3038037651538849, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [40][20/40]	Time  1.497 ( 1.516)	Data  0.031 ( 0.041)	InnerLoop  0.628 ( 0.645)	Loss 5.0999e-01 (6.9496e-01)	Acc@1  82.62 ( 74.51)
Epoch: [40][40/40]	Time  1.468 ( 1.518)	Data  0.012 ( 0.038)	InnerLoop  0.622 ( 0.649)	Loss 5.2487e-01 (6.9704e-01)	Acc@1  82.29 ( 74.58)
The current update step is 1640
GPU_0_using curriculum 20 with window 20
Epoch: [41][20/40]	Time  1.602 ( 1.523)	Data  0.027 ( 0.048)	InnerLoop  0.749 ( 0.644)	Loss 5.6594e-01 (6.5977e-01)	Acc@1  79.75 ( 75.76)
Epoch: [41][40/40]	Time  1.475 ( 1.516)	Data  0.013 ( 0.044)	InnerLoop  0.634 ( 0.643)	Loss 8.1275e-01 (6.3550e-01)	Acc@1  72.40 ( 76.87)
The current update step is 1680
GPU_0_using curriculum 20 with window 20
Epoch: [42][20/40]	Time  1.490 ( 1.513)	Data  0.028 ( 0.048)	InnerLoop  0.633 ( 0.635)	Loss 5.5693e-01 (6.7709e-01)	Acc@1  81.05 ( 76.02)
Epoch: [42][40/40]	Time  1.463 ( 1.515)	Data  0.012 ( 0.041)	InnerLoop  0.624 ( 0.643)	Loss 4.7998e-01 (6.3764e-01)	Acc@1  83.85 ( 77.16)
The current update step is 1720
GPU_0_using curriculum 20 with window 20
Epoch: [43][20/40]	Time  1.498 ( 1.515)	Data  0.031 ( 0.042)	InnerLoop  0.635 ( 0.644)	Loss 7.1499e-01 (6.2691e-01)	Acc@1  76.20 ( 76.75)
Epoch: [43][40/40]	Time  1.495 ( 1.516)	Data  0.013 ( 0.042)	InnerLoop  0.635 ( 0.643)	Loss 6.6013e-01 (6.5530e-01)	Acc@1  78.12 ( 76.27)
The current update step is 1760
GPU_0_using curriculum 20 with window 20
Epoch: [44][20/40]	Time  1.499 ( 1.515)	Data  0.027 ( 0.041)	InnerLoop  0.633 ( 0.644)	Loss 6.1481e-01 (7.0504e-01)	Acc@1  76.76 ( 74.24)
Epoch: [44][40/40]	Time  1.471 ( 1.518)	Data  0.011 ( 0.041)	InnerLoop  0.627 ( 0.645)	Loss 1.1192e+00 (7.0142e-01)	Acc@1  64.06 ( 74.19)
The current update step is 1800
The current seed is 14642867532303557161
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.224
 *   Acc@1 71.079
 *   Acc@1 67.329
 *   Acc@1 67.802
 *   Acc@1 64.618
 *   Acc@1 65.433
 *   Acc@1 60.711
 *   Acc@1 60.792
 *   Acc@1 61.461
 *   Acc@1 61.831
 *   Acc@1 61.408
 *   Acc@1 61.787
Training for 300 epoch: 65.46710526315789
Training for 600 epoch: 64.39473684210526
Training for 1000 epoch: 63.013157894736835
Training for 300 epoch: 65.93583333333333
Training for 600 epoch: 64.81666666666666
Training for 1000 epoch: 63.60958333333333
[[65.46710526315789, 64.39473684210526, 63.013157894736835], [65.93583333333333, 64.81666666666666, 63.60958333333333]]
train loss 0.5172611721038818, epoch 44, best loss 0.3038037651538849, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [45][20/40]	Time  1.482 ( 1.528)	Data  0.027 ( 0.041)	InnerLoop  0.628 ( 0.655)	Loss 1.0012e+00 (8.7890e-01)	Acc@1  63.51 ( 69.72)
Epoch: [45][40/40]	Time  1.491 ( 1.522)	Data  0.013 ( 0.041)	InnerLoop  0.627 ( 0.649)	Loss 9.2399e-01 (8.0287e-01)	Acc@1  65.62 ( 71.05)
The current update step is 1840
GPU_0_using curriculum 20 with window 20
Epoch: [46][20/40]	Time  1.479 ( 1.507)	Data  0.032 ( 0.048)	InnerLoop  0.626 ( 0.630)	Loss 6.2723e-01 (6.8919e-01)	Acc@1  77.05 ( 75.05)
Epoch: [46][40/40]	Time  1.576 ( 1.508)	Data  0.013 ( 0.042)	InnerLoop  0.744 ( 0.640)	Loss 6.2463e-01 (6.9039e-01)	Acc@1  80.21 ( 74.40)
The current update step is 1880
GPU_0_using curriculum 20 with window 20
Epoch: [47][20/40]	Time  1.468 ( 1.503)	Data  0.028 ( 0.041)	InnerLoop  0.623 ( 0.636)	Loss 7.4378e-01 (6.2997e-01)	Acc@1  75.78 ( 77.02)
Epoch: [47][40/40]	Time  1.475 ( 1.506)	Data  0.012 ( 0.041)	InnerLoop  0.639 ( 0.638)	Loss 7.9100e-01 (6.8865e-01)	Acc@1  70.31 ( 75.30)
The current update step is 1920
GPU_0_using curriculum 20 with window 20
Epoch: [48][20/40]	Time  1.488 ( 1.511)	Data  0.028 ( 0.047)	InnerLoop  0.637 ( 0.639)	Loss 6.6476e-01 (6.3295e-01)	Acc@1  71.81 ( 76.39)
Epoch: [48][40/40]	Time  1.460 ( 1.511)	Data  0.015 ( 0.044)	InnerLoop  0.626 ( 0.639)	Loss 5.8451e-01 (6.4785e-01)	Acc@1  78.65 ( 76.34)
The current update step is 1960
GPU_0_using curriculum 20 with window 20
Epoch: [49][20/40]	Time  1.609 ( 1.519)	Data  0.029 ( 0.042)	InnerLoop  0.754 ( 0.646)	Loss 5.8244e-01 (6.4194e-01)	Acc@1  79.82 ( 75.71)
Epoch: [49][40/40]	Time  1.462 ( 1.513)	Data  0.013 ( 0.041)	InnerLoop  0.631 ( 0.643)	Loss 5.8294e-01 (6.3011e-01)	Acc@1  77.08 ( 76.25)
The current update step is 2000
The current seed is 5150187684132793467
The current lr is: 0.001
Testing Results:
 *   Acc@1 74.382
 *   Acc@1 75.234
 *   Acc@1 75.329
 *   Acc@1 76.332
 *   Acc@1 75.987
 *   Acc@1 76.394
 *   Acc@1 69.026
 *   Acc@1 69.252
 *   Acc@1 62.092
 *   Acc@1 62.182
 *   Acc@1 58.382
 *   Acc@1 59.398
Training for 300 epoch: 71.70394736842105
Training for 600 epoch: 68.71052631578948
Training for 1000 epoch: 67.1842105263158
Training for 300 epoch: 72.24291666666667
Training for 600 epoch: 69.2575
Training for 1000 epoch: 67.89583333333333
[[71.70394736842105, 68.71052631578948, 67.1842105263158], [72.24291666666667, 69.2575, 67.89583333333333]]
train loss 0.5433577382087708, epoch 49, best loss 0.3038037651538849, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [50][20/40]	Time  1.490 ( 1.511)	Data  0.028 ( 0.035)	InnerLoop  0.626 ( 0.646)	Loss 4.9993e-01 (6.6360e-01)	Acc@1  82.16 ( 75.98)
Epoch: [50][40/40]	Time  1.473 ( 1.515)	Data  0.014 ( 0.038)	InnerLoop  0.642 ( 0.646)	Loss 4.4904e-01 (6.6999e-01)	Acc@1  81.77 ( 75.76)
The current update step is 2040
GPU_0_using curriculum 20 with window 20
Epoch: [51][20/40]	Time  1.510 ( 1.511)	Data  0.032 ( 0.037)	InnerLoop  0.632 ( 0.648)	Loss 5.2141e-01 (6.9337e-01)	Acc@1  82.00 ( 74.15)
Epoch: [51][40/40]	Time  1.476 ( 1.511)	Data  0.013 ( 0.038)	InnerLoop  0.633 ( 0.645)	Loss 5.5269e-01 (6.6130e-01)	Acc@1  80.21 ( 75.50)
The current update step is 2080
GPU_0_using curriculum 20 with window 20
Epoch: [52][20/40]	Time  1.602 ( 1.513)	Data  0.029 ( 0.042)	InnerLoop  0.751 ( 0.645)	Loss 9.5701e-01 (6.5061e-01)	Acc@1  62.89 ( 76.38)
Epoch: [52][40/40]	Time  1.484 ( 1.514)	Data  0.014 ( 0.042)	InnerLoop  0.647 ( 0.644)	Loss 6.0354e-01 (6.4758e-01)	Acc@1  75.00 ( 76.44)
The current update step is 2120
GPU_0_using curriculum 20 with window 20
Epoch: [53][20/40]	Time  1.493 ( 1.512)	Data  0.029 ( 0.036)	InnerLoop  0.637 ( 0.647)	Loss 5.6092e-01 (6.6711e-01)	Acc@1  80.27 ( 75.34)
Epoch: [53][40/40]	Time  1.457 ( 1.515)	Data  0.012 ( 0.038)	InnerLoop  0.627 ( 0.648)	Loss 4.8660e-01 (6.8003e-01)	Acc@1  81.25 ( 74.84)
The current update step is 2160
GPU_0_using curriculum 20 with window 20
Epoch: [54][20/40]	Time  1.468 ( 1.502)	Data  0.029 ( 0.041)	InnerLoop  0.616 ( 0.636)	Loss 7.2099e-01 (7.1941e-01)	Acc@1  72.59 ( 74.51)
Epoch: [54][40/40]	Time  1.464 ( 1.506)	Data  0.011 ( 0.038)	InnerLoop  0.630 ( 0.641)	Loss 5.6836e-01 (6.9918e-01)	Acc@1  77.60 ( 74.64)
The current update step is 2200
The current seed is 9992722349053186476
The current lr is: 0.001
Testing Results:
 *   Acc@1 72.487
 *   Acc@1 72.807
 *   Acc@1 68.882
 *   Acc@1 68.714
 *   Acc@1 69.776
 *   Acc@1 69.961
 *   Acc@1 76.421
 *   Acc@1 76.804
 *   Acc@1 77.000
 *   Acc@1 77.127
 *   Acc@1 78.105
 *   Acc@1 78.589
Training for 300 epoch: 74.45394736842105
Training for 600 epoch: 72.94078947368422
Training for 1000 epoch: 73.94078947368422
Training for 300 epoch: 74.80541666666667
Training for 600 epoch: 72.92083333333333
Training for 1000 epoch: 74.275
[[74.45394736842105, 72.94078947368422, 73.94078947368422], [74.80541666666667, 72.92083333333333, 74.275]]
train loss 0.3267941806793213, epoch 54, best loss 0.3038037651538849, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [55][20/40]	Time  1.473 ( 1.503)	Data  0.028 ( 0.041)	InnerLoop  0.626 ( 0.637)	Loss 5.2829e-01 (6.2592e-01)	Acc@1  81.90 ( 77.69)
Epoch: [55][40/40]	Time  1.466 ( 1.504)	Data  0.011 ( 0.037)	InnerLoop  0.631 ( 0.641)	Loss 7.9567e-01 (6.1721e-01)	Acc@1  72.92 ( 78.16)
The current update step is 2240
GPU_0_using curriculum 20 with window 20
Epoch: [56][20/40]	Time  1.630 ( 1.506)	Data  0.027 ( 0.047)	InnerLoop  0.744 ( 0.635)	Loss 5.8437e-01 (6.6875e-01)	Acc@1  77.18 ( 76.27)
Epoch: [56][40/40]	Time  1.486 ( 1.512)	Data  0.014 ( 0.044)	InnerLoop  0.653 ( 0.640)	Loss 6.7949e-01 (6.5302e-01)	Acc@1  77.08 ( 76.50)
The current update step is 2280
GPU_0_using curriculum 20 with window 20
Epoch: [57][20/40]	Time  1.511 ( 1.516)	Data  0.031 ( 0.048)	InnerLoop  0.657 ( 0.636)	Loss 7.2980e-01 (6.7398e-01)	Acc@1  72.82 ( 76.13)
Epoch: [57][40/40]	Time  1.465 ( 1.515)	Data  0.011 ( 0.041)	InnerLoop  0.623 ( 0.641)	Loss 6.1003e-01 (6.5059e-01)	Acc@1  71.35 ( 76.94)
The current update step is 2320
GPU_0_using curriculum 20 with window 20
Epoch: [58][20/40]	Time  1.470 ( 1.527)	Data  0.027 ( 0.040)	InnerLoop  0.620 ( 0.649)	Loss 5.5721e-01 (6.2423e-01)	Acc@1  80.73 ( 77.63)
Epoch: [58][40/40]	Time  1.452 ( 1.520)	Data  0.013 ( 0.040)	InnerLoop  0.624 ( 0.644)	Loss 8.0310e-01 (6.3439e-01)	Acc@1  71.88 ( 77.15)
The current update step is 2360
GPU_0_using curriculum 20 with window 20
Epoch: [59][20/40]	Time  1.487 ( 1.514)	Data  0.029 ( 0.042)	InnerLoop  0.617 ( 0.642)	Loss 5.8632e-01 (6.4572e-01)	Acc@1  78.55 ( 76.97)
Epoch: [59][40/40]	Time  1.556 ( 1.520)	Data  0.014 ( 0.041)	InnerLoop  0.644 ( 0.643)	Loss 5.6532e-01 (6.4091e-01)	Acc@1  79.17 ( 76.53)
The current update step is 2400
The current seed is 117520681072953833
The current lr is: 0.001
Testing Results:
 *   Acc@1 57.289
 *   Acc@1 57.722
 *   Acc@1 52.329
 *   Acc@1 52.928
 *   Acc@1 49.118
 *   Acc@1 49.488
 *   Acc@1 65.421
 *   Acc@1 65.829
 *   Acc@1 63.763
 *   Acc@1 64.304
 *   Acc@1 58.039
 *   Acc@1 58.077
Training for 300 epoch: 61.35526315789474
Training for 600 epoch: 58.046052631578945
Training for 1000 epoch: 53.578947368421055
Training for 300 epoch: 61.775416666666665
Training for 600 epoch: 58.616249999999994
Training for 1000 epoch: 53.7825
[[61.35526315789474, 58.046052631578945, 53.578947368421055], [61.775416666666665, 58.616249999999994, 53.7825]]
train loss 0.6026332450866699, epoch 59, best loss 0.3038037651538849, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [60][20/40]	Time  1.499 ( 1.522)	Data  0.030 ( 0.041)	InnerLoop  0.630 ( 0.648)	Loss 5.2924e-01 (6.3019e-01)	Acc@1  80.53 ( 76.53)
Epoch: [60][40/40]	Time  1.453 ( 1.520)	Data  0.014 ( 0.041)	InnerLoop  0.617 ( 0.645)	Loss 5.0756e-01 (6.2661e-01)	Acc@1  79.17 ( 76.96)
The current update step is 2440
GPU_0_using curriculum 20 with window 20
Epoch: [61][20/40]	Time  1.467 ( 1.505)	Data  0.029 ( 0.046)	InnerLoop  0.618 ( 0.630)	Loss 5.4909e-01 (6.7967e-01)	Acc@1  80.47 ( 75.33)
Epoch: [61][40/40]	Time  1.601 ( 1.515)	Data  0.015 ( 0.041)	InnerLoop  0.754 ( 0.643)	Loss 1.0323e+00 (6.5179e-01)	Acc@1  65.62 ( 76.41)
The current update step is 2480
GPU_0_using curriculum 20 with window 20
Epoch: [62][20/40]	Time  1.494 ( 1.514)	Data  0.030 ( 0.042)	InnerLoop  0.628 ( 0.641)	Loss 5.6490e-01 (6.7636e-01)	Acc@1  80.18 ( 75.92)
Epoch: [62][40/40]	Time  1.461 ( 1.517)	Data  0.014 ( 0.042)	InnerLoop  0.624 ( 0.642)	Loss 5.9554e-01 (6.4495e-01)	Acc@1  75.52 ( 76.76)
The current update step is 2520
GPU_0_using curriculum 20 with window 20
Epoch: [63][20/40]	Time  1.496 ( 1.518)	Data  0.031 ( 0.048)	InnerLoop  0.624 ( 0.639)	Loss 5.1121e-01 (6.6290e-01)	Acc@1  82.16 ( 75.66)
Epoch: [63][40/40]	Time  1.477 ( 1.516)	Data  0.014 ( 0.044)	InnerLoop  0.630 ( 0.642)	Loss 8.5391e-01 (6.5646e-01)	Acc@1  76.04 ( 76.24)
The current update step is 2560
GPU_0_using curriculum 20 with window 20
Epoch: [64][20/40]	Time  1.618 ( 1.518)	Data  0.030 ( 0.041)	InnerLoop  0.755 ( 0.647)	Loss 5.2284e-01 (6.1697e-01)	Acc@1  80.83 ( 77.53)
Epoch: [64][40/40]	Time  1.477 ( 1.519)	Data  0.012 ( 0.041)	InnerLoop  0.632 ( 0.645)	Loss 3.4702e-01 (6.5839e-01)	Acc@1  89.06 ( 76.46)
The current update step is 2600
The current seed is 11987783331587863735
The current lr is: 0.001
Testing Results:
 *   Acc@1 74.079
 *   Acc@1 74.562
 *   Acc@1 73.553
 *   Acc@1 73.719
 *   Acc@1 72.632
 *   Acc@1 73.281
 *   Acc@1 69.947
 *   Acc@1 69.782
 *   Acc@1 61.789
 *   Acc@1 62.432
 *   Acc@1 56.500
 *   Acc@1 57.510
Training for 300 epoch: 72.01315789473685
Training for 600 epoch: 67.67105263157895
Training for 1000 epoch: 64.56578947368422
Training for 300 epoch: 72.17166666666667
Training for 600 epoch: 68.07541666666667
Training for 1000 epoch: 65.39541666666666
[[72.01315789473685, 67.67105263157895, 64.56578947368422], [72.17166666666667, 68.07541666666667, 65.39541666666666]]
train loss 0.6376893463134765, epoch 64, best loss 0.3038037651538849, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [65][20/40]	Time  1.491 ( 1.511)	Data  0.031 ( 0.037)	InnerLoop  0.635 ( 0.647)	Loss 6.8188e-01 (7.1883e-01)	Acc@1  73.96 ( 75.38)
Epoch: [65][40/40]	Time  1.480 ( 1.519)	Data  0.012 ( 0.039)	InnerLoop  0.642 ( 0.651)	Loss 5.2763e-01 (7.0092e-01)	Acc@1  79.69 ( 75.11)
The current update step is 2640
GPU_0_using curriculum 20 with window 20
Epoch: [66][20/40]	Time  1.491 ( 1.517)	Data  0.031 ( 0.036)	InnerLoop  0.632 ( 0.652)	Loss 6.4457e-01 (7.2337e-01)	Acc@1  75.59 ( 74.33)
Epoch: [66][40/40]	Time  1.470 ( 1.518)	Data  0.013 ( 0.039)	InnerLoop  0.630 ( 0.648)	Loss 7.1178e-01 (6.8521e-01)	Acc@1  71.35 ( 75.30)
The current update step is 2680
GPU_0_using curriculum 20 with window 20
Epoch: [67][20/40]	Time  1.620 ( 1.530)	Data  0.030 ( 0.043)	InnerLoop  0.749 ( 0.655)	Loss 5.6413e-01 (6.8268e-01)	Acc@1  78.48 ( 74.17)
Epoch: [67][40/40]	Time  1.509 ( 1.526)	Data  0.013 ( 0.043)	InnerLoop  0.640 ( 0.652)	Loss 8.0956e-01 (6.5318e-01)	Acc@1  75.52 ( 75.73)
The current update step is 2720
GPU_0_using curriculum 20 with window 20
Epoch: [68][20/40]	Time  1.496 ( 1.513)	Data  0.032 ( 0.036)	InnerLoop  0.628 ( 0.650)	Loss 6.1710e-01 (6.2567e-01)	Acc@1  76.89 ( 76.78)
Epoch: [68][40/40]	Time  1.496 ( 1.523)	Data  0.013 ( 0.039)	InnerLoop  0.643 ( 0.653)	Loss 4.0579e-01 (6.5717e-01)	Acc@1  85.42 ( 76.15)
The current update step is 2760
GPU_0_using curriculum 20 with window 20
Epoch: [69][20/40]	Time  1.485 ( 1.523)	Data  0.032 ( 0.042)	InnerLoop  0.628 ( 0.645)	Loss 5.2716e-01 (6.3861e-01)	Acc@1  80.92 ( 76.39)
Epoch: [69][40/40]	Time  1.466 ( 1.520)	Data  0.012 ( 0.039)	InnerLoop  0.628 ( 0.647)	Loss 4.7355e-01 (6.4208e-01)	Acc@1  81.77 ( 76.30)
The current update step is 2800
The current seed is 13715500970090359067
The current lr is: 0.001
Testing Results:
 *   Acc@1 80.500
 *   Acc@1 80.904
 *   Acc@1 79.750
 *   Acc@1 80.640
 *   Acc@1 79.566
 *   Acc@1 80.059
 *   Acc@1 76.276
 *   Acc@1 75.960
 *   Acc@1 74.289
 *   Acc@1 74.495
 *   Acc@1 74.632
 *   Acc@1 74.327
Training for 300 epoch: 78.38815789473685
Training for 600 epoch: 77.01973684210526
Training for 1000 epoch: 77.09868421052632
Training for 300 epoch: 78.43208333333334
Training for 600 epoch: 77.5675
Training for 1000 epoch: 77.19291666666666
[[78.38815789473685, 77.01973684210526, 77.09868421052632], [78.43208333333334, 77.5675, 77.19291666666666]]
train loss 0.3199698533058167, epoch 69, best loss 0.3038037651538849, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [70][20/40]	Time  1.510 ( 1.515)	Data  0.029 ( 0.042)	InnerLoop  0.624 ( 0.641)	Loss 8.4707e-01 (6.7573e-01)	Acc@1  69.63 ( 75.27)
Epoch: [70][40/40]	Time  1.493 ( 1.518)	Data  0.013 ( 0.039)	InnerLoop  0.654 ( 0.648)	Loss 8.3804e-01 (6.8807e-01)	Acc@1  65.10 ( 74.83)
The current update step is 2840
GPU_0_using curriculum 20 with window 20
Epoch: [71][20/40]	Time  1.611 ( 1.524)	Data  0.026 ( 0.048)	InnerLoop  0.757 ( 0.647)	Loss 8.4258e-01 (6.6020e-01)	Acc@1  70.93 ( 75.34)
Epoch: [71][40/40]	Time  1.541 ( 1.527)	Data  0.013 ( 0.044)	InnerLoop  0.627 ( 0.643)	Loss 8.0714e-01 (6.7921e-01)	Acc@1  70.31 ( 74.74)
The current update step is 2880
GPU_0_using curriculum 20 with window 20
Epoch: [72][20/40]	Time  1.511 ( 1.528)	Data  0.030 ( 0.047)	InnerLoop  0.629 ( 0.636)	Loss 6.4922e-01 (7.1124e-01)	Acc@1  77.64 ( 73.67)
Epoch: [72][40/40]	Time  1.474 ( 1.526)	Data  0.012 ( 0.041)	InnerLoop  0.639 ( 0.645)	Loss 6.4004e-01 (6.7355e-01)	Acc@1  73.44 ( 75.16)
The current update step is 2920
GPU_0_using curriculum 20 with window 20
Epoch: [73][20/40]	Time  1.484 ( 1.534)	Data  0.030 ( 0.042)	InnerLoop  0.632 ( 0.652)	Loss 7.8936e-01 (6.7504e-01)	Acc@1  68.65 ( 74.76)
Epoch: [73][40/40]	Time  1.519 ( 1.534)	Data  0.011 ( 0.042)	InnerLoop  0.679 ( 0.650)	Loss 4.7756e-01 (6.6955e-01)	Acc@1  84.38 ( 75.69)
The current update step is 2960
GPU_0_using curriculum 20 with window 20
Epoch: [74][20/40]	Time  1.477 ( 1.524)	Data  0.032 ( 0.043)	InnerLoop  0.627 ( 0.646)	Loss 5.1108e-01 (6.3322e-01)	Acc@1  81.67 ( 76.63)
Epoch: [74][40/40]	Time  1.508 ( 1.530)	Data  0.012 ( 0.042)	InnerLoop  0.647 ( 0.648)	Loss 4.5655e-01 (6.1522e-01)	Acc@1  80.73 ( 77.39)
The current update step is 3000
The current seed is 8882831813154482721
The current lr is: 0.001
Testing Results:
 *   Acc@1 75.355
 *   Acc@1 76.168
 *   Acc@1 74.526
 *   Acc@1 75.146
 *   Acc@1 73.355
 *   Acc@1 73.726
 *   Acc@1 74.197
 *   Acc@1 74.152
 *   Acc@1 69.500
 *   Acc@1 69.683
 *   Acc@1 65.947
 *   Acc@1 65.967
Training for 300 epoch: 74.77631578947368
Training for 600 epoch: 72.01315789473685
Training for 1000 epoch: 69.65131578947368
Training for 300 epoch: 75.16
Training for 600 epoch: 72.41458333333333
Training for 1000 epoch: 69.84625
[[74.77631578947368, 72.01315789473685, 69.65131578947368], [75.16, 72.41458333333333, 69.84625]]
train loss 0.467044627904892, epoch 74, best loss 0.3038037651538849, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [75][20/40]	Time  1.466 ( 1.518)	Data  0.026 ( 0.041)	InnerLoop  0.618 ( 0.647)	Loss 6.6224e-01 (6.5925e-01)	Acc@1  78.22 ( 76.80)
Epoch: [75][40/40]	Time  1.478 ( 1.518)	Data  0.011 ( 0.041)	InnerLoop  0.639 ( 0.642)	Loss 6.6985e-01 (6.6361e-01)	Acc@1  77.60 ( 76.35)
The current update step is 3040
GPU_0_using curriculum 20 with window 20
Epoch: [76][20/40]	Time  1.474 ( 1.522)	Data  0.030 ( 0.049)	InnerLoop  0.619 ( 0.633)	Loss 9.5419e-01 (6.5691e-01)	Acc@1  63.12 ( 76.11)
Epoch: [76][40/40]	Time  1.651 ( 1.525)	Data  0.013 ( 0.041)	InnerLoop  0.733 ( 0.643)	Loss 8.4454e-01 (6.5547e-01)	Acc@1  69.79 ( 76.13)
The current update step is 3080
GPU_0_using curriculum 20 with window 20
Epoch: [77][20/40]	Time  1.474 ( 1.511)	Data  0.030 ( 0.041)	InnerLoop  0.623 ( 0.635)	Loss 6.1304e-01 (6.3451e-01)	Acc@1  75.52 ( 76.29)
Epoch: [77][40/40]	Time  1.454 ( 1.512)	Data  0.012 ( 0.041)	InnerLoop  0.625 ( 0.636)	Loss 7.9461e-01 (6.9151e-01)	Acc@1  70.31 ( 74.75)
The current update step is 3120
GPU_0_using curriculum 20 with window 20
Epoch: [78][20/40]	Time  1.532 ( 1.522)	Data  0.034 ( 0.047)	InnerLoop  0.627 ( 0.637)	Loss 7.9063e-01 (6.8916e-01)	Acc@1  72.46 ( 75.28)
Epoch: [78][40/40]	Time  1.471 ( 1.525)	Data  0.013 ( 0.044)	InnerLoop  0.622 ( 0.639)	Loss 4.8767e-01 (6.6848e-01)	Acc@1  81.25 ( 75.95)
The current update step is 3160
GPU_0_using curriculum 20 with window 20
Epoch: [79][20/40]	Time  1.627 ( 1.528)	Data  0.029 ( 0.043)	InnerLoop  0.751 ( 0.648)	Loss 5.5966e-01 (6.1137e-01)	Acc@1  81.35 ( 77.42)
Epoch: [79][40/40]	Time  1.473 ( 1.522)	Data  0.014 ( 0.042)	InnerLoop  0.634 ( 0.646)	Loss 4.8113e-01 (6.3830e-01)	Acc@1  80.73 ( 76.42)
The current update step is 3200
The current seed is 5717172893774289611
The current lr is: 0.001
Testing Results:
 *   Acc@1 65.711
 *   Acc@1 66.172
 *   Acc@1 68.605
 *   Acc@1 68.795
 *   Acc@1 69.184
 *   Acc@1 70.000
 *   Acc@1 77.816
 *   Acc@1 77.826
 *   Acc@1 75.447
 *   Acc@1 76.165
 *   Acc@1 74.303
 *   Acc@1 74.743
Training for 300 epoch: 71.76315789473685
Training for 600 epoch: 72.02631578947368
Training for 1000 epoch: 71.74342105263159
Training for 300 epoch: 71.99916666666667
Training for 600 epoch: 72.48
Training for 1000 epoch: 72.37166666666667
[[71.76315789473685, 72.02631578947368, 71.74342105263159], [71.99916666666667, 72.48, 72.37166666666667]]
train loss 0.3277704951763153, epoch 79, best loss 0.3038037651538849, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [80][20/40]	Time  1.494 ( 1.506)	Data  0.031 ( 0.036)	InnerLoop  0.631 ( 0.645)	Loss 1.0245e+00 (6.4829e-01)	Acc@1  67.22 ( 76.41)
Epoch: [80][40/40]	Time  1.470 ( 1.516)	Data  0.013 ( 0.039)	InnerLoop  0.628 ( 0.646)	Loss 7.9306e-01 (6.7768e-01)	Acc@1  72.40 ( 75.20)
The current update step is 3240
GPU_0_using curriculum 20 with window 20
Epoch: [81][20/40]	Time  1.484 ( 1.512)	Data  0.030 ( 0.037)	InnerLoop  0.621 ( 0.648)	Loss 5.8933e-01 (6.5169e-01)	Acc@1  80.14 ( 77.82)
Epoch: [81][40/40]	Time  1.486 ( 1.516)	Data  0.013 ( 0.039)	InnerLoop  0.634 ( 0.646)	Loss 1.3330e+00 (6.4121e-01)	Acc@1  56.77 ( 77.69)
The current update step is 3280
GPU_0_using curriculum 20 with window 20
Epoch: [82][20/40]	Time  1.606 ( 1.518)	Data  0.029 ( 0.041)	InnerLoop  0.733 ( 0.649)	Loss 7.4526e-01 (6.8608e-01)	Acc@1  76.73 ( 76.44)
Epoch: [82][40/40]	Time  1.461 ( 1.522)	Data  0.011 ( 0.041)	InnerLoop  0.630 ( 0.649)	Loss 6.6630e-01 (6.8550e-01)	Acc@1  76.04 ( 76.30)
The current update step is 3320
GPU_0_using curriculum 20 with window 20
Epoch: [83][20/40]	Time  1.483 ( 1.509)	Data  0.029 ( 0.035)	InnerLoop  0.632 ( 0.649)	Loss 5.8071e-01 (7.9563e-01)	Acc@1  78.39 ( 72.73)
Epoch: [83][40/40]	Time  1.507 ( 1.516)	Data  0.014 ( 0.038)	InnerLoop  0.630 ( 0.647)	Loss 7.5162e-01 (7.4387e-01)	Acc@1  73.96 ( 73.46)
The current update step is 3360
GPU_0_using curriculum 20 with window 20
Epoch: [84][20/40]	Time  1.488 ( 1.519)	Data  0.031 ( 0.042)	InnerLoop  0.637 ( 0.643)	Loss 5.8359e-01 (7.6069e-01)	Acc@1  79.00 ( 71.53)
Epoch: [84][40/40]	Time  1.511 ( 1.515)	Data  0.012 ( 0.038)	InnerLoop  0.628 ( 0.644)	Loss 6.6213e-01 (7.1947e-01)	Acc@1  73.96 ( 73.05)
The current update step is 3400
The current seed is 7526403138628344142
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.368
 *   Acc@1 77.836
 *   Acc@1 75.553
 *   Acc@1 75.647
 *   Acc@1 74.013
 *   Acc@1 74.237
 *   Acc@1 76.776
 *   Acc@1 77.428
 *   Acc@1 76.908
 *   Acc@1 76.739
 *   Acc@1 75.566
 *   Acc@1 75.537
Training for 300 epoch: 77.07236842105263
Training for 600 epoch: 76.23026315789474
Training for 1000 epoch: 74.78947368421052
Training for 300 epoch: 77.63208333333333
Training for 600 epoch: 76.19291666666666
Training for 1000 epoch: 74.88708333333332
[[77.07236842105263, 76.23026315789474, 74.78947368421052], [77.63208333333333, 76.19291666666666, 74.88708333333332]]
train loss 0.33656857323646544, epoch 84, best loss 0.3038037651538849, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [85][20/40]	Time  1.485 ( 1.509)	Data  0.030 ( 0.041)	InnerLoop  0.633 ( 0.642)	Loss 5.7017e-01 (6.6361e-01)	Acc@1  77.86 ( 75.19)
Epoch: [85][40/40]	Time  1.479 ( 1.509)	Data  0.012 ( 0.037)	InnerLoop  0.619 ( 0.642)	Loss 5.7158e-01 (7.0793e-01)	Acc@1  78.12 ( 74.14)
The current update step is 3440
GPU_0_using curriculum 20 with window 20
Epoch: [86][20/40]	Time  1.581 ( 1.516)	Data  0.028 ( 0.048)	InnerLoop  0.733 ( 0.638)	Loss 2.0217e+00 (8.2676e-01)	Acc@1  44.37 ( 70.79)
Epoch: [86][40/40]	Time  1.473 ( 1.513)	Data  0.013 ( 0.044)	InnerLoop  0.636 ( 0.637)	Loss 6.6607e-01 (7.7683e-01)	Acc@1  72.40 ( 71.62)
The current update step is 3480
GPU_0_using curriculum 20 with window 20
Epoch: [87][20/40]	Time  1.521 ( 1.511)	Data  0.029 ( 0.047)	InnerLoop  0.630 ( 0.634)	Loss 7.2468e-01 (6.9180e-01)	Acc@1  74.32 ( 75.28)
Epoch: [87][40/40]	Time  1.511 ( 1.516)	Data  0.010 ( 0.041)	InnerLoop  0.625 ( 0.642)	Loss 5.6281e-01 (7.3519e-01)	Acc@1  80.73 ( 74.21)
The current update step is 3520
GPU_0_using curriculum 20 with window 20
Epoch: [88][20/40]	Time  1.536 ( 1.523)	Data  0.029 ( 0.042)	InnerLoop  0.629 ( 0.644)	Loss 7.6962e-01 (6.7555e-01)	Acc@1  74.97 ( 75.40)
Epoch: [88][40/40]	Time  1.476 ( 1.520)	Data  0.012 ( 0.041)	InnerLoop  0.628 ( 0.641)	Loss 6.3731e-01 (6.9395e-01)	Acc@1  76.04 ( 75.07)
The current update step is 3560
GPU_0_using curriculum 20 with window 20
Epoch: [89][20/40]	Time  1.499 ( 1.505)	Data  0.030 ( 0.042)	InnerLoop  0.641 ( 0.638)	Loss 6.4961e-01 (8.1683e-01)	Acc@1  73.86 ( 70.46)
Epoch: [89][40/40]	Time  1.535 ( 1.517)	Data  0.012 ( 0.041)	InnerLoop  0.643 ( 0.645)	Loss 4.6999e-01 (7.6940e-01)	Acc@1  82.29 ( 72.26)
The current update step is 3600
The current seed is 8731328021955014929
The current lr is: 0.001
Testing Results:
 *   Acc@1 65.803
 *   Acc@1 66.559
 *   Acc@1 62.263
 *   Acc@1 62.600
 *   Acc@1 62.118
 *   Acc@1 61.979
 *   Acc@1 78.171
 *   Acc@1 78.483
 *   Acc@1 76.395
 *   Acc@1 76.647
 *   Acc@1 73.750
 *   Acc@1 74.183
Training for 300 epoch: 71.98684210526315
Training for 600 epoch: 69.32894736842105
Training for 1000 epoch: 67.9342105263158
Training for 300 epoch: 72.52083333333334
Training for 600 epoch: 69.62375
Training for 1000 epoch: 68.08125
[[71.98684210526315, 69.32894736842105, 67.9342105263158], [72.52083333333334, 69.62375, 68.08125]]
train loss 0.33994845604896545, epoch 89, best loss 0.3038037651538849, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [90][20/40]	Time  1.482 ( 1.519)	Data  0.028 ( 0.041)	InnerLoop  0.623 ( 0.643)	Loss 6.2421e-01 (7.3206e-01)	Acc@1  77.99 ( 73.42)
Epoch: [90][40/40]	Time  1.445 ( 1.515)	Data  0.012 ( 0.041)	InnerLoop  0.615 ( 0.641)	Loss 6.7080e-01 (6.9225e-01)	Acc@1  78.12 ( 74.76)
The current update step is 3640
GPU_0_using curriculum 20 with window 20
Epoch: [91][20/40]	Time  1.485 ( 1.512)	Data  0.029 ( 0.048)	InnerLoop  0.636 ( 0.635)	Loss 7.2894e-01 (7.0489e-01)	Acc@1  70.80 ( 74.31)
Epoch: [91][40/40]	Time  1.603 ( 1.518)	Data  0.012 ( 0.042)	InnerLoop  0.758 ( 0.645)	Loss 6.1187e-01 (7.0088e-01)	Acc@1  78.65 ( 74.74)
The current update step is 3680
GPU_0_using curriculum 20 with window 20
Epoch: [92][20/40]	Time  1.518 ( 1.522)	Data  0.029 ( 0.043)	InnerLoop  0.634 ( 0.643)	Loss 5.8257e-01 (6.7072e-01)	Acc@1  81.51 ( 75.30)
Epoch: [92][40/40]	Time  1.488 ( 1.523)	Data  0.011 ( 0.043)	InnerLoop  0.645 ( 0.646)	Loss 5.1788e-01 (6.4494e-01)	Acc@1  84.38 ( 76.68)
The current update step is 3720
GPU_0_using curriculum 20 with window 20
Epoch: [93][20/40]	Time  1.494 ( 1.527)	Data  0.030 ( 0.049)	InnerLoop  0.637 ( 0.647)	Loss 6.4698e-01 (6.9556e-01)	Acc@1  74.58 ( 75.06)
Epoch: [93][40/40]	Time  1.476 ( 1.527)	Data  0.012 ( 0.046)	InnerLoop  0.636 ( 0.646)	Loss 5.2987e-01 (6.5905e-01)	Acc@1  83.85 ( 76.26)
The current update step is 3760
GPU_0_using curriculum 20 with window 20
Epoch: [94][20/40]	Time  1.607 ( 1.529)	Data  0.028 ( 0.043)	InnerLoop  0.755 ( 0.653)	Loss 5.7906e-01 (7.2090e-01)	Acc@1  79.39 ( 73.74)
Epoch: [94][40/40]	Time  1.468 ( 1.525)	Data  0.013 ( 0.043)	InnerLoop  0.627 ( 0.650)	Loss 7.1099e-01 (6.7571e-01)	Acc@1  70.83 ( 75.60)
The current update step is 3800
The current seed is 6732316333305860137
The current lr is: 0.001
Testing Results:
 *   Acc@1 68.276
 *   Acc@1 69.007
 *   Acc@1 68.329
 *   Acc@1 68.895
 *   Acc@1 67.171
 *   Acc@1 68.188
 *   Acc@1 75.961
 *   Acc@1 76.552
 *   Acc@1 74.513
 *   Acc@1 75.019
 *   Acc@1 73.500
 *   Acc@1 74.419
Training for 300 epoch: 72.11842105263159
Training for 600 epoch: 71.42105263157895
Training for 1000 epoch: 70.33552631578948
Training for 300 epoch: 72.77958333333333
Training for 600 epoch: 71.95708333333333
Training for 1000 epoch: 71.30375000000001
[[72.11842105263159, 71.42105263157895, 70.33552631578948], [72.77958333333333, 71.95708333333333, 71.30375000000001]]
train loss 0.35149400954246524, epoch 94, best loss 0.3038037651538849, best_epoch 39
GPU_0_using curriculum 20 with window 20
Epoch: [95][20/40]	Time  1.482 ( 1.521)	Data  0.027 ( 0.036)	InnerLoop  0.629 ( 0.652)	Loss 7.7163e-01 (6.1311e-01)	Acc@1  68.59 ( 77.23)
Epoch: [95][40/40]	Time  1.479 ( 1.522)	Data  0.013 ( 0.039)	InnerLoop  0.630 ( 0.651)	Loss 1.0446e+00 (6.4105e-01)	Acc@1  63.54 ( 76.75)
The current update step is 3840
GPU_0_using curriculum 20 with window 20
Epoch: [96][20/40]	Time  1.496 ( 1.528)	Data  0.034 ( 0.037)	InnerLoop  0.636 ( 0.652)	Loss 5.7045e-01 (6.5042e-01)	Acc@1  76.73 ( 76.27)
Epoch: [96][40/40]	Time  1.477 ( 1.524)	Data  0.013 ( 0.039)	InnerLoop  0.637 ( 0.648)	Loss 6.9333e-01 (6.5070e-01)	Acc@1  74.48 ( 76.38)
The current update step is 3880
GPU_0_using curriculum 20 with window 20
Epoch: [97][20/40]	Time  1.620 ( 1.525)	Data  0.029 ( 0.042)	InnerLoop  0.763 ( 0.654)	Loss 5.1480e-01 (6.3712e-01)	Acc@1  80.40 ( 77.22)
Epoch: [97][40/40]	Time  1.479 ( 1.522)	Data  0.011 ( 0.041)	InnerLoop  0.626 ( 0.648)	Loss 4.6979e-01 (6.3871e-01)	Acc@1  81.77 ( 76.90)
The current update step is 3920
GPU_0_using curriculum 20 with window 20
Epoch: [98][20/40]	Time  1.485 ( 1.519)	Data  0.031 ( 0.038)	InnerLoop  0.627 ( 0.648)	Loss 5.0048e-01 (6.3918e-01)	Acc@1  81.45 ( 77.29)
Epoch: [98][40/40]	Time  1.492 ( 1.523)	Data  0.011 ( 0.040)	InnerLoop  0.643 ( 0.650)	Loss 5.0198e-01 (6.3291e-01)	Acc@1  82.81 ( 77.29)
The current update step is 3960
GPU_0_using curriculum 20 with window 20
Epoch: [99][20/40]	Time  1.506 ( 1.515)	Data  0.031 ( 0.043)	InnerLoop  0.630 ( 0.644)	Loss 7.6598e-01 (6.6378e-01)	Acc@1  69.37 ( 74.94)
Epoch: [99][40/40]	Time  1.462 ( 1.515)	Data  0.013 ( 0.040)	InnerLoop  0.627 ( 0.645)	Loss 4.8671e-01 (6.4289e-01)	Acc@1  79.17 ( 76.43)
The current update step is 4000
The current seed is 6839946164137228160
The current lr is: 0.001
Testing Results:
 *   Acc@1 68.579
 *   Acc@1 68.975
 *   Acc@1 65.329
 *   Acc@1 65.843
 *   Acc@1 64.132
 *   Acc@1 64.434
 *   Acc@1 76.645
 *   Acc@1 77.248
 *   Acc@1 72.776
 *   Acc@1 74.038
 *   Acc@1 70.724
 *   Acc@1 71.486
Training for 300 epoch: 72.61184210526315
Training for 600 epoch: 69.05263157894737
Training for 1000 epoch: 67.42763157894737
Training for 300 epoch: 73.11166666666666
Training for 600 epoch: 69.94041666666666
Training for 1000 epoch: 67.96000000000001
[[72.61184210526315, 69.05263157894737, 67.42763157894737], [73.11166666666666, 69.94041666666666, 67.96000000000001]]
train loss 0.3531221097946167, epoch 99, best loss 0.3038037651538849, best_epoch 99
GPU_0_using curriculum 20 with window 20
Epoch: [100][20/40]	Time  1.514 ( 1.524)	Data  0.036 ( 0.043)	InnerLoop  0.629 ( 0.646)	Loss 5.0239e-01 (6.4249e-01)	Acc@1  81.25 ( 76.80)
Epoch: [100][40/40]	Time  1.490 ( 1.523)	Data  0.013 ( 0.039)	InnerLoop  0.656 ( 0.648)	Loss 5.3276e-01 (6.5536e-01)	Acc@1  79.17 ( 76.58)
The current update step is 4040
GPU_0_using curriculum 20 with window 20
Epoch: [101][20/40]	Time  1.639 ( 1.515)	Data  0.029 ( 0.048)	InnerLoop  0.746 ( 0.640)	Loss 6.7547e-01 (6.6095e-01)	Acc@1  76.99 ( 75.56)
Epoch: [101][40/40]	Time  1.495 ( 1.520)	Data  0.012 ( 0.044)	InnerLoop  0.639 ( 0.642)	Loss 6.8611e-01 (6.4369e-01)	Acc@1  75.52 ( 76.61)
The current update step is 4080
GPU_0_using curriculum 20 with window 20
Epoch: [102][20/40]	Time  1.474 ( 1.506)	Data  0.028 ( 0.048)	InnerLoop  0.624 ( 0.631)	Loss 7.6305e-01 (6.8427e-01)	Acc@1  75.59 ( 75.61)
Epoch: [102][40/40]	Time  1.472 ( 1.509)	Data  0.012 ( 0.041)	InnerLoop  0.640 ( 0.639)	Loss 4.4730e-01 (6.8312e-01)	Acc@1  81.25 ( 75.44)
The current update step is 4120
GPU_0_using curriculum 20 with window 20
Epoch: [103][20/40]	Time  1.499 ( 1.508)	Data  0.028 ( 0.041)	InnerLoop  0.626 ( 0.640)	Loss 5.6926e-01 (6.0527e-01)	Acc@1  80.01 ( 78.13)
Epoch: [103][40/40]	Time  1.488 ( 1.515)	Data  0.012 ( 0.041)	InnerLoop  0.651 ( 0.641)	Loss 5.4911e-01 (6.4728e-01)	Acc@1  83.85 ( 77.08)
The current update step is 4160
GPU_0_using curriculum 20 with window 20
Epoch: [104][20/40]	Time  1.501 ( 1.516)	Data  0.028 ( 0.042)	InnerLoop  0.650 ( 0.639)	Loss 6.4944e-01 (6.6865e-01)	Acc@1  78.26 ( 76.18)
Epoch: [104][40/40]	Time  1.493 ( 1.518)	Data  0.012 ( 0.041)	InnerLoop  0.638 ( 0.642)	Loss 5.0234e-01 (6.7368e-01)	Acc@1  77.60 ( 75.99)
The current update step is 4200
The current seed is 16065229849669314649
The current lr is: 0.001
Testing Results:
 *   Acc@1 68.974
 *   Acc@1 70.110
 *   Acc@1 63.000
 *   Acc@1 64.543
 *   Acc@1 58.645
 *   Acc@1 60.062
 *   Acc@1 72.513
 *   Acc@1 73.418
 *   Acc@1 68.053
 *   Acc@1 68.788
 *   Acc@1 64.145
 *   Acc@1 65.413
Training for 300 epoch: 70.74342105263158
Training for 600 epoch: 65.52631578947368
Training for 1000 epoch: 61.39473684210526
Training for 300 epoch: 71.76416666666667
Training for 600 epoch: 66.66541666666666
Training for 1000 epoch: 62.73791666666666
[[70.74342105263158, 65.52631578947368, 61.39473684210526], [71.76416666666667, 66.66541666666666, 62.73791666666666]]
train loss 0.44538868675231935, epoch 104, best loss 0.3038037651538849, best_epoch 99
GPU_0_using curriculum 20 with window 20
Epoch: [105][20/40]	Time  1.530 ( 1.513)	Data  0.028 ( 0.041)	InnerLoop  0.657 ( 0.645)	Loss 7.9301e-01 (6.3367e-01)	Acc@1  74.09 ( 77.22)
Epoch: [105][40/40]	Time  1.488 ( 1.520)	Data  0.010 ( 0.040)	InnerLoop  0.663 ( 0.642)	Loss 5.3316e-01 (6.6130e-01)	Acc@1  79.69 ( 76.52)
The current update step is 4240
GPU_0_using curriculum 20 with window 20
Epoch: [106][20/40]	Time  1.477 ( 1.521)	Data  0.027 ( 0.048)	InnerLoop  0.628 ( 0.635)	Loss 7.7823e-01 (7.4423e-01)	Acc@1  72.36 ( 73.65)
Epoch: [106][40/40]	Time  1.601 ( 1.521)	Data  0.012 ( 0.041)	InnerLoop  0.765 ( 0.644)	Loss 5.2164e-01 (7.0179e-01)	Acc@1  78.12 ( 74.96)
The current update step is 4280
GPU_0_using curriculum 20 with window 20
Epoch: [107][20/40]	Time  1.490 ( 1.520)	Data  0.031 ( 0.041)	InnerLoop  0.632 ( 0.640)	Loss 8.0401e-01 (6.7379e-01)	Acc@1  72.20 ( 76.17)
Epoch: [107][40/40]	Time  1.489 ( 1.523)	Data  0.013 ( 0.042)	InnerLoop  0.619 ( 0.640)	Loss 5.2740e-01 (6.4201e-01)	Acc@1  81.77 ( 77.23)
The current update step is 4320
GPU_0_using curriculum 20 with window 20
Epoch: [108][20/40]	Time  1.488 ( 1.512)	Data  0.028 ( 0.047)	InnerLoop  0.623 ( 0.637)	Loss 6.9758e-01 (6.9101e-01)	Acc@1  72.46 ( 75.26)
Epoch: [108][40/40]	Time  1.481 ( 1.514)	Data  0.012 ( 0.043)	InnerLoop  0.630 ( 0.638)	Loss 7.5605e-01 (7.8366e-01)	Acc@1  65.10 ( 71.97)
The current update step is 4360
GPU_0_using curriculum 20 with window 20
Epoch: [109][20/40]	Time  1.597 ( 1.511)	Data  0.029 ( 0.042)	InnerLoop  0.737 ( 0.644)	Loss 8.1507e-01 (8.0804e-01)	Acc@1  71.97 ( 68.52)
Epoch: [109][40/40]	Time  1.488 ( 1.516)	Data  0.013 ( 0.042)	InnerLoop  0.651 ( 0.642)	Loss 6.9356e-01 (7.8845e-01)	Acc@1  73.96 ( 70.01)
The current update step is 4400
The current seed is 4305324529201672808
The current lr is: 0.001
Testing Results:
 *   Acc@1 66.737
 *   Acc@1 67.233
 *   Acc@1 62.355
 *   Acc@1 62.291
 *   Acc@1 60.724
 *   Acc@1 60.613
 *   Acc@1 75.921
 *   Acc@1 76.829
 *   Acc@1 74.592
 *   Acc@1 75.277
 *   Acc@1 73.737
 *   Acc@1 74.412
Training for 300 epoch: 71.32894736842105
Training for 600 epoch: 68.47368421052632
Training for 1000 epoch: 67.23026315789474
Training for 300 epoch: 72.03125
Training for 600 epoch: 68.78375
Training for 1000 epoch: 67.5125
[[71.32894736842105, 68.47368421052632, 67.23026315789474], [72.03125, 68.78375, 67.5125]]
train loss 0.3429480405330658, epoch 109, best loss 0.3038037651538849, best_epoch 99
GPU_0_using curriculum 20 with window 20
Epoch: [110][20/40]	Time  1.520 ( 1.530)	Data  0.027 ( 0.036)	InnerLoop  0.624 ( 0.649)	Loss 1.1885e+00 (7.5716e-01)	Acc@1  65.79 ( 72.38)
Epoch: [110][40/40]	Time  1.465 ( 1.539)	Data  0.013 ( 0.038)	InnerLoop  0.620 ( 0.651)	Loss 1.3730e+00 (6.9993e-01)	Acc@1  52.60 ( 74.35)
The current update step is 4440
GPU_0_using curriculum 20 with window 20
Epoch: [111][20/40]	Time  1.540 ( 1.536)	Data  0.029 ( 0.036)	InnerLoop  0.663 ( 0.649)	Loss 6.5712e-01 (6.8581e-01)	Acc@1  71.78 ( 75.02)
Epoch: [111][40/40]	Time  1.456 ( 1.537)	Data  0.012 ( 0.039)	InnerLoop  0.621 ( 0.647)	Loss 5.8261e-01 (6.7982e-01)	Acc@1  80.73 ( 75.31)
The current update step is 4480
GPU_0_using curriculum 20 with window 20
Epoch: [112][20/40]	Time  1.626 ( 1.530)	Data  0.030 ( 0.041)	InnerLoop  0.750 ( 0.644)	Loss 6.8410e-01 (7.5995e-01)	Acc@1  77.38 ( 72.75)
Epoch: [112][40/40]	Time  1.500 ( 1.530)	Data  0.012 ( 0.042)	InnerLoop  0.626 ( 0.643)	Loss 5.4710e-01 (6.9815e-01)	Acc@1  81.77 ( 74.72)
The current update step is 4520
GPU_0_using curriculum 20 with window 20
Epoch: [113][20/40]	Time  1.540 ( 1.535)	Data  0.030 ( 0.037)	InnerLoop  0.635 ( 0.654)	Loss 7.2627e-01 (7.6848e-01)	Acc@1  72.72 ( 72.52)
Epoch: [113][40/40]	Time  1.484 ( 1.536)	Data  0.011 ( 0.039)	InnerLoop  0.637 ( 0.653)	Loss 6.3440e-01 (7.4252e-01)	Acc@1  76.56 ( 73.11)
The current update step is 4560
GPU_0_using curriculum 20 with window 20
Epoch: [114][20/40]	Time  1.521 ( 1.531)	Data  0.032 ( 0.042)	InnerLoop  0.620 ( 0.641)	Loss 6.5341e-01 (7.1240e-01)	Acc@1  75.49 ( 72.64)
Epoch: [114][40/40]	Time  1.464 ( 1.529)	Data  0.011 ( 0.038)	InnerLoop  0.632 ( 0.646)	Loss 8.0339e-01 (7.3547e-01)	Acc@1  70.31 ( 72.61)
The current update step is 4600
The current seed is 15418549205585378354
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.289
 *   Acc@1 76.606
 *   Acc@1 73.895
 *   Acc@1 74.285
 *   Acc@1 72.789
 *   Acc@1 73.718
 *   Acc@1 67.000
 *   Acc@1 66.862
 *   Acc@1 66.539
 *   Acc@1 66.373
 *   Acc@1 66.026
 *   Acc@1 66.158
Training for 300 epoch: 71.64473684210526
Training for 600 epoch: 70.21710526315789
Training for 1000 epoch: 69.40789473684211
Training for 300 epoch: 71.73416666666667
Training for 600 epoch: 70.32916666666667
Training for 1000 epoch: 69.93791666666667
[[71.64473684210526, 70.21710526315789, 69.40789473684211], [71.73416666666667, 70.32916666666667, 69.93791666666667]]
train loss 0.43864668951034547, epoch 114, best loss 0.3038037651538849, best_epoch 99
GPU_0_using curriculum 20 with window 20
Epoch: [115][20/40]	Time  1.492 ( 1.545)	Data  0.030 ( 0.042)	InnerLoop  0.633 ( 0.650)	Loss 1.1538e+00 (7.2652e-01)	Acc@1  65.07 ( 73.92)
Epoch: [115][40/40]	Time  1.476 ( 1.541)	Data  0.010 ( 0.039)	InnerLoop  0.625 ( 0.650)	Loss 1.3025e+00 (7.5162e-01)	Acc@1  48.44 ( 72.59)
The current update step is 4640
GPU_0_using curriculum 20 with window 20
Epoch: [116][20/40]	Time  1.648 ( 1.535)	Data  0.032 ( 0.048)	InnerLoop  0.744 ( 0.646)	Loss 7.4276e-01 (7.4398e-01)	Acc@1  70.77 ( 73.56)
Epoch: [116][40/40]	Time  1.522 ( 1.533)	Data  0.012 ( 0.044)	InnerLoop  0.646 ( 0.646)	Loss 1.0633e+00 (7.2081e-01)	Acc@1  60.94 ( 73.96)
The current update step is 4680
GPU_0_using curriculum 20 with window 20
Epoch: [117][20/40]	Time  1.503 ( 1.532)	Data  0.031 ( 0.048)	InnerLoop  0.627 ( 0.641)	Loss 7.1520e-01 (6.3650e-01)	Acc@1  74.80 ( 77.56)
Epoch: [117][40/40]	Time  1.471 ( 1.534)	Data  0.012 ( 0.041)	InnerLoop  0.635 ( 0.647)	Loss 8.3079e-01 (6.6485e-01)	Acc@1  67.19 ( 76.47)
The current update step is 4720
GPU_0_using curriculum 20 with window 20
Epoch: [118][20/40]	Time  1.518 ( 1.520)	Data  0.027 ( 0.041)	InnerLoop  0.623 ( 0.647)	Loss 6.6499e-01 (6.7821e-01)	Acc@1  75.20 ( 74.98)
Epoch: [118][40/40]	Time  1.475 ( 1.523)	Data  0.012 ( 0.040)	InnerLoop  0.628 ( 0.644)	Loss 1.0232e+00 (6.7646e-01)	Acc@1  68.23 ( 75.05)
The current update step is 4760
GPU_0_using curriculum 20 with window 20
Epoch: [119][20/40]	Time  1.480 ( 1.533)	Data  0.029 ( 0.042)	InnerLoop  0.626 ( 0.647)	Loss 5.8216e-01 (6.4668e-01)	Acc@1  76.73 ( 76.76)
Epoch: [119][40/40]	Time  1.523 ( 1.532)	Data  0.013 ( 0.042)	InnerLoop  0.638 ( 0.648)	Loss 5.2960e-01 (6.3568e-01)	Acc@1  80.21 ( 76.97)
The current update step is 4800
The current seed is 6357348372442021441
The current lr is: 0.001
Testing Results:
 *   Acc@1 66.276
 *   Acc@1 66.925
 *   Acc@1 62.789
 *   Acc@1 63.716
 *   Acc@1 60.816
 *   Acc@1 61.547
 *   Acc@1 68.987
 *   Acc@1 68.849
 *   Acc@1 64.553
 *   Acc@1 65.279
 *   Acc@1 62.961
 *   Acc@1 63.235
Training for 300 epoch: 67.63157894736842
Training for 600 epoch: 63.671052631578945
Training for 1000 epoch: 61.88815789473684
Training for 300 epoch: 67.88708333333332
Training for 600 epoch: 64.4975
Training for 1000 epoch: 62.39125
[[67.63157894736842, 63.671052631578945, 61.88815789473684], [67.88708333333332, 64.4975, 62.39125]]
train loss 0.578003900718689, epoch 119, best loss 0.3038037651538849, best_epoch 99
GPU_0_using curriculum 20 with window 20
Epoch: [120][20/40]	Time  1.492 ( 1.521)	Data  0.034 ( 0.042)	InnerLoop  0.634 ( 0.651)	Loss 7.2941e-01 (6.6324e-01)	Acc@1  73.18 ( 75.70)
Epoch: [120][40/40]	Time  1.483 ( 1.519)	Data  0.012 ( 0.041)	InnerLoop  0.624 ( 0.646)	Loss 6.8730e-01 (6.6422e-01)	Acc@1  69.79 ( 75.61)
The current update step is 4840
GPU_0_using curriculum 20 with window 20
Epoch: [121][20/40]	Time  1.527 ( 1.526)	Data  0.028 ( 0.048)	InnerLoop  0.620 ( 0.635)	Loss 7.0646e-01 (7.0775e-01)	Acc@1  73.73 ( 74.36)
Epoch: [121][40/40]	Time  1.608 ( 1.529)	Data  0.013 ( 0.041)	InnerLoop  0.746 ( 0.645)	Loss 8.9298e-01 (6.8385e-01)	Acc@1  65.10 ( 75.26)
The current update step is 4880
GPU_0_using curriculum 20 with window 20
Epoch: [122][20/40]	Time  1.479 ( 1.528)	Data  0.030 ( 0.042)	InnerLoop  0.632 ( 0.646)	Loss 5.6959e-01 (6.8595e-01)	Acc@1  80.70 ( 75.16)
Epoch: [122][40/40]	Time  1.507 ( 1.526)	Data  0.012 ( 0.042)	InnerLoop  0.654 ( 0.646)	Loss 6.3673e-01 (6.6600e-01)	Acc@1  77.60 ( 75.53)
The current update step is 4920
GPU_0_using curriculum 20 with window 20
Epoch: [123][20/40]	Time  1.485 ( 1.529)	Data  0.036 ( 0.047)	InnerLoop  0.623 ( 0.644)	Loss 7.7168e-01 (6.4962e-01)	Acc@1  73.05 ( 77.38)
Epoch: [123][40/40]	Time  1.489 ( 1.524)	Data  0.011 ( 0.044)	InnerLoop  0.624 ( 0.642)	Loss 5.8141e-01 (6.5969e-01)	Acc@1  79.17 ( 76.56)
The current update step is 4960
GPU_0_using curriculum 20 with window 20
Epoch: [124][20/40]	Time  1.673 ( 1.520)	Data  0.028 ( 0.042)	InnerLoop  0.742 ( 0.645)	Loss 7.1731e-01 (6.6152e-01)	Acc@1  71.22 ( 76.04)
Epoch: [124][40/40]	Time  1.494 ( 1.529)	Data  0.013 ( 0.042)	InnerLoop  0.631 ( 0.648)	Loss 8.3298e-01 (6.8487e-01)	Acc@1  70.83 ( 74.72)
The current update step is 5000
The current seed is 16514271193272689558
The current lr is: 0.001
Testing Results:
 *   Acc@1 75.934
 *   Acc@1 76.397
 *   Acc@1 73.579
 *   Acc@1 73.832
 *   Acc@1 71.276
 *   Acc@1 72.057
 *   Acc@1 68.395
 *   Acc@1 68.685
 *   Acc@1 65.724
 *   Acc@1 65.841
 *   Acc@1 64.592
 *   Acc@1 64.844
Training for 300 epoch: 72.16447368421052
Training for 600 epoch: 69.65131578947368
Training for 1000 epoch: 67.93421052631578
Training for 300 epoch: 72.54124999999999
Training for 600 epoch: 69.83666666666667
Training for 1000 epoch: 68.45041666666667
[[72.16447368421052, 69.65131578947368, 67.93421052631578], [72.54124999999999, 69.83666666666667, 68.45041666666667]]
train loss 0.5311901262283325, epoch 124, best loss 0.3038037651538849, best_epoch 99
GPU_0_using curriculum 20 with window 20
Epoch: [125][20/40]	Time  1.542 ( 1.516)	Data  0.028 ( 0.035)	InnerLoop  0.626 ( 0.647)	Loss 5.7073e-01 (6.7960e-01)	Acc@1  78.55 ( 75.07)
Epoch: [125][40/40]	Time  1.467 ( 1.524)	Data  0.011 ( 0.038)	InnerLoop  0.635 ( 0.648)	Loss 4.6037e-01 (6.7645e-01)	Acc@1  79.69 ( 74.93)
The current update step is 5040
GPU_0_using curriculum 20 with window 20
Epoch: [126][20/40]	Time  1.478 ( 1.523)	Data  0.027 ( 0.036)	InnerLoop  0.616 ( 0.647)	Loss 6.3582e-01 (6.3049e-01)	Acc@1  74.71 ( 76.91)
Epoch: [126][40/40]	Time  1.484 ( 1.521)	Data  0.013 ( 0.038)	InnerLoop  0.635 ( 0.646)	Loss 7.3259e-01 (6.3455e-01)	Acc@1  73.96 ( 76.77)
The current update step is 5080
GPU_0_using curriculum 20 with window 20
Epoch: [127][20/40]	Time  1.620 ( 1.522)	Data  0.031 ( 0.042)	InnerLoop  0.750 ( 0.647)	Loss 6.0919e-01 (6.6097e-01)	Acc@1  77.64 ( 75.49)
Epoch: [127][40/40]	Time  1.488 ( 1.526)	Data  0.013 ( 0.042)	InnerLoop  0.621 ( 0.646)	Loss 5.4878e-01 (6.3331e-01)	Acc@1  80.73 ( 76.76)
The current update step is 5120
GPU_0_using curriculum 20 with window 20
Epoch: [128][20/40]	Time  1.481 ( 1.527)	Data  0.029 ( 0.037)	InnerLoop  0.627 ( 0.652)	Loss 9.5444e-01 (6.1829e-01)	Acc@1  68.39 ( 77.20)
Epoch: [128][40/40]	Time  1.534 ( 1.528)	Data  0.012 ( 0.039)	InnerLoop  0.627 ( 0.649)	Loss 6.2135e-01 (6.2156e-01)	Acc@1  78.65 ( 77.01)
The current update step is 5160
GPU_0_using curriculum 20 with window 20
Epoch: [129][20/40]	Time  1.541 ( 1.519)	Data  0.029 ( 0.042)	InnerLoop  0.680 ( 0.648)	Loss 5.8243e-01 (6.5105e-01)	Acc@1  79.36 ( 76.66)
Epoch: [129][40/40]	Time  1.468 ( 1.528)	Data  0.014 ( 0.038)	InnerLoop  0.627 ( 0.651)	Loss 1.2318e+00 (6.8073e-01)	Acc@1  59.38 ( 74.96)
The current update step is 5200
The current seed is 10383866144576752777
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.171
 *   Acc@1 76.922
 *   Acc@1 75.158
 *   Acc@1 75.404
 *   Acc@1 74.316
 *   Acc@1 74.797
 *   Acc@1 70.263
 *   Acc@1 70.673
 *   Acc@1 62.237
 *   Acc@1 63.419
 *   Acc@1 58.553
 *   Acc@1 59.759
Training for 300 epoch: 73.21710526315789
Training for 600 epoch: 68.69736842105263
Training for 1000 epoch: 66.43421052631578
Training for 300 epoch: 73.79791666666667
Training for 600 epoch: 69.41166666666666
Training for 1000 epoch: 67.27791666666667
[[73.21710526315789, 68.69736842105263, 66.43421052631578], [73.79791666666667, 69.41166666666666, 67.27791666666667]]
train loss 0.5510294087409973, epoch 129, best loss 0.3038037651538849, best_epoch 99
GPU_0_using curriculum 20 with window 20
Epoch: [130][20/40]	Time  1.540 ( 1.529)	Data  0.032 ( 0.041)	InnerLoop  0.679 ( 0.651)	Loss 5.8338e-01 (6.2217e-01)	Acc@1  79.00 ( 76.93)
Epoch: [130][40/40]	Time  1.528 ( 1.534)	Data  0.013 ( 0.038)	InnerLoop  0.684 ( 0.653)	Loss 7.3441e-01 (6.6318e-01)	Acc@1  72.40 ( 75.89)
The current update step is 5240
GPU_0_using curriculum 20 with window 20
Epoch: [131][20/40]	Time  1.604 ( 1.539)	Data  0.036 ( 0.049)	InnerLoop  0.746 ( 0.645)	Loss 9.2646e-01 (6.6843e-01)	Acc@1  61.88 ( 75.26)
Epoch: [131][40/40]	Time  1.478 ( 1.540)	Data  0.015 ( 0.045)	InnerLoop  0.628 ( 0.647)	Loss 5.6519e-01 (6.6151e-01)	Acc@1  78.65 ( 75.86)
The current update step is 5280
GPU_0_using curriculum 20 with window 20
Epoch: [132][20/40]	Time  1.586 ( 1.536)	Data  0.029 ( 0.047)	InnerLoop  0.625 ( 0.639)	Loss 7.8780e-01 (6.1993e-01)	Acc@1  73.50 ( 78.37)
Epoch: [132][40/40]	Time  1.485 ( 1.537)	Data  0.014 ( 0.041)	InnerLoop  0.648 ( 0.646)	Loss 7.8159e-01 (6.7080e-01)	Acc@1  74.48 ( 75.98)
The current update step is 5320
GPU_0_using curriculum 20 with window 20
Epoch: [133][20/40]	Time  1.479 ( 1.529)	Data  0.028 ( 0.042)	InnerLoop  0.623 ( 0.646)	Loss 1.2718e+00 (7.5412e-01)	Acc@1  55.96 ( 71.48)
Epoch: [133][40/40]	Time  1.524 ( 1.537)	Data  0.012 ( 0.042)	InnerLoop  0.626 ( 0.647)	Loss 8.0508e-01 (7.8032e-01)	Acc@1  67.19 ( 69.89)
The current update step is 5360
GPU_0_using curriculum 20 with window 20
Epoch: [134][20/40]	Time  1.534 ( 1.536)	Data  0.030 ( 0.042)	InnerLoop  0.638 ( 0.643)	Loss 9.9309e-01 (7.1470e-01)	Acc@1  65.79 ( 73.43)
Epoch: [134][40/40]	Time  1.526 ( 1.543)	Data  0.013 ( 0.042)	InnerLoop  0.649 ( 0.649)	Loss 7.5965e-01 (6.9454e-01)	Acc@1  73.44 ( 74.54)
The current update step is 5400
The current seed is 1869763351931282419
The current lr is: 0.001
Testing Results:
 *   Acc@1 68.697
 *   Acc@1 68.727
 *   Acc@1 66.066
 *   Acc@1 66.262
 *   Acc@1 63.829
 *   Acc@1 64.299
 *   Acc@1 59.224
 *   Acc@1 59.135
 *   Acc@1 55.592
 *   Acc@1 56.100
 *   Acc@1 55.592
 *   Acc@1 56.013
Training for 300 epoch: 63.96052631578947
Training for 600 epoch: 60.828947368421055
Training for 1000 epoch: 59.71052631578948
Training for 300 epoch: 63.93083333333334
Training for 600 epoch: 61.18083333333334
Training for 1000 epoch: 60.155833333333334
[[63.96052631578947, 60.828947368421055, 59.71052631578948], [63.93083333333334, 61.18083333333334, 60.155833333333334]]
train loss 0.5955764846801758, epoch 134, best loss 0.3038037651538849, best_epoch 99
GPU_0_using curriculum 20 with window 20
Epoch: [135][20/40]	Time  1.504 ( 1.542)	Data  0.027 ( 0.040)	InnerLoop  0.655 ( 0.657)	Loss 6.3430e-01 (6.5046e-01)	Acc@1  76.60 ( 76.64)
Epoch: [135][40/40]	Time  1.461 ( 1.538)	Data  0.013 ( 0.040)	InnerLoop  0.628 ( 0.652)	Loss 8.0709e-01 (6.9805e-01)	Acc@1  63.02 ( 74.38)
The current update step is 5440
GPU_0_using curriculum 20 with window 20
Epoch: [136][20/40]	Time  1.503 ( 1.533)	Data  0.038 ( 0.047)	InnerLoop  0.624 ( 0.637)	Loss 5.8018e-01 (6.5031e-01)	Acc@1  81.09 ( 75.85)
Epoch: [136][40/40]	Time  1.587 ( 1.536)	Data  0.011 ( 0.041)	InnerLoop  0.739 ( 0.647)	Loss 6.1255e-01 (6.7818e-01)	Acc@1  83.33 ( 74.62)
The current update step is 5480
GPU_0_using curriculum 20 with window 20
Epoch: [137][20/40]	Time  1.487 ( 1.519)	Data  0.036 ( 0.041)	InnerLoop  0.633 ( 0.640)	Loss 5.7403e-01 (7.0471e-01)	Acc@1  77.67 ( 74.16)
Epoch: [137][40/40]	Time  1.530 ( 1.518)	Data  0.012 ( 0.041)	InnerLoop  0.629 ( 0.641)	Loss 9.5784e-01 (6.5759e-01)	Acc@1  66.67 ( 76.01)
The current update step is 5520
GPU_0_using curriculum 20 with window 20
Epoch: [138][20/40]	Time  1.543 ( 1.515)	Data  0.027 ( 0.046)	InnerLoop  0.626 ( 0.634)	Loss 6.2413e-01 (7.1666e-01)	Acc@1  77.86 ( 74.16)
Epoch: [138][40/40]	Time  1.518 ( 1.519)	Data  0.014 ( 0.044)	InnerLoop  0.680 ( 0.637)	Loss 5.0894e-01 (7.1816e-01)	Acc@1  82.29 ( 74.64)
The current update step is 5560
GPU_0_using curriculum 20 with window 20
Epoch: [139][20/40]	Time  1.614 ( 1.514)	Data  0.036 ( 0.042)	InnerLoop  0.759 ( 0.644)	Loss 5.9015e-01 (6.6660e-01)	Acc@1  78.68 ( 75.33)
Epoch: [139][40/40]	Time  1.532 ( 1.520)	Data  0.013 ( 0.041)	InnerLoop  0.625 ( 0.641)	Loss 7.4521e-01 (6.6743e-01)	Acc@1  68.75 ( 75.00)
The current update step is 5600
The current seed is 16650908903790757650
The current lr is: 0.001
Testing Results:
 *   Acc@1 78.776
 *   Acc@1 79.023
 *   Acc@1 78.197
 *   Acc@1 78.559
 *   Acc@1 77.618
 *   Acc@1 77.897
 *   Acc@1 71.763
 *   Acc@1 71.585
 *   Acc@1 70.368
 *   Acc@1 70.717
 *   Acc@1 69.118
 *   Acc@1 69.660
Training for 300 epoch: 75.26973684210526
Training for 600 epoch: 74.28289473684211
Training for 1000 epoch: 73.36842105263158
Training for 300 epoch: 75.30416666666666
Training for 600 epoch: 74.63791666666667
Training for 1000 epoch: 73.77875
[[75.26973684210526, 74.28289473684211, 73.36842105263158], [75.30416666666666, 74.63791666666667, 73.77875]]
train loss 0.4059275980472565, epoch 139, best loss 0.3038037651538849, best_epoch 99
GPU_0_using curriculum 20 with window 20
Epoch: [140][20/40]	Time  1.548 ( 1.514)	Data  0.033 ( 0.035)	InnerLoop  0.622 ( 0.641)	Loss 8.4146e-01 (7.5574e-01)	Acc@1  69.27 ( 72.09)
Epoch: [140][40/40]	Time  1.465 ( 1.515)	Data  0.013 ( 0.038)	InnerLoop  0.630 ( 0.642)	Loss 6.4762e-01 (7.4669e-01)	Acc@1  79.69 ( 72.75)
The current update step is 5640
GPU_0_using curriculum 20 with window 20
Epoch: [141][20/40]	Time  1.506 ( 1.517)	Data  0.031 ( 0.035)	InnerLoop  0.643 ( 0.652)	Loss 6.0287e-01 (7.8345e-01)	Acc@1  79.13 ( 71.21)
Epoch: [141][40/40]	Time  1.488 ( 1.521)	Data  0.015 ( 0.039)	InnerLoop  0.644 ( 0.650)	Loss 5.9385e-01 (7.2050e-01)	Acc@1  76.56 ( 73.42)
The current update step is 5680
GPU_0_using curriculum 20 with window 20
Epoch: [142][20/40]	Time  1.610 ( 1.524)	Data  0.032 ( 0.042)	InnerLoop  0.747 ( 0.652)	Loss 6.9936e-01 (7.5824e-01)	Acc@1  75.23 ( 72.84)
Epoch: [142][40/40]	Time  1.491 ( 1.523)	Data  0.012 ( 0.042)	InnerLoop  0.645 ( 0.649)	Loss 7.1626e-01 (7.3463e-01)	Acc@1  73.96 ( 73.78)
The current update step is 5720
GPU_0_using curriculum 20 with window 20
Epoch: [143][20/40]	Time  1.493 ( 1.531)	Data  0.029 ( 0.036)	InnerLoop  0.633 ( 0.655)	Loss 5.6840e-01 (6.4505e-01)	Acc@1  79.98 ( 75.59)
Epoch: [143][40/40]	Time  1.477 ( 1.531)	Data  0.014 ( 0.039)	InnerLoop  0.633 ( 0.655)	Loss 8.0769e-01 (6.5044e-01)	Acc@1  73.44 ( 75.53)
The current update step is 5760
GPU_0_using curriculum 20 with window 20
Epoch: [144][20/40]	Time  1.524 ( 1.531)	Data  0.034 ( 0.045)	InnerLoop  0.655 ( 0.651)	Loss 5.7011e-01 (6.8688e-01)	Acc@1  79.82 ( 74.17)
Epoch: [144][40/40]	Time  1.476 ( 1.526)	Data  0.014 ( 0.040)	InnerLoop  0.634 ( 0.652)	Loss 5.4428e-01 (7.0641e-01)	Acc@1  77.60 ( 73.95)
The current update step is 5800
The current seed is 5112268536764542318
The current lr is: 0.001
Testing Results:
 *   Acc@1 50.987
 *   Acc@1 51.886
 *   Acc@1 46.197
 *   Acc@1 46.725
 *   Acc@1 45.303
 *   Acc@1 45.553
 *   Acc@1 66.816
 *   Acc@1 67.540
 *   Acc@1 60.500
 *   Acc@1 60.579
 *   Acc@1 56.526
 *   Acc@1 56.778
Training for 300 epoch: 58.901315789473685
Training for 600 epoch: 53.348684210526315
Training for 1000 epoch: 50.91447368421053
Training for 300 epoch: 59.71291666666667
Training for 600 epoch: 53.65208333333334
Training for 1000 epoch: 51.16541666666667
[[58.901315789473685, 53.348684210526315, 50.91447368421053], [59.71291666666667, 53.65208333333334, 51.16541666666667]]
train loss 0.49076011791229246, epoch 144, best loss 0.3038037651538849, best_epoch 99
GPU_0_using curriculum 20 with window 20
Epoch: [145][20/40]	Time  1.495 ( 1.516)	Data  0.031 ( 0.042)	InnerLoop  0.631 ( 0.648)	Loss 1.2320e+00 (7.2126e-01)	Acc@1  57.49 ( 73.11)
Epoch: [145][40/40]	Time  1.481 ( 1.519)	Data  0.013 ( 0.039)	InnerLoop  0.641 ( 0.651)	Loss 8.3805e-01 (7.3005e-01)	Acc@1  67.71 ( 73.08)
The current update step is 5840
GPU_0_using curriculum 20 with window 20
Epoch: [146][20/40]	Time  1.641 ( 1.527)	Data  0.029 ( 0.049)	InnerLoop  0.760 ( 0.646)	Loss 6.3554e-01 (6.2382e-01)	Acc@1  74.71 ( 76.38)
Epoch: [146][40/40]	Time  1.497 ( 1.530)	Data  0.014 ( 0.045)	InnerLoop  0.647 ( 0.649)	Loss 6.1371e-01 (6.3694e-01)	Acc@1  76.04 ( 76.33)
The current update step is 5880
GPU_0_using curriculum 20 with window 20
Epoch: [147][20/40]	Time  1.509 ( 1.525)	Data  0.029 ( 0.048)	InnerLoop  0.639 ( 0.642)	Loss 5.6537e-01 (5.9716e-01)	Acc@1  79.85 ( 78.05)
Epoch: [147][40/40]	Time  1.481 ( 1.527)	Data  0.012 ( 0.042)	InnerLoop  0.635 ( 0.650)	Loss 5.2863e-01 (6.4674e-01)	Acc@1  78.12 ( 76.32)
The current update step is 5920
GPU_0_using curriculum 20 with window 20
Epoch: [148][20/40]	Time  1.499 ( 1.530)	Data  0.031 ( 0.042)	InnerLoop  0.633 ( 0.652)	Loss 6.0501e-01 (6.1735e-01)	Acc@1  77.34 ( 77.86)
Epoch: [148][40/40]	Time  1.482 ( 1.529)	Data  0.012 ( 0.041)	InnerLoop  0.640 ( 0.650)	Loss 5.3943e-01 (6.2610e-01)	Acc@1  82.29 ( 77.24)
The current update step is 5960
GPU_0_using curriculum 20 with window 20
Epoch: [149][20/40]	Time  1.496 ( 1.521)	Data  0.029 ( 0.042)	InnerLoop  0.637 ( 0.644)	Loss 6.0070e-01 (6.2247e-01)	Acc@1  77.99 ( 77.32)
Epoch: [149][40/40]	Time  1.504 ( 1.528)	Data  0.013 ( 0.041)	InnerLoop  0.645 ( 0.650)	Loss 4.7375e-01 (6.2579e-01)	Acc@1  82.29 ( 77.08)
The current update step is 6000
The current seed is 14338613691658087574
The current lr is: 0.001
Testing Results:
 *   Acc@1 74.618
 *   Acc@1 75.397
 *   Acc@1 67.539
 *   Acc@1 68.268
 *   Acc@1 64.013
 *   Acc@1 64.285
 *   Acc@1 71.000
 *   Acc@1 71.787
 *   Acc@1 61.882
 *   Acc@1 62.600
 *   Acc@1 55.579
 *   Acc@1 55.929
Training for 300 epoch: 72.80921052631578
Training for 600 epoch: 64.71052631578947
Training for 1000 epoch: 59.796052631578945
Training for 300 epoch: 73.59208333333333
Training for 600 epoch: 65.43416666666667
Training for 1000 epoch: 60.107083333333335
[[72.80921052631578, 64.71052631578947, 59.796052631578945], [73.59208333333333, 65.43416666666667, 60.107083333333335]]
train loss 0.4792202119350433, epoch 149, best loss 0.3038037651538849, best_epoch 99
GPU_0_using curriculum 20 with window 20
Epoch: [150][20/40]	Time  1.519 ( 1.537)	Data  0.030 ( 0.042)	InnerLoop  0.651 ( 0.659)	Loss 5.5792e-01 (6.4129e-01)	Acc@1  78.55 ( 76.74)
Epoch: [150][40/40]	Time  1.461 ( 1.530)	Data  0.013 ( 0.042)	InnerLoop  0.623 ( 0.653)	Loss 6.2763e-01 (6.7449e-01)	Acc@1  73.96 ( 75.21)
The current update step is 6040
GPU_0_using curriculum 20 with window 20
Epoch: [151][20/40]	Time  1.482 ( 1.514)	Data  0.027 ( 0.048)	InnerLoop  0.628 ( 0.636)	Loss 6.1971e-01 (7.3200e-01)	Acc@1  76.11 ( 72.35)
Epoch: [151][40/40]	Time  1.671 ( 1.519)	Data  0.100 ( 0.043)	InnerLoop  0.744 ( 0.646)	Loss 7.1558e-01 (7.1095e-01)	Acc@1  73.44 ( 73.99)
The current update step is 6080
GPU_0_using curriculum 20 with window 20
Epoch: [152][20/40]	Time  1.505 ( 1.513)	Data  0.031 ( 0.042)	InnerLoop  0.638 ( 0.642)	Loss 5.9837e-01 (6.9820e-01)	Acc@1  77.67 ( 75.32)
Epoch: [152][40/40]	Time  1.486 ( 1.525)	Data  0.011 ( 0.042)	InnerLoop  0.656 ( 0.645)	Loss 6.2362e-01 (7.0486e-01)	Acc@1  71.88 ( 75.20)
The current update step is 6120
GPU_0_using curriculum 20 with window 20
Epoch: [153][20/40]	Time  1.500 ( 1.535)	Data  0.028 ( 0.048)	InnerLoop  0.626 ( 0.645)	Loss 6.8303e-01 (7.3924e-01)	Acc@1  74.54 ( 73.72)
Epoch: [153][40/40]	Time  1.465 ( 1.536)	Data  0.011 ( 0.044)	InnerLoop  0.628 ( 0.646)	Loss 8.0036e-01 (6.9706e-01)	Acc@1  65.10 ( 74.85)
The current update step is 6160
GPU_0_using curriculum 20 with window 20
Epoch: [154][20/40]	Time  1.655 ( 1.540)	Data  0.027 ( 0.041)	InnerLoop  0.756 ( 0.648)	Loss 7.4891e-01 (6.3735e-01)	Acc@1  74.74 ( 77.49)
Epoch: [154][40/40]	Time  1.478 ( 1.532)	Data  0.013 ( 0.041)	InnerLoop  0.629 ( 0.644)	Loss 6.6817e-01 (6.3300e-01)	Acc@1  76.56 ( 77.47)
The current update step is 6200
The current seed is 2825064855327623352
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.724
 *   Acc@1 78.369
 *   Acc@1 75.408
 *   Acc@1 76.251
 *   Acc@1 73.539
 *   Acc@1 74.711
 *   Acc@1 74.461
 *   Acc@1 75.087
 *   Acc@1 72.408
 *   Acc@1 73.157
 *   Acc@1 70.066
 *   Acc@1 71.028
Training for 300 epoch: 76.09210526315789
Training for 600 epoch: 73.90789473684211
Training for 1000 epoch: 71.80263157894737
Training for 300 epoch: 76.72791666666667
Training for 600 epoch: 74.70375
Training for 1000 epoch: 72.86916666666667
[[76.09210526315789, 73.90789473684211, 71.80263157894737], [76.72791666666667, 74.70375, 72.86916666666667]]
train loss 0.3768334691524506, epoch 154, best loss 0.3038037651538849, best_epoch 99
GPU_0_using curriculum 20 with window 20
Epoch: [155][20/40]	Time  1.498 ( 1.540)	Data  0.028 ( 0.035)	InnerLoop  0.624 ( 0.646)	Loss 5.1192e-01 (6.5897e-01)	Acc@1  81.51 ( 76.32)
Epoch: [155][40/40]	Time  1.511 ( 1.541)	Data  0.011 ( 0.037)	InnerLoop  0.638 ( 0.646)	Loss 8.2737e-01 (6.6823e-01)	Acc@1  71.88 ( 75.91)
The current update step is 6240
GPU_0_using curriculum 20 with window 20
Epoch: [156][20/40]	Time  1.495 ( 1.526)	Data  0.029 ( 0.036)	InnerLoop  0.640 ( 0.646)	Loss 7.6718e-01 (7.5403e-01)	Acc@1  70.64 ( 72.86)
Epoch: [156][40/40]	Time  1.550 ( 1.530)	Data  0.011 ( 0.039)	InnerLoop  0.671 ( 0.647)	Loss 5.9325e-01 (7.7004e-01)	Acc@1  80.21 ( 72.15)
The current update step is 6280
GPU_0_using curriculum 20 with window 20
Epoch: [157][20/40]	Time  1.645 ( 1.530)	Data  0.036 ( 0.042)	InnerLoop  0.765 ( 0.650)	Loss 6.9596e-01 (6.8657e-01)	Acc@1  74.48 ( 75.34)
Epoch: [157][40/40]	Time  1.482 ( 1.529)	Data  0.012 ( 0.042)	InnerLoop  0.627 ( 0.645)	Loss 5.4004e-01 (6.6914e-01)	Acc@1  82.81 ( 75.77)
The current update step is 6320
GPU_0_using curriculum 20 with window 20
Epoch: [158][20/40]	Time  1.480 ( 1.515)	Data  0.029 ( 0.037)	InnerLoop  0.622 ( 0.644)	Loss 6.0848e-01 (6.7292e-01)	Acc@1  77.25 ( 75.90)
Epoch: [158][40/40]	Time  1.460 ( 1.525)	Data  0.012 ( 0.039)	InnerLoop  0.622 ( 0.645)	Loss 4.8208e-01 (6.5456e-01)	Acc@1  81.25 ( 76.20)
The current update step is 6360
GPU_0_using curriculum 20 with window 20
Epoch: [159][20/40]	Time  1.540 ( 1.529)	Data  0.030 ( 0.042)	InnerLoop  0.624 ( 0.643)	Loss 6.8269e-01 (6.4218e-01)	Acc@1  74.97 ( 76.49)
Epoch: [159][40/40]	Time  1.471 ( 1.527)	Data  0.015 ( 0.038)	InnerLoop  0.635 ( 0.647)	Loss 6.0767e-01 (6.5239e-01)	Acc@1  77.08 ( 76.35)
The current update step is 6400
The current seed is 15503354375933222576
The current lr is: 0.001
Testing Results:
 *   Acc@1 75.987
 *   Acc@1 76.513
 *   Acc@1 74.526
 *   Acc@1 74.803
 *   Acc@1 72.553
 *   Acc@1 72.889
 *   Acc@1 61.342
 *   Acc@1 61.399
 *   Acc@1 54.224
 *   Acc@1 54.675
 *   Acc@1 50.553
 *   Acc@1 50.822
Training for 300 epoch: 68.66447368421053
Training for 600 epoch: 64.375
Training for 1000 epoch: 61.55263157894737
Training for 300 epoch: 68.95583333333333
Training for 600 epoch: 64.73916666666666
Training for 1000 epoch: 61.85541666666667
[[68.66447368421053, 64.375, 61.55263157894737], [68.95583333333333, 64.73916666666666, 61.85541666666667]]
train loss 0.6240921208381652, epoch 159, best loss 0.3038037651538849, best_epoch 159
GPU_0_using curriculum 20 with window 20
Epoch: [160][20/40]	Time  1.597 ( 1.537)	Data  0.028 ( 0.041)	InnerLoop  0.661 ( 0.646)	Loss 6.3689e-01 (6.4820e-01)	Acc@1  76.82 ( 76.38)
Epoch: [160][40/40]	Time  1.462 ( 1.532)	Data  0.013 ( 0.038)	InnerLoop  0.624 ( 0.647)	Loss 7.2092e-01 (6.6631e-01)	Acc@1  71.88 ( 75.52)
The current update step is 6440
GPU_0_using curriculum 20 with window 20
Epoch: [161][20/40]	Time  1.634 ( 1.532)	Data  0.028 ( 0.048)	InnerLoop  0.738 ( 0.643)	Loss 8.5719e-01 (6.3608e-01)	Acc@1  67.68 ( 76.21)
Epoch: [161][40/40]	Time  1.514 ( 1.532)	Data  0.013 ( 0.044)	InnerLoop  0.636 ( 0.644)	Loss 4.8857e-01 (6.3185e-01)	Acc@1  79.17 ( 76.56)
The current update step is 6480
GPU_0_using curriculum 20 with window 20
Epoch: [162][20/40]	Time  1.505 ( 1.531)	Data  0.031 ( 0.048)	InnerLoop  0.625 ( 0.638)	Loss 5.7962e-01 (6.0849e-01)	Acc@1  77.12 ( 77.29)
Epoch: [162][40/40]	Time  1.504 ( 1.537)	Data  0.012 ( 0.042)	InnerLoop  0.647 ( 0.646)	Loss 6.8470e-01 (6.3299e-01)	Acc@1  71.88 ( 76.62)
The current update step is 6520
GPU_0_using curriculum 20 with window 20
Epoch: [163][20/40]	Time  1.563 ( 1.551)	Data  0.029 ( 0.043)	InnerLoop  0.661 ( 0.649)	Loss 7.6592e-01 (6.6891e-01)	Acc@1  71.84 ( 75.98)
Epoch: [163][40/40]	Time  1.503 ( 1.541)	Data  0.015 ( 0.042)	InnerLoop  0.625 ( 0.648)	Loss 1.1548e+00 (6.5900e-01)	Acc@1  68.23 ( 75.91)
The current update step is 6560
GPU_0_using curriculum 20 with window 20
Epoch: [164][20/40]	Time  1.484 ( 1.513)	Data  0.033 ( 0.042)	InnerLoop  0.616 ( 0.636)	Loss 5.4919e-01 (6.2846e-01)	Acc@1  78.55 ( 76.59)
Epoch: [164][40/40]	Time  1.456 ( 1.520)	Data  0.012 ( 0.042)	InnerLoop  0.619 ( 0.641)	Loss 6.7534e-01 (6.9250e-01)	Acc@1  73.96 ( 74.99)
The current update step is 6600
The current seed is 11561833712731069528
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.921
 *   Acc@1 71.932
 *   Acc@1 70.053
 *   Acc@1 70.058
 *   Acc@1 68.211
 *   Acc@1 68.267
 *   Acc@1 77.197
 *   Acc@1 77.512
 *   Acc@1 75.539
 *   Acc@1 75.987
 *   Acc@1 74.487
 *   Acc@1 75.172
Training for 300 epoch: 74.55921052631578
Training for 600 epoch: 72.79605263157895
Training for 1000 epoch: 71.34868421052633
Training for 300 epoch: 74.72166666666666
Training for 600 epoch: 73.02250000000001
Training for 1000 epoch: 71.72
[[74.55921052631578, 72.79605263157895, 71.34868421052633], [74.72166666666666, 73.02250000000001, 71.72]]
train loss 0.35412758584022525, epoch 164, best loss 0.3038037651538849, best_epoch 159
GPU_0_using curriculum 20 with window 20
Epoch: [165][20/40]	Time  1.545 ( 1.538)	Data  0.027 ( 0.041)	InnerLoop  0.628 ( 0.647)	Loss 6.7145e-01 (6.4412e-01)	Acc@1  75.94 ( 76.63)
Epoch: [165][40/40]	Time  1.483 ( 1.537)	Data  0.012 ( 0.041)	InnerLoop  0.626 ( 0.646)	Loss 5.8063e-01 (6.3378e-01)	Acc@1  79.17 ( 76.93)
The current update step is 6640
GPU_0_using curriculum 20 with window 20
Epoch: [166][20/40]	Time  1.516 ( 1.531)	Data  0.030 ( 0.048)	InnerLoop  0.625 ( 0.638)	Loss 5.4805e-01 (6.3812e-01)	Acc@1  80.63 ( 76.21)
Epoch: [166][40/40]	Time  1.632 ( 1.541)	Data  0.012 ( 0.041)	InnerLoop  0.758 ( 0.645)	Loss 5.3500e-01 (6.5735e-01)	Acc@1  80.73 ( 75.98)
The current update step is 6680
GPU_0_using curriculum 20 with window 20
Epoch: [167][20/40]	Time  1.502 ( 1.528)	Data  0.027 ( 0.042)	InnerLoop  0.631 ( 0.639)	Loss 8.3145e-01 (6.9234e-01)	Acc@1  74.77 ( 74.36)
Epoch: [167][40/40]	Time  1.480 ( 1.530)	Data  0.011 ( 0.042)	InnerLoop  0.619 ( 0.641)	Loss 1.0180e+00 (6.9034e-01)	Acc@1  64.58 ( 74.54)
The current update step is 6720
GPU_0_using curriculum 20 with window 20
Epoch: [168][20/40]	Time  1.565 ( 1.551)	Data  0.038 ( 0.048)	InnerLoop  0.654 ( 0.646)	Loss 7.7230e-01 (6.1328e-01)	Acc@1  71.29 ( 76.51)
Epoch: [168][40/40]	Time  1.531 ( 1.539)	Data  0.012 ( 0.045)	InnerLoop  0.639 ( 0.643)	Loss 5.8601e-01 (6.3477e-01)	Acc@1  78.12 ( 75.92)
The current update step is 6760
GPU_0_using curriculum 20 with window 20
Epoch: [169][20/40]	Time  1.624 ( 1.542)	Data  0.027 ( 0.042)	InnerLoop  0.741 ( 0.651)	Loss 8.1805e-01 (6.8985e-01)	Acc@1  68.16 ( 74.15)
Epoch: [169][40/40]	Time  1.468 ( 1.542)	Data  0.014 ( 0.042)	InnerLoop  0.629 ( 0.651)	Loss 7.9747e-01 (6.9856e-01)	Acc@1  71.35 ( 73.41)
The current update step is 6800
The current seed is 607841290236738396
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.737
 *   Acc@1 74.123
 *   Acc@1 70.487
 *   Acc@1 71.206
 *   Acc@1 68.566
 *   Acc@1 69.178
 *   Acc@1 62.026
 *   Acc@1 62.115
 *   Acc@1 57.066
 *   Acc@1 57.489
 *   Acc@1 54.526
 *   Acc@1 54.714
Training for 300 epoch: 67.88157894736842
Training for 600 epoch: 63.776315789473685
Training for 1000 epoch: 61.546052631578945
Training for 300 epoch: 68.11875
Training for 600 epoch: 64.3475
Training for 1000 epoch: 61.94624999999999
[[67.88157894736842, 63.776315789473685, 61.546052631578945], [68.11875, 64.3475, 61.94624999999999]]
train loss 0.6214763350486755, epoch 169, best loss 0.3038037651538849, best_epoch 159
=== Final results:
{'acc': 78.38815789473685, 'test': [78.38815789473685, 77.01973684210526, 77.09868421052632], 'train': [78.38815789473685, 77.01973684210526, 77.09868421052632], 'ind': 0, 'epoch': 70, 'data': array([[-0.13073844, -0.0008651 , -0.00123254, ...,  0.1013402 ,
         0.00341251, -0.01594312],
       [-0.01749884,  0.03530139, -0.01164932, ..., -0.03607232,
         0.00373061,  0.04532341],
       [-0.04638984,  0.04200057, -0.0925212 , ...,  0.03354476,
         0.05346235, -0.03293466],
       ...,
       [-0.04318041,  0.01290356,  0.00535327, ..., -0.06868207,
         0.03328153,  0.01616588],
       [ 0.04388341,  0.05967181,  0.01359505, ...,  0.0148107 ,
        -0.01786464, -0.03417057],
       [ 0.01025213,  0.04163754,  0.02043125, ..., -0.04760395,
        -0.07779864, -0.0103004 ]], shape=(80, 768), dtype=float32)}
