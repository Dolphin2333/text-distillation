Torch Seed Specified with rank: 0
Dataset: agnews_emb
Dataset Path: ./scripts
Namespace(seed=0, mp_distributed=False, world_size=1, rank=0, dist_url='tcp://224.66.41.62:23456', dist_backend='nccl', workers=0, gpu=None, root='./scripts', dataset='agnews_emb', arch='text_transformer', width=256, lr=0.001, inner_optim='Adam', outer_optim='Adam', inner_lr=0.001, label_lr_scale=1, num_per_class=1, batch_per_class=1, task_sampler_nc=4, window=40, minwindow=0, totwindow=100, num_train_eval=4, train_y=False, batch_size=4096, eps=1e-08, wd=0, test_freq=5, print_freq=20, start_epoch=0, epochs=200, ddtype='standard', cctype=0, zca=False, wandb=False, clip_coef=0.9, fname='out_tf_ratbptt_ipc01_s0', out_dir='./checkpoints', name='agnews_tf_ratbptt_s0', comp_aug=False, comp_aug_real=False, syn_strategy='none', real_strategy='none', ckptname='none', limit_train=False, load_ckpt=False, complete_random=False, boost_dd=False, boost_init_from='none', boost_beta=1.0, stage=0, distributed=False, data_root='./scripts/agnews_emb')
==> Preparing data..
None None
Dataset: number of classes: 4
Training set size: 120000
Image size: channel 1, height 768, width 1
Synthetic images, not_single False, keys []
==> Building model..
Initialized data with size, x: torch.Size([4, 768]), y:torch.Size([4])
TextTransformer(
  (input_proj): Linear(in_features=192, out_features=256, bias=True)
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=1024, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=1024, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (cls_head): Linear(in_features=256, out_features=4, bias=True)
)
use data parallel only
GPU_0_using curriculum 40 with window 40
Epoch: [0][20/30]	Time  4.041 ( 4.166)	Data  0.052 ( 0.075)	InnerLoop  1.683 ( 1.762)	Loss 6.2755e+00 (5.5278e+00)	Acc@1  26.03 ( 27.54)
The current update step is 30
GPU_0_using curriculum 40 with window 40
Epoch: [1][20/30]	Time  3.961 ( 4.014)	Data  0.057 ( 0.079)	InnerLoop  1.625 ( 1.662)	Loss 5.0579e+00 (4.2273e+00)	Acc@1  27.98 ( 32.71)
The current update step is 60
GPU_0_using curriculum 40 with window 40
Epoch: [2][20/30]	Time  4.033 ( 4.007)	Data  0.187 ( 0.080)	InnerLoop  1.602 ( 1.665)	Loss 3.6058e+00 (4.0666e+00)	Acc@1  42.90 ( 35.96)
The current update step is 90
GPU_0_using curriculum 40 with window 40
Epoch: [3][20/30]	Time  4.019 ( 3.999)	Data  0.050 ( 0.066)	InnerLoop  1.747 ( 1.661)	Loss 3.2579e+00 (3.4964e+00)	Acc@1  39.45 ( 39.20)
The current update step is 120
GPU_0_using curriculum 40 with window 40
Epoch: [4][20/30]	Time  3.765 ( 3.854)	Data  0.053 ( 0.076)	InnerLoop  1.546 ( 1.599)	Loss 4.4554e+00 (2.8618e+00)	Acc@1  31.13 ( 39.48)
The current update step is 150
The current seed is 7538355564140111659
The current lr is: 0.001
Testing Results:
 *   Acc@1 47.934
 *   Acc@1 48.097
 *   Acc@1 46.684
 *   Acc@1 46.757
 *   Acc@1 45.829
 *   Acc@1 46.068
 *   Acc@1 45.829
 *   Acc@1 46.224
 *   Acc@1 46.553
 *   Acc@1 47.031
 *   Acc@1 47.421
 *   Acc@1 47.374
 *   Acc@1 46.829
 *   Acc@1 47.057
 *   Acc@1 45.737
 *   Acc@1 45.511
 *   Acc@1 33.105
 *   Acc@1 32.853
 *   Acc@1 31.566
 *   Acc@1 31.633
 *   Acc@1 31.395
 *   Acc@1 31.237
 *   Acc@1 30.539
 *   Acc@1 30.356
 *   Acc@1 39.039
 *   Acc@1 38.915
 *   Acc@1 38.987
 *   Acc@1 38.590
 *   Acc@1 38.474
 *   Acc@1 38.377
 *   Acc@1 37.408
 *   Acc@1 37.112
Training for 300 epoch: 41.6578947368421
Training for 600 epoch: 41.16447368421053
Training for 1000 epoch: 40.631578947368425
Training for 3000 epoch: 39.87828947368421
Training for 300 epoch: 41.72416666666666
Training for 600 epoch: 41.088541666666664
Training for 1000 epoch: 40.684583333333336
Training for 3000 epoch: 39.800625
[[41.6578947368421, 41.16447368421053, 40.631578947368425, 39.87828947368421], [41.72416666666666, 41.088541666666664, 40.684583333333336, 39.800625]]
train loss 0.8621334918340047, epoch 4, best loss 0.8621334918340047, best_epoch 4
GPU_0_using curriculum 40 with window 40
Epoch: [5][20/30]	Time  3.687 ( 3.752)	Data  0.046 ( 0.065)	InnerLoop  1.550 ( 1.589)	Loss 2.6578e+00 (2.4056e+00)	Acc@1  40.80 ( 42.18)
The current update step is 180
GPU_0_using curriculum 40 with window 40
Epoch: [6][20/30]	Time  3.783 ( 3.740)	Data  0.047 ( 0.078)	InnerLoop  1.654 ( 1.565)	Loss 1.4581e+00 (2.2424e+00)	Acc@1  52.83 ( 44.92)
The current update step is 210
GPU_0_using curriculum 40 with window 40
Epoch: [7][20/30]	Time  3.685 ( 3.741)	Data  0.043 ( 0.053)	InnerLoop  1.517 ( 1.591)	Loss 2.0804e+00 (1.9794e+00)	Acc@1  44.73 ( 46.14)
The current update step is 240
GPU_0_using curriculum 40 with window 40
Epoch: [8][20/30]	Time  3.703 ( 3.729)	Data  0.051 ( 0.078)	InnerLoop  1.537 ( 1.556)	Loss 3.9962e+00 (2.5951e+00)	Acc@1  26.32 ( 38.53)
The current update step is 270
GPU_0_using curriculum 40 with window 40
Epoch: [9][20/30]	Time  3.658 ( 3.723)	Data  0.048 ( 0.059)	InnerLoop  1.524 ( 1.568)	Loss 2.2701e+00 (2.0592e+00)	Acc@1  44.38 ( 42.67)
The current update step is 300
The current seed is 7896996174537667737
The current lr is: 0.001
Testing Results:
 *   Acc@1 55.553
 *   Acc@1 55.638
 *   Acc@1 55.921
 *   Acc@1 55.948
 *   Acc@1 56.197
 *   Acc@1 56.184
 *   Acc@1 56.500
 *   Acc@1 56.358
 *   Acc@1 31.829
 *   Acc@1 31.813
 *   Acc@1 31.092
 *   Acc@1 31.001
 *   Acc@1 31.855
 *   Acc@1 31.773
 *   Acc@1 32.250
 *   Acc@1 32.127
 *   Acc@1 39.289
 *   Acc@1 39.149
 *   Acc@1 38.000
 *   Acc@1 37.752
 *   Acc@1 37.934
 *   Acc@1 38.193
 *   Acc@1 37.579
 *   Acc@1 37.043
 *   Acc@1 45.671
 *   Acc@1 45.653
 *   Acc@1 47.250
 *   Acc@1 47.344
 *   Acc@1 47.474
 *   Acc@1 47.968
 *   Acc@1 48.342
 *   Acc@1 48.462
Training for 300 epoch: 43.08552631578948
Training for 600 epoch: 43.065789473684205
Training for 1000 epoch: 43.36513157894737
Training for 3000 epoch: 43.66776315789474
Training for 300 epoch: 43.063125
Training for 600 epoch: 43.01145833333333
Training for 1000 epoch: 43.529375
Training for 3000 epoch: 43.497708333333335
[[43.08552631578948, 43.065789473684205, 43.36513157894737, 43.66776315789474], [43.063125, 43.01145833333333, 43.529375, 43.497708333333335]]
train loss 0.5825978358268737, epoch 9, best loss 0.5825978358268737, best_epoch 9
GPU_0_using curriculum 40 with window 40
Epoch: [10][20/30]	Time  3.797 ( 3.716)	Data  0.045 ( 0.065)	InnerLoop  1.654 ( 1.556)	Loss 1.8775e+00 (1.6732e+00)	Acc@1  46.51 ( 49.10)
The current update step is 330
GPU_0_using curriculum 40 with window 40
Epoch: [11][20/30]	Time  3.698 ( 3.715)	Data  0.048 ( 0.051)	InnerLoop  1.519 ( 1.571)	Loss 1.3893e+00 (1.5371e+00)	Acc@1  53.59 ( 51.39)
The current update step is 360
GPU_0_using curriculum 40 with window 40
Epoch: [12][20/30]	Time  3.645 ( 3.734)	Data  0.047 ( 0.051)	InnerLoop  1.512 ( 1.584)	Loss 2.2747e+00 (1.7271e+00)	Acc@1  32.45 ( 47.31)
The current update step is 390
GPU_0_using curriculum 40 with window 40
Epoch: [13][20/30]	Time  3.674 ( 3.714)	Data  0.048 ( 0.065)	InnerLoop  1.525 ( 1.559)	Loss 2.7943e+00 (1.6674e+00)	Acc@1  40.31 ( 50.10)
The current update step is 420
GPU_0_using curriculum 40 with window 40
Epoch: [14][20/30]	Time  3.826 ( 3.751)	Data  0.183 ( 0.074)	InnerLoop  1.536 ( 1.571)	Loss 1.2305e+00 (1.8096e+00)	Acc@1  51.03 ( 44.65)
The current update step is 450
The current seed is 2331128847084349078
The current lr is: 0.001
Testing Results:
 *   Acc@1 42.079
 *   Acc@1 42.657
 *   Acc@1 44.487
 *   Acc@1 44.515
 *   Acc@1 43.566
 *   Acc@1 44.072
 *   Acc@1 40.711
 *   Acc@1 41.200
 *   Acc@1 48.421
 *   Acc@1 48.642
 *   Acc@1 52.868
 *   Acc@1 53.470
 *   Acc@1 56.447
 *   Acc@1 56.578
 *   Acc@1 62.579
 *   Acc@1 62.669
 *   Acc@1 40.934
 *   Acc@1 40.883
 *   Acc@1 42.171
 *   Acc@1 41.977
 *   Acc@1 42.355
 *   Acc@1 42.580
 *   Acc@1 43.987
 *   Acc@1 44.375
 *   Acc@1 48.355
 *   Acc@1 48.145
 *   Acc@1 49.461
 *   Acc@1 49.346
 *   Acc@1 49.329
 *   Acc@1 49.416
 *   Acc@1 49.421
 *   Acc@1 49.973
Training for 300 epoch: 44.94736842105263
Training for 600 epoch: 47.246710526315795
Training for 1000 epoch: 47.924342105263165
Training for 3000 epoch: 49.17434210526315
Training for 300 epoch: 45.081875000000004
Training for 600 epoch: 47.326875
Training for 1000 epoch: 48.161458333333336
Training for 3000 epoch: 49.554375
[[44.94736842105263, 47.246710526315795, 47.924342105263165, 49.17434210526315], [45.081875000000004, 47.326875, 48.161458333333336, 49.554375]]
train loss 0.38809782719612124, epoch 14, best loss 0.38809782719612124, best_epoch 14
GPU_0_using curriculum 40 with window 40
Epoch: [15][20/30]	Time  3.828 ( 3.727)	Data  0.049 ( 0.058)	InnerLoop  1.662 ( 1.574)	Loss 1.6494e+00 (1.8847e+00)	Acc@1  48.80 ( 45.52)
The current update step is 480
GPU_0_using curriculum 40 with window 40
Epoch: [16][20/30]	Time  3.850 ( 3.737)	Data  0.048 ( 0.052)	InnerLoop  1.678 ( 1.587)	Loss 1.2937e+00 (1.5316e+00)	Acc@1  48.56 ( 49.51)
The current update step is 510
GPU_0_using curriculum 40 with window 40
Epoch: [17][20/30]	Time  3.734 ( 3.754)	Data  0.045 ( 0.071)	InnerLoop  1.550 ( 1.574)	Loss 1.2351e+00 (1.3342e+00)	Acc@1  52.22 ( 52.17)
The current update step is 540
GPU_0_using curriculum 40 with window 40
Epoch: [18][20/30]	Time  3.647 ( 3.728)	Data  0.045 ( 0.059)	InnerLoop  1.512 ( 1.575)	Loss 8.7176e-01 (1.3600e+00)	Acc@1  66.19 ( 52.45)
The current update step is 570
GPU_0_using curriculum 40 with window 40
Epoch: [19][20/30]	Time  3.804 ( 3.728)	Data  0.050 ( 0.059)	InnerLoop  1.648 ( 1.570)	Loss 1.2876e+00 (1.4482e+00)	Acc@1  54.54 ( 52.79)
The current update step is 600
The current seed is 6299977972242098449
The current lr is: 0.001
Testing Results:
 *   Acc@1 53.250
 *   Acc@1 53.263
 *   Acc@1 54.434
 *   Acc@1 54.391
 *   Acc@1 53.632
 *   Acc@1 54.206
 *   Acc@1 51.316
 *   Acc@1 51.341
 *   Acc@1 53.724
 *   Acc@1 54.526
 *   Acc@1 52.961
 *   Acc@1 53.468
 *   Acc@1 54.697
 *   Acc@1 55.196
 *   Acc@1 56.434
 *   Acc@1 57.054
 *   Acc@1 56.592
 *   Acc@1 56.992
 *   Acc@1 51.289
 *   Acc@1 51.773
 *   Acc@1 49.079
 *   Acc@1 49.702
 *   Acc@1 46.908
 *   Acc@1 47.375
 *   Acc@1 42.763
 *   Acc@1 43.084
 *   Acc@1 40.408
 *   Acc@1 41.297
 *   Acc@1 39.461
 *   Acc@1 40.282
 *   Acc@1 37.316
 *   Acc@1 38.886
Training for 300 epoch: 51.58223684210527
Training for 600 epoch: 49.77302631578947
Training for 1000 epoch: 49.21710526315789
Training for 3000 epoch: 47.99342105263158
Training for 300 epoch: 51.96625
Training for 600 epoch: 50.232083333333335
Training for 1000 epoch: 49.846250000000005
Training for 3000 epoch: 48.66395833333333
[[51.58223684210527, 49.77302631578947, 49.21710526315789, 47.99342105263158], [51.96625, 50.232083333333335, 49.846250000000005, 48.66395833333333]]
train loss 0.42022029512723286, epoch 19, best loss 0.38809782719612124, best_epoch 14
GPU_0_using curriculum 40 with window 40
Epoch: [20][20/30]	Time  3.639 ( 3.721)	Data  0.048 ( 0.052)	InnerLoop  1.496 ( 1.574)	Loss 1.1964e+00 (1.2601e+00)	Acc@1  56.42 ( 55.18)
The current update step is 630
GPU_0_using curriculum 40 with window 40
Epoch: [21][20/30]	Time  3.659 ( 3.735)	Data  0.047 ( 0.053)	InnerLoop  1.527 ( 1.581)	Loss 1.5829e+00 (1.1733e+00)	Acc@1  49.83 ( 57.36)
The current update step is 660
GPU_0_using curriculum 40 with window 40
Epoch: [22][20/30]	Time  3.649 ( 3.726)	Data  0.046 ( 0.064)	InnerLoop  1.507 ( 1.561)	Loss 9.0345e-01 (1.1916e+00)	Acc@1  63.87 ( 56.72)
The current update step is 690
GPU_0_using curriculum 40 with window 40
Epoch: [23][20/30]	Time  3.825 ( 3.712)	Data  0.178 ( 0.071)	InnerLoop  1.519 ( 1.541)	Loss 1.7195e+00 (1.2636e+00)	Acc@1  50.63 ( 54.63)
The current update step is 720
GPU_0_using curriculum 40 with window 40
Epoch: [24][20/30]	Time  3.850 ( 3.716)	Data  0.049 ( 0.058)	InnerLoop  1.663 ( 1.564)	Loss 1.5639e+00 (1.9635e+00)	Acc@1  46.46 ( 48.11)
The current update step is 750
The current seed is 11110027171056151882
The current lr is: 0.001
Testing Results:
 *   Acc@1 47.487
 *   Acc@1 48.053
 *   Acc@1 45.526
 *   Acc@1 46.222
 *   Acc@1 43.987
 *   Acc@1 44.484
 *   Acc@1 41.303
 *   Acc@1 41.691
 *   Acc@1 57.105
 *   Acc@1 56.847
 *   Acc@1 54.118
 *   Acc@1 54.054
 *   Acc@1 49.526
 *   Acc@1 49.627
 *   Acc@1 44.434
 *   Acc@1 44.337
 *   Acc@1 43.829
 *   Acc@1 44.137
 *   Acc@1 42.105
 *   Acc@1 42.354
 *   Acc@1 39.895
 *   Acc@1 40.225
 *   Acc@1 39.171
 *   Acc@1 39.542
 *   Acc@1 53.316
 *   Acc@1 53.290
 *   Acc@1 56.579
 *   Acc@1 56.614
 *   Acc@1 56.934
 *   Acc@1 57.705
 *   Acc@1 57.039
 *   Acc@1 57.545
Training for 300 epoch: 50.434210526315795
Training for 600 epoch: 49.58223684210526
Training for 1000 epoch: 47.58552631578947
Training for 3000 epoch: 45.48684210526316
Training for 300 epoch: 50.58166666666666
Training for 600 epoch: 49.81104166666667
Training for 1000 epoch: 48.01020833333334
Training for 3000 epoch: 45.77875
[[50.434210526315795, 49.58223684210526, 47.58552631578947, 45.48684210526316], [50.58166666666666, 49.81104166666667, 48.01020833333334, 45.77875]]
train loss 0.45276035855611163, epoch 24, best loss 0.38809782719612124, best_epoch 14
GPU_0_using curriculum 40 with window 40
Epoch: [25][20/30]	Time  3.878 ( 3.743)	Data  0.044 ( 0.065)	InnerLoop  1.713 ( 1.569)	Loss 1.2201e+00 (1.3699e+00)	Acc@1  60.35 ( 54.99)
The current update step is 780
GPU_0_using curriculum 40 with window 40
Epoch: [26][20/30]	Time  3.641 ( 3.725)	Data  0.048 ( 0.058)	InnerLoop  1.500 ( 1.575)	Loss 1.2574e+00 (1.0918e+00)	Acc@1  53.64 ( 60.34)
The current update step is 810
GPU_0_using curriculum 40 with window 40
Epoch: [27][20/30]	Time  3.688 ( 3.717)	Data  0.043 ( 0.062)	InnerLoop  1.512 ( 1.565)	Loss 1.0025e+00 (1.1119e+00)	Acc@1  61.38 ( 58.86)
The current update step is 840
GPU_0_using curriculum 40 with window 40
Epoch: [28][20/30]	Time  3.705 ( 3.743)	Data  0.049 ( 0.072)	InnerLoop  1.532 ( 1.563)	Loss 9.6601e-01 (1.1332e+00)	Acc@1  68.24 ( 57.39)
The current update step is 870
GPU_0_using curriculum 40 with window 40
Epoch: [29][20/30]	Time  3.786 ( 3.717)	Data  0.176 ( 0.072)	InnerLoop  1.518 ( 1.552)	Loss 1.1311e+00 (1.1020e+00)	Acc@1  56.03 ( 57.74)
The current update step is 900
The current seed is 7916289365752281863
The current lr is: 0.001
Testing Results:
 *   Acc@1 60.066
 *   Acc@1 60.962
 *   Acc@1 56.250
 *   Acc@1 57.477
 *   Acc@1 54.868
 *   Acc@1 56.097
 *   Acc@1 53.921
 *   Acc@1 54.709
 *   Acc@1 44.026
 *   Acc@1 44.350
 *   Acc@1 42.368
 *   Acc@1 42.642
 *   Acc@1 44.289
 *   Acc@1 44.835
 *   Acc@1 44.132
 *   Acc@1 44.089
 *   Acc@1 55.566
 *   Acc@1 55.546
 *   Acc@1 50.908
 *   Acc@1 51.194
 *   Acc@1 49.303
 *   Acc@1 49.290
 *   Acc@1 48.263
 *   Acc@1 48.288
 *   Acc@1 63.408
 *   Acc@1 63.858
 *   Acc@1 64.921
 *   Acc@1 65.066
 *   Acc@1 64.105
 *   Acc@1 64.882
 *   Acc@1 64.355
 *   Acc@1 65.733
Training for 300 epoch: 55.766447368421055
Training for 600 epoch: 53.611842105263165
Training for 1000 epoch: 53.141447368421055
Training for 3000 epoch: 52.66776315789474
Training for 300 epoch: 56.17895833333334
Training for 600 epoch: 54.094791666666666
Training for 1000 epoch: 53.776041666666664
Training for 3000 epoch: 53.204791666666665
[[55.766447368421055, 53.611842105263165, 53.141447368421055, 52.66776315789474], [56.17895833333334, 54.094791666666666, 53.776041666666664, 53.204791666666665]]
train loss 0.23808218155701955, epoch 29, best loss 0.23808218155701955, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [30][20/30]	Time  3.879 ( 3.811)	Data  0.049 ( 0.059)	InnerLoop  1.670 ( 1.622)	Loss 1.4983e+00 (1.1495e+00)	Acc@1  43.87 ( 58.14)
The current update step is 930
GPU_0_using curriculum 40 with window 40
Epoch: [31][20/30]	Time  3.858 ( 3.787)	Data  0.046 ( 0.052)	InnerLoop  1.692 ( 1.612)	Loss 1.0462e+00 (1.2533e+00)	Acc@1  66.77 ( 57.19)
The current update step is 960
GPU_0_using curriculum 40 with window 40
Epoch: [32][20/30]	Time  3.692 ( 3.753)	Data  0.049 ( 0.073)	InnerLoop  1.537 ( 1.576)	Loss 1.2947e+00 (1.1087e+00)	Acc@1  49.78 ( 59.89)
The current update step is 990
GPU_0_using curriculum 40 with window 40
Epoch: [33][20/30]	Time  3.667 ( 3.730)	Data  0.048 ( 0.057)	InnerLoop  1.498 ( 1.574)	Loss 9.0790e-01 (1.2617e+00)	Acc@1  67.55 ( 56.89)
The current update step is 1020
GPU_0_using curriculum 40 with window 40
Epoch: [34][20/30]	Time  3.789 ( 3.727)	Data  0.050 ( 0.059)	InnerLoop  1.642 ( 1.570)	Loss 1.1325e+00 (1.2511e+00)	Acc@1  57.59 ( 55.58)
The current update step is 1050
The current seed is 12132742718187111709
The current lr is: 0.001
Testing Results:
 *   Acc@1 44.908
 *   Acc@1 44.925
 *   Acc@1 47.316
 *   Acc@1 47.823
 *   Acc@1 47.500
 *   Acc@1 47.966
 *   Acc@1 47.224
 *   Acc@1 47.929
 *   Acc@1 44.158
 *   Acc@1 44.543
 *   Acc@1 42.763
 *   Acc@1 42.928
 *   Acc@1 41.039
 *   Acc@1 41.083
 *   Acc@1 39.684
 *   Acc@1 40.254
 *   Acc@1 65.026
 *   Acc@1 65.515
 *   Acc@1 61.908
 *   Acc@1 63.169
 *   Acc@1 60.013
 *   Acc@1 60.836
 *   Acc@1 57.263
 *   Acc@1 57.306
 *   Acc@1 48.026
 *   Acc@1 48.442
 *   Acc@1 44.395
 *   Acc@1 45.068
 *   Acc@1 45.289
 *   Acc@1 46.028
 *   Acc@1 49.684
 *   Acc@1 51.059
Training for 300 epoch: 50.52960526315789
Training for 600 epoch: 49.0953947368421
Training for 1000 epoch: 48.46052631578947
Training for 3000 epoch: 48.463815789473685
Training for 300 epoch: 50.85625
Training for 600 epoch: 49.746875
Training for 1000 epoch: 48.97833333333334
Training for 3000 epoch: 49.13708333333334
[[50.52960526315789, 49.0953947368421, 48.46052631578947, 48.463815789473685], [50.85625, 49.746875, 48.97833333333334, 49.13708333333334]]
train loss 0.37590994017918905, epoch 34, best loss 0.23808218155701955, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [35][20/30]	Time  3.694 ( 3.719)	Data  0.045 ( 0.051)	InnerLoop  1.550 ( 1.572)	Loss 8.1478e-01 (1.1099e+00)	Acc@1  72.66 ( 59.19)
The current update step is 1080
GPU_0_using curriculum 40 with window 40
Epoch: [36][20/30]	Time  3.693 ( 3.721)	Data  0.044 ( 0.053)	InnerLoop  1.525 ( 1.573)	Loss 9.1823e-01 (1.1200e+00)	Acc@1  65.14 ( 59.31)
The current update step is 1110
GPU_0_using curriculum 40 with window 40
Epoch: [37][20/30]	Time  3.674 ( 3.725)	Data  0.042 ( 0.064)	InnerLoop  1.526 ( 1.567)	Loss 1.7580e+00 (1.2797e+00)	Acc@1  45.02 ( 55.52)
The current update step is 1140
GPU_0_using curriculum 40 with window 40
Epoch: [38][20/30]	Time  3.789 ( 3.725)	Data  0.178 ( 0.072)	InnerLoop  1.514 ( 1.563)	Loss 1.2656e+00 (1.2954e+00)	Acc@1  54.25 ( 53.28)
The current update step is 1170
GPU_0_using curriculum 40 with window 40
Epoch: [39][20/30]	Time  3.853 ( 3.737)	Data  0.050 ( 0.060)	InnerLoop  1.671 ( 1.578)	Loss 1.0157e+00 (1.1142e+00)	Acc@1  61.94 ( 60.56)
The current update step is 1200
The current seed is 2732804117813041543
The current lr is: 0.001
Testing Results:
 *   Acc@1 54.224
 *   Acc@1 54.753
 *   Acc@1 50.487
 *   Acc@1 50.835
 *   Acc@1 48.303
 *   Acc@1 49.328
 *   Acc@1 45.132
 *   Acc@1 45.526
 *   Acc@1 61.408
 *   Acc@1 61.961
 *   Acc@1 54.474
 *   Acc@1 54.383
 *   Acc@1 50.539
 *   Acc@1 50.367
 *   Acc@1 48.092
 *   Acc@1 48.142
 *   Acc@1 51.342
 *   Acc@1 51.800
 *   Acc@1 53.342
 *   Acc@1 53.539
 *   Acc@1 53.303
 *   Acc@1 53.993
 *   Acc@1 48.947
 *   Acc@1 49.189
 *   Acc@1 57.566
 *   Acc@1 57.655
 *   Acc@1 53.276
 *   Acc@1 53.209
 *   Acc@1 49.684
 *   Acc@1 50.298
 *   Acc@1 45.461
 *   Acc@1 46.004
Training for 300 epoch: 56.13486842105263
Training for 600 epoch: 52.89473684210526
Training for 1000 epoch: 50.45723684210526
Training for 3000 epoch: 46.90789473684211
Training for 300 epoch: 56.542291666666664
Training for 600 epoch: 52.99166666666667
Training for 1000 epoch: 50.996875
Training for 3000 epoch: 47.21541666666666
[[56.13486842105263, 52.89473684210526, 50.45723684210526, 46.90789473684211], [56.542291666666664, 52.99166666666667, 50.996875, 47.21541666666666]]
train loss 0.4186946682135264, epoch 39, best loss 0.23808218155701955, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [40][20/30]	Time  3.811 ( 3.722)	Data  0.048 ( 0.064)	InnerLoop  1.667 ( 1.556)	Loss 1.0109e+00 (1.0391e+00)	Acc@1  64.48 ( 61.81)
The current update step is 1230
GPU_0_using curriculum 40 with window 40
Epoch: [41][20/30]	Time  3.676 ( 3.712)	Data  0.044 ( 0.058)	InnerLoop  1.515 ( 1.562)	Loss 7.9268e-01 (1.0210e+00)	Acc@1  71.90 ( 62.90)
The current update step is 1260
GPU_0_using curriculum 40 with window 40
Epoch: [42][20/30]	Time  3.683 ( 3.697)	Data  0.044 ( 0.063)	InnerLoop  1.519 ( 1.549)	Loss 9.6098e-01 (1.2120e+00)	Acc@1  66.82 ( 59.35)
The current update step is 1290
GPU_0_using curriculum 40 with window 40
Epoch: [43][20/30]	Time  3.687 ( 3.711)	Data  0.046 ( 0.070)	InnerLoop  1.532 ( 1.547)	Loss 2.6861e+00 (1.2233e+00)	Acc@1  47.56 ( 61.25)
The current update step is 1320
GPU_0_using curriculum 40 with window 40
Epoch: [44][20/30]	Time  3.796 ( 3.736)	Data  0.176 ( 0.072)	InnerLoop  1.530 ( 1.562)	Loss 1.6974e+00 (1.2193e+00)	Acc@1  52.08 ( 59.80)
The current update step is 1350
The current seed is 5613617221355513716
The current lr is: 0.001
Testing Results:
 *   Acc@1 59.395
 *   Acc@1 59.172
 *   Acc@1 58.711
 *   Acc@1 58.731
 *   Acc@1 60.566
 *   Acc@1 60.442
 *   Acc@1 63.329
 *   Acc@1 63.598
 *   Acc@1 61.039
 *   Acc@1 61.232
 *   Acc@1 60.237
 *   Acc@1 60.718
 *   Acc@1 59.158
 *   Acc@1 59.240
 *   Acc@1 55.579
 *   Acc@1 55.490
 *   Acc@1 50.592
 *   Acc@1 50.508
 *   Acc@1 50.961
 *   Acc@1 51.149
 *   Acc@1 49.763
 *   Acc@1 49.907
 *   Acc@1 47.263
 *   Acc@1 47.282
 *   Acc@1 46.184
 *   Acc@1 46.581
 *   Acc@1 45.355
 *   Acc@1 45.251
 *   Acc@1 45.829
 *   Acc@1 45.901
 *   Acc@1 49.263
 *   Acc@1 49.314
Training for 300 epoch: 54.30263157894736
Training for 600 epoch: 53.81578947368421
Training for 1000 epoch: 53.828947368421055
Training for 3000 epoch: 53.85855263157895
Training for 300 epoch: 54.373125
Training for 600 epoch: 53.962291666666665
Training for 1000 epoch: 53.8725
Training for 3000 epoch: 53.92104166666667
[[54.30263157894736, 53.81578947368421, 53.828947368421055, 53.85855263157895], [54.373125, 53.962291666666665, 53.8725, 53.92104166666667]]
train loss 0.40194421655337015, epoch 44, best loss 0.23808218155701955, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [45][20/30]	Time  3.859 ( 3.769)	Data  0.045 ( 0.057)	InnerLoop  1.706 ( 1.603)	Loss 7.1583e-01 (1.1178e+00)	Acc@1  73.61 ( 64.24)
The current update step is 1380
GPU_0_using curriculum 40 with window 40
Epoch: [46][20/30]	Time  3.822 ( 3.752)	Data  0.044 ( 0.052)	InnerLoop  1.672 ( 1.601)	Loss 1.0196e+00 (1.0712e+00)	Acc@1  66.38 ( 62.80)
The current update step is 1410
GPU_0_using curriculum 40 with window 40
Epoch: [47][20/30]	Time  3.711 ( 3.737)	Data  0.044 ( 0.072)	InnerLoop  1.558 ( 1.566)	Loss 7.5445e-01 (9.9873e-01)	Acc@1  72.58 ( 64.54)
The current update step is 1440
GPU_0_using curriculum 40 with window 40
Epoch: [48][20/30]	Time  3.729 ( 3.730)	Data  0.046 ( 0.059)	InnerLoop  1.544 ( 1.571)	Loss 8.8996e-01 (1.0507e+00)	Acc@1  65.65 ( 62.80)
The current update step is 1470
GPU_0_using curriculum 40 with window 40
Epoch: [49][20/30]	Time  3.808 ( 3.724)	Data  0.047 ( 0.057)	InnerLoop  1.643 ( 1.574)	Loss 1.1857e+00 (1.2808e+00)	Acc@1  58.11 ( 57.28)
The current update step is 1500
The current seed is 17472606627741644343
The current lr is: 0.001
Testing Results:
 *   Acc@1 49.895
 *   Acc@1 50.359
 *   Acc@1 51.092
 *   Acc@1 51.247
 *   Acc@1 49.829
 *   Acc@1 50.003
 *   Acc@1 47.934
 *   Acc@1 48.018
 *   Acc@1 59.316
 *   Acc@1 59.778
 *   Acc@1 64.276
 *   Acc@1 65.215
 *   Acc@1 64.671
 *   Acc@1 65.972
 *   Acc@1 57.947
 *   Acc@1 59.158
 *   Acc@1 69.711
 *   Acc@1 69.799
 *   Acc@1 69.987
 *   Acc@1 69.639
 *   Acc@1 69.013
 *   Acc@1 68.609
 *   Acc@1 67.513
 *   Acc@1 67.494
 *   Acc@1 58.987
 *   Acc@1 59.551
 *   Acc@1 54.750
 *   Acc@1 54.723
 *   Acc@1 49.961
 *   Acc@1 50.179
 *   Acc@1 47.750
 *   Acc@1 47.682
Training for 300 epoch: 59.47697368421053
Training for 600 epoch: 60.026315789473685
Training for 1000 epoch: 58.368421052631575
Training for 3000 epoch: 55.286184210526315
Training for 300 epoch: 59.871875
Training for 600 epoch: 60.20604166666667
Training for 1000 epoch: 58.69104166666666
Training for 3000 epoch: 55.58833333333334
[[59.47697368421053, 60.026315789473685, 58.368421052631575, 55.286184210526315], [59.871875, 60.20604166666667, 58.69104166666666, 55.58833333333334]]
train loss 0.3996267003059387, epoch 49, best loss 0.23808218155701955, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [50][20/30]	Time  3.640 ( 3.730)	Data  0.046 ( 0.052)	InnerLoop  1.516 ( 1.579)	Loss 9.3670e-01 (1.1273e+00)	Acc@1  66.19 ( 62.91)
The current update step is 1530
GPU_0_using curriculum 40 with window 40
Epoch: [51][20/30]	Time  3.686 ( 3.727)	Data  0.043 ( 0.052)	InnerLoop  1.537 ( 1.578)	Loss 8.2384e-01 (1.0259e+00)	Acc@1  70.95 ( 63.67)
The current update step is 1560
GPU_0_using curriculum 40 with window 40
Epoch: [52][20/30]	Time  3.694 ( 3.718)	Data  0.051 ( 0.063)	InnerLoop  1.545 ( 1.560)	Loss 8.7461e-01 (1.0841e+00)	Acc@1  68.04 ( 63.05)
The current update step is 1590
GPU_0_using curriculum 40 with window 40
Epoch: [53][20/30]	Time  3.786 ( 3.733)	Data  0.170 ( 0.073)	InnerLoop  1.525 ( 1.559)	Loss 9.0087e-01 (1.0179e+00)	Acc@1  69.17 ( 64.37)
The current update step is 1620
GPU_0_using curriculum 40 with window 40
Epoch: [54][20/30]	Time  3.836 ( 3.725)	Data  0.046 ( 0.058)	InnerLoop  1.675 ( 1.571)	Loss 9.2905e-01 (1.1557e+00)	Acc@1  68.63 ( 61.40)
The current update step is 1650
The current seed is 11293978260508848437
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.737
 *   Acc@1 74.327
 *   Acc@1 72.197
 *   Acc@1 73.323
 *   Acc@1 71.895
 *   Acc@1 72.809
 *   Acc@1 70.461
 *   Acc@1 71.457
 *   Acc@1 64.079
 *   Acc@1 64.534
 *   Acc@1 58.921
 *   Acc@1 59.769
 *   Acc@1 57.553
 *   Acc@1 58.052
 *   Acc@1 55.566
 *   Acc@1 56.311
 *   Acc@1 64.697
 *   Acc@1 64.772
 *   Acc@1 60.882
 *   Acc@1 61.106
 *   Acc@1 59.026
 *   Acc@1 59.018
 *   Acc@1 57.289
 *   Acc@1 57.396
 *   Acc@1 69.632
 *   Acc@1 69.933
 *   Acc@1 70.579
 *   Acc@1 71.146
 *   Acc@1 70.000
 *   Acc@1 70.641
 *   Acc@1 69.579
 *   Acc@1 69.579
Training for 300 epoch: 68.03618421052632
Training for 600 epoch: 65.64473684210526
Training for 1000 epoch: 64.61842105263158
Training for 3000 epoch: 63.223684210526315
Training for 300 epoch: 68.39145833333333
Training for 600 epoch: 66.33604166666666
Training for 1000 epoch: 65.13
Training for 3000 epoch: 63.685625
[[68.03618421052632, 65.64473684210526, 64.61842105263158, 63.223684210526315], [68.39145833333333, 66.33604166666666, 65.13, 63.685625]]
train loss 0.2109489746173223, epoch 54, best loss 0.2109489746173223, best_epoch 54
GPU_0_using curriculum 40 with window 40
Epoch: [55][20/30]	Time  3.813 ( 3.735)	Data  0.041 ( 0.064)	InnerLoop  1.678 ( 1.571)	Loss 8.8811e-01 (9.1197e-01)	Acc@1  68.68 ( 67.20)
The current update step is 1680
GPU_0_using curriculum 40 with window 40
Epoch: [56][20/30]	Time  3.678 ( 3.728)	Data  0.044 ( 0.059)	InnerLoop  1.500 ( 1.567)	Loss 1.0203e+00 (9.4813e-01)	Acc@1  61.23 ( 65.18)
The current update step is 1710
GPU_0_using curriculum 40 with window 40
Epoch: [57][20/30]	Time  3.676 ( 3.746)	Data  0.048 ( 0.066)	InnerLoop  1.532 ( 1.570)	Loss 8.2009e-01 (8.7272e-01)	Acc@1  69.09 ( 68.23)
The current update step is 1740
GPU_0_using curriculum 40 with window 40
Epoch: [58][20/30]	Time  3.704 ( 3.749)	Data  0.050 ( 0.071)	InnerLoop  1.531 ( 1.571)	Loss 1.0098e+00 (9.6177e-01)	Acc@1  64.06 ( 64.72)
The current update step is 1770
GPU_0_using curriculum 40 with window 40
Epoch: [59][20/30]	Time  3.871 ( 3.768)	Data  0.177 ( 0.072)	InnerLoop  1.561 ( 1.580)	Loss 1.0688e+00 (9.2022e-01)	Acc@1  60.28 ( 67.35)
The current update step is 1800
The current seed is 8875067463984046252
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.842
 *   Acc@1 71.773
 *   Acc@1 71.553
 *   Acc@1 72.384
 *   Acc@1 72.711
 *   Acc@1 73.525
 *   Acc@1 70.579
 *   Acc@1 72.022
 *   Acc@1 72.842
 *   Acc@1 73.158
 *   Acc@1 69.645
 *   Acc@1 70.446
 *   Acc@1 69.224
 *   Acc@1 69.562
 *   Acc@1 67.171
 *   Acc@1 67.418
 *   Acc@1 71.408
 *   Acc@1 71.881
 *   Acc@1 68.000
 *   Acc@1 68.347
 *   Acc@1 66.974
 *   Acc@1 67.300
 *   Acc@1 65.368
 *   Acc@1 65.726
 *   Acc@1 71.711
 *   Acc@1 72.372
 *   Acc@1 68.500
 *   Acc@1 68.637
 *   Acc@1 67.105
 *   Acc@1 67.882
 *   Acc@1 65.447
 *   Acc@1 65.856
Training for 300 epoch: 71.70065789473685
Training for 600 epoch: 69.42434210526315
Training for 1000 epoch: 69.0032894736842
Training for 3000 epoch: 67.14144736842104
Training for 300 epoch: 72.29604166666667
Training for 600 epoch: 69.95354166666667
Training for 1000 epoch: 69.56729166666666
Training for 3000 epoch: 67.75520833333333
[[71.70065789473685, 69.42434210526315, 69.0032894736842, 67.14144736842104], [72.29604166666667, 69.95354166666667, 69.56729166666666, 67.75520833333333]]
train loss 0.23831234304904939, epoch 59, best loss 0.2109489746173223, best_epoch 54
GPU_0_using curriculum 40 with window 40
Epoch: [60][20/30]	Time  3.818 ( 3.750)	Data  0.046 ( 0.059)	InnerLoop  1.671 ( 1.588)	Loss 8.2057e-01 (9.6835e-01)	Acc@1  68.12 ( 65.18)
The current update step is 1830
GPU_0_using curriculum 40 with window 40
Epoch: [61][20/30]	Time  3.815 ( 3.732)	Data  0.051 ( 0.052)	InnerLoop  1.660 ( 1.581)	Loss 7.8409e-01 (1.2392e+00)	Acc@1  71.78 ( 60.41)
The current update step is 1860
GPU_0_using curriculum 40 with window 40
Epoch: [62][20/30]	Time  3.709 ( 3.721)	Data  0.047 ( 0.071)	InnerLoop  1.539 ( 1.555)	Loss 1.0453e+00 (1.0163e+00)	Acc@1  63.28 ( 64.58)
The current update step is 1890
GPU_0_using curriculum 40 with window 40
Epoch: [63][20/30]	Time  3.651 ( 3.719)	Data  0.047 ( 0.058)	InnerLoop  1.510 ( 1.566)	Loss 1.0863e+00 (9.1560e-01)	Acc@1  65.33 ( 67.81)
The current update step is 1920
GPU_0_using curriculum 40 with window 40
Epoch: [64][20/30]	Time  3.806 ( 3.737)	Data  0.046 ( 0.058)	InnerLoop  1.643 ( 1.577)	Loss 8.0831e-01 (9.5204e-01)	Acc@1  70.04 ( 64.71)
The current update step is 1950
The current seed is 8768926062094758885
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.289
 *   Acc@1 71.787
 *   Acc@1 69.474
 *   Acc@1 70.049
 *   Acc@1 66.934
 *   Acc@1 67.539
 *   Acc@1 65.342
 *   Acc@1 65.705
 *   Acc@1 65.382
 *   Acc@1 65.153
 *   Acc@1 65.355
 *   Acc@1 65.280
 *   Acc@1 64.342
 *   Acc@1 64.467
 *   Acc@1 65.145
 *   Acc@1 64.916
 *   Acc@1 62.395
 *   Acc@1 62.715
 *   Acc@1 59.605
 *   Acc@1 59.705
 *   Acc@1 58.711
 *   Acc@1 58.928
 *   Acc@1 59.316
 *   Acc@1 59.219
 *   Acc@1 49.789
 *   Acc@1 50.304
 *   Acc@1 47.711
 *   Acc@1 47.825
 *   Acc@1 45.408
 *   Acc@1 45.459
 *   Acc@1 41.474
 *   Acc@1 41.583
Training for 300 epoch: 62.213815789473685
Training for 600 epoch: 60.536184210526315
Training for 1000 epoch: 58.84868421052632
Training for 3000 epoch: 57.819078947368425
Training for 300 epoch: 62.489583333333336
Training for 600 epoch: 60.714791666666656
Training for 1000 epoch: 59.098125
Training for 3000 epoch: 57.85583333333334
[[62.213815789473685, 60.536184210526315, 58.84868421052632, 57.819078947368425], [62.489583333333336, 60.714791666666656, 59.098125, 57.85583333333334]]
train loss 0.5454950074195862, epoch 64, best loss 0.2109489746173223, best_epoch 54
GPU_0_using curriculum 40 with window 40
Epoch: [65][20/30]	Time  3.651 ( 3.717)	Data  0.048 ( 0.050)	InnerLoop  1.500 ( 1.576)	Loss 7.3858e-01 (8.7571e-01)	Acc@1  73.19 ( 67.90)
The current update step is 1980
GPU_0_using curriculum 40 with window 40
Epoch: [66][20/30]	Time  3.642 ( 3.736)	Data  0.045 ( 0.052)	InnerLoop  1.509 ( 1.577)	Loss 9.0731e-01 (9.3696e-01)	Acc@1  65.53 ( 65.69)
The current update step is 2010
GPU_0_using curriculum 40 with window 40
Epoch: [67][20/30]	Time  3.677 ( 3.724)	Data  0.043 ( 0.065)	InnerLoop  1.520 ( 1.561)	Loss 1.2406e+00 (9.4762e-01)	Acc@1  57.23 ( 66.44)
The current update step is 2040
GPU_0_using curriculum 40 with window 40
Epoch: [68][20/30]	Time  3.817 ( 3.759)	Data  0.176 ( 0.073)	InnerLoop  1.525 ( 1.573)	Loss 7.3582e-01 (9.5156e-01)	Acc@1  72.71 ( 65.87)
The current update step is 2070
GPU_0_using curriculum 40 with window 40
Epoch: [69][20/30]	Time  3.786 ( 3.744)	Data  0.045 ( 0.058)	InnerLoop  1.637 ( 1.579)	Loss 9.0845e-01 (9.4245e-01)	Acc@1  66.55 ( 67.10)
The current update step is 2100
The current seed is 9796463907138547932
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.487
 *   Acc@1 71.377
 *   Acc@1 70.026
 *   Acc@1 70.755
 *   Acc@1 69.605
 *   Acc@1 70.061
 *   Acc@1 66.474
 *   Acc@1 66.806
 *   Acc@1 73.961
 *   Acc@1 75.159
 *   Acc@1 72.421
 *   Acc@1 72.870
 *   Acc@1 71.171
 *   Acc@1 71.288
 *   Acc@1 68.395
 *   Acc@1 68.523
 *   Acc@1 64.895
 *   Acc@1 64.957
 *   Acc@1 68.961
 *   Acc@1 68.642
 *   Acc@1 70.566
 *   Acc@1 70.403
 *   Acc@1 73.592
 *   Acc@1 73.933
 *   Acc@1 71.855
 *   Acc@1 72.207
 *   Acc@1 70.803
 *   Acc@1 71.311
 *   Acc@1 70.053
 *   Acc@1 70.701
 *   Acc@1 68.263
 *   Acc@1 68.865
Training for 300 epoch: 70.29934210526316
Training for 600 epoch: 70.55263157894737
Training for 1000 epoch: 70.34868421052633
Training for 3000 epoch: 69.18092105263158
Training for 300 epoch: 70.92520833333333
Training for 600 epoch: 70.89458333333333
Training for 1000 epoch: 70.613125
Training for 3000 epoch: 69.53166666666667
[[70.29934210526316, 70.55263157894737, 70.34868421052633, 69.18092105263158], [70.92520833333333, 70.89458333333333, 70.613125, 69.53166666666667]]
train loss 0.20623853383858998, epoch 69, best loss 0.20623853383858998, best_epoch 69
GPU_0_using curriculum 40 with window 40
Epoch: [70][20/30]	Time  3.824 ( 3.739)	Data  0.046 ( 0.064)	InnerLoop  1.652 ( 1.570)	Loss 9.2046e-01 (1.1025e+00)	Acc@1  65.48 ( 64.68)
The current update step is 2130
GPU_0_using curriculum 40 with window 40
Epoch: [71][20/30]	Time  3.660 ( 3.721)	Data  0.045 ( 0.059)	InnerLoop  1.515 ( 1.567)	Loss 7.1948e-01 (8.9772e-01)	Acc@1  74.76 ( 68.31)
The current update step is 2160
GPU_0_using curriculum 40 with window 40
Epoch: [72][20/30]	Time  3.644 ( 3.724)	Data  0.044 ( 0.064)	InnerLoop  1.513 ( 1.560)	Loss 1.1407e+00 (1.0022e+00)	Acc@1  61.40 ( 66.05)
The current update step is 2190
GPU_0_using curriculum 40 with window 40
Epoch: [73][20/30]	Time  3.669 ( 3.735)	Data  0.049 ( 0.072)	InnerLoop  1.519 ( 1.558)	Loss 9.3428e-01 (8.9544e-01)	Acc@1  64.09 ( 68.21)
The current update step is 2220
GPU_0_using curriculum 40 with window 40
Epoch: [74][20/30]	Time  3.838 ( 3.747)	Data  0.181 ( 0.072)	InnerLoop  1.540 ( 1.567)	Loss 9.3828e-01 (8.7928e-01)	Acc@1  64.65 ( 69.09)
The current update step is 2250
The current seed is 3965745644947457293
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.789
 *   Acc@1 72.126
 *   Acc@1 70.237
 *   Acc@1 71.112
 *   Acc@1 68.145
 *   Acc@1 68.665
 *   Acc@1 63.487
 *   Acc@1 64.119
 *   Acc@1 70.105
 *   Acc@1 70.258
 *   Acc@1 70.237
 *   Acc@1 70.549
 *   Acc@1 69.671
 *   Acc@1 70.064
 *   Acc@1 70.447
 *   Acc@1 70.450
 *   Acc@1 66.303
 *   Acc@1 66.978
 *   Acc@1 65.974
 *   Acc@1 66.548
 *   Acc@1 63.987
 *   Acc@1 64.215
 *   Acc@1 62.197
 *   Acc@1 63.072
 *   Acc@1 67.197
 *   Acc@1 67.688
 *   Acc@1 68.987
 *   Acc@1 69.937
 *   Acc@1 71.408
 *   Acc@1 72.123
 *   Acc@1 72.645
 *   Acc@1 73.369
Training for 300 epoch: 68.84868421052632
Training for 600 epoch: 68.85855263157896
Training for 1000 epoch: 68.30263157894737
Training for 3000 epoch: 67.19407894736841
Training for 300 epoch: 69.2625
Training for 600 epoch: 69.53666666666666
Training for 1000 epoch: 68.76666666666668
Training for 3000 epoch: 67.7525
[[68.84868421052632, 68.85855263157896, 68.30263157894737, 67.19407894736841], [69.2625, 69.53666666666666, 68.76666666666668, 67.7525]]
train loss 0.23869851665496827, epoch 74, best loss 0.20623853383858998, best_epoch 69
GPU_0_using curriculum 40 with window 40
Epoch: [75][20/30]	Time  3.798 ( 3.765)	Data  0.042 ( 0.058)	InnerLoop  1.662 ( 1.599)	Loss 9.9537e-01 (9.4640e-01)	Acc@1  69.31 ( 68.20)
The current update step is 2280
GPU_0_using curriculum 40 with window 40
Epoch: [76][20/30]	Time  3.818 ( 3.736)	Data  0.050 ( 0.051)	InnerLoop  1.661 ( 1.588)	Loss 9.5816e-01 (9.4639e-01)	Acc@1  69.75 ( 67.47)
The current update step is 2310
GPU_0_using curriculum 40 with window 40
Epoch: [77][20/30]	Time  3.697 ( 3.730)	Data  0.048 ( 0.071)	InnerLoop  1.537 ( 1.563)	Loss 8.1462e-01 (1.0420e+00)	Acc@1  71.53 ( 65.23)
The current update step is 2340
GPU_0_using curriculum 40 with window 40
Epoch: [78][20/30]	Time  3.687 ( 3.720)	Data  0.045 ( 0.057)	InnerLoop  1.528 ( 1.567)	Loss 9.1056e-01 (1.0601e+00)	Acc@1  66.82 ( 64.14)
The current update step is 2370
GPU_0_using curriculum 40 with window 40
Epoch: [79][20/30]	Time  3.796 ( 3.717)	Data  0.041 ( 0.057)	InnerLoop  1.650 ( 1.566)	Loss 7.9878e-01 (9.4269e-01)	Acc@1  73.36 ( 67.53)
The current update step is 2400
The current seed is 12218851236910733530
The current lr is: 0.001
Testing Results:
 *   Acc@1 60.461
 *   Acc@1 61.427
 *   Acc@1 61.789
 *   Acc@1 62.205
 *   Acc@1 61.303
 *   Acc@1 62.364
 *   Acc@1 62.750
 *   Acc@1 63.551
 *   Acc@1 70.697
 *   Acc@1 70.567
 *   Acc@1 66.921
 *   Acc@1 66.967
 *   Acc@1 65.803
 *   Acc@1 65.300
 *   Acc@1 68.250
 *   Acc@1 69.189
 *   Acc@1 73.316
 *   Acc@1 73.850
 *   Acc@1 73.092
 *   Acc@1 73.952
 *   Acc@1 73.658
 *   Acc@1 73.946
 *   Acc@1 74.092
 *   Acc@1 74.368
 *   Acc@1 70.289
 *   Acc@1 70.184
 *   Acc@1 68.618
 *   Acc@1 68.437
 *   Acc@1 65.553
 *   Acc@1 65.998
 *   Acc@1 63.592
 *   Acc@1 63.699
Training for 300 epoch: 68.6907894736842
Training for 600 epoch: 67.60526315789474
Training for 1000 epoch: 66.57894736842105
Training for 3000 epoch: 67.17105263157895
Training for 300 epoch: 69.00687500000001
Training for 600 epoch: 67.89
Training for 1000 epoch: 66.901875
Training for 3000 epoch: 67.70166666666667
[[68.6907894736842, 67.60526315789474, 66.57894736842105, 67.17105263157895], [69.00687500000001, 67.89, 66.901875, 67.70166666666667]]
train loss 0.23211900579134623, epoch 79, best loss 0.20623853383858998, best_epoch 69
GPU_0_using curriculum 40 with window 40
Epoch: [80][20/30]	Time  3.722 ( 3.735)	Data  0.046 ( 0.050)	InnerLoop  1.537 ( 1.585)	Loss 1.4284e+00 (9.9372e-01)	Acc@1  56.25 ( 64.98)
The current update step is 2430
GPU_0_using curriculum 40 with window 40
Epoch: [81][20/30]	Time  3.706 ( 3.733)	Data  0.044 ( 0.053)	InnerLoop  1.520 ( 1.581)	Loss 9.4998e-01 (1.0631e+00)	Acc@1  61.82 ( 62.59)
The current update step is 2460
GPU_0_using curriculum 40 with window 40
Epoch: [82][20/30]	Time  3.702 ( 3.746)	Data  0.043 ( 0.064)	InnerLoop  1.526 ( 1.573)	Loss 7.8428e-01 (9.6686e-01)	Acc@1  70.00 ( 66.42)
The current update step is 2490
GPU_0_using curriculum 40 with window 40
Epoch: [83][20/30]	Time  3.795 ( 3.732)	Data  0.172 ( 0.071)	InnerLoop  1.526 ( 1.563)	Loss 7.0089e-01 (8.7879e-01)	Acc@1  75.05 ( 68.86)
The current update step is 2520
GPU_0_using curriculum 40 with window 40
Epoch: [84][20/30]	Time  3.839 ( 3.729)	Data  0.046 ( 0.057)	InnerLoop  1.682 ( 1.580)	Loss 9.4853e-01 (9.9962e-01)	Acc@1  68.97 ( 67.14)
The current update step is 2550
The current seed is 710791069346227142
The current lr is: 0.001
Testing Results:
 *   Acc@1 54.276
 *   Acc@1 54.593
 *   Acc@1 51.658
 *   Acc@1 51.568
 *   Acc@1 51.092
 *   Acc@1 51.517
 *   Acc@1 50.092
 *   Acc@1 50.501
 *   Acc@1 55.184
 *   Acc@1 55.048
 *   Acc@1 53.184
 *   Acc@1 52.922
 *   Acc@1 52.013
 *   Acc@1 52.313
 *   Acc@1 54.447
 *   Acc@1 54.644
 *   Acc@1 55.105
 *   Acc@1 54.991
 *   Acc@1 53.961
 *   Acc@1 53.656
 *   Acc@1 52.553
 *   Acc@1 52.317
 *   Acc@1 50.250
 *   Acc@1 50.021
 *   Acc@1 64.105
 *   Acc@1 64.403
 *   Acc@1 61.237
 *   Acc@1 61.680
 *   Acc@1 61.553
 *   Acc@1 61.208
 *   Acc@1 60.592
 *   Acc@1 60.462
Training for 300 epoch: 57.16776315789474
Training for 600 epoch: 55.00986842105263
Training for 1000 epoch: 54.30263157894737
Training for 3000 epoch: 53.8453947368421
Training for 300 epoch: 57.258541666666666
Training for 600 epoch: 54.956250000000004
Training for 1000 epoch: 54.338750000000005
Training for 3000 epoch: 53.90708333333333
[[57.16776315789474, 55.00986842105263, 54.30263157894737, 53.8453947368421], [57.258541666666666, 54.956250000000004, 54.338750000000005, 53.90708333333333]]
train loss 0.32127643179893495, epoch 84, best loss 0.20623853383858998, best_epoch 69
GPU_0_using curriculum 40 with window 40
Epoch: [85][20/30]	Time  3.795 ( 3.741)	Data  0.042 ( 0.064)	InnerLoop  1.664 ( 1.578)	Loss 9.5709e-01 (9.4829e-01)	Acc@1  68.21 ( 66.63)
The current update step is 2580
GPU_0_using curriculum 40 with window 40
Epoch: [86][20/30]	Time  3.727 ( 3.732)	Data  0.053 ( 0.058)	InnerLoop  1.553 ( 1.570)	Loss 1.0708e+00 (9.8267e-01)	Acc@1  59.03 ( 64.76)
The current update step is 2610
GPU_0_using curriculum 40 with window 40
Epoch: [87][20/30]	Time  3.686 ( 3.733)	Data  0.045 ( 0.065)	InnerLoop  1.522 ( 1.571)	Loss 8.6967e-01 (9.3116e-01)	Acc@1  68.51 ( 67.60)
The current update step is 2640
GPU_0_using curriculum 40 with window 40
Epoch: [88][20/30]	Time  3.687 ( 3.727)	Data  0.046 ( 0.071)	InnerLoop  1.543 ( 1.562)	Loss 7.5730e-01 (1.0177e+00)	Acc@1  73.90 ( 65.99)
The current update step is 2670
GPU_0_using curriculum 40 with window 40
Epoch: [89][20/30]	Time  3.792 ( 3.739)	Data  0.169 ( 0.071)	InnerLoop  1.532 ( 1.566)	Loss 1.2484e+00 (9.0819e-01)	Acc@1  54.13 ( 67.55)
The current update step is 2700
The current seed is 890627933747592614
The current lr is: 0.001
Testing Results:
 *   Acc@1 74.039
 *   Acc@1 74.494
 *   Acc@1 72.276
 *   Acc@1 72.849
 *   Acc@1 71.105
 *   Acc@1 71.927
 *   Acc@1 70.171
 *   Acc@1 71.209
 *   Acc@1 65.947
 *   Acc@1 66.389
 *   Acc@1 69.145
 *   Acc@1 69.632
 *   Acc@1 70.382
 *   Acc@1 71.319
 *   Acc@1 69.671
 *   Acc@1 70.047
 *   Acc@1 73.513
 *   Acc@1 73.362
 *   Acc@1 72.934
 *   Acc@1 72.589
 *   Acc@1 71.487
 *   Acc@1 71.448
 *   Acc@1 68.987
 *   Acc@1 69.626
 *   Acc@1 68.829
 *   Acc@1 69.532
 *   Acc@1 65.816
 *   Acc@1 66.463
 *   Acc@1 63.000
 *   Acc@1 63.838
 *   Acc@1 59.171
 *   Acc@1 60.112
Training for 300 epoch: 70.58223684210526
Training for 600 epoch: 70.04276315789474
Training for 1000 epoch: 68.99342105263159
Training for 3000 epoch: 67.0
Training for 300 epoch: 70.94437500000001
Training for 600 epoch: 70.38354166666667
Training for 1000 epoch: 69.63312499999999
Training for 3000 epoch: 67.74833333333333
[[70.58223684210526, 70.04276315789474, 68.99342105263159, 67.0], [70.94437500000001, 70.38354166666667, 69.63312499999999, 67.74833333333333]]
train loss 0.27537833568255105, epoch 89, best loss 0.20623853383858998, best_epoch 69
GPU_0_using curriculum 40 with window 40
Epoch: [90][20/30]	Time  3.770 ( 3.720)	Data  0.049 ( 0.056)	InnerLoop  1.634 ( 1.573)	Loss 6.6091e-01 (8.6516e-01)	Acc@1  77.12 ( 69.29)
The current update step is 2730
GPU_0_using curriculum 40 with window 40
Epoch: [91][20/30]	Time  3.823 ( 3.742)	Data  0.044 ( 0.051)	InnerLoop  1.661 ( 1.591)	Loss 1.0317e+00 (9.9884e-01)	Acc@1  62.92 ( 66.42)
The current update step is 2760
GPU_0_using curriculum 40 with window 40
Epoch: [92][20/30]	Time  3.667 ( 3.729)	Data  0.049 ( 0.070)	InnerLoop  1.529 ( 1.561)	Loss 1.3245e+00 (9.7823e-01)	Acc@1  54.42 ( 65.21)
The current update step is 2790
GPU_0_using curriculum 40 with window 40
Epoch: [93][20/30]	Time  3.673 ( 3.719)	Data  0.043 ( 0.059)	InnerLoop  1.514 ( 1.567)	Loss 1.3659e+00 (9.6398e-01)	Acc@1  59.23 ( 67.70)
The current update step is 2820
GPU_0_using curriculum 40 with window 40
Epoch: [94][20/30]	Time  3.814 ( 3.721)	Data  0.045 ( 0.058)	InnerLoop  1.660 ( 1.563)	Loss 9.8058e-01 (1.0178e+00)	Acc@1  67.85 ( 65.47)
The current update step is 2850
The current seed is 12437500379921218825
The current lr is: 0.001
Testing Results:
 *   Acc@1 74.526
 *   Acc@1 75.269
 *   Acc@1 74.145
 *   Acc@1 74.711
 *   Acc@1 73.447
 *   Acc@1 74.335
 *   Acc@1 72.237
 *   Acc@1 72.848
 *   Acc@1 73.132
 *   Acc@1 74.195
 *   Acc@1 72.092
 *   Acc@1 73.246
 *   Acc@1 71.474
 *   Acc@1 72.502
 *   Acc@1 68.711
 *   Acc@1 69.700
 *   Acc@1 73.118
 *   Acc@1 73.536
 *   Acc@1 71.776
 *   Acc@1 72.397
 *   Acc@1 71.763
 *   Acc@1 72.025
 *   Acc@1 68.961
 *   Acc@1 68.963
 *   Acc@1 64.868
 *   Acc@1 66.029
 *   Acc@1 64.461
 *   Acc@1 65.054
 *   Acc@1 64.145
 *   Acc@1 64.517
 *   Acc@1 61.421
 *   Acc@1 61.932
Training for 300 epoch: 71.41118421052632
Training for 600 epoch: 70.61842105263158
Training for 1000 epoch: 70.20723684210526
Training for 3000 epoch: 67.83223684210527
Training for 300 epoch: 72.25729166666666
Training for 600 epoch: 71.35208333333333
Training for 1000 epoch: 70.84479166666667
Training for 3000 epoch: 68.36104166666667
[[71.41118421052632, 70.61842105263158, 70.20723684210526, 67.83223684210527], [72.25729166666666, 71.35208333333333, 70.84479166666667, 68.36104166666667]]
train loss 0.22933702847162882, epoch 94, best loss 0.20623853383858998, best_epoch 69
GPU_0_using curriculum 40 with window 40
Epoch: [95][20/30]	Time  3.716 ( 3.776)	Data  0.045 ( 0.052)	InnerLoop  1.546 ( 1.607)	Loss 7.0705e-01 (9.1876e-01)	Acc@1  74.34 ( 67.76)
The current update step is 2880
GPU_0_using curriculum 40 with window 40
Epoch: [96][20/30]	Time  3.679 ( 3.762)	Data  0.042 ( 0.051)	InnerLoop  1.528 ( 1.604)	Loss 2.1051e+00 (9.3700e-01)	Acc@1  43.16 ( 67.66)
The current update step is 2910
GPU_0_using curriculum 40 with window 40
Epoch: [97][20/30]	Time  3.716 ( 3.739)	Data  0.043 ( 0.064)	InnerLoop  1.562 ( 1.574)	Loss 9.5956e-01 (1.0122e+00)	Acc@1  66.21 ( 64.66)
The current update step is 2940
GPU_0_using curriculum 40 with window 40
Epoch: [98][20/30]	Time  3.830 ( 3.742)	Data  0.172 ( 0.070)	InnerLoop  1.549 ( 1.567)	Loss 1.0071e+00 (1.0476e+00)	Acc@1  62.35 ( 63.85)
The current update step is 2970
GPU_0_using curriculum 40 with window 40
Epoch: [99][20/30]	Time  3.812 ( 3.741)	Data  0.046 ( 0.057)	InnerLoop  1.673 ( 1.583)	Loss 6.9024e-01 (1.0447e+00)	Acc@1  74.56 ( 62.84)
The current update step is 3000
The current seed is 2615952159309304349
The current lr is: 0.001
Testing Results:
 *   Acc@1 65.382
 *   Acc@1 66.319
 *   Acc@1 66.553
 *   Acc@1 67.105
 *   Acc@1 64.553
 *   Acc@1 65.563
 *   Acc@1 60.000
 *   Acc@1 61.024
 *   Acc@1 51.908
 *   Acc@1 51.828
 *   Acc@1 57.711
 *   Acc@1 57.708
 *   Acc@1 60.632
 *   Acc@1 60.538
 *   Acc@1 64.145
 *   Acc@1 64.374
 *   Acc@1 59.868
 *   Acc@1 60.105
 *   Acc@1 62.934
 *   Acc@1 63.358
 *   Acc@1 63.026
 *   Acc@1 63.734
 *   Acc@1 61.658
 *   Acc@1 62.301
 *   Acc@1 54.934
 *   Acc@1 54.888
 *   Acc@1 65.145
 *   Acc@1 65.061
 *   Acc@1 68.355
 *   Acc@1 68.569
 *   Acc@1 70.316
 *   Acc@1 70.957
Training for 300 epoch: 58.02302631578947
Training for 600 epoch: 63.08552631578947
Training for 1000 epoch: 64.14144736842105
Training for 3000 epoch: 64.02960526315789
Training for 300 epoch: 58.28479166666666
Training for 600 epoch: 63.30770833333334
Training for 1000 epoch: 64.60125
Training for 3000 epoch: 64.66395833333334
[[58.02302631578947, 63.08552631578947, 64.14144736842105, 64.02960526315789], [58.28479166666666, 63.30770833333334, 64.60125, 64.66395833333334]]
train loss 0.21110089054107667, epoch 99, best loss 0.20623853383858998, best_epoch 69
GPU_0_using curriculum 40 with window 40
Epoch: [100][20/30]	Time  3.787 ( 3.722)	Data  0.049 ( 0.064)	InnerLoop  1.643 ( 1.567)	Loss 7.2553e-01 (1.0309e+00)	Acc@1  71.78 ( 64.28)
The current update step is 3030
GPU_0_using curriculum 40 with window 40
Epoch: [101][20/30]	Time  3.657 ( 3.725)	Data  0.045 ( 0.057)	InnerLoop  1.518 ( 1.570)	Loss 1.0947e+00 (1.0210e+00)	Acc@1  63.60 ( 64.15)
The current update step is 3060
GPU_0_using curriculum 40 with window 40
Epoch: [102][20/30]	Time  3.745 ( 3.732)	Data  0.046 ( 0.065)	InnerLoop  1.558 ( 1.571)	Loss 7.9533e-01 (8.7339e-01)	Acc@1  71.80 ( 68.29)
The current update step is 3090
GPU_0_using curriculum 40 with window 40
Epoch: [103][20/30]	Time  3.642 ( 3.716)	Data  0.047 ( 0.071)	InnerLoop  1.505 ( 1.554)	Loss 1.0224e+00 (9.2965e-01)	Acc@1  59.57 ( 66.60)
The current update step is 3120
GPU_0_using curriculum 40 with window 40
Epoch: [104][20/30]	Time  3.791 ( 3.720)	Data  0.171 ( 0.070)	InnerLoop  1.516 ( 1.555)	Loss 9.2359e-01 (9.0488e-01)	Acc@1  66.33 ( 67.61)
The current update step is 3150
The current seed is 4293301068761438709
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.000
 *   Acc@1 74.319
 *   Acc@1 74.263
 *   Acc@1 74.923
 *   Acc@1 72.816
 *   Acc@1 73.780
 *   Acc@1 68.513
 *   Acc@1 69.871
 *   Acc@1 67.487
 *   Acc@1 68.284
 *   Acc@1 65.500
 *   Acc@1 65.798
 *   Acc@1 62.658
 *   Acc@1 63.117
 *   Acc@1 62.237
 *   Acc@1 62.908
 *   Acc@1 68.553
 *   Acc@1 68.882
 *   Acc@1 64.908
 *   Acc@1 64.718
 *   Acc@1 64.868
 *   Acc@1 64.498
 *   Acc@1 65.671
 *   Acc@1 65.126
 *   Acc@1 65.105
 *   Acc@1 65.297
 *   Acc@1 63.882
 *   Acc@1 64.220
 *   Acc@1 60.250
 *   Acc@1 61.032
 *   Acc@1 56.211
 *   Acc@1 56.888
Training for 300 epoch: 68.53618421052633
Training for 600 epoch: 67.13815789473684
Training for 1000 epoch: 65.14802631578947
Training for 3000 epoch: 63.15789473684211
Training for 300 epoch: 69.19583333333333
Training for 600 epoch: 67.41479166666667
Training for 1000 epoch: 65.606875
Training for 3000 epoch: 63.698125000000005
[[68.53618421052633, 67.13815789473684, 65.14802631578947, 63.15789473684211], [69.19583333333333, 67.41479166666667, 65.606875, 63.698125000000005]]
train loss 0.32674314357439677, epoch 104, best loss 0.20623853383858998, best_epoch 69
GPU_0_using curriculum 40 with window 40
Epoch: [105][20/30]	Time  3.791 ( 3.731)	Data  0.046 ( 0.056)	InnerLoop  1.642 ( 1.577)	Loss 7.2736e-01 (1.0059e+00)	Acc@1  75.37 ( 66.27)
The current update step is 3180
GPU_0_using curriculum 40 with window 40
Epoch: [106][20/30]	Time  3.809 ( 3.757)	Data  0.046 ( 0.051)	InnerLoop  1.665 ( 1.597)	Loss 9.2306e-01 (9.8449e-01)	Acc@1  65.09 ( 65.97)
The current update step is 3210
GPU_0_using curriculum 40 with window 40
Epoch: [107][20/30]	Time  3.735 ( 3.772)	Data  0.051 ( 0.072)	InnerLoop  1.536 ( 1.583)	Loss 8.2953e-01 (1.0109e+00)	Acc@1  72.44 ( 64.17)
The current update step is 3240
GPU_0_using curriculum 40 with window 40
Epoch: [108][20/30]	Time  3.733 ( 3.744)	Data  0.059 ( 0.059)	InnerLoop  1.552 ( 1.583)	Loss 7.7965e-01 (9.1974e-01)	Acc@1  70.19 ( 67.25)
The current update step is 3270
GPU_0_using curriculum 40 with window 40
Epoch: [109][20/30]	Time  3.841 ( 3.742)	Data  0.049 ( 0.058)	InnerLoop  1.674 ( 1.581)	Loss 7.3563e-01 (1.0416e+00)	Acc@1  70.87 ( 64.43)
The current update step is 3300
The current seed is 11566858585282934292
The current lr is: 0.001
Testing Results:
 *   Acc@1 57.368
 *   Acc@1 57.875
 *   Acc@1 56.053
 *   Acc@1 56.992
 *   Acc@1 58.395
 *   Acc@1 59.033
 *   Acc@1 62.750
 *   Acc@1 63.748
 *   Acc@1 66.855
 *   Acc@1 67.535
 *   Acc@1 68.434
 *   Acc@1 69.238
 *   Acc@1 68.816
 *   Acc@1 69.696
 *   Acc@1 69.434
 *   Acc@1 70.382
 *   Acc@1 73.395
 *   Acc@1 74.207
 *   Acc@1 74.395
 *   Acc@1 74.639
 *   Acc@1 72.237
 *   Acc@1 72.677
 *   Acc@1 70.500
 *   Acc@1 71.448
 *   Acc@1 68.684
 *   Acc@1 69.948
 *   Acc@1 67.118
 *   Acc@1 68.454
 *   Acc@1 65.092
 *   Acc@1 66.655
 *   Acc@1 63.171
 *   Acc@1 64.412
Training for 300 epoch: 66.57565789473685
Training for 600 epoch: 66.5
Training for 1000 epoch: 66.13486842105263
Training for 3000 epoch: 66.46381578947368
Training for 300 epoch: 67.39104166666667
Training for 600 epoch: 67.33104166666666
Training for 1000 epoch: 67.01541666666668
Training for 3000 epoch: 67.4975
[[66.57565789473685, 66.5, 66.13486842105263, 66.46381578947368], [67.39104166666667, 67.33104166666666, 67.01541666666668, 67.4975]]
train loss 0.2656528846740723, epoch 109, best loss 0.20623853383858998, best_epoch 69
GPU_0_using curriculum 40 with window 40
Epoch: [110][20/30]	Time  3.717 ( 3.736)	Data  0.050 ( 0.053)	InnerLoop  1.540 ( 1.584)	Loss 1.1107e+00 (9.9299e-01)	Acc@1  61.40 ( 66.82)
The current update step is 3330
GPU_0_using curriculum 40 with window 40
Epoch: [111][20/30]	Time  3.734 ( 3.774)	Data  0.045 ( 0.054)	InnerLoop  1.581 ( 1.598)	Loss 7.7823e-01 (9.6536e-01)	Acc@1  73.07 ( 67.15)
The current update step is 3360
GPU_0_using curriculum 40 with window 40
Epoch: [112][20/30]	Time  3.717 ( 3.753)	Data  0.044 ( 0.066)	InnerLoop  1.538 ( 1.576)	Loss 7.9901e-01 (8.3648e-01)	Acc@1  69.51 ( 70.15)
The current update step is 3390
GPU_0_using curriculum 40 with window 40
Epoch: [113][20/30]	Time  3.797 ( 3.730)	Data  0.166 ( 0.071)	InnerLoop  1.534 ( 1.560)	Loss 1.5100e+00 (8.8099e-01)	Acc@1  55.08 ( 68.86)
The current update step is 3420
GPU_0_using curriculum 40 with window 40
Epoch: [114][20/30]	Time  3.847 ( 3.746)	Data  0.045 ( 0.057)	InnerLoop  1.691 ( 1.585)	Loss 8.4956e-01 (9.6384e-01)	Acc@1  68.07 ( 68.00)
The current update step is 3450
The current seed is 12933397454994980084
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.566
 *   Acc@1 71.263
 *   Acc@1 66.763
 *   Acc@1 67.184
 *   Acc@1 65.250
 *   Acc@1 65.822
 *   Acc@1 64.184
 *   Acc@1 64.338
 *   Acc@1 74.474
 *   Acc@1 75.211
 *   Acc@1 71.789
 *   Acc@1 72.787
 *   Acc@1 68.092
 *   Acc@1 69.028
 *   Acc@1 62.132
 *   Acc@1 63.339
 *   Acc@1 60.000
 *   Acc@1 61.351
 *   Acc@1 61.158
 *   Acc@1 62.880
 *   Acc@1 60.632
 *   Acc@1 62.335
 *   Acc@1 57.618
 *   Acc@1 59.188
 *   Acc@1 69.842
 *   Acc@1 70.453
 *   Acc@1 67.987
 *   Acc@1 68.359
 *   Acc@1 65.289
 *   Acc@1 66.098
 *   Acc@1 61.987
 *   Acc@1 62.633
Training for 300 epoch: 68.72039473684211
Training for 600 epoch: 66.92434210526315
Training for 1000 epoch: 64.8157894736842
Training for 3000 epoch: 61.48026315789474
Training for 300 epoch: 69.569375
Training for 600 epoch: 67.80270833333333
Training for 1000 epoch: 65.82083333333334
Training for 3000 epoch: 62.37416666666667
[[68.72039473684211, 66.92434210526315, 64.8157894736842, 61.48026315789474], [69.569375, 67.80270833333333, 65.82083333333334, 62.37416666666667]]
train loss 0.2606224610010783, epoch 114, best loss 0.20623853383858998, best_epoch 69
GPU_0_using curriculum 40 with window 40
Epoch: [115][20/30]	Time  3.839 ( 3.737)	Data  0.041 ( 0.064)	InnerLoop  1.715 ( 1.581)	Loss 9.8835e-01 (1.0451e+00)	Acc@1  65.75 ( 64.77)
The current update step is 3480
GPU_0_using curriculum 40 with window 40
Epoch: [116][20/30]	Time  3.694 ( 3.726)	Data  0.046 ( 0.058)	InnerLoop  1.532 ( 1.573)	Loss 1.2093e+00 (1.0225e+00)	Acc@1  63.16 ( 65.13)
The current update step is 3510
GPU_0_using curriculum 40 with window 40
Epoch: [117][20/30]	Time  3.678 ( 3.732)	Data  0.049 ( 0.065)	InnerLoop  1.513 ( 1.567)	Loss 1.1362e+00 (8.7461e-01)	Acc@1  62.79 ( 68.97)
The current update step is 3540
GPU_0_using curriculum 40 with window 40
Epoch: [118][20/30]	Time  3.719 ( 3.743)	Data  0.048 ( 0.070)	InnerLoop  1.555 ( 1.570)	Loss 9.1972e-01 (8.8651e-01)	Acc@1  67.92 ( 68.52)
The current update step is 3570
GPU_0_using curriculum 40 with window 40
Epoch: [119][20/30]	Time  3.787 ( 3.728)	Data  0.176 ( 0.072)	InnerLoop  1.524 ( 1.560)	Loss 9.8183e-01 (8.9099e-01)	Acc@1  65.65 ( 69.05)
The current update step is 3600
The current seed is 10380005224878872489
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.303
 *   Acc@1 70.902
 *   Acc@1 69.197
 *   Acc@1 69.510
 *   Acc@1 68.421
 *   Acc@1 68.715
 *   Acc@1 67.329
 *   Acc@1 67.592
 *   Acc@1 66.224
 *   Acc@1 66.959
 *   Acc@1 63.171
 *   Acc@1 63.312
 *   Acc@1 60.987
 *   Acc@1 61.501
 *   Acc@1 59.039
 *   Acc@1 59.779
 *   Acc@1 75.408
 *   Acc@1 76.177
 *   Acc@1 74.105
 *   Acc@1 75.177
 *   Acc@1 73.132
 *   Acc@1 73.662
 *   Acc@1 73.066
 *   Acc@1 73.535
 *   Acc@1 65.513
 *   Acc@1 65.391
 *   Acc@1 62.658
 *   Acc@1 62.727
 *   Acc@1 61.974
 *   Acc@1 62.566
 *   Acc@1 64.039
 *   Acc@1 63.939
Training for 300 epoch: 69.36184210526316
Training for 600 epoch: 67.2828947368421
Training for 1000 epoch: 66.1282894736842
Training for 3000 epoch: 65.86842105263158
Training for 300 epoch: 69.85708333333334
Training for 600 epoch: 67.68166666666667
Training for 1000 epoch: 66.61104166666667
Training for 3000 epoch: 66.21125
[[69.36184210526316, 67.2828947368421, 66.1282894736842, 65.86842105263158], [69.85708333333334, 67.68166666666667, 66.61104166666667, 66.21125]]
train loss 0.2759117248058319, epoch 119, best loss 0.20623853383858998, best_epoch 69
GPU_0_using curriculum 40 with window 40
Epoch: [120][20/30]	Time  3.791 ( 3.741)	Data  0.042 ( 0.056)	InnerLoop  1.652 ( 1.580)	Loss 8.3491e-01 (9.7702e-01)	Acc@1  70.19 ( 67.42)
The current update step is 3630
GPU_0_using curriculum 40 with window 40
Epoch: [121][20/30]	Time  3.861 ( 3.729)	Data  0.046 ( 0.050)	InnerLoop  1.724 ( 1.586)	Loss 8.5790e-01 (9.2108e-01)	Acc@1  67.53 ( 67.10)
The current update step is 3660
GPU_0_using curriculum 40 with window 40
Epoch: [122][20/30]	Time  3.656 ( 3.718)	Data  0.047 ( 0.070)	InnerLoop  1.507 ( 1.553)	Loss 9.2885e-01 (9.2321e-01)	Acc@1  66.77 ( 67.21)
The current update step is 3690
GPU_0_using curriculum 40 with window 40
Epoch: [123][20/30]	Time  3.656 ( 3.723)	Data  0.042 ( 0.058)	InnerLoop  1.506 ( 1.564)	Loss 1.0434e+00 (1.0032e+00)	Acc@1  65.87 ( 65.68)
The current update step is 3720
GPU_0_using curriculum 40 with window 40
Epoch: [124][20/30]	Time  3.782 ( 3.718)	Data  0.048 ( 0.059)	InnerLoop  1.638 ( 1.561)	Loss 8.5341e-01 (9.3719e-01)	Acc@1  66.97 ( 67.07)
The current update step is 3750
The current seed is 9369400898804768732
The current lr is: 0.001
Testing Results:
 *   Acc@1 68.303
 *   Acc@1 68.541
 *   Acc@1 63.145
 *   Acc@1 63.975
 *   Acc@1 60.895
 *   Acc@1 61.773
 *   Acc@1 57.211
 *   Acc@1 57.587
 *   Acc@1 62.053
 *   Acc@1 63.249
 *   Acc@1 60.513
 *   Acc@1 62.090
 *   Acc@1 62.197
 *   Acc@1 62.806
 *   Acc@1 60.789
 *   Acc@1 62.167
 *   Acc@1 73.500
 *   Acc@1 74.114
 *   Acc@1 73.487
 *   Acc@1 73.668
 *   Acc@1 71.816
 *   Acc@1 72.696
 *   Acc@1 71.974
 *   Acc@1 72.252
 *   Acc@1 69.408
 *   Acc@1 70.424
 *   Acc@1 71.263
 *   Acc@1 72.101
 *   Acc@1 69.579
 *   Acc@1 71.250
 *   Acc@1 70.158
 *   Acc@1 70.864
Training for 300 epoch: 68.31578947368422
Training for 600 epoch: 67.10197368421052
Training for 1000 epoch: 66.12171052631578
Training for 3000 epoch: 65.03289473684211
Training for 300 epoch: 69.08208333333334
Training for 600 epoch: 67.95833333333334
Training for 1000 epoch: 67.13104166666668
Training for 3000 epoch: 65.71770833333333
[[68.31578947368422, 67.10197368421052, 66.12171052631578, 65.03289473684211], [69.08208333333334, 67.95833333333334, 67.13104166666668, 65.71770833333333]]
train loss 0.20086198711395264, epoch 124, best loss 0.20086198711395264, best_epoch 124
GPU_0_using curriculum 40 with window 40
Epoch: [125][20/30]	Time  3.636 ( 3.716)	Data  0.043 ( 0.051)	InnerLoop  1.512 ( 1.570)	Loss 7.3696e-01 (8.2598e-01)	Acc@1  73.39 ( 70.55)
The current update step is 3780
GPU_0_using curriculum 40 with window 40
Epoch: [126][20/30]	Time  3.656 ( 3.712)	Data  0.047 ( 0.053)	InnerLoop  1.514 ( 1.567)	Loss 1.0234e+00 (8.7541e-01)	Acc@1  65.58 ( 69.03)
The current update step is 3810
GPU_0_using curriculum 40 with window 40
Epoch: [127][20/30]	Time  3.659 ( 3.720)	Data  0.045 ( 0.064)	InnerLoop  1.522 ( 1.558)	Loss 1.0124e+00 (8.6718e-01)	Acc@1  64.33 ( 69.60)
The current update step is 3840
GPU_0_using curriculum 40 with window 40
Epoch: [128][20/30]	Time  3.813 ( 3.724)	Data  0.170 ( 0.070)	InnerLoop  1.538 ( 1.558)	Loss 7.4510e-01 (8.4231e-01)	Acc@1  75.44 ( 70.46)
The current update step is 3870
GPU_0_using curriculum 40 with window 40
Epoch: [129][20/30]	Time  3.795 ( 3.732)	Data  0.045 ( 0.058)	InnerLoop  1.642 ( 1.578)	Loss 1.3990e+00 (8.7796e-01)	Acc@1  53.25 ( 69.72)
The current update step is 3900
The current seed is 5215462342000561599
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.539
 *   Acc@1 69.817
 *   Acc@1 66.763
 *   Acc@1 67.282
 *   Acc@1 67.434
 *   Acc@1 67.906
 *   Acc@1 62.250
 *   Acc@1 62.587
 *   Acc@1 71.355
 *   Acc@1 71.778
 *   Acc@1 69.737
 *   Acc@1 69.615
 *   Acc@1 68.645
 *   Acc@1 68.602
 *   Acc@1 68.395
 *   Acc@1 68.633
 *   Acc@1 62.053
 *   Acc@1 62.425
 *   Acc@1 60.237
 *   Acc@1 60.233
 *   Acc@1 58.724
 *   Acc@1 59.151
 *   Acc@1 59.303
 *   Acc@1 59.566
 *   Acc@1 72.816
 *   Acc@1 73.828
 *   Acc@1 71.211
 *   Acc@1 71.685
 *   Acc@1 69.566
 *   Acc@1 70.281
 *   Acc@1 67.487
 *   Acc@1 68.099
Training for 300 epoch: 68.9407894736842
Training for 600 epoch: 66.98684210526315
Training for 1000 epoch: 66.09210526315789
Training for 3000 epoch: 64.35855263157895
Training for 300 epoch: 69.46208333333333
Training for 600 epoch: 67.20395833333333
Training for 1000 epoch: 66.48479166666667
Training for 3000 epoch: 64.72125
[[68.9407894736842, 66.98684210526315, 66.09210526315789, 64.35855263157895], [69.46208333333333, 67.20395833333333, 66.48479166666667, 64.72125]]
train loss 0.2168789570569992, epoch 129, best loss 0.20086198711395264, best_epoch 124
GPU_0_using curriculum 40 with window 40
Epoch: [130][20/30]	Time  3.751 ( 3.722)	Data  0.043 ( 0.064)	InnerLoop  1.614 ( 1.567)	Loss 1.0597e+00 (8.7487e-01)	Acc@1  61.30 ( 69.38)
The current update step is 3930
GPU_0_using curriculum 40 with window 40
Epoch: [131][20/30]	Time  3.676 ( 3.725)	Data  0.047 ( 0.058)	InnerLoop  1.540 ( 1.569)	Loss 6.3984e-01 (8.5620e-01)	Acc@1  77.73 ( 69.69)
The current update step is 3960
GPU_0_using curriculum 40 with window 40
Epoch: [132][20/30]	Time  3.723 ( 3.750)	Data  0.044 ( 0.065)	InnerLoop  1.557 ( 1.578)	Loss 9.6766e-01 (1.0319e+00)	Acc@1  61.21 ( 62.98)
The current update step is 3990
GPU_0_using curriculum 40 with window 40
Epoch: [133][20/30]	Time  3.706 ( 3.765)	Data  0.048 ( 0.072)	InnerLoop  1.547 ( 1.584)	Loss 6.3893e-01 (9.1123e-01)	Acc@1  76.59 ( 67.66)
The current update step is 4020
GPU_0_using curriculum 40 with window 40
Epoch: [134][20/30]	Time  3.829 ( 3.750)	Data  0.181 ( 0.072)	InnerLoop  1.527 ( 1.565)	Loss 1.5343e+00 (9.9778e-01)	Acc@1  51.46 ( 65.06)
The current update step is 4050
The current seed is 13514055644404391976
The current lr is: 0.001
Testing Results:
 *   Acc@1 64.447
 *   Acc@1 64.088
 *   Acc@1 64.566
 *   Acc@1 64.779
 *   Acc@1 62.158
 *   Acc@1 62.071
 *   Acc@1 64.145
 *   Acc@1 64.366
 *   Acc@1 59.592
 *   Acc@1 59.946
 *   Acc@1 59.776
 *   Acc@1 59.643
 *   Acc@1 60.434
 *   Acc@1 60.194
 *   Acc@1 59.171
 *   Acc@1 59.673
 *   Acc@1 66.395
 *   Acc@1 66.783
 *   Acc@1 61.605
 *   Acc@1 61.970
 *   Acc@1 60.724
 *   Acc@1 60.549
 *   Acc@1 59.987
 *   Acc@1 59.521
 *   Acc@1 46.605
 *   Acc@1 46.636
 *   Acc@1 41.553
 *   Acc@1 41.646
 *   Acc@1 39.211
 *   Acc@1 39.282
 *   Acc@1 38.987
 *   Acc@1 39.021
Training for 300 epoch: 59.25986842105263
Training for 600 epoch: 56.875
Training for 1000 epoch: 55.631578947368425
Training for 3000 epoch: 55.57236842105263
Training for 300 epoch: 59.36333333333333
Training for 600 epoch: 57.00958333333333
Training for 1000 epoch: 55.52395833333333
Training for 3000 epoch: 55.645208333333336
[[59.25986842105263, 56.875, 55.631578947368425, 55.57236842105263], [59.36333333333333, 57.00958333333333, 55.52395833333333, 55.645208333333336]]
train loss 0.4739563894748688, epoch 134, best loss 0.20086198711395264, best_epoch 124
GPU_0_using curriculum 40 with window 40
Epoch: [135][20/30]	Time  3.798 ( 3.729)	Data  0.047 ( 0.057)	InnerLoop  1.657 ( 1.578)	Loss 8.6727e-01 (8.9009e-01)	Acc@1  69.70 ( 67.54)
The current update step is 4080
GPU_0_using curriculum 40 with window 40
Epoch: [136][20/30]	Time  3.789 ( 3.766)	Data  0.046 ( 0.051)	InnerLoop  1.645 ( 1.600)	Loss 9.7488e-01 (8.7663e-01)	Acc@1  64.04 ( 68.90)
The current update step is 4110
GPU_0_using curriculum 40 with window 40
Epoch: [137][20/30]	Time  3.712 ( 3.755)	Data  0.049 ( 0.070)	InnerLoop  1.531 ( 1.580)	Loss 6.0745e-01 (8.3952e-01)	Acc@1  77.86 ( 70.21)
The current update step is 4140
GPU_0_using curriculum 40 with window 40
Epoch: [138][20/30]	Time  3.727 ( 3.761)	Data  0.045 ( 0.058)	InnerLoop  1.562 ( 1.594)	Loss 6.5781e-01 (8.7921e-01)	Acc@1  76.54 ( 69.15)
The current update step is 4170
GPU_0_using curriculum 40 with window 40
Epoch: [139][20/30]	Time  3.890 ( 3.769)	Data  0.049 ( 0.060)	InnerLoop  1.702 ( 1.598)	Loss 7.2808e-01 (8.2211e-01)	Acc@1  73.56 ( 70.33)
The current update step is 4200
The current seed is 4233022726629770408
The current lr is: 0.001
Testing Results:
 *   Acc@1 52.776
 *   Acc@1 53.068
 *   Acc@1 51.934
 *   Acc@1 52.244
 *   Acc@1 51.539
 *   Acc@1 51.529
 *   Acc@1 52.579
 *   Acc@1 52.581
 *   Acc@1 43.276
 *   Acc@1 43.665
 *   Acc@1 39.605
 *   Acc@1 39.809
 *   Acc@1 37.395
 *   Acc@1 37.358
 *   Acc@1 34.684
 *   Acc@1 34.886
 *   Acc@1 46.921
 *   Acc@1 46.910
 *   Acc@1 45.961
 *   Acc@1 45.678
 *   Acc@1 46.776
 *   Acc@1 46.215
 *   Acc@1 50.224
 *   Acc@1 50.126
 *   Acc@1 75.408
 *   Acc@1 75.918
 *   Acc@1 72.513
 *   Acc@1 72.244
 *   Acc@1 70.908
 *   Acc@1 71.208
 *   Acc@1 69.118
 *   Acc@1 69.113
Training for 300 epoch: 54.5953947368421
Training for 600 epoch: 52.503289473684205
Training for 1000 epoch: 51.6546052631579
Training for 3000 epoch: 51.651315789473685
Training for 300 epoch: 54.890208333333334
Training for 600 epoch: 52.49395833333334
Training for 1000 epoch: 51.577708333333334
Training for 3000 epoch: 51.67645833333333
[[54.5953947368421, 52.503289473684205, 51.6546052631579, 51.651315789473685], [54.890208333333334, 52.49395833333334, 51.577708333333334, 51.67645833333333]]
train loss 0.23227268022696176, epoch 139, best loss 0.20086198711395264, best_epoch 124
GPU_0_using curriculum 40 with window 40
Epoch: [140][20/30]	Time  3.718 ( 3.729)	Data  0.042 ( 0.050)	InnerLoop  1.523 ( 1.576)	Loss 7.6471e-01 (8.6746e-01)	Acc@1  72.36 ( 69.74)
The current update step is 4230
GPU_0_using curriculum 40 with window 40
Epoch: [141][20/30]	Time  3.662 ( 3.732)	Data  0.044 ( 0.050)	InnerLoop  1.527 ( 1.586)	Loss 8.3857e-01 (8.1299e-01)	Acc@1  66.38 ( 70.16)
The current update step is 4260
GPU_0_using curriculum 40 with window 40
Epoch: [142][20/30]	Time  3.666 ( 3.719)	Data  0.044 ( 0.063)	InnerLoop  1.514 ( 1.557)	Loss 6.6292e-01 (8.1785e-01)	Acc@1  74.41 ( 70.03)
The current update step is 4290
GPU_0_using curriculum 40 with window 40
Epoch: [143][20/30]	Time  3.782 ( 3.735)	Data  0.178 ( 0.070)	InnerLoop  1.516 ( 1.558)	Loss 1.2056e+00 (1.0063e+00)	Acc@1  61.72 ( 65.75)
The current update step is 4320
GPU_0_using curriculum 40 with window 40
Epoch: [144][20/30]	Time  3.788 ( 3.725)	Data  0.045 ( 0.057)	InnerLoop  1.650 ( 1.579)	Loss 7.1692e-01 (9.3340e-01)	Acc@1  72.88 ( 67.74)
The current update step is 4350
The current seed is 18128067540545528514
The current lr is: 0.001
Testing Results:
 *   Acc@1 62.513
 *   Acc@1 63.288
 *   Acc@1 61.066
 *   Acc@1 62.071
 *   Acc@1 60.171
 *   Acc@1 60.874
 *   Acc@1 59.079
 *   Acc@1 59.230
 *   Acc@1 66.500
 *   Acc@1 66.685
 *   Acc@1 66.013
 *   Acc@1 65.902
 *   Acc@1 65.434
 *   Acc@1 65.101
 *   Acc@1 64.224
 *   Acc@1 63.775
 *   Acc@1 62.079
 *   Acc@1 62.493
 *   Acc@1 56.224
 *   Acc@1 57.027
 *   Acc@1 54.961
 *   Acc@1 55.582
 *   Acc@1 51.934
 *   Acc@1 52.605
 *   Acc@1 63.013
 *   Acc@1 63.228
 *   Acc@1 60.421
 *   Acc@1 60.284
 *   Acc@1 57.276
 *   Acc@1 57.528
 *   Acc@1 53.895
 *   Acc@1 53.739
Training for 300 epoch: 63.52631578947369
Training for 600 epoch: 60.930921052631575
Training for 1000 epoch: 59.46052631578948
Training for 3000 epoch: 57.2828947368421
Training for 300 epoch: 63.92375
Training for 600 epoch: 61.32083333333333
Training for 1000 epoch: 59.77125
Training for 3000 epoch: 57.337291666666665
[[63.52631578947369, 60.930921052631575, 59.46052631578948, 57.2828947368421], [63.92375, 61.32083333333333, 59.77125, 57.337291666666665]]
train loss 0.2796914056301117, epoch 144, best loss 0.20086198711395264, best_epoch 124
GPU_0_using curriculum 40 with window 40
Epoch: [145][20/30]	Time  3.795 ( 3.766)	Data  0.050 ( 0.065)	InnerLoop  1.638 ( 1.590)	Loss 1.0922e+00 (9.8664e-01)	Acc@1  61.89 ( 66.16)
The current update step is 4380
GPU_0_using curriculum 40 with window 40
Epoch: [146][20/30]	Time  3.648 ( 3.732)	Data  0.043 ( 0.058)	InnerLoop  1.512 ( 1.575)	Loss 7.4443e-01 (8.5734e-01)	Acc@1  73.80 ( 68.72)
The current update step is 4410
GPU_0_using curriculum 40 with window 40
Epoch: [147][20/30]	Time  3.630 ( 3.723)	Data  0.045 ( 0.063)	InnerLoop  1.492 ( 1.560)	Loss 1.1174e+00 (9.0716e-01)	Acc@1  60.72 ( 67.98)
The current update step is 4440
GPU_0_using curriculum 40 with window 40
Epoch: [148][20/30]	Time  3.718 ( 3.705)	Data  0.047 ( 0.070)	InnerLoop  1.548 ( 1.545)	Loss 7.6459e-01 (9.6312e-01)	Acc@1  70.97 ( 64.71)
The current update step is 4470
GPU_0_using curriculum 40 with window 40
Epoch: [149][20/30]	Time  3.823 ( 3.711)	Data  0.172 ( 0.068)	InnerLoop  1.544 ( 1.551)	Loss 1.5078e+00 (9.2317e-01)	Acc@1  50.76 ( 66.11)
The current update step is 4500
The current seed is 8996009240014080299
The current lr is: 0.001
Testing Results:
 *   Acc@1 64.276
 *   Acc@1 64.025
 *   Acc@1 63.526
 *   Acc@1 63.598
 *   Acc@1 62.947
 *   Acc@1 63.099
 *   Acc@1 61.382
 *   Acc@1 61.437
 *   Acc@1 72.487
 *   Acc@1 72.687
 *   Acc@1 71.868
 *   Acc@1 71.798
 *   Acc@1 70.803
 *   Acc@1 71.177
 *   Acc@1 67.711
 *   Acc@1 67.902
 *   Acc@1 63.684
 *   Acc@1 64.699
 *   Acc@1 61.539
 *   Acc@1 62.738
 *   Acc@1 63.434
 *   Acc@1 63.843
 *   Acc@1 63.092
 *   Acc@1 64.562
 *   Acc@1 65.303
 *   Acc@1 65.252
 *   Acc@1 64.737
 *   Acc@1 65.321
 *   Acc@1 64.171
 *   Acc@1 64.853
 *   Acc@1 63.118
 *   Acc@1 63.228
Training for 300 epoch: 66.4375
Training for 600 epoch: 65.41776315789474
Training for 1000 epoch: 65.33881578947368
Training for 3000 epoch: 63.82565789473684
Training for 300 epoch: 66.66583333333334
Training for 600 epoch: 65.86395833333334
Training for 1000 epoch: 65.74333333333334
Training for 3000 epoch: 64.28229166666667
[[66.4375, 65.41776315789474, 65.33881578947368, 63.82565789473684], [66.66583333333334, 65.86395833333334, 65.74333333333334, 64.28229166666667]]
train loss 0.2344797782341639, epoch 149, best loss 0.20086198711395264, best_epoch 124
GPU_0_using curriculum 40 with window 40
Epoch: [150][20/30]	Time  3.846 ( 3.731)	Data  0.046 ( 0.057)	InnerLoop  1.695 ( 1.580)	Loss 6.9945e-01 (9.3414e-01)	Acc@1  75.17 ( 66.86)
The current update step is 4530
GPU_0_using curriculum 40 with window 40
Epoch: [151][20/30]	Time  3.822 ( 3.735)	Data  0.042 ( 0.052)	InnerLoop  1.690 ( 1.586)	Loss 6.5054e-01 (9.8994e-01)	Acc@1  75.93 ( 64.52)
The current update step is 4560
GPU_0_using curriculum 40 with window 40
Epoch: [152][20/30]	Time  3.687 ( 3.733)	Data  0.047 ( 0.071)	InnerLoop  1.539 ( 1.562)	Loss 6.0895e-01 (8.2139e-01)	Acc@1  78.34 ( 70.47)
The current update step is 4590
GPU_0_using curriculum 40 with window 40
Epoch: [153][20/30]	Time  3.663 ( 3.720)	Data  0.048 ( 0.058)	InnerLoop  1.518 ( 1.566)	Loss 1.1638e+00 (8.4410e-01)	Acc@1  54.37 ( 69.14)
The current update step is 4620
GPU_0_using curriculum 40 with window 40
Epoch: [154][20/30]	Time  3.752 ( 3.716)	Data  0.046 ( 0.057)	InnerLoop  1.626 ( 1.566)	Loss 6.5093e-01 (8.3665e-01)	Acc@1  77.49 ( 69.45)
The current update step is 4650
The current seed is 8378613452659632858
The current lr is: 0.001
Testing Results:
 *   Acc@1 60.434
 *   Acc@1 61.153
 *   Acc@1 56.829
 *   Acc@1 57.005
 *   Acc@1 55.868
 *   Acc@1 56.171
 *   Acc@1 55.197
 *   Acc@1 55.667
 *   Acc@1 66.566
 *   Acc@1 67.651
 *   Acc@1 64.711
 *   Acc@1 65.617
 *   Acc@1 64.145
 *   Acc@1 65.131
 *   Acc@1 62.513
 *   Acc@1 63.304
 *   Acc@1 65.803
 *   Acc@1 66.204
 *   Acc@1 62.105
 *   Acc@1 62.203
 *   Acc@1 59.868
 *   Acc@1 59.872
 *   Acc@1 60.618
 *   Acc@1 60.694
 *   Acc@1 71.329
 *   Acc@1 71.129
 *   Acc@1 69.039
 *   Acc@1 69.257
 *   Acc@1 68.566
 *   Acc@1 68.254
 *   Acc@1 67.947
 *   Acc@1 67.933
Training for 300 epoch: 66.03289473684211
Training for 600 epoch: 63.171052631578945
Training for 1000 epoch: 62.111842105263165
Training for 3000 epoch: 61.569078947368425
Training for 300 epoch: 66.534375
Training for 600 epoch: 63.52020833333333
Training for 1000 epoch: 62.356875
Training for 3000 epoch: 61.899791666666665
[[66.03289473684211, 63.171052631578945, 62.111842105263165, 61.569078947368425], [66.534375, 63.52020833333333, 62.356875, 61.899791666666665]]
train loss 0.2601064285437266, epoch 154, best loss 0.20086198711395264, best_epoch 124
GPU_0_using curriculum 40 with window 40
Epoch: [155][20/30]	Time  3.643 ( 3.728)	Data  0.045 ( 0.051)	InnerLoop  1.508 ( 1.578)	Loss 9.7580e-01 (8.3762e-01)	Acc@1  59.30 ( 69.39)
The current update step is 4680
GPU_0_using curriculum 40 with window 40
Epoch: [156][20/30]	Time  3.704 ( 3.718)	Data  0.040 ( 0.052)	InnerLoop  1.541 ( 1.574)	Loss 8.8672e-01 (8.8596e-01)	Acc@1  69.14 ( 68.92)
The current update step is 4710
GPU_0_using curriculum 40 with window 40
Epoch: [157][20/30]	Time  3.701 ( 3.721)	Data  0.045 ( 0.064)	InnerLoop  1.559 ( 1.561)	Loss 6.7861e-01 (7.3352e-01)	Acc@1  76.20 ( 73.64)
The current update step is 4740
GPU_0_using curriculum 40 with window 40
Epoch: [158][20/30]	Time  3.784 ( 3.714)	Data  0.173 ( 0.071)	InnerLoop  1.510 ( 1.551)	Loss 8.3039e-01 (7.8633e-01)	Acc@1  72.53 ( 72.00)
The current update step is 4770
GPU_0_using curriculum 40 with window 40
Epoch: [159][20/30]	Time  3.800 ( 3.730)	Data  0.049 ( 0.057)	InnerLoop  1.658 ( 1.579)	Loss 8.3866e-01 (8.4103e-01)	Acc@1  70.07 ( 70.34)
The current update step is 4800
The current seed is 5463630714418681197
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.237
 *   Acc@1 73.398
 *   Acc@1 73.276
 *   Acc@1 73.737
 *   Acc@1 73.474
 *   Acc@1 73.877
 *   Acc@1 72.526
 *   Acc@1 72.607
 *   Acc@1 72.829
 *   Acc@1 72.823
 *   Acc@1 74.026
 *   Acc@1 74.416
 *   Acc@1 74.921
 *   Acc@1 75.236
 *   Acc@1 75.645
 *   Acc@1 76.237
 *   Acc@1 69.079
 *   Acc@1 69.520
 *   Acc@1 68.934
 *   Acc@1 69.599
 *   Acc@1 69.303
 *   Acc@1 70.216
 *   Acc@1 67.526
 *   Acc@1 68.343
 *   Acc@1 68.750
 *   Acc@1 69.142
 *   Acc@1 65.474
 *   Acc@1 65.713
 *   Acc@1 63.592
 *   Acc@1 63.468
 *   Acc@1 62.658
 *   Acc@1 63.028
Training for 300 epoch: 70.97368421052632
Training for 600 epoch: 70.42763157894737
Training for 1000 epoch: 70.32236842105263
Training for 3000 epoch: 69.58881578947368
Training for 300 epoch: 71.22104166666666
Training for 600 epoch: 70.86645833333333
Training for 1000 epoch: 70.69916666666667
Training for 3000 epoch: 70.05354166666666
[[70.97368421052632, 70.42763157894737, 70.32236842105263, 69.58881578947368], [71.22104166666666, 70.86645833333333, 70.69916666666667, 70.05354166666666]]
train loss 0.22160199433962505, epoch 159, best loss 0.20086198711395264, best_epoch 124
GPU_0_using curriculum 40 with window 40
Epoch: [160][20/30]	Time  3.853 ( 3.758)	Data  0.048 ( 0.065)	InnerLoop  1.685 ( 1.584)	Loss 7.4027e-01 (9.7342e-01)	Acc@1  72.61 ( 69.01)
The current update step is 4830
GPU_0_using curriculum 40 with window 40
Epoch: [161][20/30]	Time  3.660 ( 3.773)	Data  0.047 ( 0.059)	InnerLoop  1.518 ( 1.591)	Loss 7.1357e-01 (9.6996e-01)	Acc@1  72.34 ( 67.07)
The current update step is 4860
GPU_0_using curriculum 40 with window 40
Epoch: [162][20/30]	Time  3.695 ( 3.723)	Data  0.045 ( 0.065)	InnerLoop  1.568 ( 1.566)	Loss 6.6938e-01 (8.7122e-01)	Acc@1  75.73 ( 69.48)
The current update step is 4890
GPU_0_using curriculum 40 with window 40
Epoch: [163][20/30]	Time  3.743 ( 3.730)	Data  0.045 ( 0.070)	InnerLoop  1.558 ( 1.567)	Loss 8.1708e-01 (8.3673e-01)	Acc@1  68.85 ( 70.87)
The current update step is 4920
GPU_0_using curriculum 40 with window 40
Epoch: [164][20/30]	Time  3.805 ( 3.724)	Data  0.174 ( 0.070)	InnerLoop  1.545 ( 1.550)	Loss 7.7870e-01 (8.2041e-01)	Acc@1  71.53 ( 70.98)
The current update step is 4950
The current seed is 9019046994524609548
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.618
 *   Acc@1 70.267
 *   Acc@1 66.961
 *   Acc@1 66.916
 *   Acc@1 63.566
 *   Acc@1 63.220
 *   Acc@1 61.539
 *   Acc@1 61.508
 *   Acc@1 70.434
 *   Acc@1 70.902
 *   Acc@1 65.605
 *   Acc@1 65.693
 *   Acc@1 62.053
 *   Acc@1 62.161
 *   Acc@1 55.461
 *   Acc@1 55.619
 *   Acc@1 71.382
 *   Acc@1 71.490
 *   Acc@1 70.132
 *   Acc@1 70.511
 *   Acc@1 69.303
 *   Acc@1 70.030
 *   Acc@1 68.408
 *   Acc@1 68.926
 *   Acc@1 57.855
 *   Acc@1 58.455
 *   Acc@1 56.316
 *   Acc@1 56.617
 *   Acc@1 56.750
 *   Acc@1 57.574
 *   Acc@1 58.632
 *   Acc@1 58.891
Training for 300 epoch: 67.32236842105263
Training for 600 epoch: 64.75328947368422
Training for 1000 epoch: 62.91776315789474
Training for 3000 epoch: 61.00986842105263
Training for 300 epoch: 67.77833333333334
Training for 600 epoch: 64.93416666666667
Training for 1000 epoch: 63.246249999999996
Training for 3000 epoch: 61.23583333333333
[[67.32236842105263, 64.75328947368422, 62.91776315789474, 61.00986842105263], [67.77833333333334, 64.93416666666667, 63.246249999999996, 61.23583333333333]]
train loss 0.30431778852144875, epoch 164, best loss 0.20086198711395264, best_epoch 124
GPU_0_using curriculum 40 with window 40
Epoch: [165][20/30]	Time  3.857 ( 3.756)	Data  0.048 ( 0.058)	InnerLoop  1.679 ( 1.591)	Loss 6.4060e-01 (8.0058e-01)	Acc@1  78.47 ( 71.48)
The current update step is 4980
GPU_0_using curriculum 40 with window 40
Epoch: [166][20/30]	Time  3.816 ( 3.735)	Data  0.047 ( 0.052)	InnerLoop  1.675 ( 1.588)	Loss 5.7604e-01 (8.1983e-01)	Acc@1  79.17 ( 72.06)
The current update step is 5010
GPU_0_using curriculum 40 with window 40
Epoch: [167][20/30]	Time  3.695 ( 3.722)	Data  0.048 ( 0.072)	InnerLoop  1.530 ( 1.553)	Loss 9.3522e-01 (8.2008e-01)	Acc@1  66.43 ( 71.24)
The current update step is 5040
GPU_0_using curriculum 40 with window 40
Epoch: [168][20/30]	Time  3.774 ( 3.754)	Data  0.046 ( 0.058)	InnerLoop  1.589 ( 1.590)	Loss 8.4760e-01 (9.1032e-01)	Acc@1  67.14 ( 66.79)
The current update step is 5070
GPU_0_using curriculum 40 with window 40
Epoch: [169][20/30]	Time  3.852 ( 3.767)	Data  0.044 ( 0.059)	InnerLoop  1.691 ( 1.597)	Loss 7.2460e-01 (8.0611e-01)	Acc@1  72.61 ( 70.66)
The current update step is 5100
The current seed is 2324768159681315898
The current lr is: 0.001
Testing Results:
 *   Acc@1 57.987
 *   Acc@1 58.419
 *   Acc@1 58.092
 *   Acc@1 58.322
 *   Acc@1 57.461
 *   Acc@1 57.700
 *   Acc@1 57.974
 *   Acc@1 58.494
 *   Acc@1 74.908
 *   Acc@1 75.107
 *   Acc@1 73.855
 *   Acc@1 74.585
 *   Acc@1 72.092
 *   Acc@1 73.099
 *   Acc@1 72.447
 *   Acc@1 72.737
 *   Acc@1 70.526
 *   Acc@1 70.447
 *   Acc@1 64.526
 *   Acc@1 64.386
 *   Acc@1 61.461
 *   Acc@1 61.632
 *   Acc@1 59.276
 *   Acc@1 59.366
 *   Acc@1 75.618
 *   Acc@1 76.186
 *   Acc@1 75.263
 *   Acc@1 76.080
 *   Acc@1 74.000
 *   Acc@1 74.869
 *   Acc@1 71.592
 *   Acc@1 72.089
Training for 300 epoch: 69.75986842105263
Training for 600 epoch: 67.93421052631578
Training for 1000 epoch: 66.25328947368422
Training for 3000 epoch: 65.32236842105263
Training for 300 epoch: 70.03958333333334
Training for 600 epoch: 68.34333333333333
Training for 1000 epoch: 66.825
Training for 3000 epoch: 65.67145833333333
[[69.75986842105263, 67.93421052631578, 66.25328947368422, 65.32236842105263], [70.03958333333334, 68.34333333333333, 66.825, 65.67145833333333]]
train loss 0.2036345539410909, epoch 169, best loss 0.20086198711395264, best_epoch 124
GPU_0_using curriculum 40 with window 40
Epoch: [170][20/30]	Time  3.697 ( 3.731)	Data  0.047 ( 0.051)	InnerLoop  1.526 ( 1.576)	Loss 6.3609e-01 (8.1238e-01)	Acc@1  77.47 ( 72.26)
The current update step is 5130
GPU_0_using curriculum 40 with window 40
Epoch: [171][20/30]	Time  3.713 ( 3.732)	Data  0.043 ( 0.053)	InnerLoop  1.504 ( 1.574)	Loss 7.8821e-01 (9.8913e-01)	Acc@1  72.22 ( 66.87)
The current update step is 5160
GPU_0_using curriculum 40 with window 40
Epoch: [172][20/30]	Time  3.753 ( 3.744)	Data  0.051 ( 0.065)	InnerLoop  1.552 ( 1.576)	Loss 6.5004e-01 (8.7705e-01)	Acc@1  76.15 ( 69.93)
The current update step is 5190
GPU_0_using curriculum 40 with window 40
Epoch: [173][20/30]	Time  3.801 ( 3.717)	Data  0.175 ( 0.072)	InnerLoop  1.526 ( 1.558)	Loss 7.8190e-01 (8.4997e-01)	Acc@1  73.88 ( 69.74)
The current update step is 5220
GPU_0_using curriculum 40 with window 40
Epoch: [174][20/30]	Time  3.899 ( 3.736)	Data  0.045 ( 0.057)	InnerLoop  1.726 ( 1.581)	Loss 8.0453e-01 (8.7375e-01)	Acc@1  73.05 ( 69.45)
The current update step is 5250
The current seed is 16151523606949793847
The current lr is: 0.001
Testing Results:
 *   Acc@1 68.289
 *   Acc@1 68.247
 *   Acc@1 68.434
 *   Acc@1 68.261
 *   Acc@1 67.579
 *   Acc@1 67.462
 *   Acc@1 62.789
 *   Acc@1 63.182
 *   Acc@1 63.224
 *   Acc@1 64.147
 *   Acc@1 62.539
 *   Acc@1 63.308
 *   Acc@1 63.066
 *   Acc@1 63.616
 *   Acc@1 59.658
 *   Acc@1 60.352
 *   Acc@1 65.855
 *   Acc@1 66.242
 *   Acc@1 65.934
 *   Acc@1 65.815
 *   Acc@1 64.447
 *   Acc@1 65.063
 *   Acc@1 65.447
 *   Acc@1 65.576
 *   Acc@1 67.158
 *   Acc@1 67.827
 *   Acc@1 64.513
 *   Acc@1 64.888
 *   Acc@1 64.408
 *   Acc@1 64.960
 *   Acc@1 64.171
 *   Acc@1 65.180
Training for 300 epoch: 66.13157894736841
Training for 600 epoch: 65.35526315789474
Training for 1000 epoch: 64.875
Training for 3000 epoch: 63.016447368421055
Training for 300 epoch: 66.61541666666666
Training for 600 epoch: 65.56791666666666
Training for 1000 epoch: 65.27520833333334
Training for 3000 epoch: 63.57229166666667
[[66.13157894736841, 65.35526315789474, 64.875, 63.016447368421055], [66.61541666666666, 65.56791666666666, 65.27520833333334, 63.57229166666667]]
train loss 0.24626650520960489, epoch 174, best loss 0.20086198711395264, best_epoch 124
GPU_0_using curriculum 40 with window 40
Epoch: [175][20/30]	Time  3.793 ( 3.723)	Data  0.049 ( 0.065)	InnerLoop  1.639 ( 1.566)	Loss 9.0708e-01 (8.8515e-01)	Acc@1  68.53 ( 69.43)
The current update step is 5280
GPU_0_using curriculum 40 with window 40
Epoch: [176][20/30]	Time  3.657 ( 3.730)	Data  0.042 ( 0.056)	InnerLoop  1.519 ( 1.580)	Loss 6.2523e-01 (8.4949e-01)	Acc@1  77.61 ( 70.75)
The current update step is 5310
GPU_0_using curriculum 40 with window 40
Epoch: [177][20/30]	Time  3.676 ( 3.733)	Data  0.043 ( 0.066)	InnerLoop  1.523 ( 1.571)	Loss 1.1193e+00 (8.0910e-01)	Acc@1  57.20 ( 70.32)
The current update step is 5340
GPU_0_using curriculum 40 with window 40
Epoch: [178][20/30]	Time  3.671 ( 3.729)	Data  0.046 ( 0.072)	InnerLoop  1.519 ( 1.561)	Loss 8.3040e-01 (8.2194e-01)	Acc@1  68.97 ( 71.44)
The current update step is 5370
GPU_0_using curriculum 40 with window 40
Epoch: [179][20/30]	Time  3.770 ( 3.713)	Data  0.170 ( 0.070)	InnerLoop  1.504 ( 1.550)	Loss 7.8704e-01 (9.0052e-01)	Acc@1  72.78 ( 69.50)
The current update step is 5400
The current seed is 18255976447325838388
The current lr is: 0.001
Testing Results:
 *   Acc@1 72.026
 *   Acc@1 72.325
 *   Acc@1 67.237
 *   Acc@1 68.347
 *   Acc@1 65.553
 *   Acc@1 65.713
 *   Acc@1 59.908
 *   Acc@1 60.453
 *   Acc@1 65.816
 *   Acc@1 65.626
 *   Acc@1 66.553
 *   Acc@1 66.571
 *   Acc@1 66.132
 *   Acc@1 66.206
 *   Acc@1 65.329
 *   Acc@1 65.385
 *   Acc@1 68.711
 *   Acc@1 69.002
 *   Acc@1 68.908
 *   Acc@1 69.110
 *   Acc@1 69.171
 *   Acc@1 69.164
 *   Acc@1 68.803
 *   Acc@1 69.043
 *   Acc@1 62.171
 *   Acc@1 62.635
 *   Acc@1 61.145
 *   Acc@1 61.782
 *   Acc@1 64.132
 *   Acc@1 64.365
 *   Acc@1 66.500
 *   Acc@1 67.071
Training for 300 epoch: 67.18092105263158
Training for 600 epoch: 65.96052631578948
Training for 1000 epoch: 66.2467105263158
Training for 3000 epoch: 65.13486842105263
Training for 300 epoch: 67.396875
Training for 600 epoch: 66.45229166666667
Training for 1000 epoch: 66.36208333333335
Training for 3000 epoch: 65.48770833333333
[[67.18092105263158, 65.96052631578948, 66.2467105263158, 65.13486842105263], [67.396875, 66.45229166666667, 66.36208333333335, 65.48770833333333]]
train loss 0.2858243493715922, epoch 179, best loss 0.20086198711395264, best_epoch 124
GPU_0_using curriculum 40 with window 40
Epoch: [180][20/30]	Time  3.858 ( 3.727)	Data  0.046 ( 0.057)	InnerLoop  1.689 ( 1.577)	Loss 7.1120e-01 (8.1972e-01)	Acc@1  74.49 ( 71.51)
The current update step is 5430
GPU_0_using curriculum 40 with window 40
Epoch: [181][20/30]	Time  3.823 ( 3.785)	Data  0.045 ( 0.053)	InnerLoop  1.662 ( 1.611)	Loss 9.2103e-01 (8.7578e-01)	Acc@1  62.57 ( 70.33)
The current update step is 5460
GPU_0_using curriculum 40 with window 40
Epoch: [182][20/30]	Time  3.770 ( 3.779)	Data  0.059 ( 0.073)	InnerLoop  1.596 ( 1.592)	Loss 7.1480e-01 (8.7779e-01)	Acc@1  73.51 ( 69.66)
The current update step is 5490
GPU_0_using curriculum 40 with window 40
Epoch: [183][20/30]	Time  3.703 ( 3.735)	Data  0.043 ( 0.059)	InnerLoop  1.535 ( 1.578)	Loss 9.9032e-01 (8.3088e-01)	Acc@1  69.65 ( 71.33)
The current update step is 5520
GPU_0_using curriculum 40 with window 40
Epoch: [184][20/30]	Time  3.746 ( 3.700)	Data  0.044 ( 0.057)	InnerLoop  1.611 ( 1.557)	Loss 6.9320e-01 (7.6183e-01)	Acc@1  76.17 ( 72.99)
The current update step is 5550
The current seed is 3264790423732451019
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.039
 *   Acc@1 73.252
 *   Acc@1 72.947
 *   Acc@1 72.942
 *   Acc@1 70.763
 *   Acc@1 70.767
 *   Acc@1 69.961
 *   Acc@1 69.731
 *   Acc@1 77.329
 *   Acc@1 77.796
 *   Acc@1 76.987
 *   Acc@1 78.037
 *   Acc@1 77.421
 *   Acc@1 77.728
 *   Acc@1 75.711
 *   Acc@1 76.422
 *   Acc@1 41.487
 *   Acc@1 41.483
 *   Acc@1 39.737
 *   Acc@1 39.687
 *   Acc@1 39.592
 *   Acc@1 39.699
 *   Acc@1 41.789
 *   Acc@1 42.342
 *   Acc@1 69.684
 *   Acc@1 69.383
 *   Acc@1 67.145
 *   Acc@1 67.215
 *   Acc@1 66.421
 *   Acc@1 66.660
 *   Acc@1 64.237
 *   Acc@1 64.706
Training for 300 epoch: 65.38486842105263
Training for 600 epoch: 64.20394736842104
Training for 1000 epoch: 63.54934210526315
Training for 3000 epoch: 62.924342105263165
Training for 300 epoch: 65.47875
Training for 600 epoch: 64.47041666666667
Training for 1000 epoch: 63.713541666666664
Training for 3000 epoch: 63.30020833333333
[[65.38486842105263, 64.20394736842104, 63.54934210526315, 62.924342105263165], [65.47875, 64.47041666666667, 63.713541666666664, 63.30020833333333]]
train loss 0.28004908595085143, epoch 184, best loss 0.20086198711395264, best_epoch 184
GPU_0_using curriculum 40 with window 40
Epoch: [185][20/30]	Time  3.590 ( 3.651)	Data  0.045 ( 0.048)	InnerLoop  1.481 ( 1.530)	Loss 6.6677e-01 (8.3845e-01)	Acc@1  76.15 ( 71.83)
The current update step is 5580
GPU_0_using curriculum 40 with window 40
Epoch: [186][20/30]	Time  3.624 ( 3.657)	Data  0.040 ( 0.050)	InnerLoop  1.478 ( 1.533)	Loss 6.4944e-01 (8.3814e-01)	Acc@1  76.39 ( 70.54)
The current update step is 5610
GPU_0_using curriculum 40 with window 40
Epoch: [187][20/30]	Time  3.616 ( 3.663)	Data  0.046 ( 0.062)	InnerLoop  1.477 ( 1.524)	Loss 1.0313e+00 (9.7537e-01)	Acc@1  68.29 ( 67.13)
The current update step is 5640
GPU_0_using curriculum 40 with window 40
Epoch: [188][20/30]	Time  3.736 ( 3.648)	Data  0.167 ( 0.067)	InnerLoop  1.488 ( 1.511)	Loss 6.3901e-01 (8.1571e-01)	Acc@1  77.37 ( 71.81)
The current update step is 5670
GPU_0_using curriculum 40 with window 40
Epoch: [189][20/30]	Time  3.729 ( 3.664)	Data  0.046 ( 0.055)	InnerLoop  1.603 ( 1.530)	Loss 6.3862e-01 (7.8699e-01)	Acc@1  77.44 ( 72.34)
The current update step is 5700
The current seed is 14476329875883253849
The current lr is: 0.001
Testing Results:
 *   Acc@1 63.289
 *   Acc@1 63.583
 *   Acc@1 60.500
 *   Acc@1 61.042
 *   Acc@1 59.474
 *   Acc@1 60.147
 *   Acc@1 59.276
 *   Acc@1 59.748
 *   Acc@1 74.816
 *   Acc@1 75.446
 *   Acc@1 75.461
 *   Acc@1 75.220
 *   Acc@1 75.132
 *   Acc@1 75.366
 *   Acc@1 75.461
 *   Acc@1 75.038
 *   Acc@1 77.908
 *   Acc@1 78.999
 *   Acc@1 77.461
 *   Acc@1 78.364
 *   Acc@1 76.592
 *   Acc@1 77.315
 *   Acc@1 76.039
 *   Acc@1 76.279
 *   Acc@1 72.145
 *   Acc@1 72.419
 *   Acc@1 70.474
 *   Acc@1 70.618
 *   Acc@1 69.132
 *   Acc@1 69.485
 *   Acc@1 68.829
 *   Acc@1 69.304
Training for 300 epoch: 72.03947368421052
Training for 600 epoch: 70.97368421052632
Training for 1000 epoch: 70.08223684210526
Training for 3000 epoch: 69.90131578947368
Training for 300 epoch: 72.61166666666666
Training for 600 epoch: 71.31083333333333
Training for 1000 epoch: 70.578125
Training for 3000 epoch: 70.0925
[[72.03947368421052, 70.97368421052632, 70.08223684210526, 69.90131578947368], [72.61166666666666, 71.31083333333333, 70.578125, 70.0925]]
train loss 0.24818598011334736, epoch 189, best loss 0.20086198711395264, best_epoch 184
GPU_0_using curriculum 40 with window 40
Epoch: [190][20/30]	Time  3.774 ( 3.691)	Data  0.041 ( 0.064)	InnerLoop  1.622 ( 1.540)	Loss 9.0025e-01 (8.0808e-01)	Acc@1  69.78 ( 72.11)
The current update step is 5730
GPU_0_using curriculum 40 with window 40
Epoch: [191][20/30]	Time  3.647 ( 3.676)	Data  0.048 ( 0.055)	InnerLoop  1.495 ( 1.530)	Loss 8.6760e-01 (8.2373e-01)	Acc@1  71.00 ( 71.18)
The current update step is 5760
GPU_0_using curriculum 40 with window 40
Epoch: [192][20/30]	Time  3.641 ( 3.663)	Data  0.039 ( 0.062)	InnerLoop  1.486 ( 1.525)	Loss 7.3860e-01 (7.6181e-01)	Acc@1  73.44 ( 73.36)
The current update step is 5790
GPU_0_using curriculum 40 with window 40
Epoch: [193][20/30]	Time  3.720 ( 3.699)	Data  0.045 ( 0.069)	InnerLoop  1.540 ( 1.539)	Loss 7.4503e-01 (8.0716e-01)	Acc@1  72.85 ( 72.67)
The current update step is 5820
GPU_0_using curriculum 40 with window 40
Epoch: [194][20/30]	Time  3.794 ( 3.698)	Data  0.171 ( 0.070)	InnerLoop  1.534 ( 1.539)	Loss 9.6031e-01 (7.9408e-01)	Acc@1  69.04 ( 72.58)
The current update step is 5850
The current seed is 4377902825479051386
The current lr is: 0.001
Testing Results:
 *   Acc@1 65.711
 *   Acc@1 65.782
 *   Acc@1 60.513
 *   Acc@1 60.702
 *   Acc@1 58.145
 *   Acc@1 58.671
 *   Acc@1 55.487
 *   Acc@1 55.811
 *   Acc@1 76.474
 *   Acc@1 77.276
 *   Acc@1 75.355
 *   Acc@1 75.975
 *   Acc@1 74.000
 *   Acc@1 74.661
 *   Acc@1 71.184
 *   Acc@1 72.099
 *   Acc@1 54.092
 *   Acc@1 54.195
 *   Acc@1 53.132
 *   Acc@1 53.200
 *   Acc@1 51.645
 *   Acc@1 52.176
 *   Acc@1 48.605
 *   Acc@1 48.763
 *   Acc@1 70.921
 *   Acc@1 71.459
 *   Acc@1 65.803
 *   Acc@1 66.754
 *   Acc@1 63.579
 *   Acc@1 64.377
 *   Acc@1 62.487
 *   Acc@1 63.244
Training for 300 epoch: 66.79934210526315
Training for 600 epoch: 63.70065789473684
Training for 1000 epoch: 61.84210526315789
Training for 3000 epoch: 59.44078947368421
Training for 300 epoch: 67.17791666666666
Training for 600 epoch: 64.15770833333333
Training for 1000 epoch: 62.47125
Training for 3000 epoch: 59.97916666666667
[[66.79934210526315, 63.70065789473684, 61.84210526315789, 59.44078947368421], [67.17791666666666, 64.15770833333333, 62.47125, 59.97916666666667]]
train loss 0.2651830500602722, epoch 194, best loss 0.20086198711395264, best_epoch 184
GPU_0_using curriculum 40 with window 40
Epoch: [195][20/30]	Time  3.771 ( 3.668)	Data  0.042 ( 0.053)	InnerLoop  1.627 ( 1.535)	Loss 8.5529e-01 (7.7281e-01)	Acc@1  68.09 ( 72.80)
The current update step is 5880
GPU_0_using curriculum 40 with window 40
Epoch: [196][20/30]	Time  3.774 ( 3.716)	Data  0.045 ( 0.052)	InnerLoop  1.627 ( 1.569)	Loss 6.3648e-01 (8.1776e-01)	Acc@1  78.12 ( 71.65)
The current update step is 5910
GPU_0_using curriculum 40 with window 40
Epoch: [197][20/30]	Time  3.678 ( 3.712)	Data  0.051 ( 0.070)	InnerLoop  1.543 ( 1.550)	Loss 9.6546e-01 (8.6588e-01)	Acc@1  67.48 ( 69.78)
The current update step is 5940
GPU_0_using curriculum 40 with window 40
Epoch: [198][20/30]	Time  3.641 ( 3.672)	Data  0.040 ( 0.057)	InnerLoop  1.504 ( 1.537)	Loss 8.1895e-01 (7.8340e-01)	Acc@1  69.38 ( 72.11)
The current update step is 5970
GPU_0_using curriculum 40 with window 40
Epoch: [199][20/30]	Time  3.714 ( 3.670)	Data  0.040 ( 0.054)	InnerLoop  1.593 ( 1.534)	Loss 6.4200e-01 (7.8843e-01)	Acc@1  77.17 ( 72.01)
The current update step is 6000
The current seed is 16867394974806831203
The current lr is: 0.001
Testing Results:
 *   Acc@1 67.776
 *   Acc@1 68.163
 *   Acc@1 63.592
 *   Acc@1 63.247
 *   Acc@1 58.434
 *   Acc@1 58.493
 *   Acc@1 56.263
 *   Acc@1 56.398
 *   Acc@1 69.053
 *   Acc@1 69.562
 *   Acc@1 65.921
 *   Acc@1 66.392
 *   Acc@1 61.803
 *   Acc@1 62.318
 *   Acc@1 56.355
 *   Acc@1 56.942
 *   Acc@1 65.526
 *   Acc@1 65.990
 *   Acc@1 63.013
 *   Acc@1 63.187
 *   Acc@1 62.618
 *   Acc@1 62.491
 *   Acc@1 63.382
 *   Acc@1 63.502
 *   Acc@1 68.697
 *   Acc@1 68.799
 *   Acc@1 66.276
 *   Acc@1 66.454
 *   Acc@1 68.434
 *   Acc@1 68.429
 *   Acc@1 70.263
 *   Acc@1 70.240
Training for 300 epoch: 67.76315789473685
Training for 600 epoch: 64.70065789473685
Training for 1000 epoch: 62.82236842105263
Training for 3000 epoch: 61.565789473684205
Training for 300 epoch: 68.12854166666666
Training for 600 epoch: 64.82
Training for 1000 epoch: 62.93291666666667
Training for 3000 epoch: 61.770624999999995
[[67.76315789473685, 64.70065789473685, 62.82236842105263, 61.565789473684205], [68.12854166666666, 64.82, 62.93291666666667, 61.770624999999995]]
train loss 0.2145790593703588, epoch 199, best loss 0.20086198711395264, best_epoch 184
=== Final results:
{'acc': 72.03947368421052, 'test': [72.03947368421052, 70.97368421052632, 70.08223684210526, 69.90131578947368], 'train': [72.03947368421052, 70.97368421052632, 70.08223684210526, 69.90131578947368], 'ind': 0, 'epoch': 190, 'data': array([[-0.01746116, -0.13961889, -0.0450091 , ...,  0.03297778,
         0.03703544, -0.0740938 ],
       [-0.00171994, -0.11562585,  0.10911109, ...,  0.00477356,
        -0.06632973,  0.08445217],
       [ 0.06534911,  0.0168813 , -0.03668746, ...,  0.00151617,
         0.01541934, -0.12133787],
       [ 0.07701232,  0.08199033,  0.00986964, ..., -0.0830039 ,
        -0.03046151, -0.09816872]], shape=(4, 768), dtype=float32)}
