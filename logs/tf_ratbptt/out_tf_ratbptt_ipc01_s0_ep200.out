Torch Seed Specified with rank: 0
Dataset: agnews_emb
Dataset Path: ./scripts
Namespace(seed=0, mp_distributed=False, world_size=1, rank=0, dist_url='tcp://224.66.41.62:23456', dist_backend='nccl', workers=0, gpu=None, root='./scripts', dataset='agnews_emb', arch='text_transformer', width=256, lr=0.001, inner_optim='Adam', outer_optim='Adam', inner_lr=0.001, label_lr_scale=1, num_per_class=1, batch_per_class=1, task_sampler_nc=4, window=20, minwindow=0, totwindow=40, num_train_eval=2, train_y=False, batch_size=2048, eps=1e-08, wd=0, test_freq=5, print_freq=20, start_epoch=0, epochs=200, ddtype='standard', cctype=0, zca=False, wandb=False, clip_coef=0.9, fname='out_tf_ratbptt_ipc01_s0_ep200', out_dir='./checkpoints', name='agnews_tf_ratbptt_s0_ep200', comp_aug=False, comp_aug_real=False, syn_strategy='none', real_strategy='none', ckptname='none', limit_train=False, load_ckpt=False, complete_random=False, boost_dd=False, boost_init_from='none', boost_beta=1.0, stage=0, distributed=False, data_root='./scripts/agnews_emb')
==> Preparing data..
None None
Dataset: number of classes: 4
Training set size: 120000
Image size: channel 1, height 768, width 1
Synthetic images, not_single False, keys []
==> Building model..
Initialized data with size, x: torch.Size([4, 768]), y:torch.Size([4])
TextTransformer(
  (input_proj): Linear(in_features=192, out_features=256, bias=True)
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=1024, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=1024, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (cls_head): Linear(in_features=256, out_features=4, bias=True)
)
use data parallel only
GPU_0_using curriculum 20 with window 20
Epoch: [0][20/59]	Time  1.522 ( 1.617)	Data  0.018 ( 0.028)	InnerLoop  0.636 ( 0.699)	Loss 5.7042e+00 (5.1295e+00)	Acc@1  24.85 ( 27.24)
Epoch: [0][40/59]	Time  1.519 ( 1.581)	Data  0.020 ( 0.027)	InnerLoop  0.630 ( 0.673)	Loss 2.0231e+00 (4.1697e+00)	Acc@1  42.92 ( 31.74)
The current update step is 59
GPU_0_using curriculum 20 with window 20
Epoch: [1][20/59]	Time  1.519 ( 1.531)	Data  0.020 ( 0.025)	InnerLoop  0.630 ( 0.642)	Loss 1.6238e+00 (1.5786e+00)	Acc@1  50.39 ( 51.14)
Epoch: [1][40/59]	Time  1.523 ( 1.534)	Data  0.021 ( 0.026)	InnerLoop  0.633 ( 0.643)	Loss 1.6279e+00 (1.6760e+00)	Acc@1  51.17 ( 48.72)
The current update step is 118
GPU_0_using curriculum 20 with window 20
Epoch: [2][20/59]	Time  1.502 ( 1.513)	Data  0.019 ( 0.019)	InnerLoop  0.621 ( 0.638)	Loss 1.9121e+00 (1.4986e+00)	Acc@1  41.02 ( 51.31)
Epoch: [2][40/59]	Time  1.504 ( 1.516)	Data  0.020 ( 0.023)	InnerLoop  0.621 ( 0.635)	Loss 9.0038e-01 (1.4018e+00)	Acc@1  64.75 ( 52.60)
The current update step is 177
GPU_0_using curriculum 20 with window 20
Epoch: [3][20/59]	Time  1.605 ( 1.515)	Data  0.020 ( 0.031)	InnerLoop  0.730 ( 0.629)	Loss 1.2839e+00 (1.3472e+00)	Acc@1  51.32 ( 53.88)
Epoch: [3][40/59]	Time  1.497 ( 1.515)	Data  0.021 ( 0.028)	InnerLoop  0.617 ( 0.630)	Loss 1.5302e+00 (1.2541e+00)	Acc@1  46.34 ( 55.81)
The current update step is 236
GPU_0_using curriculum 20 with window 20
Epoch: [4][20/59]	Time  1.586 ( 1.510)	Data  0.132 ( 0.031)	InnerLoop  0.606 ( 0.628)	Loss 1.1165e+00 (1.2239e+00)	Acc@1  61.52 ( 58.24)
Epoch: [4][40/59]	Time  1.454 ( 1.491)	Data  0.017 ( 0.025)	InnerLoop  0.609 ( 0.625)	Loss 1.4105e+00 (1.2371e+00)	Acc@1  48.97 ( 58.27)
The current update step is 295
The current seed is 17231033660605739069
The current lr is: 0.001
Testing Results:
 *   Acc@1 61.158
 *   Acc@1 61.306
 *   Acc@1 62.118
 *   Acc@1 62.175
 *   Acc@1 61.961
 *   Acc@1 62.161
 *   Acc@1 53.105
 *   Acc@1 53.705
 *   Acc@1 54.724
 *   Acc@1 54.946
 *   Acc@1 55.105
 *   Acc@1 55.651
Training for 300 epoch: 57.131578947368425
Training for 600 epoch: 58.421052631578945
Training for 1000 epoch: 58.53289473684211
Training for 300 epoch: 57.50541666666666
Training for 600 epoch: 58.56041666666667
Training for 1000 epoch: 58.905833333333334
[[57.131578947368425, 58.421052631578945, 58.53289473684211], [57.50541666666666, 58.56041666666667, 58.905833333333334]]
train loss 0.6439987244288127, epoch 4, best loss 0.6439987244288127, best_epoch 4
GPU_0_using curriculum 20 with window 20
Epoch: [5][20/59]	Time  1.436 ( 1.456)	Data  0.019 ( 0.024)	InnerLoop  0.596 ( 0.615)	Loss 1.2370e+00 (1.3941e+00)	Acc@1  61.04 ( 56.67)
Epoch: [5][40/59]	Time  1.420 ( 1.451)	Data  0.018 ( 0.021)	InnerLoop  0.593 ( 0.613)	Loss 1.1292e+00 (1.3223e+00)	Acc@1  56.54 ( 58.68)
The current update step is 354
GPU_0_using curriculum 20 with window 20
Epoch: [6][20/59]	Time  1.425 ( 1.442)	Data  0.019 ( 0.019)	InnerLoop  0.593 ( 0.612)	Loss 9.9119e-01 (1.3252e+00)	Acc@1  57.96 ( 56.47)
Epoch: [6][40/59]	Time  1.412 ( 1.438)	Data  0.020 ( 0.024)	InnerLoop  0.590 ( 0.607)	Loss 9.9451e-01 (1.2640e+00)	Acc@1  63.53 ( 57.84)
The current update step is 413
GPU_0_using curriculum 20 with window 20
Epoch: [7][20/59]	Time  1.417 ( 1.427)	Data  0.019 ( 0.030)	InnerLoop  0.593 ( 0.596)	Loss 1.1181e+00 (9.9074e-01)	Acc@1  56.93 ( 63.82)
Epoch: [7][40/59]	Time  1.413 ( 1.430)	Data  0.017 ( 0.027)	InnerLoop  0.593 ( 0.601)	Loss 1.0092e+00 (1.0715e+00)	Acc@1  66.36 ( 61.97)
The current update step is 472
GPU_0_using curriculum 20 with window 20
Epoch: [8][20/59]	Time  1.415 ( 1.425)	Data  0.019 ( 0.030)	InnerLoop  0.595 ( 0.596)	Loss 1.0437e+00 (1.0296e+00)	Acc@1  65.14 ( 62.33)
Epoch: [8][40/59]	Time  1.414 ( 1.429)	Data  0.018 ( 0.024)	InnerLoop  0.592 ( 0.604)	Loss 8.2127e-01 (1.0889e+00)	Acc@1  71.09 ( 60.76)
The current update step is 531
GPU_0_using curriculum 20 with window 20
Epoch: [9][20/59]	Time  1.409 ( 1.424)	Data  0.018 ( 0.030)	InnerLoop  0.592 ( 0.595)	Loss 7.8345e-01 (1.0596e+00)	Acc@1  70.56 ( 59.94)
Epoch: [9][40/59]	Time  1.522 ( 1.428)	Data  0.019 ( 0.024)	InnerLoop  0.698 ( 0.603)	Loss 1.5776e+00 (1.1328e+00)	Acc@1  54.74 ( 58.92)
The current update step is 590
The current seed is 14048602768993908172
The current lr is: 0.001
Testing Results:
 *   Acc@1 44.329
 *   Acc@1 44.679
 *   Acc@1 38.789
 *   Acc@1 38.799
 *   Acc@1 36.421
 *   Acc@1 36.619
 *   Acc@1 70.158
 *   Acc@1 70.125
 *   Acc@1 66.408
 *   Acc@1 65.795
 *   Acc@1 63.921
 *   Acc@1 63.298
Training for 300 epoch: 57.24342105263158
Training for 600 epoch: 52.598684210526315
Training for 1000 epoch: 50.171052631578945
Training for 300 epoch: 57.40208333333334
Training for 600 epoch: 52.29708333333333
Training for 1000 epoch: 49.958749999999995
[[57.24342105263158, 52.598684210526315, 50.171052631578945], [57.40208333333334, 52.29708333333333, 49.958749999999995]]
train loss 0.5842412700653076, epoch 9, best loss 0.5842412700653076, best_epoch 9
GPU_0_using curriculum 20 with window 20
Epoch: [10][20/59]	Time  1.530 ( 1.433)	Data  0.016 ( 0.023)	InnerLoop  0.707 ( 0.609)	Loss 1.5908e+00 (1.2317e+00)	Acc@1  50.59 ( 60.71)
Epoch: [10][40/59]	Time  1.426 ( 1.432)	Data  0.017 ( 0.021)	InnerLoop  0.591 ( 0.608)	Loss 1.3214e+00 (1.2121e+00)	Acc@1  54.64 ( 59.33)
The current update step is 649
GPU_0_using curriculum 20 with window 20
Epoch: [11][20/59]	Time  1.404 ( 1.424)	Data  0.018 ( 0.029)	InnerLoop  0.583 ( 0.594)	Loss 7.9137e-01 (1.2087e+00)	Acc@1  72.66 ( 62.62)
Epoch: [11][40/59]	Time  1.514 ( 1.427)	Data  0.018 ( 0.026)	InnerLoop  0.694 ( 0.599)	Loss 1.4769e+00 (1.1318e+00)	Acc@1  54.49 ( 63.34)
The current update step is 708
GPU_0_using curriculum 20 with window 20
Epoch: [12][20/59]	Time  1.408 ( 1.422)	Data  0.018 ( 0.024)	InnerLoop  0.587 ( 0.598)	Loss 8.0185e-01 (9.7767e-01)	Acc@1  73.10 ( 66.36)
Epoch: [12][40/59]	Time  1.403 ( 1.424)	Data  0.017 ( 0.024)	InnerLoop  0.587 ( 0.601)	Loss 1.4745e+00 (1.0241e+00)	Acc@1  51.86 ( 64.64)
The current update step is 767
GPU_0_using curriculum 20 with window 20
Epoch: [13][20/59]	Time  1.413 ( 1.423)	Data  0.018 ( 0.029)	InnerLoop  0.591 ( 0.594)	Loss 8.3658e-01 (1.1876e+00)	Acc@1  72.36 ( 60.24)
Epoch: [13][40/59]	Time  1.402 ( 1.423)	Data  0.018 ( 0.027)	InnerLoop  0.585 ( 0.596)	Loss 1.3386e+00 (1.0687e+00)	Acc@1  52.39 ( 62.55)
The current update step is 826
GPU_0_using curriculum 20 with window 20
Epoch: [14][20/59]	Time  1.402 ( 1.422)	Data  0.018 ( 0.029)	InnerLoop  0.586 ( 0.594)	Loss 1.0643e+00 (1.0036e+00)	Acc@1  59.81 ( 65.01)
Epoch: [14][40/59]	Time  1.407 ( 1.421)	Data  0.017 ( 0.026)	InnerLoop  0.590 ( 0.596)	Loss 1.0711e+00 (1.0166e+00)	Acc@1  67.24 ( 64.84)
The current update step is 885
The current seed is 11139668309513539107
The current lr is: 0.001
Testing Results:
 *   Acc@1 65.684
 *   Acc@1 65.862
 *   Acc@1 66.263
 *   Acc@1 66.481
 *   Acc@1 64.355
 *   Acc@1 64.622
 *   Acc@1 69.039
 *   Acc@1 69.529
 *   Acc@1 67.961
 *   Acc@1 68.758
 *   Acc@1 65.355
 *   Acc@1 65.597
Training for 300 epoch: 67.36184210526315
Training for 600 epoch: 67.11184210526315
Training for 1000 epoch: 64.85526315789474
Training for 300 epoch: 67.69541666666666
Training for 600 epoch: 67.61958333333334
Training for 1000 epoch: 65.10916666666667
[[67.36184210526315, 67.11184210526315, 64.85526315789474], [67.69541666666666, 67.61958333333334, 65.10916666666667]]
train loss 0.504165983136495, epoch 14, best loss 0.504165983136495, best_epoch 14
GPU_0_using curriculum 20 with window 20
Epoch: [15][20/59]	Time  1.411 ( 1.421)	Data  0.018 ( 0.018)	InnerLoop  0.589 ( 0.603)	Loss 8.6859e-01 (1.0173e+00)	Acc@1  67.19 ( 65.00)
Epoch: [15][40/59]	Time  1.512 ( 1.425)	Data  0.131 ( 0.023)	InnerLoop  0.582 ( 0.601)	Loss 7.0455e-01 (9.7238e-01)	Acc@1  73.34 ( 65.74)
The current update step is 944
GPU_0_using curriculum 20 with window 20
Epoch: [16][20/59]	Time  1.406 ( 1.424)	Data  0.018 ( 0.029)	InnerLoop  0.587 ( 0.593)	Loss 1.4517e+00 (1.1913e+00)	Acc@1  60.64 ( 63.17)
Epoch: [16][40/59]	Time  1.413 ( 1.427)	Data  0.017 ( 0.026)	InnerLoop  0.593 ( 0.600)	Loss 1.6256e+00 (1.0895e+00)	Acc@1  64.70 ( 64.88)
The current update step is 1003
GPU_0_using curriculum 20 with window 20
Epoch: [17][20/59]	Time  1.410 ( 1.421)	Data  0.017 ( 0.029)	InnerLoop  0.591 ( 0.593)	Loss 9.5859e-01 (8.9087e-01)	Acc@1  68.31 ( 68.02)
Epoch: [17][40/59]	Time  1.515 ( 1.426)	Data  0.018 ( 0.023)	InnerLoop  0.697 ( 0.602)	Loss 7.4594e-01 (8.6702e-01)	Acc@1  71.24 ( 68.74)
The current update step is 1062
GPU_0_using curriculum 20 with window 20
Epoch: [18][20/59]	Time  1.407 ( 1.422)	Data  0.018 ( 0.023)	InnerLoop  0.586 ( 0.599)	Loss 1.2006e+00 (9.0645e-01)	Acc@1  62.99 ( 66.71)
Epoch: [18][40/59]	Time  1.515 ( 1.425)	Data  0.018 ( 0.021)	InnerLoop  0.696 ( 0.604)	Loss 1.2861e+00 (9.3402e-01)	Acc@1  52.10 ( 66.49)
The current update step is 1121
GPU_0_using curriculum 20 with window 20
Epoch: [19][20/59]	Time  1.403 ( 1.423)	Data  0.018 ( 0.023)	InnerLoop  0.586 ( 0.600)	Loss 9.8514e-01 (1.0008e+00)	Acc@1  64.21 ( 66.17)
Epoch: [19][40/59]	Time  1.527 ( 1.426)	Data  0.017 ( 0.021)	InnerLoop  0.706 ( 0.605)	Loss 9.6905e-01 (1.0240e+00)	Acc@1  60.99 ( 64.87)
The current update step is 1180
The current seed is 1632393727972833915
The current lr is: 0.001
Testing Results:
 *   Acc@1 65.434
 *   Acc@1 65.747
 *   Acc@1 62.000
 *   Acc@1 61.667
 *   Acc@1 58.711
 *   Acc@1 58.592
 *   Acc@1 62.105
 *   Acc@1 62.493
 *   Acc@1 58.013
 *   Acc@1 58.274
 *   Acc@1 56.171
 *   Acc@1 56.410
Training for 300 epoch: 63.76973684210527
Training for 600 epoch: 60.006578947368425
Training for 1000 epoch: 57.440789473684205
Training for 300 epoch: 64.12
Training for 600 epoch: 59.97083333333333
Training for 1000 epoch: 57.50083333333333
[[63.76973684210527, 60.006578947368425, 57.440789473684205], [64.12, 59.97083333333333, 57.50083333333333]]
train loss 0.6237051941553752, epoch 19, best loss 0.504165983136495, best_epoch 14
GPU_0_using curriculum 20 with window 20
Epoch: [20][20/59]	Time  1.522 ( 1.427)	Data  0.020 ( 0.024)	InnerLoop  0.698 ( 0.604)	Loss 9.0849e-01 (1.0683e+00)	Acc@1  63.33 ( 62.59)
Epoch: [20][40/59]	Time  1.409 ( 1.425)	Data  0.017 ( 0.021)	InnerLoop  0.588 ( 0.603)	Loss 1.0344e+00 (1.0176e+00)	Acc@1  65.43 ( 63.97)
The current update step is 1239
GPU_0_using curriculum 20 with window 20
Epoch: [21][20/59]	Time  1.409 ( 1.426)	Data  0.018 ( 0.030)	InnerLoop  0.589 ( 0.592)	Loss 1.2854e+00 (8.7745e-01)	Acc@1  62.79 ( 68.57)
Epoch: [21][40/59]	Time  1.504 ( 1.428)	Data  0.018 ( 0.027)	InnerLoop  0.688 ( 0.598)	Loss 1.2300e+00 (9.1024e-01)	Acc@1  54.00 ( 67.63)
The current update step is 1298
GPU_0_using curriculum 20 with window 20
Epoch: [22][20/59]	Time  1.408 ( 1.424)	Data  0.018 ( 0.024)	InnerLoop  0.588 ( 0.599)	Loss 7.1935e-01 (1.0716e+00)	Acc@1  71.39 ( 64.03)
Epoch: [22][40/59]	Time  1.410 ( 1.426)	Data  0.019 ( 0.024)	InnerLoop  0.587 ( 0.601)	Loss 7.9990e-01 (1.0402e+00)	Acc@1  73.00 ( 64.35)
The current update step is 1357
GPU_0_using curriculum 20 with window 20
Epoch: [23][20/59]	Time  1.406 ( 1.421)	Data  0.018 ( 0.029)	InnerLoop  0.585 ( 0.591)	Loss 6.3557e-01 (9.3102e-01)	Acc@1  75.63 ( 67.31)
Epoch: [23][40/59]	Time  1.410 ( 1.422)	Data  0.017 ( 0.027)	InnerLoop  0.592 ( 0.594)	Loss 6.2783e-01 (9.0835e-01)	Acc@1  75.88 ( 67.33)
The current update step is 1416
GPU_0_using curriculum 20 with window 20
Epoch: [24][20/59]	Time  1.413 ( 1.423)	Data  0.020 ( 0.030)	InnerLoop  0.591 ( 0.593)	Loss 1.2885e+00 (9.5844e-01)	Acc@1  51.37 ( 64.66)
Epoch: [24][40/59]	Time  1.406 ( 1.426)	Data  0.018 ( 0.027)	InnerLoop  0.585 ( 0.596)	Loss 7.5411e-01 (9.7248e-01)	Acc@1  69.68 ( 64.54)
The current update step is 1475
The current seed is 4295923538972822673
The current lr is: 0.001
Testing Results:
 *   Acc@1 48.421
 *   Acc@1 48.952
 *   Acc@1 43.658
 *   Acc@1 43.286
 *   Acc@1 42.684
 *   Acc@1 42.757
 *   Acc@1 73.566
 *   Acc@1 73.797
 *   Acc@1 73.671
 *   Acc@1 74.353
 *   Acc@1 71.289
 *   Acc@1 71.664
Training for 300 epoch: 60.993421052631575
Training for 600 epoch: 58.66447368421052
Training for 1000 epoch: 56.98684210526315
Training for 300 epoch: 61.374583333333334
Training for 600 epoch: 58.81958333333334
Training for 1000 epoch: 57.210416666666674
[[60.993421052631575, 58.66447368421052, 56.98684210526315], [61.374583333333334, 58.81958333333334, 57.210416666666674]]
train loss 0.3862505106131236, epoch 24, best loss 0.3862505106131236, best_epoch 24
GPU_0_using curriculum 20 with window 20
Epoch: [25][20/59]	Time  1.405 ( 1.422)	Data  0.018 ( 0.018)	InnerLoop  0.585 ( 0.604)	Loss 8.4156e-01 (8.8655e-01)	Acc@1  66.70 ( 66.70)
Epoch: [25][40/59]	Time  1.524 ( 1.426)	Data  0.132 ( 0.023)	InnerLoop  0.588 ( 0.601)	Loss 1.1106e+00 (9.3497e-01)	Acc@1  57.96 ( 65.25)
The current update step is 1534
GPU_0_using curriculum 20 with window 20
Epoch: [26][20/59]	Time  1.414 ( 1.422)	Data  0.019 ( 0.029)	InnerLoop  0.589 ( 0.593)	Loss 7.5726e-01 (9.9655e-01)	Acc@1  69.78 ( 64.39)
Epoch: [26][40/59]	Time  1.405 ( 1.426)	Data  0.017 ( 0.027)	InnerLoop  0.584 ( 0.598)	Loss 1.0481e+00 (1.0122e+00)	Acc@1  61.57 ( 63.92)
The current update step is 1593
GPU_0_using curriculum 20 with window 20
Epoch: [27][20/59]	Time  1.406 ( 1.425)	Data  0.018 ( 0.030)	InnerLoop  0.589 ( 0.594)	Loss 6.5271e-01 (8.7236e-01)	Acc@1  75.88 ( 68.87)
Epoch: [27][40/59]	Time  1.521 ( 1.427)	Data  0.020 ( 0.024)	InnerLoop  0.697 ( 0.602)	Loss 7.7277e-01 (8.8237e-01)	Acc@1  69.58 ( 68.12)
The current update step is 1652
GPU_0_using curriculum 20 with window 20
Epoch: [28][20/59]	Time  1.406 ( 1.423)	Data  0.017 ( 0.024)	InnerLoop  0.588 ( 0.599)	Loss 5.7753e-01 (8.1635e-01)	Acc@1  77.73 ( 71.48)
Epoch: [28][40/59]	Time  1.516 ( 1.427)	Data  0.019 ( 0.021)	InnerLoop  0.695 ( 0.604)	Loss 1.1991e+00 (8.3651e-01)	Acc@1  61.96 ( 69.96)
The current update step is 1711
GPU_0_using curriculum 20 with window 20
Epoch: [29][20/59]	Time  1.400 ( 1.421)	Data  0.018 ( 0.024)	InnerLoop  0.582 ( 0.598)	Loss 3.2211e+00 (1.1420e+00)	Acc@1  34.47 ( 63.34)
Epoch: [29][40/59]	Time  1.518 ( 1.424)	Data  0.019 ( 0.021)	InnerLoop  0.691 ( 0.603)	Loss 1.4401e+00 (1.0596e+00)	Acc@1  48.49 ( 64.15)
The current update step is 1770
The current seed is 2495560695385021336
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.316
 *   Acc@1 77.025
 *   Acc@1 74.013
 *   Acc@1 74.778
 *   Acc@1 73.342
 *   Acc@1 74.033
 *   Acc@1 71.039
 *   Acc@1 70.978
 *   Acc@1 71.921
 *   Acc@1 72.077
 *   Acc@1 71.513
 *   Acc@1 71.454
Training for 300 epoch: 73.67763157894737
Training for 600 epoch: 72.96710526315789
Training for 1000 epoch: 72.42763157894737
Training for 300 epoch: 74.00125
Training for 600 epoch: 73.42750000000001
Training for 1000 epoch: 72.74375
[[73.67763157894737, 72.96710526315789, 72.42763157894737], [74.00125, 73.42750000000001, 72.74375]]
train loss 0.39009875144958495, epoch 29, best loss 0.3862505106131236, best_epoch 24
GPU_0_using curriculum 20 with window 20
Epoch: [30][20/59]	Time  1.523 ( 1.429)	Data  0.017 ( 0.023)	InnerLoop  0.700 ( 0.605)	Loss 1.2063e+00 (8.8520e-01)	Acc@1  61.13 ( 68.34)
Epoch: [30][40/59]	Time  1.411 ( 1.427)	Data  0.018 ( 0.021)	InnerLoop  0.588 ( 0.604)	Loss 8.4067e-01 (9.3936e-01)	Acc@1  64.21 ( 67.40)
The current update step is 1829
GPU_0_using curriculum 20 with window 20
Epoch: [31][20/59]	Time  1.407 ( 1.427)	Data  0.017 ( 0.030)	InnerLoop  0.590 ( 0.595)	Loss 8.7821e-01 (8.6752e-01)	Acc@1  71.24 ( 70.28)
Epoch: [31][40/59]	Time  1.517 ( 1.428)	Data  0.017 ( 0.027)	InnerLoop  0.696 ( 0.600)	Loss 1.0695e+00 (8.6185e-01)	Acc@1  61.87 ( 70.28)
The current update step is 1888
GPU_0_using curriculum 20 with window 20
Epoch: [32][20/59]	Time  1.412 ( 1.423)	Data  0.018 ( 0.024)	InnerLoop  0.590 ( 0.599)	Loss 7.6221e-01 (8.6180e-01)	Acc@1  71.44 ( 68.60)
Epoch: [32][40/59]	Time  1.405 ( 1.427)	Data  0.018 ( 0.024)	InnerLoop  0.585 ( 0.602)	Loss 9.7456e-01 (8.6994e-01)	Acc@1  62.45 ( 68.77)
The current update step is 1947
GPU_0_using curriculum 20 with window 20
Epoch: [33][20/59]	Time  1.408 ( 1.422)	Data  0.017 ( 0.030)	InnerLoop  0.586 ( 0.593)	Loss 1.0553e+00 (8.8857e-01)	Acc@1  58.69 ( 67.60)
Epoch: [33][40/59]	Time  1.401 ( 1.423)	Data  0.018 ( 0.027)	InnerLoop  0.582 ( 0.595)	Loss 6.8507e-01 (8.7778e-01)	Acc@1  74.80 ( 68.20)
The current update step is 2006
GPU_0_using curriculum 20 with window 20
Epoch: [34][20/59]	Time  1.407 ( 1.423)	Data  0.019 ( 0.029)	InnerLoop  0.586 ( 0.593)	Loss 6.9169e-01 (8.3668e-01)	Acc@1  73.34 ( 70.27)
Epoch: [34][40/59]	Time  1.420 ( 1.425)	Data  0.019 ( 0.026)	InnerLoop  0.587 ( 0.597)	Loss 6.5899e-01 (9.0639e-01)	Acc@1  79.00 ( 67.87)
The current update step is 2065
The current seed is 1933529350201986091
The current lr is: 0.001
Testing Results:
 *   Acc@1 72.079
 *   Acc@1 72.106
 *   Acc@1 71.211
 *   Acc@1 71.331
 *   Acc@1 70.684
 *   Acc@1 70.865
 *   Acc@1 76.039
 *   Acc@1 76.558
 *   Acc@1 75.184
 *   Acc@1 76.052
 *   Acc@1 75.184
 *   Acc@1 75.809
Training for 300 epoch: 74.05921052631578
Training for 600 epoch: 73.19736842105263
Training for 1000 epoch: 72.9342105263158
Training for 300 epoch: 74.33208333333334
Training for 600 epoch: 73.69125
Training for 1000 epoch: 73.33708333333334
[[74.05921052631578, 73.19736842105263, 72.9342105263158], [74.33208333333334, 73.69125, 73.33708333333334]]
train loss 0.3143122046152751, epoch 34, best loss 0.3143122046152751, best_epoch 34
GPU_0_using curriculum 20 with window 20
Epoch: [35][20/59]	Time  1.407 ( 1.422)	Data  0.019 ( 0.018)	InnerLoop  0.587 ( 0.604)	Loss 7.3970e-01 (9.4955e-01)	Acc@1  72.02 ( 67.17)
Epoch: [35][40/59]	Time  1.508 ( 1.426)	Data  0.127 ( 0.023)	InnerLoop  0.578 ( 0.600)	Loss 1.0968e+00 (9.6501e-01)	Acc@1  59.23 ( 66.31)
The current update step is 2124
GPU_0_using curriculum 20 with window 20
Epoch: [36][20/59]	Time  1.413 ( 1.424)	Data  0.018 ( 0.029)	InnerLoop  0.592 ( 0.593)	Loss 7.9216e-01 (1.0086e+00)	Acc@1  70.95 ( 63.70)
Epoch: [36][40/59]	Time  1.412 ( 1.428)	Data  0.017 ( 0.026)	InnerLoop  0.589 ( 0.600)	Loss 7.5435e-01 (9.7204e-01)	Acc@1  72.12 ( 64.74)
The current update step is 2183
GPU_0_using curriculum 20 with window 20
Epoch: [37][20/59]	Time  1.407 ( 1.424)	Data  0.019 ( 0.029)	InnerLoop  0.588 ( 0.594)	Loss 8.2012e-01 (8.7903e-01)	Acc@1  71.29 ( 67.16)
Epoch: [37][40/59]	Time  1.521 ( 1.427)	Data  0.018 ( 0.024)	InnerLoop  0.698 ( 0.602)	Loss 1.0600e+00 (8.9681e-01)	Acc@1  59.18 ( 67.11)
The current update step is 2242
GPU_0_using curriculum 20 with window 20
Epoch: [38][20/59]	Time  1.409 ( 1.425)	Data  0.017 ( 0.024)	InnerLoop  0.591 ( 0.600)	Loss 9.2173e-01 (9.3764e-01)	Acc@1  67.82 ( 64.88)
Epoch: [38][40/59]	Time  1.519 ( 1.430)	Data  0.019 ( 0.021)	InnerLoop  0.697 ( 0.607)	Loss 6.7551e-01 (9.0110e-01)	Acc@1  73.49 ( 67.10)
The current update step is 2301
GPU_0_using curriculum 20 with window 20
Epoch: [39][20/59]	Time  1.407 ( 1.422)	Data  0.017 ( 0.024)	InnerLoop  0.591 ( 0.599)	Loss 6.3584e-01 (8.1798e-01)	Acc@1  76.46 ( 70.81)
Epoch: [39][40/59]	Time  1.524 ( 1.427)	Data  0.020 ( 0.021)	InnerLoop  0.702 ( 0.605)	Loss 7.2003e-01 (8.5434e-01)	Acc@1  71.88 ( 69.41)
The current update step is 2360
The current seed is 15929926780361689106
The current lr is: 0.001
Testing Results:
 *   Acc@1 65.763
 *   Acc@1 65.850
 *   Acc@1 65.868
 *   Acc@1 65.620
 *   Acc@1 67.105
 *   Acc@1 66.389
 *   Acc@1 67.592
 *   Acc@1 67.123
 *   Acc@1 66.750
 *   Acc@1 66.139
 *   Acc@1 65.855
 *   Acc@1 65.465
Training for 300 epoch: 66.67763157894737
Training for 600 epoch: 66.30921052631578
Training for 1000 epoch: 66.48026315789474
Training for 300 epoch: 66.48666666666666
Training for 600 epoch: 65.87958333333333
Training for 1000 epoch: 65.92708333333334
[[66.67763157894737, 66.30921052631578, 66.48026315789474], [66.48666666666666, 65.87958333333333, 65.92708333333334]]
train loss 0.4950104891141256, epoch 39, best loss 0.3143122046152751, best_epoch 34
GPU_0_using curriculum 20 with window 20
Epoch: [40][20/59]	Time  1.514 ( 1.432)	Data  0.017 ( 0.024)	InnerLoop  0.695 ( 0.606)	Loss 8.2453e-01 (8.4481e-01)	Acc@1  66.80 ( 69.06)
Epoch: [40][40/59]	Time  1.412 ( 1.430)	Data  0.017 ( 0.021)	InnerLoop  0.591 ( 0.606)	Loss 9.2964e-01 (8.8716e-01)	Acc@1  70.02 ( 67.36)
The current update step is 2419
GPU_0_using curriculum 20 with window 20
Epoch: [41][20/59]	Time  1.415 ( 1.423)	Data  0.020 ( 0.030)	InnerLoop  0.591 ( 0.593)	Loss 7.2394e-01 (8.3541e-01)	Acc@1  72.22 ( 69.92)
Epoch: [41][40/59]	Time  1.515 ( 1.427)	Data  0.017 ( 0.027)	InnerLoop  0.695 ( 0.599)	Loss 5.9422e-01 (8.9580e-01)	Acc@1  78.37 ( 67.85)
The current update step is 2478
GPU_0_using curriculum 20 with window 20
Epoch: [42][20/59]	Time  1.396 ( 1.423)	Data  0.017 ( 0.024)	InnerLoop  0.580 ( 0.598)	Loss 8.2790e-01 (8.8677e-01)	Acc@1  69.43 ( 67.68)
Epoch: [42][40/59]	Time  1.404 ( 1.427)	Data  0.019 ( 0.024)	InnerLoop  0.586 ( 0.602)	Loss 6.9118e-01 (8.7721e-01)	Acc@1  73.63 ( 68.49)
The current update step is 2537
GPU_0_using curriculum 20 with window 20
Epoch: [43][20/59]	Time  1.408 ( 1.423)	Data  0.018 ( 0.030)	InnerLoop  0.587 ( 0.594)	Loss 6.0725e-01 (8.4636e-01)	Acc@1  76.95 ( 70.19)
Epoch: [43][40/59]	Time  1.409 ( 1.424)	Data  0.018 ( 0.027)	InnerLoop  0.589 ( 0.597)	Loss 8.8170e-01 (8.5567e-01)	Acc@1  66.80 ( 68.89)
The current update step is 2596
GPU_0_using curriculum 20 with window 20
Epoch: [44][20/59]	Time  1.408 ( 1.422)	Data  0.018 ( 0.029)	InnerLoop  0.588 ( 0.593)	Loss 6.5617e-01 (8.5060e-01)	Acc@1  76.90 ( 68.83)
Epoch: [44][40/59]	Time  1.406 ( 1.423)	Data  0.018 ( 0.026)	InnerLoop  0.588 ( 0.596)	Loss 8.2397e-01 (8.3249e-01)	Acc@1  69.73 ( 69.94)
The current update step is 2655
The current seed is 18101346916830884562
The current lr is: 0.001
Testing Results:
 *   Acc@1 67.145
 *   Acc@1 67.412
 *   Acc@1 64.724
 *   Acc@1 64.991
 *   Acc@1 60.671
 *   Acc@1 60.754
 *   Acc@1 62.724
 *   Acc@1 63.343
 *   Acc@1 61.618
 *   Acc@1 62.372
 *   Acc@1 61.882
 *   Acc@1 62.444
Training for 300 epoch: 64.93421052631578
Training for 600 epoch: 63.171052631578945
Training for 1000 epoch: 61.276315789473685
Training for 300 epoch: 65.3775
Training for 600 epoch: 63.68125
Training for 1000 epoch: 61.59916666666667
[[64.93421052631578, 63.171052631578945, 61.276315789473685], [65.3775, 63.68125, 61.59916666666667]]
train loss 0.4630765167395274, epoch 44, best loss 0.3143122046152751, best_epoch 34
GPU_0_using curriculum 20 with window 20
Epoch: [45][20/59]	Time  1.410 ( 1.423)	Data  0.018 ( 0.018)	InnerLoop  0.590 ( 0.605)	Loss 1.1048e+00 (8.1762e-01)	Acc@1  59.33 ( 70.11)
Epoch: [45][40/59]	Time  1.513 ( 1.428)	Data  0.128 ( 0.024)	InnerLoop  0.584 ( 0.603)	Loss 6.3884e-01 (8.3059e-01)	Acc@1  75.00 ( 69.47)
The current update step is 2714
GPU_0_using curriculum 20 with window 20
Epoch: [46][20/59]	Time  1.398 ( 1.425)	Data  0.019 ( 0.029)	InnerLoop  0.585 ( 0.595)	Loss 9.2775e-01 (8.7858e-01)	Acc@1  65.92 ( 67.71)
Epoch: [46][40/59]	Time  1.415 ( 1.429)	Data  0.019 ( 0.026)	InnerLoop  0.591 ( 0.601)	Loss 9.7135e-01 (8.4931e-01)	Acc@1  64.60 ( 69.09)
The current update step is 2773
GPU_0_using curriculum 20 with window 20
Epoch: [47][20/59]	Time  1.402 ( 1.421)	Data  0.017 ( 0.030)	InnerLoop  0.586 ( 0.592)	Loss 7.9307e-01 (9.2201e-01)	Acc@1  70.31 ( 66.84)
Epoch: [47][40/59]	Time  1.516 ( 1.426)	Data  0.019 ( 0.024)	InnerLoop  0.694 ( 0.600)	Loss 7.5877e-01 (8.9417e-01)	Acc@1  73.29 ( 67.58)
The current update step is 2832
GPU_0_using curriculum 20 with window 20
Epoch: [48][20/59]	Time  1.403 ( 1.425)	Data  0.018 ( 0.024)	InnerLoop  0.585 ( 0.598)	Loss 9.5994e-01 (8.4223e-01)	Acc@1  64.99 ( 69.50)
Epoch: [48][40/59]	Time  1.519 ( 1.428)	Data  0.018 ( 0.021)	InnerLoop  0.696 ( 0.604)	Loss 5.7559e-01 (8.2347e-01)	Acc@1  78.61 ( 70.33)
The current update step is 2891
GPU_0_using curriculum 20 with window 20
Epoch: [49][20/59]	Time  1.418 ( 1.426)	Data  0.019 ( 0.024)	InnerLoop  0.592 ( 0.600)	Loss 1.4553e+00 (9.2348e-01)	Acc@1  54.79 ( 66.84)
Epoch: [49][40/59]	Time  1.524 ( 1.428)	Data  0.018 ( 0.021)	InnerLoop  0.699 ( 0.604)	Loss 7.3172e-01 (8.6835e-01)	Acc@1  72.66 ( 67.92)
The current update step is 2950
The current seed is 1631128985441717026
The current lr is: 0.001
Testing Results:
 *   Acc@1 78.658
 *   Acc@1 79.009
 *   Acc@1 78.579
 *   Acc@1 79.044
 *   Acc@1 78.355
 *   Acc@1 78.329
 *   Acc@1 71.829
 *   Acc@1 72.243
 *   Acc@1 71.118
 *   Acc@1 71.063
 *   Acc@1 70.289
 *   Acc@1 70.191
Training for 300 epoch: 75.24342105263159
Training for 600 epoch: 74.84868421052632
Training for 1000 epoch: 74.32236842105263
Training for 300 epoch: 75.62625
Training for 600 epoch: 75.05375000000001
Training for 1000 epoch: 74.25999999999999
[[75.24342105263159, 74.84868421052632, 74.32236842105263], [75.62625, 75.05375000000001, 74.25999999999999]]
train loss 0.3794254461447398, epoch 49, best loss 0.3143122046152751, best_epoch 34
GPU_0_using curriculum 20 with window 20
Epoch: [50][20/59]	Time  1.505 ( 1.427)	Data  0.017 ( 0.023)	InnerLoop  0.691 ( 0.604)	Loss 1.1727e+00 (8.2319e-01)	Acc@1  60.35 ( 70.09)
Epoch: [50][40/59]	Time  1.404 ( 1.425)	Data  0.019 ( 0.020)	InnerLoop  0.584 ( 0.603)	Loss 8.6582e-01 (8.2587e-01)	Acc@1  71.19 ( 70.09)
The current update step is 3009
GPU_0_using curriculum 20 with window 20
Epoch: [51][20/59]	Time  1.409 ( 1.423)	Data  0.019 ( 0.029)	InnerLoop  0.590 ( 0.593)	Loss 7.5945e-01 (7.8978e-01)	Acc@1  69.48 ( 70.88)
Epoch: [51][40/59]	Time  1.516 ( 1.427)	Data  0.019 ( 0.026)	InnerLoop  0.699 ( 0.598)	Loss 1.8443e+00 (8.0776e-01)	Acc@1  47.07 ( 70.91)
The current update step is 3068
GPU_0_using curriculum 20 with window 20
Epoch: [52][20/59]	Time  1.409 ( 1.423)	Data  0.016 ( 0.023)	InnerLoop  0.592 ( 0.599)	Loss 7.1309e-01 (7.7298e-01)	Acc@1  72.95 ( 70.28)
Epoch: [52][40/59]	Time  1.410 ( 1.427)	Data  0.017 ( 0.023)	InnerLoop  0.589 ( 0.602)	Loss 7.9603e-01 (7.9768e-01)	Acc@1  70.31 ( 69.74)
The current update step is 3127
GPU_0_using curriculum 20 with window 20
Epoch: [53][20/59]	Time  1.407 ( 1.423)	Data  0.019 ( 0.029)	InnerLoop  0.586 ( 0.593)	Loss 7.7352e-01 (9.3651e-01)	Acc@1  68.75 ( 65.97)
Epoch: [53][40/59]	Time  1.415 ( 1.423)	Data  0.019 ( 0.026)	InnerLoop  0.593 ( 0.596)	Loss 6.5780e-01 (9.0993e-01)	Acc@1  73.93 ( 66.47)
The current update step is 3186
GPU_0_using curriculum 20 with window 20
Epoch: [54][20/59]	Time  1.400 ( 1.423)	Data  0.017 ( 0.030)	InnerLoop  0.586 ( 0.593)	Loss 8.4743e-01 (8.5448e-01)	Acc@1  68.07 ( 68.31)
Epoch: [54][40/59]	Time  1.404 ( 1.423)	Data  0.018 ( 0.027)	InnerLoop  0.585 ( 0.595)	Loss 1.2007e+00 (8.3354e-01)	Acc@1  55.62 ( 68.77)
The current update step is 3245
The current seed is 13284906630142479441
The current lr is: 0.001
Testing Results:
 *   Acc@1 78.092
 *   Acc@1 78.927
 *   Acc@1 77.658
 *   Acc@1 78.332
 *   Acc@1 77.500
 *   Acc@1 77.732
 *   Acc@1 68.303
 *   Acc@1 68.541
 *   Acc@1 67.303
 *   Acc@1 67.306
 *   Acc@1 64.263
 *   Acc@1 64.966
Training for 300 epoch: 73.19736842105263
Training for 600 epoch: 72.48026315789474
Training for 1000 epoch: 70.88157894736841
Training for 300 epoch: 73.73375
Training for 600 epoch: 72.81916666666666
Training for 1000 epoch: 71.34875
[[73.19736842105263, 72.48026315789474, 70.88157894736841], [73.73375, 72.81916666666666, 71.34875]]
train loss 0.4490517813205719, epoch 54, best loss 0.3143122046152751, best_epoch 34
GPU_0_using curriculum 20 with window 20
Epoch: [55][20/59]	Time  1.408 ( 1.422)	Data  0.019 ( 0.018)	InnerLoop  0.588 ( 0.604)	Loss 6.9704e-01 (8.1875e-01)	Acc@1  73.97 ( 68.65)
Epoch: [55][40/59]	Time  1.526 ( 1.425)	Data  0.128 ( 0.023)	InnerLoop  0.590 ( 0.601)	Loss 6.7865e-01 (8.0690e-01)	Acc@1  74.90 ( 69.77)
The current update step is 3304
GPU_0_using curriculum 20 with window 20
Epoch: [56][20/59]	Time  1.402 ( 1.420)	Data  0.018 ( 0.029)	InnerLoop  0.586 ( 0.592)	Loss 1.9820e+00 (8.5443e-01)	Acc@1  44.87 ( 69.90)
Epoch: [56][40/59]	Time  1.406 ( 1.424)	Data  0.017 ( 0.026)	InnerLoop  0.585 ( 0.597)	Loss 7.8386e-01 (8.5919e-01)	Acc@1  72.36 ( 68.74)
The current update step is 3363
GPU_0_using curriculum 20 with window 20
Epoch: [57][20/59]	Time  1.410 ( 1.421)	Data  0.018 ( 0.029)	InnerLoop  0.589 ( 0.591)	Loss 9.0704e-01 (9.4544e-01)	Acc@1  70.41 ( 65.93)
Epoch: [57][40/59]	Time  1.509 ( 1.424)	Data  0.017 ( 0.023)	InnerLoop  0.691 ( 0.600)	Loss 8.4246e-01 (9.4281e-01)	Acc@1  68.95 ( 66.16)
The current update step is 3422
GPU_0_using curriculum 20 with window 20
Epoch: [58][20/59]	Time  1.406 ( 1.422)	Data  0.017 ( 0.024)	InnerLoop  0.588 ( 0.598)	Loss 7.0609e-01 (8.1508e-01)	Acc@1  72.85 ( 69.46)
Epoch: [58][40/59]	Time  1.519 ( 1.426)	Data  0.017 ( 0.021)	InnerLoop  0.700 ( 0.604)	Loss 1.1102e+00 (8.2050e-01)	Acc@1  58.94 ( 69.37)
The current update step is 3481
GPU_0_using curriculum 20 with window 20
Epoch: [59][20/59]	Time  1.414 ( 1.423)	Data  0.020 ( 0.024)	InnerLoop  0.593 ( 0.599)	Loss 8.9938e-01 (8.7586e-01)	Acc@1  67.82 ( 67.71)
Epoch: [59][40/59]	Time  1.527 ( 1.428)	Data  0.018 ( 0.021)	InnerLoop  0.700 ( 0.605)	Loss 6.8039e-01 (8.5702e-01)	Acc@1  73.68 ( 68.45)
The current update step is 3540
The current seed is 17696512384976051976
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.395
 *   Acc@1 78.093
 *   Acc@1 72.974
 *   Acc@1 73.371
 *   Acc@1 70.789
 *   Acc@1 71.181
 *   Acc@1 72.013
 *   Acc@1 72.317
 *   Acc@1 70.974
 *   Acc@1 71.857
 *   Acc@1 69.842
 *   Acc@1 70.603
Training for 300 epoch: 74.70394736842104
Training for 600 epoch: 71.97368421052632
Training for 1000 epoch: 70.3157894736842
Training for 300 epoch: 75.20541666666666
Training for 600 epoch: 72.61375000000001
Training for 1000 epoch: 70.89166666666668
[[74.70394736842104, 71.97368421052632, 70.3157894736842], [75.20541666666666, 72.61375000000001, 70.89166666666668]]
train loss 0.3882543468475342, epoch 59, best loss 0.3143122046152751, best_epoch 34
GPU_0_using curriculum 20 with window 20
Epoch: [60][20/59]	Time  1.523 ( 1.424)	Data  0.019 ( 0.024)	InnerLoop  0.700 ( 0.602)	Loss 1.0371e+00 (8.6615e-01)	Acc@1  63.87 ( 67.84)
Epoch: [60][40/59]	Time  1.410 ( 1.425)	Data  0.017 ( 0.021)	InnerLoop  0.590 ( 0.604)	Loss 6.6980e-01 (9.4050e-01)	Acc@1  75.78 ( 67.31)
The current update step is 3599
GPU_0_using curriculum 20 with window 20
Epoch: [61][20/59]	Time  1.404 ( 1.423)	Data  0.018 ( 0.030)	InnerLoop  0.586 ( 0.593)	Loss 6.9390e-01 (8.4222e-01)	Acc@1  75.83 ( 68.11)
Epoch: [61][40/59]	Time  1.526 ( 1.430)	Data  0.018 ( 0.027)	InnerLoop  0.700 ( 0.600)	Loss 8.4637e-01 (8.1192e-01)	Acc@1  66.75 ( 69.45)
The current update step is 3658
GPU_0_using curriculum 20 with window 20
Epoch: [62][20/59]	Time  1.401 ( 1.423)	Data  0.018 ( 0.024)	InnerLoop  0.582 ( 0.599)	Loss 7.1106e-01 (7.9940e-01)	Acc@1  75.24 ( 70.62)
Epoch: [62][40/59]	Time  1.405 ( 1.426)	Data  0.018 ( 0.024)	InnerLoop  0.586 ( 0.602)	Loss 7.3179e-01 (8.0663e-01)	Acc@1  72.07 ( 70.33)
The current update step is 3717
GPU_0_using curriculum 20 with window 20
Epoch: [63][20/59]	Time  1.408 ( 1.422)	Data  0.017 ( 0.029)	InnerLoop  0.587 ( 0.593)	Loss 6.4097e-01 (7.8645e-01)	Acc@1  77.73 ( 71.28)
Epoch: [63][40/59]	Time  1.406 ( 1.422)	Data  0.018 ( 0.026)	InnerLoop  0.588 ( 0.595)	Loss 7.0153e-01 (8.1977e-01)	Acc@1  72.95 ( 70.25)
The current update step is 3776
GPU_0_using curriculum 20 with window 20
Epoch: [64][20/59]	Time  1.408 ( 1.421)	Data  0.017 ( 0.029)	InnerLoop  0.589 ( 0.592)	Loss 6.5437e-01 (8.8770e-01)	Acc@1  75.15 ( 68.76)
Epoch: [64][40/59]	Time  1.405 ( 1.422)	Data  0.018 ( 0.026)	InnerLoop  0.586 ( 0.595)	Loss 6.3667e-01 (8.3538e-01)	Acc@1  76.42 ( 70.26)
The current update step is 3835
The current seed is 10908599903951763356
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.882
 *   Acc@1 78.414
 *   Acc@1 76.684
 *   Acc@1 77.028
 *   Acc@1 75.329
 *   Acc@1 75.832
 *   Acc@1 69.474
 *   Acc@1 69.568
 *   Acc@1 70.303
 *   Acc@1 70.498
 *   Acc@1 71.684
 *   Acc@1 72.323
Training for 300 epoch: 73.67763157894737
Training for 600 epoch: 73.49342105263159
Training for 1000 epoch: 73.50657894736842
Training for 300 epoch: 73.99125000000001
Training for 600 epoch: 73.7625
Training for 1000 epoch: 74.0775
[[73.67763157894737, 73.49342105263159, 73.50657894736842], [73.99125000000001, 73.7625, 74.0775]]
train loss 0.38479574265480043, epoch 64, best loss 0.3143122046152751, best_epoch 34
GPU_0_using curriculum 20 with window 20
Epoch: [65][20/59]	Time  1.410 ( 1.424)	Data  0.018 ( 0.018)	InnerLoop  0.591 ( 0.605)	Loss 1.4106e+00 (8.8682e-01)	Acc@1  59.47 ( 69.79)
Epoch: [65][40/59]	Time  1.511 ( 1.427)	Data  0.128 ( 0.024)	InnerLoop  0.584 ( 0.602)	Loss 7.2663e-01 (9.1021e-01)	Acc@1  72.36 ( 69.22)
The current update step is 3894
GPU_0_using curriculum 20 with window 20
Epoch: [66][20/59]	Time  1.412 ( 1.421)	Data  0.019 ( 0.029)	InnerLoop  0.591 ( 0.593)	Loss 6.3235e-01 (9.1294e-01)	Acc@1  76.66 ( 67.60)
Epoch: [66][40/59]	Time  1.403 ( 1.424)	Data  0.017 ( 0.026)	InnerLoop  0.585 ( 0.598)	Loss 9.4775e-01 (8.8865e-01)	Acc@1  64.11 ( 68.12)
The current update step is 3953
GPU_0_using curriculum 20 with window 20
Epoch: [67][20/59]	Time  1.416 ( 1.422)	Data  0.018 ( 0.030)	InnerLoop  0.597 ( 0.592)	Loss 6.3926e-01 (9.9316e-01)	Acc@1  76.03 ( 65.31)
Epoch: [67][40/59]	Time  1.517 ( 1.425)	Data  0.020 ( 0.024)	InnerLoop  0.694 ( 0.600)	Loss 1.3256e+00 (9.4481e-01)	Acc@1  62.30 ( 67.03)
The current update step is 4012
GPU_0_using curriculum 20 with window 20
Epoch: [68][20/59]	Time  1.409 ( 1.421)	Data  0.017 ( 0.024)	InnerLoop  0.590 ( 0.598)	Loss 6.2491e-01 (1.0111e+00)	Acc@1  76.86 ( 66.36)
Epoch: [68][40/59]	Time  1.518 ( 1.425)	Data  0.020 ( 0.021)	InnerLoop  0.690 ( 0.603)	Loss 8.0948e-01 (8.9885e-01)	Acc@1  69.29 ( 68.85)
The current update step is 4071
GPU_0_using curriculum 20 with window 20
Epoch: [69][20/59]	Time  1.412 ( 1.420)	Data  0.018 ( 0.024)	InnerLoop  0.592 ( 0.597)	Loss 7.7673e-01 (9.7016e-01)	Acc@1  73.14 ( 67.20)
Epoch: [69][40/59]	Time  1.521 ( 1.425)	Data  0.019 ( 0.021)	InnerLoop  0.699 ( 0.604)	Loss 8.2989e-01 (1.0562e+00)	Acc@1  69.29 ( 65.17)
The current update step is 4130
The current seed is 14928592797786364521
The current lr is: 0.001
Testing Results:
 *   Acc@1 67.724
 *   Acc@1 68.111
 *   Acc@1 68.171
 *   Acc@1 68.374
 *   Acc@1 69.013
 *   Acc@1 69.347
 *   Acc@1 71.645
 *   Acc@1 71.835
 *   Acc@1 69.316
 *   Acc@1 69.882
 *   Acc@1 67.842
 *   Acc@1 68.355
Training for 300 epoch: 69.68421052631578
Training for 600 epoch: 68.74342105263158
Training for 1000 epoch: 68.42763157894737
Training for 300 epoch: 69.97291666666666
Training for 600 epoch: 69.12833333333333
Training for 1000 epoch: 68.85083333333333
[[69.68421052631578, 68.74342105263158, 68.42763157894737], [69.97291666666666, 69.12833333333333, 68.85083333333333]]
train loss 0.4379103123982747, epoch 69, best loss 0.3143122046152751, best_epoch 34
GPU_0_using curriculum 20 with window 20
Epoch: [70][20/59]	Time  1.518 ( 1.430)	Data  0.017 ( 0.024)	InnerLoop  0.696 ( 0.607)	Loss 1.3446e+00 (1.0165e+00)	Acc@1  56.15 ( 65.05)
Epoch: [70][40/59]	Time  1.403 ( 1.428)	Data  0.017 ( 0.021)	InnerLoop  0.582 ( 0.606)	Loss 1.0620e+00 (1.0294e+00)	Acc@1  62.11 ( 64.99)
The current update step is 4189
GPU_0_using curriculum 20 with window 20
Epoch: [71][20/59]	Time  1.411 ( 1.421)	Data  0.017 ( 0.029)	InnerLoop  0.590 ( 0.592)	Loss 7.3798e-01 (9.8147e-01)	Acc@1  71.78 ( 65.59)
Epoch: [71][40/59]	Time  1.509 ( 1.425)	Data  0.018 ( 0.026)	InnerLoop  0.689 ( 0.597)	Loss 9.5828e-01 (9.5115e-01)	Acc@1  66.16 ( 66.24)
The current update step is 4248
GPU_0_using curriculum 20 with window 20
Epoch: [72][20/59]	Time  1.407 ( 1.421)	Data  0.017 ( 0.024)	InnerLoop  0.587 ( 0.597)	Loss 8.1182e-01 (9.6467e-01)	Acc@1  70.12 ( 65.54)
Epoch: [72][40/59]	Time  1.404 ( 1.425)	Data  0.017 ( 0.023)	InnerLoop  0.587 ( 0.600)	Loss 7.9121e-01 (9.7864e-01)	Acc@1  69.87 ( 65.10)
The current update step is 4307
GPU_0_using curriculum 20 with window 20
Epoch: [73][20/59]	Time  1.409 ( 1.418)	Data  0.019 ( 0.029)	InnerLoop  0.590 ( 0.590)	Loss 7.1479e-01 (8.5884e-01)	Acc@1  73.97 ( 68.51)
Epoch: [73][40/59]	Time  1.405 ( 1.420)	Data  0.017 ( 0.026)	InnerLoop  0.585 ( 0.593)	Loss 8.5811e-01 (9.0498e-01)	Acc@1  65.28 ( 67.25)
The current update step is 4366
GPU_0_using curriculum 20 with window 20
Epoch: [74][20/59]	Time  1.409 ( 1.422)	Data  0.018 ( 0.029)	InnerLoop  0.588 ( 0.593)	Loss 8.1615e-01 (8.9959e-01)	Acc@1  65.23 ( 66.71)
Epoch: [74][40/59]	Time  1.401 ( 1.423)	Data  0.017 ( 0.026)	InnerLoop  0.581 ( 0.595)	Loss 1.0240e+00 (8.8903e-01)	Acc@1  65.19 ( 66.99)
The current update step is 4425
The current seed is 15852843399573183895
The current lr is: 0.001
Testing Results:
 *   Acc@1 66.289
 *   Acc@1 65.498
 *   Acc@1 66.658
 *   Acc@1 66.693
 *   Acc@1 67.184
 *   Acc@1 66.895
 *   Acc@1 64.224
 *   Acc@1 64.907
 *   Acc@1 66.237
 *   Acc@1 66.438
 *   Acc@1 66.684
 *   Acc@1 66.447
Training for 300 epoch: 65.25657894736841
Training for 600 epoch: 66.44736842105263
Training for 1000 epoch: 66.9342105263158
Training for 300 epoch: 65.2025
Training for 600 epoch: 66.56541666666666
Training for 1000 epoch: 66.67083333333333
[[65.25657894736841, 66.44736842105263, 66.9342105263158], [65.2025, 66.56541666666666, 66.67083333333333]]
train loss 0.4133942493438721, epoch 74, best loss 0.3143122046152751, best_epoch 34
GPU_0_using curriculum 20 with window 20
Epoch: [75][20/59]	Time  1.418 ( 1.423)	Data  0.019 ( 0.017)	InnerLoop  0.595 ( 0.605)	Loss 7.8400e-01 (8.9158e-01)	Acc@1  68.12 ( 67.51)
Epoch: [75][40/59]	Time  1.506 ( 1.425)	Data  0.127 ( 0.023)	InnerLoop  0.582 ( 0.601)	Loss 7.5598e-01 (8.9607e-01)	Acc@1  71.09 ( 67.38)
The current update step is 4484
GPU_0_using curriculum 20 with window 20
Epoch: [76][20/59]	Time  1.409 ( 1.421)	Data  0.020 ( 0.029)	InnerLoop  0.588 ( 0.591)	Loss 8.1658e-01 (9.4477e-01)	Acc@1  69.38 ( 66.86)
Epoch: [76][40/59]	Time  1.407 ( 1.425)	Data  0.018 ( 0.026)	InnerLoop  0.586 ( 0.597)	Loss 1.1388e+00 (1.0099e+00)	Acc@1  59.23 ( 65.24)
The current update step is 4543
GPU_0_using curriculum 20 with window 20
Epoch: [77][20/59]	Time  1.406 ( 1.420)	Data  0.018 ( 0.029)	InnerLoop  0.587 ( 0.591)	Loss 6.9220e-01 (8.1866e-01)	Acc@1  76.37 ( 69.58)
Epoch: [77][40/59]	Time  1.517 ( 1.425)	Data  0.017 ( 0.023)	InnerLoop  0.695 ( 0.600)	Loss 8.0189e-01 (8.3001e-01)	Acc@1  65.92 ( 69.45)
The current update step is 4602
GPU_0_using curriculum 20 with window 20
Epoch: [78][20/59]	Time  1.413 ( 1.422)	Data  0.019 ( 0.024)	InnerLoop  0.590 ( 0.598)	Loss 8.0229e-01 (9.5435e-01)	Acc@1  68.36 ( 66.88)
Epoch: [78][40/59]	Time  1.519 ( 1.426)	Data  0.018 ( 0.021)	InnerLoop  0.700 ( 0.604)	Loss 1.1308e+00 (9.8113e-01)	Acc@1  58.74 ( 65.86)
The current update step is 4661
GPU_0_using curriculum 20 with window 20
Epoch: [79][20/59]	Time  1.413 ( 1.423)	Data  0.018 ( 0.024)	InnerLoop  0.591 ( 0.598)	Loss 7.9538e-01 (1.0085e+00)	Acc@1  72.07 ( 66.31)
Epoch: [79][40/59]	Time  1.514 ( 1.426)	Data  0.017 ( 0.021)	InnerLoop  0.695 ( 0.603)	Loss 1.0407e+00 (9.2661e-01)	Acc@1  58.54 ( 67.47)
The current update step is 4720
The current seed is 2210278070765894300
The current lr is: 0.001
Testing Results:
 *   Acc@1 64.895
 *   Acc@1 64.311
 *   Acc@1 59.579
 *   Acc@1 59.031
 *   Acc@1 60.553
 *   Acc@1 60.356
 *   Acc@1 74.789
 *   Acc@1 74.580
 *   Acc@1 72.303
 *   Acc@1 72.248
 *   Acc@1 72.039
 *   Acc@1 72.098
Training for 300 epoch: 69.84210526315789
Training for 600 epoch: 65.94078947368422
Training for 1000 epoch: 66.29605263157895
Training for 300 epoch: 69.44541666666666
Training for 600 epoch: 65.63916666666667
Training for 1000 epoch: 66.22708333333333
[[69.84210526315789, 65.94078947368422, 66.29605263157895], [69.44541666666666, 65.63916666666667, 66.22708333333333]]
train loss 0.3815650030295054, epoch 79, best loss 0.3143122046152751, best_epoch 34
GPU_0_using curriculum 20 with window 20
Epoch: [80][20/59]	Time  1.517 ( 1.428)	Data  0.018 ( 0.023)	InnerLoop  0.698 ( 0.603)	Loss 9.5815e-01 (1.0040e+00)	Acc@1  65.04 ( 65.41)
Epoch: [80][40/59]	Time  1.404 ( 1.427)	Data  0.018 ( 0.021)	InnerLoop  0.583 ( 0.604)	Loss 8.6015e-01 (9.0258e-01)	Acc@1  66.80 ( 67.97)
The current update step is 4779
GPU_0_using curriculum 20 with window 20
Epoch: [81][20/59]	Time  1.406 ( 1.422)	Data  0.019 ( 0.030)	InnerLoop  0.588 ( 0.592)	Loss 6.5837e-01 (8.7515e-01)	Acc@1  77.54 ( 67.92)
Epoch: [81][40/59]	Time  1.517 ( 1.425)	Data  0.017 ( 0.026)	InnerLoop  0.694 ( 0.597)	Loss 7.7007e-01 (9.5816e-01)	Acc@1  71.34 ( 66.49)
The current update step is 4838
GPU_0_using curriculum 20 with window 20
Epoch: [82][20/59]	Time  1.410 ( 1.418)	Data  0.017 ( 0.024)	InnerLoop  0.590 ( 0.596)	Loss 9.7860e-01 (1.0886e+00)	Acc@1  58.50 ( 61.27)
Epoch: [82][40/59]	Time  1.410 ( 1.423)	Data  0.017 ( 0.023)	InnerLoop  0.588 ( 0.599)	Loss 7.2755e-01 (9.8213e-01)	Acc@1  72.75 ( 64.41)
The current update step is 4897
GPU_0_using curriculum 20 with window 20
Epoch: [83][20/59]	Time  1.410 ( 1.419)	Data  0.017 ( 0.029)	InnerLoop  0.587 ( 0.590)	Loss 6.0847e-01 (9.2186e-01)	Acc@1  77.25 ( 66.97)
Epoch: [83][40/59]	Time  1.397 ( 1.419)	Data  0.016 ( 0.026)	InnerLoop  0.581 ( 0.593)	Loss 7.3262e-01 (8.6706e-01)	Acc@1  74.76 ( 68.18)
The current update step is 4956
GPU_0_using curriculum 20 with window 20
Epoch: [84][20/59]	Time  1.409 ( 1.420)	Data  0.019 ( 0.029)	InnerLoop  0.586 ( 0.591)	Loss 6.6058e-01 (8.9375e-01)	Acc@1  74.95 ( 67.33)
Epoch: [84][40/59]	Time  1.404 ( 1.420)	Data  0.018 ( 0.026)	InnerLoop  0.587 ( 0.594)	Loss 9.1737e-01 (8.8431e-01)	Acc@1  66.85 ( 68.20)
The current update step is 5015
The current seed is 15849900500871740218
The current lr is: 0.001
Testing Results:
 *   Acc@1 60.158
 *   Acc@1 60.158
 *   Acc@1 62.316
 *   Acc@1 61.981
 *   Acc@1 63.237
 *   Acc@1 62.748
 *   Acc@1 73.776
 *   Acc@1 73.670
 *   Acc@1 72.632
 *   Acc@1 72.616
 *   Acc@1 70.461
 *   Acc@1 70.444
Training for 300 epoch: 66.96710526315789
Training for 600 epoch: 67.47368421052632
Training for 1000 epoch: 66.84868421052632
Training for 300 epoch: 66.91416666666666
Training for 600 epoch: 67.29833333333333
Training for 1000 epoch: 66.59583333333333
[[66.96710526315789, 67.47368421052632, 66.84868421052632], [66.91416666666666, 67.29833333333333, 66.59583333333333]]
train loss 0.3802619476477305, epoch 84, best loss 0.3143122046152751, best_epoch 34
GPU_0_using curriculum 20 with window 20
Epoch: [85][20/59]	Time  1.417 ( 1.421)	Data  0.018 ( 0.018)	InnerLoop  0.594 ( 0.603)	Loss 1.3878e+00 (8.3945e-01)	Acc@1  54.00 ( 69.75)
Epoch: [85][40/59]	Time  1.524 ( 1.427)	Data  0.130 ( 0.023)	InnerLoop  0.589 ( 0.602)	Loss 8.9584e-01 (8.4841e-01)	Acc@1  68.99 ( 69.38)
The current update step is 5074
GPU_0_using curriculum 20 with window 20
Epoch: [86][20/59]	Time  1.413 ( 1.424)	Data  0.020 ( 0.029)	InnerLoop  0.592 ( 0.593)	Loss 6.8656e-01 (8.3843e-01)	Acc@1  74.56 ( 68.33)
Epoch: [86][40/59]	Time  1.407 ( 1.427)	Data  0.017 ( 0.026)	InnerLoop  0.587 ( 0.599)	Loss 9.0984e-01 (8.6129e-01)	Acc@1  67.92 ( 68.00)
The current update step is 5133
GPU_0_using curriculum 20 with window 20
Epoch: [87][20/59]	Time  1.409 ( 1.422)	Data  0.017 ( 0.029)	InnerLoop  0.592 ( 0.593)	Loss 6.1818e-01 (9.3632e-01)	Acc@1  78.42 ( 66.71)
Epoch: [87][40/59]	Time  1.517 ( 1.427)	Data  0.020 ( 0.024)	InnerLoop  0.695 ( 0.602)	Loss 1.0654e+00 (9.3494e-01)	Acc@1  64.36 ( 67.02)
The current update step is 5192
GPU_0_using curriculum 20 with window 20
Epoch: [88][20/59]	Time  1.402 ( 1.423)	Data  0.017 ( 0.024)	InnerLoop  0.587 ( 0.599)	Loss 7.6013e-01 (8.2755e-01)	Acc@1  72.56 ( 68.30)
Epoch: [88][40/59]	Time  1.513 ( 1.426)	Data  0.018 ( 0.020)	InnerLoop  0.694 ( 0.604)	Loss 7.1993e-01 (8.2467e-01)	Acc@1  72.36 ( 68.54)
The current update step is 5251
GPU_0_using curriculum 20 with window 20
Epoch: [89][20/59]	Time  1.406 ( 1.423)	Data  0.017 ( 0.024)	InnerLoop  0.590 ( 0.599)	Loss 6.1405e-01 (8.2884e-01)	Acc@1  75.20 ( 68.14)
Epoch: [89][40/59]	Time  1.522 ( 1.426)	Data  0.019 ( 0.021)	InnerLoop  0.699 ( 0.604)	Loss 7.9051e-01 (8.1721e-01)	Acc@1  70.80 ( 68.93)
The current update step is 5310
The current seed is 5632316102518318466
The current lr is: 0.001
Testing Results:
 *   Acc@1 72.697
 *   Acc@1 72.983
 *   Acc@1 72.724
 *   Acc@1 73.248
 *   Acc@1 73.934
 *   Acc@1 74.239
 *   Acc@1 72.987
 *   Acc@1 73.734
 *   Acc@1 71.421
 *   Acc@1 71.886
 *   Acc@1 70.842
 *   Acc@1 70.724
Training for 300 epoch: 72.84210526315789
Training for 600 epoch: 72.07236842105263
Training for 1000 epoch: 72.38815789473685
Training for 300 epoch: 73.35833333333333
Training for 600 epoch: 72.56666666666666
Training for 1000 epoch: 72.48166666666665
[[72.84210526315789, 72.07236842105263, 72.38815789473685], [73.35833333333333, 72.56666666666666, 72.48166666666665]]
train loss 0.4118485284805298, epoch 89, best loss 0.3143122046152751, best_epoch 34
GPU_0_using curriculum 20 with window 20
Epoch: [90][20/59]	Time  1.515 ( 1.427)	Data  0.016 ( 0.023)	InnerLoop  0.694 ( 0.604)	Loss 7.0146e-01 (8.8691e-01)	Acc@1  71.97 ( 67.39)
Epoch: [90][40/59]	Time  1.406 ( 1.425)	Data  0.018 ( 0.021)	InnerLoop  0.587 ( 0.604)	Loss 7.5293e-01 (9.1358e-01)	Acc@1  71.97 ( 66.73)
The current update step is 5369
GPU_0_using curriculum 20 with window 20
Epoch: [91][20/59]	Time  1.413 ( 1.426)	Data  0.017 ( 0.030)	InnerLoop  0.591 ( 0.595)	Loss 5.8815e-01 (8.9168e-01)	Acc@1  77.69 ( 67.07)
Epoch: [91][40/59]	Time  1.514 ( 1.429)	Data  0.017 ( 0.027)	InnerLoop  0.697 ( 0.601)	Loss 8.8821e-01 (8.5163e-01)	Acc@1  65.92 ( 67.97)
The current update step is 5428
GPU_0_using curriculum 20 with window 20
Epoch: [92][20/59]	Time  1.407 ( 1.423)	Data  0.017 ( 0.023)	InnerLoop  0.587 ( 0.599)	Loss 6.8805e-01 (8.0132e-01)	Acc@1  72.31 ( 69.70)
Epoch: [92][40/59]	Time  1.401 ( 1.427)	Data  0.018 ( 0.024)	InnerLoop  0.585 ( 0.602)	Loss 6.6863e-01 (8.3464e-01)	Acc@1  74.90 ( 69.12)
The current update step is 5487
GPU_0_using curriculum 20 with window 20
Epoch: [93][20/59]	Time  1.409 ( 1.424)	Data  0.018 ( 0.029)	InnerLoop  0.587 ( 0.594)	Loss 6.1569e-01 (8.1232e-01)	Acc@1  76.56 ( 68.52)
Epoch: [93][40/59]	Time  1.408 ( 1.423)	Data  0.017 ( 0.026)	InnerLoop  0.591 ( 0.596)	Loss 7.0030e-01 (8.9433e-01)	Acc@1  75.98 ( 67.70)
The current update step is 5546
GPU_0_using curriculum 20 with window 20
Epoch: [94][20/59]	Time  1.411 ( 1.422)	Data  0.017 ( 0.029)	InnerLoop  0.590 ( 0.594)	Loss 6.6389e-01 (8.3060e-01)	Acc@1  74.27 ( 68.36)
Epoch: [94][40/59]	Time  1.411 ( 1.423)	Data  0.017 ( 0.026)	InnerLoop  0.592 ( 0.596)	Loss 7.4521e-01 (8.3170e-01)	Acc@1  72.12 ( 68.55)
The current update step is 5605
The current seed is 4617109878204021074
The current lr is: 0.001
Testing Results:
 *   Acc@1 72.855
 *   Acc@1 73.475
 *   Acc@1 71.921
 *   Acc@1 72.308
 *   Acc@1 70.645
 *   Acc@1 71.264
 *   Acc@1 69.289
 *   Acc@1 70.015
 *   Acc@1 73.066
 *   Acc@1 73.703
 *   Acc@1 73.816
 *   Acc@1 74.429
Training for 300 epoch: 71.07236842105263
Training for 600 epoch: 72.49342105263158
Training for 1000 epoch: 72.23026315789474
Training for 300 epoch: 71.745
Training for 600 epoch: 73.00583333333333
Training for 1000 epoch: 72.84666666666666
[[71.07236842105263, 72.49342105263158, 72.23026315789474], [71.745, 73.00583333333333, 72.84666666666666]]
train loss 0.40785429291725156, epoch 94, best loss 0.3143122046152751, best_epoch 94
GPU_0_using curriculum 20 with window 20
Epoch: [95][20/59]	Time  1.416 ( 1.426)	Data  0.018 ( 0.018)	InnerLoop  0.588 ( 0.606)	Loss 6.5947e-01 (8.8928e-01)	Acc@1  74.66 ( 68.36)
Epoch: [95][40/59]	Time  1.525 ( 1.429)	Data  0.129 ( 0.023)	InnerLoop  0.588 ( 0.603)	Loss 1.1711e+00 (8.5225e-01)	Acc@1  60.64 ( 69.28)
The current update step is 5664
GPU_0_using curriculum 20 with window 20
Epoch: [96][20/59]	Time  1.415 ( 1.423)	Data  0.020 ( 0.029)	InnerLoop  0.592 ( 0.594)	Loss 1.0975e+00 (8.3320e-01)	Acc@1  64.70 ( 70.08)
Epoch: [96][40/59]	Time  1.408 ( 1.427)	Data  0.017 ( 0.026)	InnerLoop  0.588 ( 0.599)	Loss 7.0683e-01 (8.3243e-01)	Acc@1  73.14 ( 70.04)
The current update step is 5723
GPU_0_using curriculum 20 with window 20
Epoch: [97][20/59]	Time  1.404 ( 1.423)	Data  0.017 ( 0.029)	InnerLoop  0.588 ( 0.594)	Loss 9.2307e-01 (8.7172e-01)	Acc@1  61.82 ( 68.38)
Epoch: [97][40/59]	Time  1.514 ( 1.426)	Data  0.018 ( 0.023)	InnerLoop  0.691 ( 0.601)	Loss 1.0009e+00 (8.6502e-01)	Acc@1  61.47 ( 68.08)
The current update step is 5782
GPU_0_using curriculum 20 with window 20
Epoch: [98][20/59]	Time  1.412 ( 1.422)	Data  0.017 ( 0.023)	InnerLoop  0.593 ( 0.599)	Loss 8.4664e-01 (8.7709e-01)	Acc@1  71.09 ( 68.93)
Epoch: [98][40/59]	Time  1.513 ( 1.426)	Data  0.019 ( 0.020)	InnerLoop  0.694 ( 0.605)	Loss 1.0850e+00 (8.6585e-01)	Acc@1  59.81 ( 68.75)
The current update step is 5841
GPU_0_using curriculum 20 with window 20
Epoch: [99][20/59]	Time  1.410 ( 1.424)	Data  0.020 ( 0.024)	InnerLoop  0.589 ( 0.598)	Loss 7.8160e-01 (7.8100e-01)	Acc@1  68.65 ( 71.40)
Epoch: [99][40/59]	Time  1.524 ( 1.426)	Data  0.018 ( 0.021)	InnerLoop  0.701 ( 0.603)	Loss 8.4726e-01 (8.0904e-01)	Acc@1  66.80 ( 70.36)
The current update step is 5900
The current seed is 6866197400164235773
The current lr is: 0.001
Testing Results:
 *   Acc@1 74.553
 *   Acc@1 74.852
 *   Acc@1 75.224
 *   Acc@1 75.398
 *   Acc@1 73.184
 *   Acc@1 73.611
 *   Acc@1 73.039
 *   Acc@1 72.798
 *   Acc@1 70.724
 *   Acc@1 70.703
 *   Acc@1 70.645
 *   Acc@1 70.401
Training for 300 epoch: 73.79605263157895
Training for 600 epoch: 72.97368421052632
Training for 1000 epoch: 71.91447368421052
Training for 300 epoch: 73.825
Training for 600 epoch: 73.05041666666666
Training for 1000 epoch: 72.00583333333333
[[73.79605263157895, 72.97368421052632, 71.91447368421052], [73.825, 73.05041666666666, 72.00583333333333]]
train loss 0.37656861046155293, epoch 99, best loss 0.3143122046152751, best_epoch 94
GPU_0_using curriculum 20 with window 20
Epoch: [100][20/59]	Time  1.518 ( 1.431)	Data  0.018 ( 0.024)	InnerLoop  0.699 ( 0.607)	Loss 6.5358e-01 (8.7234e-01)	Acc@1  75.05 ( 68.87)
Epoch: [100][40/59]	Time  1.411 ( 1.427)	Data  0.017 ( 0.021)	InnerLoop  0.593 ( 0.605)	Loss 8.7323e-01 (8.5929e-01)	Acc@1  66.21 ( 68.93)
The current update step is 5959
GPU_0_using curriculum 20 with window 20
Epoch: [101][20/59]	Time  1.411 ( 1.423)	Data  0.017 ( 0.029)	InnerLoop  0.592 ( 0.594)	Loss 9.9436e-01 (8.5072e-01)	Acc@1  65.43 ( 68.38)
Epoch: [101][40/59]	Time  1.514 ( 1.425)	Data  0.017 ( 0.026)	InnerLoop  0.694 ( 0.598)	Loss 9.3287e-01 (8.6972e-01)	Acc@1  65.43 ( 68.35)
The current update step is 6018
GPU_0_using curriculum 20 with window 20
Epoch: [102][20/59]	Time  1.409 ( 1.425)	Data  0.017 ( 0.024)	InnerLoop  0.587 ( 0.598)	Loss 8.1888e-01 (9.8174e-01)	Acc@1  68.95 ( 65.24)
Epoch: [102][40/59]	Time  1.417 ( 1.428)	Data  0.017 ( 0.024)	InnerLoop  0.597 ( 0.601)	Loss 7.1204e-01 (8.7508e-01)	Acc@1  71.63 ( 68.21)
The current update step is 6077
GPU_0_using curriculum 20 with window 20
Epoch: [103][20/59]	Time  1.409 ( 1.421)	Data  0.018 ( 0.029)	InnerLoop  0.589 ( 0.592)	Loss 6.1007e-01 (9.1889e-01)	Acc@1  76.22 ( 68.55)
Epoch: [103][40/59]	Time  1.411 ( 1.422)	Data  0.019 ( 0.026)	InnerLoop  0.589 ( 0.594)	Loss 6.4686e-01 (8.8650e-01)	Acc@1  75.44 ( 68.80)
The current update step is 6136
GPU_0_using curriculum 20 with window 20
Epoch: [104][20/59]	Time  1.406 ( 1.423)	Data  0.020 ( 0.030)	InnerLoop  0.583 ( 0.593)	Loss 8.4328e-01 (1.0091e+00)	Acc@1  65.72 ( 64.28)
Epoch: [104][40/59]	Time  1.410 ( 1.423)	Data  0.019 ( 0.027)	InnerLoop  0.588 ( 0.595)	Loss 9.8949e-01 (1.0116e+00)	Acc@1  67.92 ( 64.63)
The current update step is 6195
The current seed is 4232298576970057095
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.329
 *   Acc@1 76.858
 *   Acc@1 77.132
 *   Acc@1 76.858
 *   Acc@1 76.855
 *   Acc@1 76.577
 *   Acc@1 69.697
 *   Acc@1 70.543
 *   Acc@1 67.289
 *   Acc@1 67.603
 *   Acc@1 63.013
 *   Acc@1 62.940
Training for 300 epoch: 73.51315789473685
Training for 600 epoch: 72.21052631578948
Training for 1000 epoch: 69.9342105263158
Training for 300 epoch: 73.70083333333334
Training for 600 epoch: 72.23
Training for 1000 epoch: 69.75833333333333
[[73.51315789473685, 72.21052631578948, 69.9342105263158], [73.70083333333334, 72.23, 69.75833333333333]]
train loss 0.4494531091372172, epoch 104, best loss 0.3143122046152751, best_epoch 94
GPU_0_using curriculum 20 with window 20
Epoch: [105][20/59]	Time  1.408 ( 1.423)	Data  0.018 ( 0.018)	InnerLoop  0.586 ( 0.604)	Loss 8.1853e-01 (8.9249e-01)	Acc@1  69.34 ( 68.49)
Epoch: [105][40/59]	Time  1.515 ( 1.425)	Data  0.127 ( 0.023)	InnerLoop  0.588 ( 0.601)	Loss 8.2183e-01 (9.3213e-01)	Acc@1  66.55 ( 67.14)
The current update step is 6254
GPU_0_using curriculum 20 with window 20
Epoch: [106][20/59]	Time  1.398 ( 1.421)	Data  0.018 ( 0.029)	InnerLoop  0.582 ( 0.593)	Loss 8.0210e-01 (9.4830e-01)	Acc@1  70.70 ( 65.16)
Epoch: [106][40/59]	Time  1.410 ( 1.424)	Data  0.017 ( 0.026)	InnerLoop  0.591 ( 0.598)	Loss 6.3910e-01 (8.9726e-01)	Acc@1  75.98 ( 66.86)
The current update step is 6313
GPU_0_using curriculum 20 with window 20
Epoch: [107][20/59]	Time  1.397 ( 1.420)	Data  0.017 ( 0.029)	InnerLoop  0.582 ( 0.591)	Loss 7.4536e-01 (7.6455e-01)	Acc@1  73.44 ( 71.20)
Epoch: [107][40/59]	Time  1.515 ( 1.424)	Data  0.017 ( 0.023)	InnerLoop  0.692 ( 0.600)	Loss 7.0884e-01 (8.2027e-01)	Acc@1  73.54 ( 70.02)
The current update step is 6372
GPU_0_using curriculum 20 with window 20
Epoch: [108][20/59]	Time  1.407 ( 1.423)	Data  0.017 ( 0.024)	InnerLoop  0.588 ( 0.599)	Loss 1.0407e+00 (8.0168e-01)	Acc@1  65.48 ( 70.72)
Epoch: [108][40/59]	Time  1.513 ( 1.426)	Data  0.018 ( 0.021)	InnerLoop  0.693 ( 0.604)	Loss 8.8125e-01 (8.1808e-01)	Acc@1  61.77 ( 69.81)
The current update step is 6431
GPU_0_using curriculum 20 with window 20
Epoch: [109][20/59]	Time  1.414 ( 1.421)	Data  0.019 ( 0.024)	InnerLoop  0.592 ( 0.598)	Loss 1.0305e+00 (9.5705e-01)	Acc@1  59.67 ( 65.17)
Epoch: [109][40/59]	Time  1.514 ( 1.425)	Data  0.018 ( 0.020)	InnerLoop  0.697 ( 0.603)	Loss 8.3973e-01 (9.0691e-01)	Acc@1  68.41 ( 66.39)
The current update step is 6490
The current seed is 10971403767564425449
The current lr is: 0.001
Testing Results:
 *   Acc@1 68.632
 *   Acc@1 68.544
 *   Acc@1 65.816
 *   Acc@1 66.104
 *   Acc@1 64.487
 *   Acc@1 64.804
 *   Acc@1 74.000
 *   Acc@1 74.638
 *   Acc@1 69.868
 *   Acc@1 70.344
 *   Acc@1 67.974
 *   Acc@1 68.543
Training for 300 epoch: 71.31578947368422
Training for 600 epoch: 67.84210526315789
Training for 1000 epoch: 66.23026315789474
Training for 300 epoch: 71.59083333333334
Training for 600 epoch: 68.22416666666666
Training for 1000 epoch: 66.67375
[[71.31578947368422, 67.84210526315789, 66.23026315789474], [71.59083333333334, 68.22416666666666, 66.67375]]
train loss 0.40500839172999065, epoch 109, best loss 0.3143122046152751, best_epoch 94
GPU_0_using curriculum 20 with window 20
Epoch: [110][20/59]	Time  1.516 ( 1.430)	Data  0.017 ( 0.023)	InnerLoop  0.695 ( 0.605)	Loss 8.4820e-01 (8.0628e-01)	Acc@1  72.46 ( 70.14)
Epoch: [110][40/59]	Time  1.405 ( 1.427)	Data  0.017 ( 0.021)	InnerLoop  0.587 ( 0.605)	Loss 6.2752e-01 (8.2043e-01)	Acc@1  77.49 ( 69.99)
The current update step is 6549
GPU_0_using curriculum 20 with window 20
Epoch: [111][20/59]	Time  1.399 ( 1.422)	Data  0.017 ( 0.029)	InnerLoop  0.584 ( 0.593)	Loss 9.2026e-01 (8.2143e-01)	Acc@1  65.72 ( 69.37)
Epoch: [111][40/59]	Time  1.513 ( 1.427)	Data  0.017 ( 0.026)	InnerLoop  0.696 ( 0.599)	Loss 8.1782e-01 (8.4764e-01)	Acc@1  66.46 ( 68.88)
The current update step is 6608
GPU_0_using curriculum 20 with window 20
Epoch: [112][20/59]	Time  1.399 ( 1.421)	Data  0.017 ( 0.024)	InnerLoop  0.583 ( 0.597)	Loss 1.0747e+00 (9.2106e-01)	Acc@1  59.91 ( 66.48)
Epoch: [112][40/59]	Time  1.408 ( 1.427)	Data  0.018 ( 0.024)	InnerLoop  0.587 ( 0.601)	Loss 7.4291e-01 (9.1043e-01)	Acc@1  73.83 ( 66.87)
The current update step is 6667
GPU_0_using curriculum 20 with window 20
Epoch: [113][20/59]	Time  1.412 ( 1.427)	Data  0.017 ( 0.030)	InnerLoop  0.593 ( 0.596)	Loss 8.1685e-01 (9.2829e-01)	Acc@1  66.89 ( 66.59)
Epoch: [113][40/59]	Time  1.405 ( 1.426)	Data  0.018 ( 0.027)	InnerLoop  0.585 ( 0.598)	Loss 8.7095e-01 (8.6418e-01)	Acc@1  67.82 ( 68.30)
The current update step is 6726
GPU_0_using curriculum 20 with window 20
Epoch: [114][20/59]	Time  1.416 ( 1.424)	Data  0.019 ( 0.029)	InnerLoop  0.591 ( 0.594)	Loss 7.2770e-01 (8.7583e-01)	Acc@1  74.07 ( 68.55)
Epoch: [114][40/59]	Time  1.416 ( 1.426)	Data  0.017 ( 0.027)	InnerLoop  0.590 ( 0.597)	Loss 7.3058e-01 (8.9296e-01)	Acc@1  72.61 ( 68.22)
The current update step is 6785
The current seed is 17335611815631417428
The current lr is: 0.001
Testing Results:
 *   Acc@1 72.250
 *   Acc@1 72.144
 *   Acc@1 69.987
 *   Acc@1 69.995
 *   Acc@1 68.947
 *   Acc@1 68.880
 *   Acc@1 67.487
 *   Acc@1 68.188
 *   Acc@1 62.434
 *   Acc@1 62.689
 *   Acc@1 62.684
 *   Acc@1 62.662
Training for 300 epoch: 69.86842105263159
Training for 600 epoch: 66.21052631578948
Training for 1000 epoch: 65.8157894736842
Training for 300 epoch: 70.16624999999999
Training for 600 epoch: 66.34208333333333
Training for 1000 epoch: 65.77083333333333
[[69.86842105263159, 66.21052631578948, 65.8157894736842], [70.16624999999999, 66.34208333333333, 65.77083333333333]]
train loss 0.5147512402534485, epoch 114, best loss 0.3143122046152751, best_epoch 94
GPU_0_using curriculum 20 with window 20
Epoch: [115][20/59]	Time  1.412 ( 1.424)	Data  0.018 ( 0.017)	InnerLoop  0.592 ( 0.605)	Loss 7.0859e-01 (8.0145e-01)	Acc@1  73.00 ( 70.35)
Epoch: [115][40/59]	Time  1.519 ( 1.430)	Data  0.131 ( 0.023)	InnerLoop  0.587 ( 0.604)	Loss 6.9174e-01 (8.5323e-01)	Acc@1  74.76 ( 69.27)
The current update step is 6844
GPU_0_using curriculum 20 with window 20
Epoch: [116][20/59]	Time  1.418 ( 1.431)	Data  0.019 ( 0.030)	InnerLoop  0.591 ( 0.597)	Loss 7.5766e-01 (8.3422e-01)	Acc@1  71.53 ( 68.81)
Epoch: [116][40/59]	Time  1.426 ( 1.435)	Data  0.017 ( 0.027)	InnerLoop  0.600 ( 0.603)	Loss 1.0870e+00 (8.6033e-01)	Acc@1  60.84 ( 67.94)
The current update step is 6903
GPU_0_using curriculum 20 with window 20
Epoch: [117][20/59]	Time  1.397 ( 1.424)	Data  0.018 ( 0.030)	InnerLoop  0.581 ( 0.594)	Loss 1.0119e+00 (8.5891e-01)	Acc@1  57.81 ( 66.48)
Epoch: [117][40/59]	Time  1.523 ( 1.428)	Data  0.018 ( 0.024)	InnerLoop  0.699 ( 0.602)	Loss 8.0911e-01 (8.9111e-01)	Acc@1  66.06 ( 67.22)
The current update step is 6962
GPU_0_using curriculum 20 with window 20
Epoch: [118][20/59]	Time  1.416 ( 1.426)	Data  0.019 ( 0.024)	InnerLoop  0.588 ( 0.600)	Loss 1.0069e+00 (7.4648e-01)	Acc@1  64.45 ( 72.30)
Epoch: [118][40/59]	Time  1.520 ( 1.429)	Data  0.019 ( 0.021)	InnerLoop  0.695 ( 0.605)	Loss 6.5785e-01 (7.9688e-01)	Acc@1  76.27 ( 70.55)
The current update step is 7021
GPU_0_using curriculum 20 with window 20
Epoch: [119][20/59]	Time  1.414 ( 1.424)	Data  0.019 ( 0.024)	InnerLoop  0.591 ( 0.599)	Loss 8.9191e-01 (7.9545e-01)	Acc@1  67.63 ( 70.26)
Epoch: [119][40/59]	Time  1.517 ( 1.430)	Data  0.020 ( 0.021)	InnerLoop  0.698 ( 0.606)	Loss 8.3959e-01 (7.7323e-01)	Acc@1  67.53 ( 71.14)
The current update step is 7080
The current seed is 18271188709054604939
The current lr is: 0.001
Testing Results:
 *   Acc@1 68.382
 *   Acc@1 68.078
 *   Acc@1 64.724
 *   Acc@1 64.603
 *   Acc@1 62.789
 *   Acc@1 62.227
 *   Acc@1 71.934
 *   Acc@1 72.759
 *   Acc@1 70.737
 *   Acc@1 71.483
 *   Acc@1 70.539
 *   Acc@1 71.521
Training for 300 epoch: 70.15789473684211
Training for 600 epoch: 67.73026315789474
Training for 1000 epoch: 66.66447368421052
Training for 300 epoch: 70.41875
Training for 600 epoch: 68.04291666666667
Training for 1000 epoch: 66.87416666666667
[[70.15789473684211, 67.73026315789474, 66.66447368421052], [70.41875, 68.04291666666667, 66.87416666666667]]
train loss 0.3913210579395294, epoch 119, best loss 0.3143122046152751, best_epoch 94
GPU_0_using curriculum 20 with window 20
Epoch: [120][20/59]	Time  1.521 ( 1.428)	Data  0.018 ( 0.023)	InnerLoop  0.699 ( 0.604)	Loss 8.1244e-01 (8.2737e-01)	Acc@1  70.46 ( 69.70)
Epoch: [120][40/59]	Time  1.397 ( 1.427)	Data  0.018 ( 0.021)	InnerLoop  0.583 ( 0.604)	Loss 7.0458e-01 (8.5530e-01)	Acc@1  71.97 ( 68.91)
The current update step is 7139
GPU_0_using curriculum 20 with window 20
Epoch: [121][20/59]	Time  1.398 ( 1.421)	Data  0.016 ( 0.029)	InnerLoop  0.584 ( 0.591)	Loss 1.6408e+00 (9.2817e-01)	Acc@1  43.65 ( 67.24)
Epoch: [121][40/59]	Time  1.521 ( 1.425)	Data  0.017 ( 0.026)	InnerLoop  0.699 ( 0.597)	Loss 7.8423e-01 (8.7563e-01)	Acc@1  69.24 ( 67.77)
The current update step is 7198
GPU_0_using curriculum 20 with window 20
Epoch: [122][20/59]	Time  1.408 ( 1.427)	Data  0.018 ( 0.025)	InnerLoop  0.582 ( 0.599)	Loss 8.4241e-01 (8.0350e-01)	Acc@1  65.82 ( 70.86)
Epoch: [122][40/59]	Time  1.427 ( 1.432)	Data  0.020 ( 0.024)	InnerLoop  0.594 ( 0.602)	Loss 8.1988e-01 (8.0195e-01)	Acc@1  68.12 ( 70.61)
The current update step is 7257
GPU_0_using curriculum 20 with window 20
Epoch: [123][20/59]	Time  1.415 ( 1.426)	Data  0.017 ( 0.029)	InnerLoop  0.591 ( 0.593)	Loss 6.3534e-01 (1.0186e+00)	Acc@1  74.02 ( 65.19)
Epoch: [123][40/59]	Time  1.406 ( 1.430)	Data  0.018 ( 0.027)	InnerLoop  0.585 ( 0.598)	Loss 6.4136e-01 (8.9146e-01)	Acc@1  75.39 ( 68.44)
The current update step is 7316
GPU_0_using curriculum 20 with window 20
Epoch: [124][20/59]	Time  1.405 ( 1.421)	Data  0.017 ( 0.029)	InnerLoop  0.587 ( 0.591)	Loss 9.5129e-01 (9.1323e-01)	Acc@1  68.70 ( 66.87)
Epoch: [124][40/59]	Time  1.398 ( 1.421)	Data  0.018 ( 0.026)	InnerLoop  0.581 ( 0.594)	Loss 1.0042e+00 (8.7702e-01)	Acc@1  64.36 ( 67.34)
The current update step is 7375
The current seed is 13609847564309617848
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.868
 *   Acc@1 71.371
 *   Acc@1 68.961
 *   Acc@1 69.723
 *   Acc@1 67.855
 *   Acc@1 68.520
 *   Acc@1 75.355
 *   Acc@1 75.244
 *   Acc@1 76.408
 *   Acc@1 76.492
 *   Acc@1 76.408
 *   Acc@1 76.224
Training for 300 epoch: 73.11184210526315
Training for 600 epoch: 72.6842105263158
Training for 1000 epoch: 72.13157894736842
Training for 300 epoch: 73.3075
Training for 600 epoch: 73.10749999999999
Training for 1000 epoch: 72.37208333333334
[[73.11184210526315, 72.6842105263158, 72.13157894736842], [73.3075, 73.10749999999999, 72.37208333333334]]
train loss 0.3382251338164012, epoch 124, best loss 0.3143122046152751, best_epoch 94
GPU_0_using curriculum 20 with window 20
Epoch: [125][20/59]	Time  1.404 ( 1.420)	Data  0.019 ( 0.017)	InnerLoop  0.583 ( 0.602)	Loss 1.3003e+00 (8.6638e-01)	Acc@1  57.76 ( 68.81)
Epoch: [125][40/59]	Time  1.519 ( 1.425)	Data  0.133 ( 0.023)	InnerLoop  0.584 ( 0.600)	Loss 6.6280e-01 (8.2852e-01)	Acc@1  75.98 ( 69.56)
The current update step is 7434
GPU_0_using curriculum 20 with window 20
Epoch: [126][20/59]	Time  1.412 ( 1.423)	Data  0.018 ( 0.029)	InnerLoop  0.589 ( 0.593)	Loss 6.9283e-01 (8.4110e-01)	Acc@1  73.73 ( 68.69)
Epoch: [126][40/59]	Time  1.416 ( 1.429)	Data  0.017 ( 0.027)	InnerLoop  0.591 ( 0.599)	Loss 6.5848e-01 (9.1181e-01)	Acc@1  74.80 ( 67.10)
The current update step is 7493
GPU_0_using curriculum 20 with window 20
Epoch: [127][20/59]	Time  1.405 ( 1.425)	Data  0.018 ( 0.029)	InnerLoop  0.587 ( 0.594)	Loss 7.7254e-01 (8.5955e-01)	Acc@1  70.56 ( 68.48)
Epoch: [127][40/59]	Time  1.513 ( 1.428)	Data  0.017 ( 0.023)	InnerLoop  0.695 ( 0.602)	Loss 1.0037e+00 (8.1508e-01)	Acc@1  66.36 ( 69.84)
The current update step is 7552
GPU_0_using curriculum 20 with window 20
Epoch: [128][20/59]	Time  1.416 ( 1.425)	Data  0.019 ( 0.024)	InnerLoop  0.590 ( 0.600)	Loss 1.1386e+00 (9.8499e-01)	Acc@1  62.40 ( 65.01)
Epoch: [128][40/59]	Time  1.514 ( 1.429)	Data  0.017 ( 0.021)	InnerLoop  0.695 ( 0.605)	Loss 8.3359e-01 (9.5475e-01)	Acc@1  69.68 ( 65.78)
The current update step is 7611
GPU_0_using curriculum 20 with window 20
Epoch: [129][20/59]	Time  1.412 ( 1.424)	Data  0.018 ( 0.024)	InnerLoop  0.591 ( 0.600)	Loss 7.9184e-01 (8.8594e-01)	Acc@1  70.21 ( 68.50)
Epoch: [129][40/59]	Time  1.521 ( 1.428)	Data  0.018 ( 0.021)	InnerLoop  0.700 ( 0.606)	Loss 1.4930e+00 (8.6176e-01)	Acc@1  57.03 ( 68.90)
The current update step is 7670
The current seed is 10522654701390978613
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.211
 *   Acc@1 71.358
 *   Acc@1 63.250
 *   Acc@1 63.937
 *   Acc@1 60.526
 *   Acc@1 60.987
 *   Acc@1 72.224
 *   Acc@1 71.958
 *   Acc@1 72.118
 *   Acc@1 72.407
 *   Acc@1 71.908
 *   Acc@1 71.663
Training for 300 epoch: 71.71710526315789
Training for 600 epoch: 67.68421052631578
Training for 1000 epoch: 66.21710526315789
Training for 300 epoch: 71.65833333333333
Training for 600 epoch: 68.17166666666667
Training for 1000 epoch: 66.32499999999999
[[71.71710526315789, 67.68421052631578, 66.21710526315789], [71.65833333333333, 68.17166666666667, 66.32499999999999]]
train loss 0.4239950354099274, epoch 129, best loss 0.3143122046152751, best_epoch 94
GPU_0_using curriculum 20 with window 20
Epoch: [130][20/59]	Time  1.517 ( 1.428)	Data  0.018 ( 0.024)	InnerLoop  0.696 ( 0.604)	Loss 6.7851e-01 (9.7547e-01)	Acc@1  71.88 ( 65.04)
Epoch: [130][40/59]	Time  1.410 ( 1.427)	Data  0.019 ( 0.021)	InnerLoop  0.587 ( 0.604)	Loss 8.4265e-01 (9.5890e-01)	Acc@1  70.70 ( 66.18)
The current update step is 7729
GPU_0_using curriculum 20 with window 20
Epoch: [131][20/59]	Time  1.408 ( 1.424)	Data  0.019 ( 0.030)	InnerLoop  0.586 ( 0.593)	Loss 9.2359e-01 (8.1512e-01)	Acc@1  67.04 ( 68.94)
Epoch: [131][40/59]	Time  1.520 ( 1.428)	Data  0.020 ( 0.027)	InnerLoop  0.695 ( 0.599)	Loss 8.4043e-01 (8.1690e-01)	Acc@1  67.63 ( 69.09)
The current update step is 7788
GPU_0_using curriculum 20 with window 20
Epoch: [132][20/59]	Time  1.416 ( 1.428)	Data  0.018 ( 0.024)	InnerLoop  0.594 ( 0.602)	Loss 6.8434e-01 (8.5907e-01)	Acc@1  74.51 ( 67.63)
Epoch: [132][40/59]	Time  1.407 ( 1.431)	Data  0.019 ( 0.024)	InnerLoop  0.587 ( 0.605)	Loss 8.1109e-01 (8.4661e-01)	Acc@1  67.92 ( 68.00)
The current update step is 7847
GPU_0_using curriculum 20 with window 20
Epoch: [133][20/59]	Time  1.412 ( 1.428)	Data  0.019 ( 0.029)	InnerLoop  0.589 ( 0.596)	Loss 6.5571e-01 (7.5638e-01)	Acc@1  76.71 ( 71.79)
Epoch: [133][40/59]	Time  1.413 ( 1.428)	Data  0.020 ( 0.027)	InnerLoop  0.591 ( 0.598)	Loss 1.0259e+00 (7.7616e-01)	Acc@1  60.06 ( 70.80)
The current update step is 7906
GPU_0_using curriculum 20 with window 20
Epoch: [134][20/59]	Time  1.412 ( 1.425)	Data  0.017 ( 0.029)	InnerLoop  0.589 ( 0.594)	Loss 6.1238e-01 (8.0765e-01)	Acc@1  77.88 ( 70.70)
Epoch: [134][40/59]	Time  1.407 ( 1.424)	Data  0.019 ( 0.026)	InnerLoop  0.583 ( 0.596)	Loss 7.9581e-01 (7.9286e-01)	Acc@1  68.51 ( 70.79)
The current update step is 7965
The current seed is 5844096575743760786
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.566
 *   Acc@1 72.128
 *   Acc@1 70.474
 *   Acc@1 70.874
 *   Acc@1 69.934
 *   Acc@1 70.092
 *   Acc@1 73.053
 *   Acc@1 73.116
 *   Acc@1 71.776
 *   Acc@1 72.017
 *   Acc@1 68.158
 *   Acc@1 68.515
Training for 300 epoch: 72.30921052631578
Training for 600 epoch: 71.125
Training for 1000 epoch: 69.04605263157896
Training for 300 epoch: 72.62208333333334
Training for 600 epoch: 71.44583333333333
Training for 1000 epoch: 69.30333333333334
[[72.30921052631578, 71.125, 69.04605263157896], [72.62208333333334, 71.44583333333333, 69.30333333333334]]
train loss 0.47741441346804303, epoch 134, best loss 0.3143122046152751, best_epoch 94
GPU_0_using curriculum 20 with window 20
Epoch: [135][20/59]	Time  1.402 ( 1.423)	Data  0.018 ( 0.018)	InnerLoop  0.583 ( 0.604)	Loss 7.6653e-01 (8.2129e-01)	Acc@1  72.17 ( 69.70)
Epoch: [135][40/59]	Time  1.520 ( 1.426)	Data  0.128 ( 0.023)	InnerLoop  0.589 ( 0.601)	Loss 1.2315e+00 (8.4555e-01)	Acc@1  57.71 ( 69.14)
The current update step is 8024
GPU_0_using curriculum 20 with window 20
Epoch: [136][20/59]	Time  1.412 ( 1.422)	Data  0.021 ( 0.030)	InnerLoop  0.588 ( 0.592)	Loss 6.4091e-01 (9.0956e-01)	Acc@1  75.59 ( 68.17)
Epoch: [136][40/59]	Time  1.409 ( 1.425)	Data  0.019 ( 0.027)	InnerLoop  0.588 ( 0.597)	Loss 6.2947e-01 (8.3528e-01)	Acc@1  77.00 ( 69.80)
The current update step is 8083
GPU_0_using curriculum 20 with window 20
Epoch: [137][20/59]	Time  1.419 ( 1.422)	Data  0.018 ( 0.029)	InnerLoop  0.595 ( 0.592)	Loss 8.9352e-01 (7.9187e-01)	Acc@1  67.24 ( 71.29)
Epoch: [137][40/59]	Time  1.523 ( 1.427)	Data  0.018 ( 0.024)	InnerLoop  0.698 ( 0.601)	Loss 6.0005e-01 (8.0112e-01)	Acc@1  78.61 ( 70.64)
The current update step is 8142
GPU_0_using curriculum 20 with window 20
Epoch: [138][20/59]	Time  1.407 ( 1.422)	Data  0.017 ( 0.023)	InnerLoop  0.587 ( 0.598)	Loss 6.3907e-01 (7.8328e-01)	Acc@1  75.63 ( 70.71)
Epoch: [138][40/59]	Time  1.517 ( 1.425)	Data  0.017 ( 0.021)	InnerLoop  0.694 ( 0.603)	Loss 9.3900e-01 (7.6886e-01)	Acc@1  64.70 ( 71.22)
The current update step is 8201
GPU_0_using curriculum 20 with window 20
Epoch: [139][20/59]	Time  1.406 ( 1.422)	Data  0.018 ( 0.023)	InnerLoop  0.588 ( 0.599)	Loss 7.8616e-01 (8.0377e-01)	Acc@1  72.85 ( 70.37)
Epoch: [139][40/59]	Time  1.525 ( 1.427)	Data  0.019 ( 0.021)	InnerLoop  0.699 ( 0.604)	Loss 6.3092e-01 (7.7233e-01)	Acc@1  75.98 ( 71.35)
The current update step is 8260
The current seed is 11442572336236182609
The current lr is: 0.001
Testing Results:
 *   Acc@1 75.684
 *   Acc@1 75.788
 *   Acc@1 76.461
 *   Acc@1 76.574
 *   Acc@1 75.579
 *   Acc@1 76.188
 *   Acc@1 74.197
 *   Acc@1 74.132
 *   Acc@1 72.868
 *   Acc@1 72.970
 *   Acc@1 72.500
 *   Acc@1 73.213
Training for 300 epoch: 74.94078947368422
Training for 600 epoch: 74.66447368421052
Training for 1000 epoch: 74.03947368421052
Training for 300 epoch: 74.96041666666666
Training for 600 epoch: 74.77208333333334
Training for 1000 epoch: 74.70083333333334
[[74.94078947368422, 74.66447368421052, 74.03947368421052], [74.96041666666666, 74.77208333333334, 74.70083333333334]]
train loss 0.3710703495502472, epoch 139, best loss 0.3143122046152751, best_epoch 94
GPU_0_using curriculum 20 with window 20
Epoch: [140][20/59]	Time  1.521 ( 1.428)	Data  0.018 ( 0.023)	InnerLoop  0.694 ( 0.603)	Loss 6.8991e-01 (7.4051e-01)	Acc@1  74.41 ( 72.32)
Epoch: [140][40/59]	Time  1.404 ( 1.427)	Data  0.018 ( 0.020)	InnerLoop  0.587 ( 0.604)	Loss 7.4334e-01 (7.3218e-01)	Acc@1  75.15 ( 72.82)
The current update step is 8319
GPU_0_using curriculum 20 with window 20
Epoch: [141][20/59]	Time  1.408 ( 1.424)	Data  0.018 ( 0.030)	InnerLoop  0.586 ( 0.593)	Loss 6.5694e-01 (7.9197e-01)	Acc@1  76.76 ( 71.46)
Epoch: [141][40/59]	Time  1.516 ( 1.427)	Data  0.018 ( 0.027)	InnerLoop  0.692 ( 0.598)	Loss 8.7620e-01 (7.7306e-01)	Acc@1  70.85 ( 71.95)
The current update step is 8378
GPU_0_using curriculum 20 with window 20
Epoch: [142][20/59]	Time  1.408 ( 1.425)	Data  0.018 ( 0.024)	InnerLoop  0.586 ( 0.599)	Loss 6.6263e-01 (7.6893e-01)	Acc@1  75.88 ( 71.68)
Epoch: [142][40/59]	Time  1.410 ( 1.428)	Data  0.018 ( 0.024)	InnerLoop  0.586 ( 0.602)	Loss 6.9161e-01 (7.9931e-01)	Acc@1  74.07 ( 70.89)
The current update step is 8437
GPU_0_using curriculum 20 with window 20
Epoch: [143][20/59]	Time  1.415 ( 1.425)	Data  0.017 ( 0.030)	InnerLoop  0.592 ( 0.593)	Loss 7.6410e-01 (7.9280e-01)	Acc@1  71.14 ( 71.73)
Epoch: [143][40/59]	Time  1.404 ( 1.425)	Data  0.016 ( 0.027)	InnerLoop  0.588 ( 0.596)	Loss 7.9766e-01 (7.9676e-01)	Acc@1  72.36 ( 71.24)
The current update step is 8496
GPU_0_using curriculum 20 with window 20
Epoch: [144][20/59]	Time  1.410 ( 1.424)	Data  0.019 ( 0.029)	InnerLoop  0.589 ( 0.593)	Loss 1.0115e+00 (8.1384e-01)	Acc@1  65.38 ( 70.16)
Epoch: [144][40/59]	Time  1.407 ( 1.424)	Data  0.018 ( 0.027)	InnerLoop  0.585 ( 0.595)	Loss 6.5320e-01 (7.4043e-01)	Acc@1  75.29 ( 72.51)
The current update step is 8555
The current seed is 9235840887780146920
The current lr is: 0.001
Testing Results:
 *   Acc@1 78.579
 *   Acc@1 78.972
 *   Acc@1 75.776
 *   Acc@1 76.073
 *   Acc@1 72.605
 *   Acc@1 73.591
 *   Acc@1 76.039
 *   Acc@1 76.263
 *   Acc@1 75.303
 *   Acc@1 75.395
 *   Acc@1 74.026
 *   Acc@1 74.453
Training for 300 epoch: 77.30921052631578
Training for 600 epoch: 75.53947368421052
Training for 1000 epoch: 73.31578947368422
Training for 300 epoch: 77.6175
Training for 600 epoch: 75.73375
Training for 1000 epoch: 74.02166666666668
[[77.30921052631578, 75.53947368421052, 73.31578947368422], [77.6175, 75.73375, 74.02166666666668]]
train loss 0.35292087348302204, epoch 144, best loss 0.3143122046152751, best_epoch 94
GPU_0_using curriculum 20 with window 20
Epoch: [145][20/59]	Time  1.411 ( 1.423)	Data  0.019 ( 0.018)	InnerLoop  0.587 ( 0.604)	Loss 9.0379e-01 (7.7140e-01)	Acc@1  65.58 ( 71.14)
Epoch: [145][40/59]	Time  1.520 ( 1.427)	Data  0.130 ( 0.023)	InnerLoop  0.589 ( 0.601)	Loss 7.0935e-01 (7.6189e-01)	Acc@1  73.05 ( 71.42)
The current update step is 8614
GPU_0_using curriculum 20 with window 20
Epoch: [146][20/59]	Time  1.414 ( 1.421)	Data  0.020 ( 0.030)	InnerLoop  0.589 ( 0.592)	Loss 7.7060e-01 (7.1440e-01)	Acc@1  71.09 ( 73.42)
Epoch: [146][40/59]	Time  1.406 ( 1.427)	Data  0.017 ( 0.027)	InnerLoop  0.587 ( 0.598)	Loss 5.8030e-01 (6.9771e-01)	Acc@1  78.81 ( 73.96)
The current update step is 8673
GPU_0_using curriculum 20 with window 20
Epoch: [147][20/59]	Time  1.407 ( 1.423)	Data  0.018 ( 0.030)	InnerLoop  0.586 ( 0.592)	Loss 7.4098e-01 (7.6417e-01)	Acc@1  72.22 ( 71.83)
Epoch: [147][40/59]	Time  1.524 ( 1.427)	Data  0.018 ( 0.024)	InnerLoop  0.699 ( 0.601)	Loss 6.2202e-01 (7.9850e-01)	Acc@1  77.34 ( 70.74)
The current update step is 8732
GPU_0_using curriculum 20 with window 20
Epoch: [148][20/59]	Time  1.407 ( 1.423)	Data  0.017 ( 0.023)	InnerLoop  0.587 ( 0.598)	Loss 6.4106e-01 (8.4285e-01)	Acc@1  76.42 ( 70.20)
Epoch: [148][40/59]	Time  1.517 ( 1.427)	Data  0.019 ( 0.021)	InnerLoop  0.692 ( 0.604)	Loss 6.8757e-01 (7.8171e-01)	Acc@1  74.61 ( 71.86)
The current update step is 8791
GPU_0_using curriculum 20 with window 20
Epoch: [149][20/59]	Time  1.403 ( 1.423)	Data  0.019 ( 0.024)	InnerLoop  0.585 ( 0.598)	Loss 6.8954e-01 (8.1607e-01)	Acc@1  74.37 ( 70.10)
Epoch: [149][40/59]	Time  1.520 ( 1.427)	Data  0.019 ( 0.021)	InnerLoop  0.696 ( 0.604)	Loss 6.3958e-01 (7.6755e-01)	Acc@1  76.95 ( 71.79)
The current update step is 8850
The current seed is 2900890094336847155
The current lr is: 0.001
Testing Results:
 *   Acc@1 75.750
 *   Acc@1 75.536
 *   Acc@1 75.513
 *   Acc@1 75.498
 *   Acc@1 74.947
 *   Acc@1 75.153
 *   Acc@1 63.947
 *   Acc@1 63.877
 *   Acc@1 62.816
 *   Acc@1 62.842
 *   Acc@1 61.066
 *   Acc@1 61.051
Training for 300 epoch: 69.84868421052632
Training for 600 epoch: 69.16447368421052
Training for 1000 epoch: 68.00657894736842
Training for 300 epoch: 69.70625
Training for 600 epoch: 69.16958333333334
Training for 1000 epoch: 68.10208333333334
[[69.84868421052632, 69.16447368421052, 68.00657894736842], [69.70625, 69.16958333333334, 68.10208333333334]]
train loss 0.47849976143836975, epoch 149, best loss 0.3143122046152751, best_epoch 94
GPU_0_using curriculum 20 with window 20
Epoch: [150][20/59]	Time  1.517 ( 1.428)	Data  0.016 ( 0.023)	InnerLoop  0.696 ( 0.604)	Loss 5.8596e-01 (7.4775e-01)	Acc@1  78.32 ( 72.91)
Epoch: [150][40/59]	Time  1.410 ( 1.426)	Data  0.019 ( 0.020)	InnerLoop  0.588 ( 0.604)	Loss 7.0523e-01 (7.5369e-01)	Acc@1  74.32 ( 72.48)
The current update step is 8909
GPU_0_using curriculum 20 with window 20
Epoch: [151][20/59]	Time  1.405 ( 1.421)	Data  0.018 ( 0.029)	InnerLoop  0.585 ( 0.591)	Loss 1.0725e+00 (6.9892e-01)	Acc@1  54.39 ( 73.89)
Epoch: [151][40/59]	Time  1.519 ( 1.426)	Data  0.017 ( 0.026)	InnerLoop  0.697 ( 0.598)	Loss 8.0133e-01 (7.4248e-01)	Acc@1  69.58 ( 72.37)
The current update step is 8968
GPU_0_using curriculum 20 with window 20
Epoch: [152][20/59]	Time  1.405 ( 1.424)	Data  0.018 ( 0.024)	InnerLoop  0.588 ( 0.598)	Loss 6.1196e-01 (7.0858e-01)	Acc@1  77.49 ( 73.85)
Epoch: [152][40/59]	Time  1.403 ( 1.427)	Data  0.017 ( 0.024)	InnerLoop  0.585 ( 0.602)	Loss 7.2964e-01 (7.2051e-01)	Acc@1  74.46 ( 73.61)
The current update step is 9027
GPU_0_using curriculum 20 with window 20
Epoch: [153][20/59]	Time  1.414 ( 1.430)	Data  0.017 ( 0.029)	InnerLoop  0.593 ( 0.596)	Loss 8.1873e-01 (7.2619e-01)	Acc@1  71.34 ( 72.66)
Epoch: [153][40/59]	Time  1.404 ( 1.430)	Data  0.016 ( 0.026)	InnerLoop  0.587 ( 0.598)	Loss 6.4779e-01 (7.4706e-01)	Acc@1  74.22 ( 72.19)
The current update step is 9086
GPU_0_using curriculum 20 with window 20
Epoch: [154][20/59]	Time  1.406 ( 1.424)	Data  0.018 ( 0.029)	InnerLoop  0.588 ( 0.593)	Loss 8.7080e-01 (7.8972e-01)	Acc@1  69.04 ( 70.62)
Epoch: [154][40/59]	Time  1.406 ( 1.425)	Data  0.017 ( 0.027)	InnerLoop  0.584 ( 0.596)	Loss 9.0705e-01 (7.4467e-01)	Acc@1  67.82 ( 72.60)
The current update step is 9145
The current seed is 338879643287193026
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.000
 *   Acc@1 76.005
 *   Acc@1 76.803
 *   Acc@1 77.030
 *   Acc@1 76.395
 *   Acc@1 76.644
 *   Acc@1 72.618
 *   Acc@1 72.866
 *   Acc@1 70.789
 *   Acc@1 70.724
 *   Acc@1 71.105
 *   Acc@1 70.888
Training for 300 epoch: 74.30921052631578
Training for 600 epoch: 73.79605263157895
Training for 1000 epoch: 73.75
Training for 300 epoch: 74.43541666666667
Training for 600 epoch: 73.87708333333333
Training for 1000 epoch: 73.76583333333333
[[74.30921052631578, 73.79605263157895, 73.75], [74.43541666666667, 73.87708333333333, 73.76583333333333]]
train loss 0.4417771920839946, epoch 154, best loss 0.3143122046152751, best_epoch 154
GPU_0_using curriculum 20 with window 20
Epoch: [155][20/59]	Time  1.409 ( 1.423)	Data  0.019 ( 0.018)	InnerLoop  0.586 ( 0.603)	Loss 8.3957e-01 (7.5802e-01)	Acc@1  72.31 ( 72.34)
Epoch: [155][40/59]	Time  1.510 ( 1.425)	Data  0.127 ( 0.024)	InnerLoop  0.582 ( 0.600)	Loss 6.0881e-01 (7.7670e-01)	Acc@1  77.20 ( 71.53)
The current update step is 9204
GPU_0_using curriculum 20 with window 20
Epoch: [156][20/59]	Time  1.417 ( 1.422)	Data  0.019 ( 0.029)	InnerLoop  0.594 ( 0.592)	Loss 7.2325e-01 (7.6521e-01)	Acc@1  72.46 ( 72.02)
Epoch: [156][40/59]	Time  1.412 ( 1.426)	Data  0.018 ( 0.026)	InnerLoop  0.587 ( 0.598)	Loss 5.8999e-01 (7.2333e-01)	Acc@1  77.69 ( 73.33)
The current update step is 9263
GPU_0_using curriculum 20 with window 20
Epoch: [157][20/59]	Time  1.410 ( 1.421)	Data  0.017 ( 0.029)	InnerLoop  0.591 ( 0.592)	Loss 6.2990e-01 (7.2448e-01)	Acc@1  76.46 ( 73.37)
Epoch: [157][40/59]	Time  1.514 ( 1.425)	Data  0.019 ( 0.023)	InnerLoop  0.695 ( 0.601)	Loss 8.1815e-01 (7.7465e-01)	Acc@1  66.70 ( 71.45)
The current update step is 9322
GPU_0_using curriculum 20 with window 20
Epoch: [158][20/59]	Time  1.411 ( 1.423)	Data  0.018 ( 0.024)	InnerLoop  0.592 ( 0.598)	Loss 5.7018e-01 (7.7731e-01)	Acc@1  80.03 ( 71.91)
Epoch: [158][40/59]	Time  1.510 ( 1.425)	Data  0.018 ( 0.021)	InnerLoop  0.692 ( 0.603)	Loss 1.2540e+00 (7.4010e-01)	Acc@1  55.71 ( 72.85)
The current update step is 9381
GPU_0_using curriculum 20 with window 20
Epoch: [159][20/59]	Time  1.402 ( 1.423)	Data  0.018 ( 0.024)	InnerLoop  0.581 ( 0.598)	Loss 5.4579e-01 (7.3117e-01)	Acc@1  79.25 ( 73.44)
Epoch: [159][40/59]	Time  1.525 ( 1.427)	Data  0.018 ( 0.021)	InnerLoop  0.699 ( 0.604)	Loss 7.9913e-01 (7.3914e-01)	Acc@1  70.36 ( 73.06)
The current update step is 9440
The current seed is 13932934541203282936
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.066
 *   Acc@1 73.112
 *   Acc@1 69.355
 *   Acc@1 69.203
 *   Acc@1 67.697
 *   Acc@1 67.377
 *   Acc@1 71.382
 *   Acc@1 71.605
 *   Acc@1 70.711
 *   Acc@1 70.644
 *   Acc@1 70.816
 *   Acc@1 70.653
Training for 300 epoch: 72.22368421052632
Training for 600 epoch: 70.03289473684211
Training for 1000 epoch: 69.25657894736841
Training for 300 epoch: 72.35833333333333
Training for 600 epoch: 69.92333333333333
Training for 1000 epoch: 69.01458333333333
[[72.22368421052632, 70.03289473684211, 69.25657894736841], [72.35833333333333, 69.92333333333333, 69.01458333333333]]
train loss 0.38446507318814593, epoch 159, best loss 0.3143122046152751, best_epoch 154
GPU_0_using curriculum 20 with window 20
Epoch: [160][20/59]	Time  1.520 ( 1.429)	Data  0.017 ( 0.023)	InnerLoop  0.700 ( 0.605)	Loss 5.8604e-01 (7.7175e-01)	Acc@1  78.37 ( 71.43)
Epoch: [160][40/59]	Time  1.408 ( 1.427)	Data  0.018 ( 0.021)	InnerLoop  0.587 ( 0.604)	Loss 1.3432e+00 (8.0325e-01)	Acc@1  55.71 ( 70.67)
The current update step is 9499
GPU_0_using curriculum 20 with window 20
Epoch: [161][20/59]	Time  1.403 ( 1.425)	Data  0.018 ( 0.030)	InnerLoop  0.584 ( 0.593)	Loss 6.5179e-01 (7.2560e-01)	Acc@1  75.93 ( 73.62)
Epoch: [161][40/59]	Time  1.519 ( 1.428)	Data  0.019 ( 0.027)	InnerLoop  0.693 ( 0.598)	Loss 7.6396e-01 (7.3465e-01)	Acc@1  72.02 ( 73.20)
The current update step is 9558
GPU_0_using curriculum 20 with window 20
Epoch: [162][20/59]	Time  1.411 ( 1.423)	Data  0.018 ( 0.024)	InnerLoop  0.588 ( 0.598)	Loss 6.1191e-01 (7.5221e-01)	Acc@1  77.64 ( 72.04)
Epoch: [162][40/59]	Time  1.406 ( 1.427)	Data  0.018 ( 0.023)	InnerLoop  0.586 ( 0.601)	Loss 6.3380e-01 (7.5372e-01)	Acc@1  77.39 ( 72.30)
The current update step is 9617
GPU_0_using curriculum 20 with window 20
Epoch: [163][20/59]	Time  1.407 ( 1.422)	Data  0.018 ( 0.029)	InnerLoop  0.586 ( 0.591)	Loss 8.4876e-01 (7.8310e-01)	Acc@1  68.85 ( 71.42)
Epoch: [163][40/59]	Time  1.404 ( 1.422)	Data  0.017 ( 0.026)	InnerLoop  0.585 ( 0.595)	Loss 6.1499e-01 (7.8240e-01)	Acc@1  76.71 ( 71.38)
The current update step is 9676
GPU_0_using curriculum 20 with window 20
Epoch: [164][20/59]	Time  1.410 ( 1.422)	Data  0.019 ( 0.029)	InnerLoop  0.587 ( 0.592)	Loss 7.8522e-01 (7.3867e-01)	Acc@1  66.36 ( 72.55)
Epoch: [164][40/59]	Time  1.416 ( 1.424)	Data  0.018 ( 0.026)	InnerLoop  0.590 ( 0.595)	Loss 5.9406e-01 (7.3442e-01)	Acc@1  78.56 ( 72.46)
The current update step is 9735
The current seed is 2490323388410692868
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.355
 *   Acc@1 70.733
 *   Acc@1 68.039
 *   Acc@1 68.101
 *   Acc@1 68.421
 *   Acc@1 68.438
 *   Acc@1 73.395
 *   Acc@1 73.472
 *   Acc@1 72.421
 *   Acc@1 72.148
 *   Acc@1 73.934
 *   Acc@1 74.020
Training for 300 epoch: 72.375
Training for 600 epoch: 70.23026315789474
Training for 1000 epoch: 71.17763157894737
Training for 300 epoch: 72.10291666666666
Training for 600 epoch: 70.12458333333333
Training for 1000 epoch: 71.22916666666666
[[72.375, 70.23026315789474, 71.17763157894737], [72.10291666666666, 70.12458333333333, 71.22916666666666]]
train loss 0.34711768787701924, epoch 164, best loss 0.3143122046152751, best_epoch 154
GPU_0_using curriculum 20 with window 20
Epoch: [165][20/59]	Time  1.409 ( 1.424)	Data  0.019 ( 0.018)	InnerLoop  0.589 ( 0.604)	Loss 6.6529e-01 (8.1051e-01)	Acc@1  76.37 ( 71.25)
Epoch: [165][40/59]	Time  1.513 ( 1.427)	Data  0.126 ( 0.024)	InnerLoop  0.585 ( 0.601)	Loss 7.0758e-01 (7.5739e-01)	Acc@1  74.95 ( 72.67)
The current update step is 9794
GPU_0_using curriculum 20 with window 20
Epoch: [166][20/59]	Time  1.401 ( 1.420)	Data  0.019 ( 0.029)	InnerLoop  0.587 ( 0.592)	Loss 8.9726e-01 (7.5366e-01)	Acc@1  66.65 ( 72.47)
Epoch: [166][40/59]	Time  1.403 ( 1.425)	Data  0.017 ( 0.026)	InnerLoop  0.584 ( 0.597)	Loss 6.9975e-01 (7.5789e-01)	Acc@1  76.03 ( 72.36)
The current update step is 9853
GPU_0_using curriculum 20 with window 20
Epoch: [167][20/59]	Time  1.399 ( 1.423)	Data  0.017 ( 0.029)	InnerLoop  0.584 ( 0.593)	Loss 9.3530e-01 (7.8301e-01)	Acc@1  65.77 ( 70.90)
Epoch: [167][40/59]	Time  1.521 ( 1.426)	Data  0.019 ( 0.024)	InnerLoop  0.698 ( 0.601)	Loss 6.0070e-01 (7.7722e-01)	Acc@1  76.90 ( 70.85)
The current update step is 9912
GPU_0_using curriculum 20 with window 20
Epoch: [168][20/59]	Time  1.409 ( 1.426)	Data  0.018 ( 0.024)	InnerLoop  0.589 ( 0.600)	Loss 6.8384e-01 (7.3265e-01)	Acc@1  74.61 ( 73.14)
Epoch: [168][40/59]	Time  1.518 ( 1.428)	Data  0.020 ( 0.021)	InnerLoop  0.695 ( 0.605)	Loss 9.2661e-01 (7.2231e-01)	Acc@1  64.11 ( 73.17)
The current update step is 9971
GPU_0_using curriculum 20 with window 20
Epoch: [169][20/59]	Time  1.406 ( 1.422)	Data  0.017 ( 0.024)	InnerLoop  0.589 ( 0.597)	Loss 6.6469e-01 (8.0565e-01)	Acc@1  72.51 ( 70.60)
Epoch: [169][40/59]	Time  1.511 ( 1.425)	Data  0.018 ( 0.021)	InnerLoop  0.693 ( 0.602)	Loss 8.0063e-01 (7.9326e-01)	Acc@1  68.26 ( 71.02)
The current update step is 10030
The current seed is 4264859643139246358
The current lr is: 0.001
Testing Results:
 *   Acc@1 74.487
 *   Acc@1 74.703
 *   Acc@1 71.947
 *   Acc@1 72.171
 *   Acc@1 69.421
 *   Acc@1 69.880
 *   Acc@1 78.434
 *   Acc@1 78.938
 *   Acc@1 77.487
 *   Acc@1 77.511
 *   Acc@1 77.145
 *   Acc@1 76.983
Training for 300 epoch: 76.46052631578948
Training for 600 epoch: 74.71710526315789
Training for 1000 epoch: 73.28289473684211
Training for 300 epoch: 76.82083333333333
Training for 600 epoch: 74.84083333333334
Training for 1000 epoch: 73.43166666666667
[[76.46052631578948, 74.71710526315789, 73.28289473684211], [76.82083333333333, 74.84083333333334, 73.43166666666667]]
train loss 0.3369488664150238, epoch 169, best loss 0.3143122046152751, best_epoch 154
GPU_0_using curriculum 20 with window 20
Epoch: [170][20/59]	Time  1.516 ( 1.427)	Data  0.017 ( 0.023)	InnerLoop  0.696 ( 0.603)	Loss 6.8220e-01 (7.8006e-01)	Acc@1  73.44 ( 71.30)
Epoch: [170][40/59]	Time  1.416 ( 1.426)	Data  0.018 ( 0.021)	InnerLoop  0.591 ( 0.604)	Loss 7.6742e-01 (7.6043e-01)	Acc@1  72.95 ( 71.91)
The current update step is 10089
GPU_0_using curriculum 20 with window 20
Epoch: [171][20/59]	Time  1.416 ( 1.427)	Data  0.019 ( 0.030)	InnerLoop  0.591 ( 0.595)	Loss 6.6407e-01 (7.3277e-01)	Acc@1  76.03 ( 72.90)
Epoch: [171][40/59]	Time  1.518 ( 1.430)	Data  0.018 ( 0.027)	InnerLoop  0.698 ( 0.600)	Loss 8.7520e-01 (7.4293e-01)	Acc@1  68.95 ( 72.63)
The current update step is 10148
GPU_0_using curriculum 20 with window 20
Epoch: [172][20/59]	Time  1.406 ( 1.429)	Data  0.018 ( 0.024)	InnerLoop  0.587 ( 0.603)	Loss 7.6613e-01 (7.4426e-01)	Acc@1  71.00 ( 72.61)
Epoch: [172][40/59]	Time  1.405 ( 1.432)	Data  0.017 ( 0.025)	InnerLoop  0.588 ( 0.605)	Loss 9.8864e-01 (7.2354e-01)	Acc@1  66.60 ( 73.29)
The current update step is 10207
GPU_0_using curriculum 20 with window 20
Epoch: [173][20/59]	Time  1.411 ( 1.426)	Data  0.018 ( 0.030)	InnerLoop  0.589 ( 0.595)	Loss 7.4505e-01 (7.1318e-01)	Acc@1  69.68 ( 74.08)
Epoch: [173][40/59]	Time  1.410 ( 1.428)	Data  0.017 ( 0.027)	InnerLoop  0.589 ( 0.598)	Loss 7.6345e-01 (7.2259e-01)	Acc@1  72.22 ( 73.71)
The current update step is 10266
GPU_0_using curriculum 20 with window 20
Epoch: [174][20/59]	Time  1.413 ( 1.427)	Data  0.018 ( 0.030)	InnerLoop  0.590 ( 0.595)	Loss 1.0127e+00 (7.3689e-01)	Acc@1  62.11 ( 72.77)
Epoch: [174][40/59]	Time  1.407 ( 1.427)	Data  0.017 ( 0.027)	InnerLoop  0.586 ( 0.597)	Loss 5.7587e-01 (7.2190e-01)	Acc@1  78.76 ( 73.29)
The current update step is 10325
The current seed is 12218455142914652235
The current lr is: 0.001
Testing Results:
 *   Acc@1 68.079
 *   Acc@1 68.370
 *   Acc@1 67.447
 *   Acc@1 67.696
 *   Acc@1 68.382
 *   Acc@1 68.595
 *   Acc@1 76.395
 *   Acc@1 76.632
 *   Acc@1 76.684
 *   Acc@1 76.562
 *   Acc@1 75.474
 *   Acc@1 76.147
Training for 300 epoch: 72.23684210526315
Training for 600 epoch: 72.06578947368422
Training for 1000 epoch: 71.92763157894737
Training for 300 epoch: 72.50125
Training for 600 epoch: 72.12875
Training for 1000 epoch: 72.37125
[[72.23684210526315, 72.06578947368422, 71.92763157894737], [72.50125, 72.12875, 72.37125]]
train loss 0.33725959065755207, epoch 174, best loss 0.3143122046152751, best_epoch 154
GPU_0_using curriculum 20 with window 20
Epoch: [175][20/59]	Time  1.409 ( 1.428)	Data  0.019 ( 0.018)	InnerLoop  0.586 ( 0.607)	Loss 5.8384e-01 (7.2048e-01)	Acc@1  79.59 ( 73.44)
Epoch: [175][40/59]	Time  1.534 ( 1.432)	Data  0.132 ( 0.024)	InnerLoop  0.591 ( 0.604)	Loss 8.9297e-01 (7.2431e-01)	Acc@1  66.60 ( 73.14)
The current update step is 10384
GPU_0_using curriculum 20 with window 20
Epoch: [176][20/59]	Time  1.414 ( 1.428)	Data  0.020 ( 0.030)	InnerLoop  0.591 ( 0.595)	Loss 7.4861e-01 (7.4659e-01)	Acc@1  74.37 ( 73.12)
Epoch: [176][40/59]	Time  1.410 ( 1.431)	Data  0.017 ( 0.027)	InnerLoop  0.586 ( 0.601)	Loss 6.9672e-01 (7.3716e-01)	Acc@1  75.49 ( 73.35)
The current update step is 10443
GPU_0_using curriculum 20 with window 20
Epoch: [177][20/59]	Time  1.414 ( 1.430)	Data  0.020 ( 0.030)	InnerLoop  0.588 ( 0.595)	Loss 8.1020e-01 (7.8736e-01)	Acc@1  71.53 ( 72.08)
Epoch: [177][40/59]	Time  1.520 ( 1.431)	Data  0.019 ( 0.024)	InnerLoop  0.698 ( 0.603)	Loss 5.7258e-01 (7.9280e-01)	Acc@1  79.25 ( 71.38)
The current update step is 10502
GPU_0_using curriculum 20 with window 20
Epoch: [178][20/59]	Time  1.411 ( 1.427)	Data  0.017 ( 0.024)	InnerLoop  0.592 ( 0.600)	Loss 6.6075e-01 (7.7748e-01)	Acc@1  77.93 ( 71.51)
Epoch: [178][40/59]	Time  1.516 ( 1.429)	Data  0.019 ( 0.021)	InnerLoop  0.697 ( 0.605)	Loss 6.7564e-01 (7.7465e-01)	Acc@1  76.17 ( 71.83)
The current update step is 10561
GPU_0_using curriculum 20 with window 20
Epoch: [179][20/59]	Time  1.415 ( 1.426)	Data  0.017 ( 0.024)	InnerLoop  0.593 ( 0.601)	Loss 6.8467e-01 (7.7096e-01)	Acc@1  75.05 ( 71.64)
Epoch: [179][40/59]	Time  1.527 ( 1.428)	Data  0.020 ( 0.021)	InnerLoop  0.699 ( 0.606)	Loss 7.5107e-01 (7.7504e-01)	Acc@1  76.07 ( 72.15)
The current update step is 10620
The current seed is 13882984553605150046
The current lr is: 0.001
Testing Results:
 *   Acc@1 78.763
 *   Acc@1 79.648
 *   Acc@1 77.461
 *   Acc@1 78.323
 *   Acc@1 76.724
 *   Acc@1 77.488
 *   Acc@1 70.947
 *   Acc@1 70.981
 *   Acc@1 69.763
 *   Acc@1 70.417
 *   Acc@1 68.645
 *   Acc@1 68.046
Training for 300 epoch: 74.85526315789474
Training for 600 epoch: 73.61184210526315
Training for 1000 epoch: 72.68421052631578
Training for 300 epoch: 75.31458333333333
Training for 600 epoch: 74.36958333333334
Training for 1000 epoch: 72.76708333333333
[[74.85526315789474, 73.61184210526315, 72.68421052631578], [75.31458333333333, 74.36958333333334, 72.76708333333333]]
train loss 0.5089009754657745, epoch 179, best loss 0.3143122046152751, best_epoch 154
GPU_0_using curriculum 20 with window 20
Epoch: [180][20/59]	Time  1.524 ( 1.433)	Data  0.016 ( 0.023)	InnerLoop  0.703 ( 0.608)	Loss 6.0209e-01 (6.8775e-01)	Acc@1  78.47 ( 74.86)
Epoch: [180][40/59]	Time  1.416 ( 1.431)	Data  0.018 ( 0.020)	InnerLoop  0.591 ( 0.607)	Loss 9.9949e-01 (7.6097e-01)	Acc@1  63.43 ( 73.23)
The current update step is 10679
GPU_0_using curriculum 20 with window 20
Epoch: [181][20/59]	Time  1.409 ( 1.426)	Data  0.018 ( 0.030)	InnerLoop  0.589 ( 0.594)	Loss 7.2085e-01 (7.9065e-01)	Acc@1  73.54 ( 71.26)
Epoch: [181][40/59]	Time  1.519 ( 1.429)	Data  0.017 ( 0.027)	InnerLoop  0.699 ( 0.600)	Loss 9.5719e-01 (7.5320e-01)	Acc@1  67.58 ( 72.50)
The current update step is 10738
GPU_0_using curriculum 20 with window 20
Epoch: [182][20/59]	Time  1.407 ( 1.423)	Data  0.018 ( 0.024)	InnerLoop  0.589 ( 0.599)	Loss 7.2809e-01 (7.3874e-01)	Acc@1  72.80 ( 72.89)
Epoch: [182][40/59]	Time  1.413 ( 1.429)	Data  0.018 ( 0.024)	InnerLoop  0.589 ( 0.602)	Loss 9.3943e-01 (7.6720e-01)	Acc@1  62.16 ( 71.77)
The current update step is 10797
GPU_0_using curriculum 20 with window 20
Epoch: [183][20/59]	Time  1.413 ( 1.427)	Data  0.019 ( 0.030)	InnerLoop  0.590 ( 0.595)	Loss 8.2631e-01 (7.9967e-01)	Acc@1  68.02 ( 70.82)
Epoch: [183][40/59]	Time  1.412 ( 1.428)	Data  0.016 ( 0.027)	InnerLoop  0.591 ( 0.598)	Loss 6.5701e-01 (7.5667e-01)	Acc@1  76.37 ( 72.20)
The current update step is 10856
GPU_0_using curriculum 20 with window 20
Epoch: [184][20/59]	Time  1.414 ( 1.425)	Data  0.019 ( 0.030)	InnerLoop  0.590 ( 0.595)	Loss 6.5033e-01 (7.7736e-01)	Acc@1  74.02 ( 70.88)
Epoch: [184][40/59]	Time  1.412 ( 1.426)	Data  0.017 ( 0.027)	InnerLoop  0.591 ( 0.597)	Loss 9.4966e-01 (7.5391e-01)	Acc@1  61.43 ( 71.76)
The current update step is 10915
The current seed is 9722438743485976598
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.566
 *   Acc@1 76.785
 *   Acc@1 75.105
 *   Acc@1 75.044
 *   Acc@1 74.789
 *   Acc@1 74.439
 *   Acc@1 77.737
 *   Acc@1 77.762
 *   Acc@1 72.750
 *   Acc@1 72.694
 *   Acc@1 68.724
 *   Acc@1 68.728
Training for 300 epoch: 77.15131578947368
Training for 600 epoch: 73.92763157894737
Training for 1000 epoch: 71.75657894736841
Training for 300 epoch: 77.27333333333334
Training for 600 epoch: 73.86916666666667
Training for 1000 epoch: 71.58333333333334
[[77.15131578947368, 73.92763157894737, 71.75657894736841], [77.27333333333334, 73.86916666666667, 71.58333333333334]]
train loss 0.5467011266072591, epoch 184, best loss 0.3143122046152751, best_epoch 154
GPU_0_using curriculum 20 with window 20
Epoch: [185][20/59]	Time  1.416 ( 1.426)	Data  0.019 ( 0.018)	InnerLoop  0.591 ( 0.607)	Loss 5.3780e-01 (6.8380e-01)	Acc@1  80.13 ( 75.11)
Epoch: [185][40/59]	Time  1.528 ( 1.431)	Data  0.132 ( 0.024)	InnerLoop  0.590 ( 0.604)	Loss 1.0085e+00 (6.9150e-01)	Acc@1  63.77 ( 74.89)
The current update step is 10974
GPU_0_using curriculum 20 with window 20
Epoch: [186][20/59]	Time  1.406 ( 1.424)	Data  0.019 ( 0.030)	InnerLoop  0.589 ( 0.595)	Loss 5.5632e-01 (6.8387e-01)	Acc@1  79.54 ( 74.46)
Epoch: [186][40/59]	Time  1.414 ( 1.426)	Data  0.018 ( 0.027)	InnerLoop  0.592 ( 0.599)	Loss 1.4105e+00 (6.9862e-01)	Acc@1  55.22 ( 74.11)
The current update step is 11033
GPU_0_using curriculum 20 with window 20
Epoch: [187][20/59]	Time  1.407 ( 1.427)	Data  0.019 ( 0.030)	InnerLoop  0.588 ( 0.595)	Loss 7.2306e-01 (7.0219e-01)	Acc@1  72.07 ( 73.76)
Epoch: [187][40/59]	Time  1.521 ( 1.431)	Data  0.018 ( 0.024)	InnerLoop  0.699 ( 0.603)	Loss 5.0703e-01 (7.2582e-01)	Acc@1  81.59 ( 73.44)
The current update step is 11092
GPU_0_using curriculum 20 with window 20
Epoch: [188][20/59]	Time  1.415 ( 1.425)	Data  0.017 ( 0.024)	InnerLoop  0.591 ( 0.600)	Loss 7.2557e-01 (7.4855e-01)	Acc@1  75.39 ( 73.26)
Epoch: [188][40/59]	Time  1.521 ( 1.427)	Data  0.020 ( 0.021)	InnerLoop  0.695 ( 0.604)	Loss 8.2186e-01 (7.4600e-01)	Acc@1  71.04 ( 73.66)
The current update step is 11151
GPU_0_using curriculum 20 with window 20
Epoch: [189][20/59]	Time  1.409 ( 1.427)	Data  0.018 ( 0.024)	InnerLoop  0.590 ( 0.601)	Loss 9.2288e-01 (7.7083e-01)	Acc@1  67.53 ( 72.07)
Epoch: [189][40/59]	Time  1.522 ( 1.431)	Data  0.020 ( 0.021)	InnerLoop  0.698 ( 0.606)	Loss 7.0437e-01 (7.5191e-01)	Acc@1  75.59 ( 72.67)
The current update step is 11210
The current seed is 5461423908383076044
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.053
 *   Acc@1 76.387
 *   Acc@1 75.303
 *   Acc@1 75.833
 *   Acc@1 76.566
 *   Acc@1 76.917
 *   Acc@1 69.276
 *   Acc@1 69.935
 *   Acc@1 71.974
 *   Acc@1 72.452
 *   Acc@1 71.461
 *   Acc@1 71.847
Training for 300 epoch: 72.66447368421052
Training for 600 epoch: 73.63815789473685
Training for 1000 epoch: 74.01315789473685
Training for 300 epoch: 73.16083333333333
Training for 600 epoch: 74.1425
Training for 1000 epoch: 74.38166666666666
[[72.66447368421052, 73.63815789473685, 74.01315789473685], [73.16083333333333, 74.1425, 74.38166666666666]]
train loss 0.37967738796869915, epoch 189, best loss 0.3143122046152751, best_epoch 154
GPU_0_using curriculum 20 with window 20
Epoch: [190][20/59]	Time  1.526 ( 1.432)	Data  0.018 ( 0.023)	InnerLoop  0.702 ( 0.606)	Loss 8.6065e-01 (7.5138e-01)	Acc@1  68.75 ( 71.98)
Epoch: [190][40/59]	Time  1.413 ( 1.430)	Data  0.018 ( 0.021)	InnerLoop  0.590 ( 0.606)	Loss 7.5168e-01 (7.1171e-01)	Acc@1  73.73 ( 73.71)
The current update step is 11269
GPU_0_using curriculum 20 with window 20
Epoch: [191][20/59]	Time  1.413 ( 1.422)	Data  0.018 ( 0.030)	InnerLoop  0.593 ( 0.592)	Loss 7.5083e-01 (7.0189e-01)	Acc@1  73.73 ( 74.50)
Epoch: [191][40/59]	Time  1.525 ( 1.428)	Data  0.020 ( 0.027)	InnerLoop  0.700 ( 0.599)	Loss 6.6279e-01 (7.3983e-01)	Acc@1  77.69 ( 73.31)
The current update step is 11328
GPU_0_using curriculum 20 with window 20
Epoch: [192][20/59]	Time  1.414 ( 1.426)	Data  0.020 ( 0.024)	InnerLoop  0.592 ( 0.600)	Loss 6.0885e-01 (7.2078e-01)	Acc@1  78.27 ( 74.11)
Epoch: [192][40/59]	Time  1.417 ( 1.430)	Data  0.019 ( 0.024)	InnerLoop  0.591 ( 0.603)	Loss 6.5392e-01 (6.9078e-01)	Acc@1  75.83 ( 75.15)
The current update step is 11387
GPU_0_using curriculum 20 with window 20
Epoch: [193][20/59]	Time  1.413 ( 1.427)	Data  0.019 ( 0.030)	InnerLoop  0.590 ( 0.595)	Loss 9.2042e-01 (7.0131e-01)	Acc@1  65.19 ( 73.90)
Epoch: [193][40/59]	Time  1.405 ( 1.428)	Data  0.017 ( 0.027)	InnerLoop  0.589 ( 0.598)	Loss 5.8987e-01 (6.9879e-01)	Acc@1  79.25 ( 74.23)
The current update step is 11446
GPU_0_using curriculum 20 with window 20
Epoch: [194][20/59]	Time  1.415 ( 1.428)	Data  0.021 ( 0.030)	InnerLoop  0.592 ( 0.596)	Loss 5.9182e-01 (7.3075e-01)	Acc@1  78.52 ( 73.61)
Epoch: [194][40/59]	Time  1.414 ( 1.429)	Data  0.019 ( 0.027)	InnerLoop  0.590 ( 0.599)	Loss 6.0470e-01 (7.3330e-01)	Acc@1  77.88 ( 73.13)
The current update step is 11505
The current seed is 11503889685690420743
The current lr is: 0.001
Testing Results:
 *   Acc@1 80.395
 *   Acc@1 80.440
 *   Acc@1 79.737
 *   Acc@1 80.249
 *   Acc@1 79.579
 *   Acc@1 79.868
 *   Acc@1 76.368
 *   Acc@1 75.877
 *   Acc@1 75.566
 *   Acc@1 75.353
 *   Acc@1 75.697
 *   Acc@1 75.053
Training for 300 epoch: 78.38157894736841
Training for 600 epoch: 77.65131578947368
Training for 1000 epoch: 77.63815789473685
Training for 300 epoch: 78.15875
Training for 600 epoch: 77.80083333333334
Training for 1000 epoch: 77.46041666666667
[[78.38157894736841, 77.65131578947368, 77.63815789473685], [78.15875, 77.80083333333334, 77.46041666666667]]
train loss 0.36905154455502825, epoch 194, best loss 0.3143122046152751, best_epoch 154
GPU_0_using curriculum 20 with window 20
Epoch: [195][20/59]	Time  1.412 ( 1.425)	Data  0.019 ( 0.018)	InnerLoop  0.587 ( 0.605)	Loss 1.0262e+00 (7.1282e-01)	Acc@1  65.19 ( 74.08)
Epoch: [195][40/59]	Time  1.526 ( 1.430)	Data  0.133 ( 0.024)	InnerLoop  0.586 ( 0.602)	Loss 9.4753e-01 (7.3470e-01)	Acc@1  66.85 ( 73.54)
The current update step is 11564
GPU_0_using curriculum 20 with window 20
Epoch: [196][20/59]	Time  1.423 ( 1.430)	Data  0.021 ( 0.030)	InnerLoop  0.597 ( 0.596)	Loss 7.9449e-01 (7.5533e-01)	Acc@1  68.60 ( 72.56)
Epoch: [196][40/59]	Time  1.405 ( 1.433)	Data  0.017 ( 0.027)	InnerLoop  0.585 ( 0.602)	Loss 6.3750e-01 (7.6919e-01)	Acc@1  76.46 ( 72.31)
The current update step is 11623
GPU_0_using curriculum 20 with window 20
Epoch: [197][20/59]	Time  1.415 ( 1.426)	Data  0.018 ( 0.029)	InnerLoop  0.591 ( 0.595)	Loss 6.3887e-01 (7.2580e-01)	Acc@1  75.68 ( 73.37)
Epoch: [197][40/59]	Time  1.524 ( 1.429)	Data  0.018 ( 0.024)	InnerLoop  0.701 ( 0.604)	Loss 6.1204e-01 (7.0512e-01)	Acc@1  78.81 ( 73.80)
The current update step is 11682
GPU_0_using curriculum 20 with window 20
Epoch: [198][20/59]	Time  1.412 ( 1.427)	Data  0.019 ( 0.024)	InnerLoop  0.591 ( 0.600)	Loss 6.9787e-01 (7.0817e-01)	Acc@1  72.75 ( 73.70)
Epoch: [198][40/59]	Time  1.526 ( 1.430)	Data  0.018 ( 0.022)	InnerLoop  0.705 ( 0.606)	Loss 5.3188e-01 (7.0622e-01)	Acc@1  80.42 ( 73.88)
The current update step is 11741
GPU_0_using curriculum 20 with window 20
Epoch: [199][20/59]	Time  1.413 ( 1.426)	Data  0.017 ( 0.024)	InnerLoop  0.592 ( 0.599)	Loss 6.5315e-01 (7.1562e-01)	Acc@1  73.24 ( 73.48)
Epoch: [199][40/59]	Time  1.521 ( 1.428)	Data  0.019 ( 0.021)	InnerLoop  0.697 ( 0.604)	Loss 5.9309e-01 (7.2133e-01)	Acc@1  79.10 ( 73.48)
The current update step is 11800
The current seed is 10499161734542343301
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.316
 *   Acc@1 71.272
 *   Acc@1 70.250
 *   Acc@1 70.786
 *   Acc@1 71.026
 *   Acc@1 71.007
 *   Acc@1 77.408
 *   Acc@1 77.285
 *   Acc@1 75.632
 *   Acc@1 75.918
 *   Acc@1 74.303
 *   Acc@1 74.779
Training for 300 epoch: 74.36184210526315
Training for 600 epoch: 72.94078947368422
Training for 1000 epoch: 72.66447368421052
Training for 300 epoch: 74.27833333333334
Training for 600 epoch: 73.35166666666666
Training for 1000 epoch: 72.89291666666666
[[74.36184210526315, 72.94078947368422, 72.66447368421052], [74.27833333333334, 73.35166666666666, 72.89291666666666]]
train loss 0.37708453168869016, epoch 199, best loss 0.3143122046152751, best_epoch 154
=== Final results:
{'acc': 78.38157894736841, 'test': [78.38157894736841, 77.65131578947368, 77.63815789473685], 'train': [78.38157894736841, 77.65131578947368, 77.63815789473685], 'ind': 0, 'epoch': 195, 'data': array([[-0.18077697, -0.12699522, -0.08627491, ..., -0.05452043,
         0.153392  ,  0.02602399],
       [ 0.19382752, -0.19403417,  0.09591439, ..., -0.1492276 ,
         0.00507464,  0.06360614],
       [ 0.02510739, -0.02017039, -0.17078976, ...,  0.01617529,
         0.10403958, -0.07902509],
       [ 0.0457427 ,  0.01801825,  0.19355434, ..., -0.12293095,
         0.03445488, -0.0187559 ]], shape=(4, 768), dtype=float32)}
