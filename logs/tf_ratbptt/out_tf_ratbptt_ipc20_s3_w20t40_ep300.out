Torch Seed Specified with rank: 0
Dataset: agnews_emb
Dataset Path: ./scripts
Namespace(seed=0, mp_distributed=False, world_size=1, rank=0, dist_url='tcp://224.66.41.62:23456', dist_backend='nccl', workers=0, gpu=None, root='./scripts', dataset='agnews_emb', arch='text_transformer', width=256, lr=0.0012, inner_optim='Adam', outer_optim='Adam', inner_lr=0.001, label_lr_scale=1, num_per_class=20, batch_per_class=12, task_sampler_nc=5, window=20, minwindow=0, totwindow=40, num_train_eval=2, train_y=False, batch_size=3072, eps=1e-08, wd=0, test_freq=5, print_freq=20, start_epoch=0, epochs=400, ddtype='standard', cctype=0, zca=False, wandb=False, clip_coef=0.9, fname='out_tf_ratbptt_ipc20_s3_w20t40_ep300', out_dir='./checkpoints', name='agnews_tf_ratbptt_s3_w20t40_ep300', comp_aug=False, comp_aug_real=False, syn_strategy='none', real_strategy='none', ckptname='none', limit_train=False, load_ckpt=False, complete_random=False, boost_dd=False, boost_init_from='none', boost_beta=1.0, stage=3, distributed=False, data_root='./scripts/agnews_emb')
==> Preparing data..
None None
Dataset: number of classes: 4
Training set size: 120000
Image size: channel 1, height 768, width 1
Synthetic images, not_single False, keys []
==> Building model..
Initialized data with size, x: torch.Size([80, 768]), y:torch.Size([80])
TextTransformer(
  (input_proj): Linear(in_features=192, out_features=256, bias=True)
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=1024, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=1024, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (cls_head): Linear(in_features=256, out_features=4, bias=True)
)
use data parallel only
GPU_0_using curriculum 20 with window 20
Epoch: [0][20/40]	Time  1.587 ( 1.694)	Data  0.028 ( 0.045)	InnerLoop  0.672 ( 0.739)	Loss 3.9576e+00 (2.9635e+00)	Acc@1  29.95 ( 34.86)
Epoch: [0][40/40]	Time  1.680 ( 1.652)	Data  0.012 ( 0.043)	InnerLoop  0.780 ( 0.711)	Loss 1.4777e+00 (2.5485e+00)	Acc@1  52.08 ( 39.53)
The current update step is 40
GPU_0_using curriculum 20 with window 20
Epoch: [1][20/40]	Time  1.582 ( 1.600)	Data  0.034 ( 0.042)	InnerLoop  0.661 ( 0.676)	Loss 1.3451e+00 (2.0974e+00)	Acc@1  58.92 ( 47.50)
Epoch: [1][40/40]	Time  1.549 ( 1.595)	Data  0.012 ( 0.038)	InnerLoop  0.658 ( 0.676)	Loss 1.2168e+00 (2.0176e+00)	Acc@1  58.33 ( 48.65)
The current update step is 80
GPU_0_using curriculum 20 with window 20
Epoch: [2][20/40]	Time  1.674 ( 1.587)	Data  0.030 ( 0.048)	InnerLoop  0.770 ( 0.667)	Loss 1.2162e+00 (2.0779e+00)	Acc@1  59.64 ( 49.66)
Epoch: [2][40/40]	Time  1.556 ( 1.587)	Data  0.013 ( 0.044)	InnerLoop  0.668 ( 0.668)	Loss 9.8724e-01 (1.6904e+00)	Acc@1  69.79 ( 54.51)
The current update step is 120
GPU_0_using curriculum 20 with window 20
Epoch: [3][20/40]	Time  1.572 ( 1.587)	Data  0.028 ( 0.048)	InnerLoop  0.659 ( 0.663)	Loss 7.2449e-01 (1.2553e+00)	Acc@1  72.43 ( 59.24)
Epoch: [3][40/40]	Time  1.541 ( 1.589)	Data  0.013 ( 0.041)	InnerLoop  0.651 ( 0.670)	Loss 1.4004e+00 (1.3917e+00)	Acc@1  55.21 ( 55.97)
The current update step is 160
GPU_0_using curriculum 20 with window 20
Epoch: [4][20/40]	Time  1.578 ( 1.598)	Data  0.033 ( 0.042)	InnerLoop  0.661 ( 0.676)	Loss 1.3079e+00 (1.0516e+00)	Acc@1  53.45 ( 61.98)
Epoch: [4][40/40]	Time  1.579 ( 1.603)	Data  0.010 ( 0.043)	InnerLoop  0.679 ( 0.677)	Loss 1.6443e+00 (1.0723e+00)	Acc@1  50.52 ( 62.00)
The current update step is 200
The current seed is 6072181003035628103
The current lr is: 0.001
Testing Results:
 *   Acc@1 58.263
 *   Acc@1 59.093
 *   Acc@1 54.303
 *   Acc@1 54.530
 *   Acc@1 50.803
 *   Acc@1 51.430
 *   Acc@1 58.987
 *   Acc@1 59.267
 *   Acc@1 61.184
 *   Acc@1 61.792
 *   Acc@1 61.447
 *   Acc@1 61.886
Training for 300 epoch: 58.625
Training for 600 epoch: 57.743421052631575
Training for 1000 epoch: 56.125
Training for 300 epoch: 59.180416666666666
Training for 600 epoch: 58.161249999999995
Training for 1000 epoch: 56.657916666666665
[[58.625, 57.743421052631575, 56.125], [59.180416666666666, 58.161249999999995, 56.657916666666665]]
train loss 0.5992767573356629, epoch 4, best loss 0.5992767573356629, best_epoch 4
GPU_0_using curriculum 20 with window 20
Epoch: [5][20/40]	Time  1.530 ( 1.564)	Data  0.026 ( 0.041)	InnerLoop  0.647 ( 0.662)	Loss 8.0355e-01 (1.1787e+00)	Acc@1  70.21 ( 58.57)
Epoch: [5][40/40]	Time  1.510 ( 1.558)	Data  0.012 ( 0.038)	InnerLoop  0.647 ( 0.663)	Loss 6.8401e-01 (1.1389e+00)	Acc@1  72.92 ( 60.58)
The current update step is 240
GPU_0_using curriculum 20 with window 20
Epoch: [6][20/40]	Time  1.526 ( 1.555)	Data  0.029 ( 0.047)	InnerLoop  0.646 ( 0.657)	Loss 7.5609e-01 (1.0401e+00)	Acc@1  72.43 ( 62.30)
Epoch: [6][40/40]	Time  1.495 ( 1.546)	Data  0.012 ( 0.043)	InnerLoop  0.638 ( 0.655)	Loss 6.5793e-01 (9.9798e-01)	Acc@1  75.00 ( 63.57)
The current update step is 280
GPU_0_using curriculum 20 with window 20
Epoch: [7][20/40]	Time  1.622 ( 1.534)	Data  0.027 ( 0.040)	InnerLoop  0.755 ( 0.655)	Loss 8.5893e-01 (9.1258e-01)	Acc@1  69.14 ( 67.50)
Epoch: [7][40/40]	Time  1.483 ( 1.528)	Data  0.011 ( 0.039)	InnerLoop  0.638 ( 0.651)	Loss 1.8593e+00 (9.1487e-01)	Acc@1  54.17 ( 68.11)
The current update step is 320
GPU_0_using curriculum 20 with window 20
Epoch: [8][20/40]	Time  1.473 ( 1.513)	Data  0.028 ( 0.034)	InnerLoop  0.621 ( 0.651)	Loss 9.1971e-01 (9.6734e-01)	Acc@1  68.33 ( 66.31)
Epoch: [8][40/40]	Time  1.469 ( 1.513)	Data  0.009 ( 0.036)	InnerLoop  0.633 ( 0.650)	Loss 1.2648e+00 (9.1604e-01)	Acc@1  58.85 ( 67.78)
The current update step is 360
GPU_0_using curriculum 20 with window 20
Epoch: [9][20/40]	Time  1.483 ( 1.506)	Data  0.028 ( 0.040)	InnerLoop  0.631 ( 0.643)	Loss 7.1935e-01 (8.9209e-01)	Acc@1  73.24 ( 69.31)
Epoch: [9][40/40]	Time  1.477 ( 1.508)	Data  0.010 ( 0.036)	InnerLoop  0.642 ( 0.646)	Loss 1.1800e+00 (9.0529e-01)	Acc@1  60.42 ( 68.81)
The current update step is 400
The current seed is 2943723668883816172
The current lr is: 0.001
Testing Results:
 *   Acc@1 58.342
 *   Acc@1 58.043
 *   Acc@1 57.697
 *   Acc@1 57.363
 *   Acc@1 57.513
 *   Acc@1 57.057
 *   Acc@1 57.908
 *   Acc@1 57.957
 *   Acc@1 56.566
 *   Acc@1 56.957
 *   Acc@1 55.579
 *   Acc@1 56.102
Training for 300 epoch: 58.125
Training for 600 epoch: 57.131578947368425
Training for 1000 epoch: 56.546052631578945
Training for 300 epoch: 58.0
Training for 600 epoch: 57.16
Training for 1000 epoch: 56.58
[[58.125, 57.131578947368425, 56.546052631578945], [58.0, 57.16, 56.58]]
train loss 0.9174409823417664, epoch 9, best loss 0.5992767573356629, best_epoch 4
GPU_0_using curriculum 20 with window 20
Epoch: [10][20/40]	Time  1.488 ( 1.503)	Data  0.027 ( 0.039)	InnerLoop  0.635 ( 0.641)	Loss 9.5452e-01 (8.8137e-01)	Acc@1  67.38 ( 69.56)
Epoch: [10][40/40]	Time  1.475 ( 1.506)	Data  0.011 ( 0.036)	InnerLoop  0.638 ( 0.645)	Loss 6.6870e-01 (9.1564e-01)	Acc@1  81.25 ( 68.88)
The current update step is 440
GPU_0_using curriculum 20 with window 20
Epoch: [11][20/40]	Time  1.600 ( 1.510)	Data  0.025 ( 0.045)	InnerLoop  0.750 ( 0.642)	Loss 1.1509e+00 (8.0404e-01)	Acc@1  54.20 ( 70.21)
Epoch: [11][40/40]	Time  1.478 ( 1.508)	Data  0.012 ( 0.042)	InnerLoop  0.638 ( 0.641)	Loss 7.0914e-01 (9.5831e-01)	Acc@1  74.48 ( 67.19)
The current update step is 480
GPU_0_using curriculum 20 with window 20
Epoch: [12][20/40]	Time  1.480 ( 1.505)	Data  0.026 ( 0.045)	InnerLoop  0.630 ( 0.636)	Loss 1.0043e+00 (1.0110e+00)	Acc@1  62.47 ( 64.30)
Epoch: [12][40/40]	Time  1.454 ( 1.505)	Data  0.010 ( 0.039)	InnerLoop  0.626 ( 0.642)	Loss 6.0450e-01 (9.3273e-01)	Acc@1  79.17 ( 66.50)
The current update step is 520
GPU_0_using curriculum 20 with window 20
Epoch: [13][20/40]	Time  1.498 ( 1.508)	Data  0.026 ( 0.039)	InnerLoop  0.639 ( 0.647)	Loss 8.7695e-01 (8.2564e-01)	Acc@1  71.06 ( 69.92)
Epoch: [13][40/40]	Time  1.468 ( 1.506)	Data  0.010 ( 0.038)	InnerLoop  0.637 ( 0.644)	Loss 6.9225e-01 (8.3357e-01)	Acc@1  75.00 ( 70.22)
The current update step is 560
GPU_0_using curriculum 20 with window 20
Epoch: [14][20/40]	Time  1.470 ( 1.501)	Data  0.028 ( 0.040)	InnerLoop  0.625 ( 0.638)	Loss 7.9886e-01 (9.1976e-01)	Acc@1  73.47 ( 69.02)
Epoch: [14][40/40]	Time  1.480 ( 1.505)	Data  0.012 ( 0.039)	InnerLoop  0.639 ( 0.642)	Loss 9.5208e-01 (8.3629e-01)	Acc@1  66.67 ( 70.90)
The current update step is 600
The current seed is 16511015198601112666
The current lr is: 0.001
Testing Results:
 *   Acc@1 53.342
 *   Acc@1 53.650
 *   Acc@1 51.250
 *   Acc@1 51.752
 *   Acc@1 50.697
 *   Acc@1 51.090
 *   Acc@1 58.342
 *   Acc@1 58.004
 *   Acc@1 55.224
 *   Acc@1 55.180
 *   Acc@1 53.658
 *   Acc@1 53.862
Training for 300 epoch: 55.8421052631579
Training for 600 epoch: 53.23684210526316
Training for 1000 epoch: 52.17763157894737
Training for 300 epoch: 55.827083333333334
Training for 600 epoch: 53.46625
Training for 1000 epoch: 52.47625
[[55.8421052631579, 53.23684210526316, 52.17763157894737], [55.827083333333334, 53.46625, 52.47625]]
train loss 0.7727562985420227, epoch 14, best loss 0.5992767573356629, best_epoch 4
GPU_0_using curriculum 20 with window 20
Epoch: [15][20/40]	Time  1.477 ( 1.502)	Data  0.027 ( 0.039)	InnerLoop  0.627 ( 0.642)	Loss 7.4968e-01 (7.9568e-01)	Acc@1  74.22 ( 72.26)
Epoch: [15][40/40]	Time  1.450 ( 1.501)	Data  0.011 ( 0.039)	InnerLoop  0.619 ( 0.639)	Loss 6.9298e-01 (7.6845e-01)	Acc@1  73.96 ( 72.78)
The current update step is 640
GPU_0_using curriculum 20 with window 20
Epoch: [16][20/40]	Time  1.483 ( 1.498)	Data  0.030 ( 0.045)	InnerLoop  0.625 ( 0.631)	Loss 7.7536e-01 (7.8092e-01)	Acc@1  69.60 ( 71.89)
Epoch: [16][40/40]	Time  1.566 ( 1.501)	Data  0.010 ( 0.039)	InnerLoop  0.734 ( 0.638)	Loss 8.2343e-01 (7.7147e-01)	Acc@1  65.10 ( 72.15)
The current update step is 680
GPU_0_using curriculum 20 with window 20
Epoch: [17][20/40]	Time  1.484 ( 1.499)	Data  0.026 ( 0.039)	InnerLoop  0.628 ( 0.636)	Loss 8.1430e-01 (7.8848e-01)	Acc@1  66.60 ( 70.96)
Epoch: [17][40/40]	Time  1.466 ( 1.501)	Data  0.010 ( 0.039)	InnerLoop  0.633 ( 0.637)	Loss 1.0224e+00 (7.9809e-01)	Acc@1  59.90 ( 71.07)
The current update step is 720
GPU_0_using curriculum 20 with window 20
Epoch: [18][20/40]	Time  1.481 ( 1.504)	Data  0.028 ( 0.044)	InnerLoop  0.627 ( 0.636)	Loss 6.0146e-01 (8.5149e-01)	Acc@1  79.10 ( 68.84)
Epoch: [18][40/40]	Time  1.465 ( 1.502)	Data  0.011 ( 0.041)	InnerLoop  0.631 ( 0.637)	Loss 8.5559e-01 (8.1359e-01)	Acc@1  70.31 ( 70.00)
The current update step is 760
GPU_0_using curriculum 20 with window 20
Epoch: [19][20/40]	Time  1.601 ( 1.505)	Data  0.030 ( 0.039)	InnerLoop  0.744 ( 0.642)	Loss 5.8820e-01 (7.5714e-01)	Acc@1  78.48 ( 72.91)
Epoch: [19][40/40]	Time  1.466 ( 1.503)	Data  0.012 ( 0.038)	InnerLoop  0.629 ( 0.640)	Loss 6.8643e-01 (7.1568e-01)	Acc@1  74.48 ( 73.87)
The current update step is 800
The current seed is 12763281001280786600
The current lr is: 0.001
Testing Results:
 *   Acc@1 74.895
 *   Acc@1 75.513
 *   Acc@1 72.118
 *   Acc@1 72.887
 *   Acc@1 71.171
 *   Acc@1 71.426
 *   Acc@1 73.224
 *   Acc@1 73.325
 *   Acc@1 70.197
 *   Acc@1 71.066
 *   Acc@1 69.789
 *   Acc@1 70.280
Training for 300 epoch: 74.05921052631578
Training for 600 epoch: 71.15789473684211
Training for 1000 epoch: 70.48026315789474
Training for 300 epoch: 74.41875
Training for 600 epoch: 71.97625
Training for 1000 epoch: 70.85291666666666
[[74.05921052631578, 71.15789473684211, 70.48026315789474], [74.41875, 71.97625, 70.85291666666666]]
train loss 0.41251616950035097, epoch 19, best loss 0.41251616950035097, best_epoch 19
GPU_0_using curriculum 20 with window 20
Epoch: [20][20/40]	Time  1.482 ( 1.497)	Data  0.026 ( 0.033)	InnerLoop  0.634 ( 0.643)	Loss 6.2046e-01 (6.9651e-01)	Acc@1  75.98 ( 73.81)
Epoch: [20][40/40]	Time  1.471 ( 1.501)	Data  0.013 ( 0.036)	InnerLoop  0.637 ( 0.643)	Loss 6.7640e-01 (7.1648e-01)	Acc@1  70.31 ( 73.42)
The current update step is 840
GPU_0_using curriculum 20 with window 20
Epoch: [21][20/40]	Time  1.483 ( 1.497)	Data  0.026 ( 0.033)	InnerLoop  0.637 ( 0.643)	Loss 6.7523e-01 (7.9554e-01)	Acc@1  75.81 ( 71.91)
Epoch: [21][40/40]	Time  1.456 ( 1.498)	Data  0.011 ( 0.036)	InnerLoop  0.625 ( 0.640)	Loss 7.9101e-01 (8.5394e-01)	Acc@1  74.48 ( 69.78)
The current update step is 880
GPU_0_using curriculum 20 with window 20
Epoch: [22][20/40]	Time  1.595 ( 1.502)	Data  0.029 ( 0.039)	InnerLoop  0.740 ( 0.643)	Loss 7.1696e-01 (8.0949e-01)	Acc@1  71.65 ( 72.14)
Epoch: [22][40/40]	Time  1.454 ( 1.500)	Data  0.011 ( 0.039)	InnerLoop  0.626 ( 0.639)	Loss 1.0865e+00 (7.8353e-01)	Acc@1  65.10 ( 73.04)
The current update step is 920
GPU_0_using curriculum 20 with window 20
Epoch: [23][20/40]	Time  1.486 ( 1.503)	Data  0.028 ( 0.033)	InnerLoop  0.632 ( 0.646)	Loss 6.2399e-01 (8.2075e-01)	Acc@1  77.67 ( 71.23)
Epoch: [23][40/40]	Time  1.455 ( 1.506)	Data  0.011 ( 0.036)	InnerLoop  0.625 ( 0.646)	Loss 7.4453e-01 (8.0147e-01)	Acc@1  72.92 ( 72.46)
The current update step is 960
GPU_0_using curriculum 20 with window 20
Epoch: [24][20/40]	Time  1.493 ( 1.499)	Data  0.026 ( 0.039)	InnerLoop  0.642 ( 0.637)	Loss 6.9879e-01 (7.6589e-01)	Acc@1  77.44 ( 74.03)
Epoch: [24][40/40]	Time  1.463 ( 1.500)	Data  0.012 ( 0.036)	InnerLoop  0.625 ( 0.640)	Loss 6.9683e-01 (7.4695e-01)	Acc@1  75.52 ( 74.10)
The current update step is 1000
The current seed is 5765076861410718995
The current lr is: 0.001
Testing Results:
 *   Acc@1 78.882
 *   Acc@1 79.093
 *   Acc@1 77.487
 *   Acc@1 78.012
 *   Acc@1 76.855
 *   Acc@1 77.007
 *   Acc@1 55.066
 *   Acc@1 54.790
 *   Acc@1 54.868
 *   Acc@1 55.076
 *   Acc@1 52.013
 *   Acc@1 52.229
Training for 300 epoch: 66.97368421052632
Training for 600 epoch: 66.17763157894737
Training for 1000 epoch: 64.4342105263158
Training for 300 epoch: 66.94125
Training for 600 epoch: 66.54375
Training for 1000 epoch: 64.61791666666666
[[66.97368421052632, 66.17763157894737, 64.4342105263158], [66.94125, 66.54375, 64.61791666666666]]
train loss 1.018132297515869, epoch 24, best loss 0.41251616950035097, best_epoch 19
GPU_0_using curriculum 20 with window 20
Epoch: [25][20/40]	Time  1.486 ( 1.502)	Data  0.031 ( 0.040)	InnerLoop  0.631 ( 0.639)	Loss 8.1881e-01 (7.5606e-01)	Acc@1  69.04 ( 72.68)
Epoch: [25][40/40]	Time  1.475 ( 1.503)	Data  0.011 ( 0.036)	InnerLoop  0.638 ( 0.642)	Loss 5.2946e-01 (7.8494e-01)	Acc@1  79.17 ( 71.78)
The current update step is 1040
GPU_0_using curriculum 20 with window 20
Epoch: [26][20/40]	Time  1.590 ( 1.503)	Data  0.028 ( 0.045)	InnerLoop  0.735 ( 0.635)	Loss 8.0278e-01 (6.9151e-01)	Acc@1  70.51 ( 74.70)
Epoch: [26][40/40]	Time  1.466 ( 1.501)	Data  0.012 ( 0.041)	InnerLoop  0.632 ( 0.635)	Loss 8.8401e-01 (6.9981e-01)	Acc@1  68.75 ( 74.66)
The current update step is 1080
GPU_0_using curriculum 20 with window 20
Epoch: [27][20/40]	Time  1.477 ( 1.493)	Data  0.028 ( 0.044)	InnerLoop  0.621 ( 0.627)	Loss 6.3162e-01 (8.1796e-01)	Acc@1  75.98 ( 70.88)
Epoch: [27][40/40]	Time  1.466 ( 1.495)	Data  0.011 ( 0.038)	InnerLoop  0.631 ( 0.634)	Loss 6.6984e-01 (7.6185e-01)	Acc@1  75.00 ( 72.27)
The current update step is 1120
GPU_0_using curriculum 20 with window 20
Epoch: [28][20/40]	Time  1.484 ( 1.504)	Data  0.030 ( 0.039)	InnerLoop  0.627 ( 0.641)	Loss 5.6528e-01 (6.6718e-01)	Acc@1  78.81 ( 75.78)
Epoch: [28][40/40]	Time  1.457 ( 1.501)	Data  0.011 ( 0.039)	InnerLoop  0.621 ( 0.638)	Loss 6.5998e-01 (6.8925e-01)	Acc@1  73.96 ( 74.80)
The current update step is 1160
GPU_0_using curriculum 20 with window 20
Epoch: [29][20/40]	Time  1.480 ( 1.495)	Data  0.027 ( 0.039)	InnerLoop  0.625 ( 0.634)	Loss 6.1238e-01 (6.7134e-01)	Acc@1  77.38 ( 75.57)
Epoch: [29][40/40]	Time  1.464 ( 1.500)	Data  0.011 ( 0.038)	InnerLoop  0.629 ( 0.638)	Loss 5.3058e-01 (7.0352e-01)	Acc@1  80.21 ( 74.50)
The current update step is 1200
The current seed is 171925430063065181
The current lr is: 0.001
Testing Results:
 *   Acc@1 56.921
 *   Acc@1 57.752
 *   Acc@1 49.921
 *   Acc@1 49.871
 *   Acc@1 47.276
 *   Acc@1 47.249
 *   Acc@1 66.855
 *   Acc@1 67.948
 *   Acc@1 67.105
 *   Acc@1 67.802
 *   Acc@1 65.039
 *   Acc@1 65.891
Training for 300 epoch: 61.88815789473684
Training for 600 epoch: 58.51315789473684
Training for 1000 epoch: 56.1578947368421
Training for 300 epoch: 62.85
Training for 600 epoch: 58.83666666666666
Training for 1000 epoch: 56.57
[[61.88815789473684, 58.51315789473684, 56.1578947368421], [62.85, 58.83666666666666, 56.57]]
train loss 0.5125033767700196, epoch 29, best loss 0.41251616950035097, best_epoch 19
GPU_0_using curriculum 20 with window 20
Epoch: [30][20/40]	Time  1.477 ( 1.502)	Data  0.027 ( 0.039)	InnerLoop  0.625 ( 0.640)	Loss 6.0979e-01 (7.0677e-01)	Acc@1  78.35 ( 73.75)
Epoch: [30][40/40]	Time  1.452 ( 1.498)	Data  0.013 ( 0.039)	InnerLoop  0.618 ( 0.637)	Loss 9.1768e-01 (7.1715e-01)	Acc@1  69.79 ( 73.56)
The current update step is 1240
GPU_0_using curriculum 20 with window 20
Epoch: [31][20/40]	Time  1.471 ( 1.496)	Data  0.027 ( 0.044)	InnerLoop  0.622 ( 0.629)	Loss 6.3375e-01 (7.0465e-01)	Acc@1  76.92 ( 74.19)
Epoch: [31][40/40]	Time  1.570 ( 1.498)	Data  0.010 ( 0.037)	InnerLoop  0.737 ( 0.637)	Loss 1.1254e+00 (7.0662e-01)	Acc@1  61.46 ( 74.21)
The current update step is 1280
GPU_0_using curriculum 20 with window 20
Epoch: [32][20/40]	Time  1.495 ( 1.498)	Data  0.028 ( 0.038)	InnerLoop  0.629 ( 0.635)	Loss 1.3021e+00 (8.5495e-01)	Acc@1  52.77 ( 69.86)
Epoch: [32][40/40]	Time  1.472 ( 1.499)	Data  0.012 ( 0.038)	InnerLoop  0.636 ( 0.637)	Loss 7.7629e-01 (8.1802e-01)	Acc@1  68.75 ( 71.39)
The current update step is 1320
GPU_0_using curriculum 20 with window 20
Epoch: [33][20/40]	Time  1.476 ( 1.509)	Data  0.027 ( 0.045)	InnerLoop  0.626 ( 0.640)	Loss 5.1722e-01 (7.2828e-01)	Acc@1  81.64 ( 72.79)
Epoch: [33][40/40]	Time  1.477 ( 1.508)	Data  0.012 ( 0.041)	InnerLoop  0.640 ( 0.641)	Loss 8.7199e-01 (7.2003e-01)	Acc@1  72.40 ( 73.55)
The current update step is 1360
GPU_0_using curriculum 20 with window 20
Epoch: [34][20/40]	Time  1.607 ( 1.537)	Data  0.030 ( 0.042)	InnerLoop  0.753 ( 0.657)	Loss 6.6268e-01 (7.5164e-01)	Acc@1  75.07 ( 72.94)
Epoch: [34][40/40]	Time  1.479 ( 1.526)	Data  0.013 ( 0.040)	InnerLoop  0.638 ( 0.652)	Loss 7.7447e-01 (7.2985e-01)	Acc@1  73.44 ( 73.87)
The current update step is 1400
The current seed is 12583362567138569839
The current lr is: 0.001
Testing Results:
 *   Acc@1 75.737
 *   Acc@1 75.939
 *   Acc@1 74.776
 *   Acc@1 74.491
 *   Acc@1 75.197
 *   Acc@1 75.225
 *   Acc@1 75.816
 *   Acc@1 76.134
 *   Acc@1 75.474
 *   Acc@1 75.873
 *   Acc@1 75.026
 *   Acc@1 75.718
Training for 300 epoch: 75.77631578947368
Training for 600 epoch: 75.125
Training for 1000 epoch: 75.11184210526315
Training for 300 epoch: 76.03666666666666
Training for 600 epoch: 75.18166666666667
Training for 1000 epoch: 75.47166666666666
[[75.77631578947368, 75.125, 75.11184210526315], [76.03666666666666, 75.18166666666667, 75.47166666666666]]
train loss 0.3883369567871094, epoch 34, best loss 0.3883369567871094, best_epoch 34
GPU_0_using curriculum 20 with window 20
Epoch: [35][20/40]	Time  1.496 ( 1.528)	Data  0.030 ( 0.036)	InnerLoop  0.629 ( 0.656)	Loss 7.2907e-01 (6.8982e-01)	Acc@1  72.85 ( 75.23)
Epoch: [35][40/40]	Time  1.485 ( 1.525)	Data  0.011 ( 0.037)	InnerLoop  0.643 ( 0.653)	Loss 6.5016e-01 (6.9998e-01)	Acc@1  76.56 ( 75.09)
The current update step is 1440
GPU_0_using curriculum 20 with window 20
Epoch: [36][20/40]	Time  1.492 ( 1.513)	Data  0.027 ( 0.034)	InnerLoop  0.635 ( 0.650)	Loss 6.3098e-01 (6.7698e-01)	Acc@1  76.56 ( 75.97)
Epoch: [36][40/40]	Time  1.485 ( 1.510)	Data  0.013 ( 0.036)	InnerLoop  0.641 ( 0.646)	Loss 7.2935e-01 (7.1846e-01)	Acc@1  72.40 ( 74.71)
The current update step is 1480
GPU_0_using curriculum 20 with window 20
Epoch: [37][20/40]	Time  1.607 ( 1.515)	Data  0.028 ( 0.040)	InnerLoop  0.743 ( 0.648)	Loss 6.0791e-01 (6.8785e-01)	Acc@1  79.92 ( 75.55)
Epoch: [37][40/40]	Time  1.476 ( 1.515)	Data  0.011 ( 0.039)	InnerLoop  0.635 ( 0.646)	Loss 5.1232e-01 (6.7804e-01)	Acc@1  79.17 ( 75.90)
The current update step is 1520
GPU_0_using curriculum 20 with window 20
Epoch: [38][20/40]	Time  1.603 ( 1.524)	Data  0.033 ( 0.034)	InnerLoop  0.695 ( 0.654)	Loss 8.5364e-01 (6.5660e-01)	Acc@1  70.44 ( 75.99)
Epoch: [38][40/40]	Time  1.492 ( 1.539)	Data  0.012 ( 0.038)	InnerLoop  0.645 ( 0.661)	Loss 7.7419e-01 (6.7480e-01)	Acc@1  72.92 ( 75.62)
The current update step is 1560
GPU_0_using curriculum 20 with window 20
Epoch: [39][20/40]	Time  1.537 ( 1.551)	Data  0.032 ( 0.043)	InnerLoop  0.649 ( 0.663)	Loss 8.5785e-01 (8.2264e-01)	Acc@1  66.28 ( 70.58)
Epoch: [39][40/40]	Time  1.484 ( 1.546)	Data  0.013 ( 0.039)	InnerLoop  0.641 ( 0.663)	Loss 5.8724e-01 (8.1673e-01)	Acc@1  78.12 ( 70.27)
The current update step is 1600
The current seed is 15479533450486547911
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.092
 *   Acc@1 73.507
 *   Acc@1 68.724
 *   Acc@1 69.246
 *   Acc@1 66.000
 *   Acc@1 66.143
 *   Acc@1 70.329
 *   Acc@1 70.342
 *   Acc@1 69.224
 *   Acc@1 68.802
 *   Acc@1 68.039
 *   Acc@1 67.786
Training for 300 epoch: 71.71052631578948
Training for 600 epoch: 68.97368421052632
Training for 1000 epoch: 67.01973684210526
Training for 300 epoch: 71.92458333333333
Training for 600 epoch: 69.02416666666667
Training for 1000 epoch: 66.96458333333334
[[71.71052631578948, 68.97368421052632, 67.01973684210526], [71.92458333333333, 69.02416666666667, 66.96458333333334]]
train loss 0.506789106464386, epoch 39, best loss 0.3883369567871094, best_epoch 34
GPU_0_using curriculum 20 with window 20
Epoch: [40][20/40]	Time  1.490 ( 1.517)	Data  0.029 ( 0.040)	InnerLoop  0.629 ( 0.646)	Loss 5.9204e-01 (6.8103e-01)	Acc@1  79.26 ( 74.82)
Epoch: [40][40/40]	Time  1.466 ( 1.513)	Data  0.013 ( 0.037)	InnerLoop  0.629 ( 0.647)	Loss 6.1741e-01 (6.5058e-01)	Acc@1  77.60 ( 76.06)
The current update step is 1640
GPU_0_using curriculum 20 with window 20
Epoch: [41][20/40]	Time  1.598 ( 1.510)	Data  0.028 ( 0.046)	InnerLoop  0.745 ( 0.639)	Loss 5.0811e-01 (6.5233e-01)	Acc@1  81.41 ( 75.98)
Epoch: [41][40/40]	Time  1.486 ( 1.512)	Data  0.014 ( 0.042)	InnerLoop  0.641 ( 0.641)	Loss 5.5699e-01 (6.8047e-01)	Acc@1  80.73 ( 74.86)
The current update step is 1680
GPU_0_using curriculum 20 with window 20
Epoch: [42][20/40]	Time  1.494 ( 1.509)	Data  0.030 ( 0.046)	InnerLoop  0.636 ( 0.635)	Loss 4.8048e-01 (6.2295e-01)	Acc@1  82.49 ( 77.55)
Epoch: [42][40/40]	Time  1.483 ( 1.511)	Data  0.012 ( 0.040)	InnerLoop  0.633 ( 0.642)	Loss 6.3115e-01 (6.5295e-01)	Acc@1  74.48 ( 76.44)
The current update step is 1720
GPU_0_using curriculum 20 with window 20
Epoch: [43][20/40]	Time  1.488 ( 1.517)	Data  0.026 ( 0.040)	InnerLoop  0.630 ( 0.648)	Loss 7.5962e-01 (6.4208e-01)	Acc@1  72.49 ( 76.61)
Epoch: [43][40/40]	Time  1.479 ( 1.515)	Data  0.012 ( 0.040)	InnerLoop  0.638 ( 0.646)	Loss 4.8123e-01 (6.3810e-01)	Acc@1  80.73 ( 76.98)
The current update step is 1760
GPU_0_using curriculum 20 with window 20
Epoch: [44][20/40]	Time  1.487 ( 1.508)	Data  0.028 ( 0.040)	InnerLoop  0.631 ( 0.641)	Loss 5.8271e-01 (6.6736e-01)	Acc@1  79.07 ( 75.91)
Epoch: [44][40/40]	Time  1.448 ( 1.512)	Data  0.011 ( 0.040)	InnerLoop  0.622 ( 0.644)	Loss 9.2879e-01 (6.8094e-01)	Acc@1  64.58 ( 75.52)
The current update step is 1800
The current seed is 10941254997311390627
The current lr is: 0.001
Testing Results:
 *   Acc@1 78.316
 *   Acc@1 78.635
 *   Acc@1 78.079
 *   Acc@1 78.458
 *   Acc@1 77.579
 *   Acc@1 78.298
 *   Acc@1 78.395
 *   Acc@1 78.515
 *   Acc@1 77.382
 *   Acc@1 77.233
 *   Acc@1 76.000
 *   Acc@1 76.093
Training for 300 epoch: 78.35526315789474
Training for 600 epoch: 77.73026315789474
Training for 1000 epoch: 76.78947368421052
Training for 300 epoch: 78.575
Training for 600 epoch: 77.84541666666667
Training for 1000 epoch: 77.19541666666666
[[78.35526315789474, 77.73026315789474, 76.78947368421052], [78.575, 77.84541666666667, 77.19541666666666]]
train loss 0.35893567123413084, epoch 44, best loss 0.35893567123413084, best_epoch 44
GPU_0_using curriculum 20 with window 20
Epoch: [45][20/40]	Time  1.483 ( 1.516)	Data  0.028 ( 0.039)	InnerLoop  0.628 ( 0.649)	Loss 5.7423e-01 (6.3181e-01)	Acc@1  79.33 ( 76.71)
Epoch: [45][40/40]	Time  1.482 ( 1.523)	Data  0.012 ( 0.039)	InnerLoop  0.636 ( 0.648)	Loss 6.0869e-01 (6.3593e-01)	Acc@1  75.00 ( 76.87)
The current update step is 1840
GPU_0_using curriculum 20 with window 20
Epoch: [46][20/40]	Time  1.490 ( 1.518)	Data  0.029 ( 0.047)	InnerLoop  0.628 ( 0.640)	Loss 6.7734e-01 (6.8877e-01)	Acc@1  75.81 ( 74.54)
Epoch: [46][40/40]	Time  1.621 ( 1.523)	Data  0.013 ( 0.040)	InnerLoop  0.761 ( 0.649)	Loss 6.6002e-01 (6.5572e-01)	Acc@1  74.48 ( 75.92)
The current update step is 1880
GPU_0_using curriculum 20 with window 20
Epoch: [47][20/40]	Time  1.508 ( 1.533)	Data  0.030 ( 0.042)	InnerLoop  0.640 ( 0.654)	Loss 5.9556e-01 (6.2279e-01)	Acc@1  78.35 ( 77.96)
Epoch: [47][40/40]	Time  1.504 ( 1.532)	Data  0.012 ( 0.041)	InnerLoop  0.639 ( 0.652)	Loss 5.1704e-01 (6.3315e-01)	Acc@1  85.94 ( 77.27)
The current update step is 1920
GPU_0_using curriculum 20 with window 20
Epoch: [48][20/40]	Time  1.495 ( 1.528)	Data  0.028 ( 0.046)	InnerLoop  0.630 ( 0.647)	Loss 5.7513e-01 (6.4178e-01)	Acc@1  78.48 ( 77.05)
Epoch: [48][40/40]	Time  1.489 ( 1.525)	Data  0.014 ( 0.043)	InnerLoop  0.638 ( 0.647)	Loss 6.4012e-01 (6.8241e-01)	Acc@1  77.08 ( 76.00)
The current update step is 1960
GPU_0_using curriculum 20 with window 20
Epoch: [49][20/40]	Time  1.600 ( 1.526)	Data  0.026 ( 0.041)	InnerLoop  0.745 ( 0.652)	Loss 5.9506e-01 (7.6865e-01)	Acc@1  76.17 ( 72.97)
Epoch: [49][40/40]	Time  1.532 ( 1.525)	Data  0.014 ( 0.040)	InnerLoop  0.670 ( 0.651)	Loss 5.3586e-01 (7.8602e-01)	Acc@1  81.25 ( 72.52)
The current update step is 2000
The current seed is 11558262184098220754
The current lr is: 0.001
Testing Results:
 *   Acc@1 75.737
 *   Acc@1 76.171
 *   Acc@1 74.645
 *   Acc@1 74.663
 *   Acc@1 74.053
 *   Acc@1 73.438
 *   Acc@1 75.053
 *   Acc@1 75.550
 *   Acc@1 74.342
 *   Acc@1 75.067
 *   Acc@1 74.355
 *   Acc@1 74.674
Training for 300 epoch: 75.39473684210526
Training for 600 epoch: 74.49342105263158
Training for 1000 epoch: 74.20394736842105
Training for 300 epoch: 75.86041666666667
Training for 600 epoch: 74.86541666666666
Training for 1000 epoch: 74.05583333333334
[[75.39473684210526, 74.49342105263158, 74.20394736842105], [75.86041666666667, 74.86541666666666, 74.05583333333334]]
train loss 0.385912525510788, epoch 49, best loss 0.35893567123413084, best_epoch 44
GPU_0_using curriculum 20 with window 20
Epoch: [50][20/40]	Time  1.508 ( 1.523)	Data  0.028 ( 0.034)	InnerLoop  0.639 ( 0.654)	Loss 6.3421e-01 (6.7355e-01)	Acc@1  74.67 ( 75.23)
Epoch: [50][40/40]	Time  1.482 ( 1.527)	Data  0.013 ( 0.037)	InnerLoop  0.636 ( 0.655)	Loss 5.8161e-01 (7.0270e-01)	Acc@1  80.21 ( 74.46)
The current update step is 2040
GPU_0_using curriculum 20 with window 20
Epoch: [51][20/40]	Time  1.471 ( 1.512)	Data  0.026 ( 0.034)	InnerLoop  0.622 ( 0.650)	Loss 7.0132e-01 (6.7541e-01)	Acc@1  71.32 ( 75.69)
Epoch: [51][40/40]	Time  1.495 ( 1.505)	Data  0.013 ( 0.035)	InnerLoop  0.649 ( 0.643)	Loss 5.9551e-01 (6.7447e-01)	Acc@1  77.08 ( 75.86)
The current update step is 2080
GPU_0_using curriculum 20 with window 20
Epoch: [52][20/40]	Time  1.623 ( 1.514)	Data  0.031 ( 0.039)	InnerLoop  0.758 ( 0.646)	Loss 5.7304e-01 (6.2654e-01)	Acc@1  79.85 ( 76.98)
Epoch: [52][40/40]	Time  1.469 ( 1.512)	Data  0.013 ( 0.039)	InnerLoop  0.627 ( 0.643)	Loss 6.6386e-01 (6.6182e-01)	Acc@1  79.17 ( 75.79)
The current update step is 2120
GPU_0_using curriculum 20 with window 20
Epoch: [53][20/40]	Time  1.474 ( 1.501)	Data  0.028 ( 0.033)	InnerLoop  0.623 ( 0.642)	Loss 6.6235e-01 (6.2128e-01)	Acc@1  76.30 ( 77.28)
Epoch: [53][40/40]	Time  1.452 ( 1.501)	Data  0.011 ( 0.035)	InnerLoop  0.622 ( 0.641)	Loss 6.5137e-01 (6.2818e-01)	Acc@1  77.08 ( 77.13)
The current update step is 2160
GPU_0_using curriculum 20 with window 20
Epoch: [54][20/40]	Time  1.471 ( 1.494)	Data  0.026 ( 0.038)	InnerLoop  0.621 ( 0.632)	Loss 8.2773e-01 (7.1332e-01)	Acc@1  71.68 ( 74.83)
Epoch: [54][40/40]	Time  1.459 ( 1.496)	Data  0.011 ( 0.035)	InnerLoop  0.625 ( 0.636)	Loss 6.5666e-01 (6.7327e-01)	Acc@1  71.88 ( 75.70)
The current update step is 2200
The current seed is 14325823514129308005
The current lr is: 0.001
Testing Results:
 *   Acc@1 68.368
 *   Acc@1 68.448
 *   Acc@1 64.316
 *   Acc@1 64.564
 *   Acc@1 63.882
 *   Acc@1 64.188
 *   Acc@1 77.316
 *   Acc@1 77.285
 *   Acc@1 72.158
 *   Acc@1 72.615
 *   Acc@1 71.882
 *   Acc@1 71.950
Training for 300 epoch: 72.84210526315789
Training for 600 epoch: 68.23684210526315
Training for 1000 epoch: 67.88157894736842
Training for 300 epoch: 72.86625000000001
Training for 600 epoch: 68.58958333333334
Training for 1000 epoch: 68.06916666666666
[[72.84210526315789, 68.23684210526315, 67.88157894736842], [72.86625000000001, 68.58958333333334, 68.06916666666666]]
train loss 0.3576132432460785, epoch 54, best loss 0.3576132432460785, best_epoch 54
GPU_0_using curriculum 20 with window 20
Epoch: [55][20/40]	Time  1.476 ( 1.502)	Data  0.025 ( 0.039)	InnerLoop  0.623 ( 0.637)	Loss 7.8441e-01 (6.8189e-01)	Acc@1  72.27 ( 76.14)
Epoch: [55][40/40]	Time  1.470 ( 1.509)	Data  0.013 ( 0.036)	InnerLoop  0.627 ( 0.643)	Loss 6.2629e-01 (6.6291e-01)	Acc@1  78.65 ( 76.37)
The current update step is 2240
GPU_0_using curriculum 20 with window 20
Epoch: [56][20/40]	Time  1.593 ( 1.505)	Data  0.026 ( 0.045)	InnerLoop  0.737 ( 0.636)	Loss 7.5632e-01 (6.6662e-01)	Acc@1  70.28 ( 75.44)
Epoch: [56][40/40]	Time  1.484 ( 1.513)	Data  0.012 ( 0.042)	InnerLoop  0.641 ( 0.641)	Loss 6.6362e-01 (6.4732e-01)	Acc@1  68.75 ( 76.30)
The current update step is 2280
GPU_0_using curriculum 20 with window 20
Epoch: [57][20/40]	Time  1.481 ( 1.523)	Data  0.026 ( 0.047)	InnerLoop  0.629 ( 0.641)	Loss 1.0110e+00 (7.5587e-01)	Acc@1  67.55 ( 73.45)
Epoch: [57][40/40]	Time  1.493 ( 1.525)	Data  0.013 ( 0.040)	InnerLoop  0.646 ( 0.648)	Loss 5.7802e-01 (7.3588e-01)	Acc@1  78.12 ( 73.75)
The current update step is 2320
GPU_0_using curriculum 20 with window 20
Epoch: [58][20/40]	Time  1.493 ( 1.513)	Data  0.027 ( 0.039)	InnerLoop  0.636 ( 0.645)	Loss 5.4366e-01 (6.5380e-01)	Acc@1  81.05 ( 76.80)
Epoch: [58][40/40]	Time  1.472 ( 1.513)	Data  0.010 ( 0.039)	InnerLoop  0.632 ( 0.644)	Loss 7.0491e-01 (6.7689e-01)	Acc@1  76.04 ( 76.14)
The current update step is 2360
GPU_0_using curriculum 20 with window 20
Epoch: [59][20/40]	Time  1.487 ( 1.509)	Data  0.027 ( 0.040)	InnerLoop  0.629 ( 0.640)	Loss 5.1830e-01 (6.4787e-01)	Acc@1  82.94 ( 76.31)
Epoch: [59][40/40]	Time  1.466 ( 1.510)	Data  0.012 ( 0.039)	InnerLoop  0.628 ( 0.642)	Loss 4.3746e-01 (6.6078e-01)	Acc@1  81.77 ( 76.03)
The current update step is 2400
The current seed is 7571004588283282743
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.566
 *   Acc@1 74.137
 *   Acc@1 74.184
 *   Acc@1 74.214
 *   Acc@1 75.618
 *   Acc@1 75.833
 *   Acc@1 71.605
 *   Acc@1 72.055
 *   Acc@1 66.395
 *   Acc@1 66.385
 *   Acc@1 63.961
 *   Acc@1 64.177
Training for 300 epoch: 72.58552631578948
Training for 600 epoch: 70.28947368421052
Training for 1000 epoch: 69.78947368421052
Training for 300 epoch: 73.09583333333333
Training for 600 epoch: 70.29958333333335
Training for 1000 epoch: 70.00541666666666
[[72.58552631578948, 70.28947368421052, 69.78947368421052], [73.09583333333333, 70.29958333333335, 70.00541666666666]]
train loss 0.5132849286079407, epoch 59, best loss 0.3576132432460785, best_epoch 54
GPU_0_using curriculum 20 with window 20
Epoch: [60][20/40]	Time  1.481 ( 1.504)	Data  0.027 ( 0.038)	InnerLoop  0.627 ( 0.645)	Loss 7.0058e-01 (6.6844e-01)	Acc@1  70.93 ( 75.68)
Epoch: [60][40/40]	Time  1.470 ( 1.503)	Data  0.012 ( 0.037)	InnerLoop  0.628 ( 0.642)	Loss 5.0819e-01 (6.7192e-01)	Acc@1  81.25 ( 76.00)
The current update step is 2440
GPU_0_using curriculum 20 with window 20
Epoch: [61][20/40]	Time  1.483 ( 1.499)	Data  0.029 ( 0.044)	InnerLoop  0.625 ( 0.632)	Loss 8.1720e-01 (7.2883e-01)	Acc@1  70.96 ( 73.78)
Epoch: [61][40/40]	Time  1.570 ( 1.503)	Data  0.011 ( 0.038)	InnerLoop  0.735 ( 0.641)	Loss 6.2965e-01 (6.9559e-01)	Acc@1  76.04 ( 74.98)
The current update step is 2480
GPU_0_using curriculum 20 with window 20
Epoch: [62][20/40]	Time  1.483 ( 1.498)	Data  0.026 ( 0.039)	InnerLoop  0.628 ( 0.637)	Loss 5.4920e-01 (6.0805e-01)	Acc@1  79.62 ( 78.06)
Epoch: [62][40/40]	Time  1.477 ( 1.502)	Data  0.010 ( 0.038)	InnerLoop  0.637 ( 0.638)	Loss 6.6896e-01 (6.4479e-01)	Acc@1  76.56 ( 77.17)
The current update step is 2520
GPU_0_using curriculum 20 with window 20
Epoch: [63][20/40]	Time  1.482 ( 1.510)	Data  0.029 ( 0.045)	InnerLoop  0.630 ( 0.638)	Loss 5.8035e-01 (6.4125e-01)	Acc@1  80.57 ( 77.21)
Epoch: [63][40/40]	Time  1.463 ( 1.504)	Data  0.013 ( 0.041)	InnerLoop  0.627 ( 0.638)	Loss 5.4248e-01 (6.2747e-01)	Acc@1  76.56 ( 77.74)
The current update step is 2560
GPU_0_using curriculum 20 with window 20
Epoch: [64][20/40]	Time  1.592 ( 1.503)	Data  0.027 ( 0.039)	InnerLoop  0.740 ( 0.642)	Loss 5.1461e-01 (6.1975e-01)	Acc@1  81.71 ( 77.65)
Epoch: [64][40/40]	Time  1.457 ( 1.501)	Data  0.014 ( 0.039)	InnerLoop  0.623 ( 0.640)	Loss 5.9564e-01 (6.2656e-01)	Acc@1  79.17 ( 77.40)
The current update step is 2600
The current seed is 12232065226223373331
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.566
 *   Acc@1 78.535
 *   Acc@1 74.079
 *   Acc@1 74.973
 *   Acc@1 70.750
 *   Acc@1 71.865
 *   Acc@1 67.895
 *   Acc@1 67.795
 *   Acc@1 62.447
 *   Acc@1 62.939
 *   Acc@1 59.368
 *   Acc@1 59.804
Training for 300 epoch: 72.73026315789474
Training for 600 epoch: 68.26315789473685
Training for 1000 epoch: 65.0592105263158
Training for 300 epoch: 73.16499999999999
Training for 600 epoch: 68.95625
Training for 1000 epoch: 65.83458333333333
[[72.73026315789474, 68.26315789473685, 65.0592105263158], [73.16499999999999, 68.95625, 65.83458333333333]]
train loss 0.4724832035064697, epoch 64, best loss 0.3576132432460785, best_epoch 54
GPU_0_using curriculum 20 with window 20
Epoch: [65][20/40]	Time  1.480 ( 1.497)	Data  0.027 ( 0.033)	InnerLoop  0.630 ( 0.642)	Loss 5.2674e-01 (6.3486e-01)	Acc@1  81.77 ( 77.64)
Epoch: [65][40/40]	Time  1.463 ( 1.501)	Data  0.013 ( 0.035)	InnerLoop  0.628 ( 0.643)	Loss 4.7419e-01 (6.1127e-01)	Acc@1  81.25 ( 78.19)
The current update step is 2640
GPU_0_using curriculum 20 with window 20
Epoch: [66][20/40]	Time  1.491 ( 1.501)	Data  0.026 ( 0.033)	InnerLoop  0.636 ( 0.645)	Loss 5.8400e-01 (6.3102e-01)	Acc@1  76.82 ( 77.43)
Epoch: [66][40/40]	Time  1.468 ( 1.502)	Data  0.012 ( 0.035)	InnerLoop  0.633 ( 0.643)	Loss 9.5448e-01 (6.3425e-01)	Acc@1  67.19 ( 77.19)
The current update step is 2680
GPU_0_using curriculum 20 with window 20
Epoch: [67][20/40]	Time  1.595 ( 1.508)	Data  0.028 ( 0.038)	InnerLoop  0.747 ( 0.646)	Loss 5.1985e-01 (6.7700e-01)	Acc@1  80.76 ( 76.06)
Epoch: [67][40/40]	Time  1.453 ( 1.505)	Data  0.011 ( 0.038)	InnerLoop  0.625 ( 0.643)	Loss 9.8766e-01 (6.7162e-01)	Acc@1  67.19 ( 76.18)
The current update step is 2720
GPU_0_using curriculum 20 with window 20
Epoch: [68][20/40]	Time  1.484 ( 1.502)	Data  0.027 ( 0.033)	InnerLoop  0.632 ( 0.647)	Loss 8.0051e-01 (6.8414e-01)	Acc@1  71.55 ( 74.75)
Epoch: [68][40/40]	Time  1.463 ( 1.505)	Data  0.010 ( 0.035)	InnerLoop  0.630 ( 0.646)	Loss 6.8544e-01 (6.7003e-01)	Acc@1  75.00 ( 75.18)
The current update step is 2760
GPU_0_using curriculum 20 with window 20
Epoch: [69][20/40]	Time  1.472 ( 1.500)	Data  0.026 ( 0.038)	InnerLoop  0.621 ( 0.639)	Loss 6.8313e-01 (6.6935e-01)	Acc@1  71.94 ( 75.66)
Epoch: [69][40/40]	Time  1.456 ( 1.501)	Data  0.011 ( 0.035)	InnerLoop  0.623 ( 0.642)	Loss 7.3162e-01 (6.5318e-01)	Acc@1  71.88 ( 76.10)
The current update step is 2800
The current seed is 8966100722159245627
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.895
 *   Acc@1 74.733
 *   Acc@1 72.961
 *   Acc@1 74.339
 *   Acc@1 72.276
 *   Acc@1 73.224
 *   Acc@1 78.132
 *   Acc@1 78.173
 *   Acc@1 75.632
 *   Acc@1 75.933
 *   Acc@1 73.276
 *   Acc@1 73.804
Training for 300 epoch: 76.01315789473685
Training for 600 epoch: 74.29605263157896
Training for 1000 epoch: 72.77631578947368
Training for 300 epoch: 76.45333333333333
Training for 600 epoch: 75.13583333333334
Training for 1000 epoch: 73.51416666666665
[[76.01315789473685, 74.29605263157896, 72.77631578947368], [76.45333333333333, 75.13583333333334, 73.51416666666665]]
train loss 0.3673246874332428, epoch 69, best loss 0.3576132432460785, best_epoch 54
GPU_0_using curriculum 20 with window 20
Epoch: [70][20/40]	Time  1.476 ( 1.495)	Data  0.026 ( 0.038)	InnerLoop  0.628 ( 0.635)	Loss 5.6220e-01 (6.9925e-01)	Acc@1  79.85 ( 75.03)
Epoch: [70][40/40]	Time  1.457 ( 1.497)	Data  0.011 ( 0.035)	InnerLoop  0.624 ( 0.638)	Loss 7.8118e-01 (6.7874e-01)	Acc@1  69.79 ( 75.59)
The current update step is 2840
GPU_0_using curriculum 20 with window 20
Epoch: [71][20/40]	Time  1.593 ( 1.503)	Data  0.027 ( 0.044)	InnerLoop  0.741 ( 0.637)	Loss 8.5482e-01 (6.7744e-01)	Acc@1  70.61 ( 75.20)
Epoch: [71][40/40]	Time  1.443 ( 1.500)	Data  0.012 ( 0.040)	InnerLoop  0.617 ( 0.636)	Loss 7.5229e-01 (6.3453e-01)	Acc@1  75.00 ( 76.82)
The current update step is 2880
GPU_0_using curriculum 20 with window 20
Epoch: [72][20/40]	Time  1.475 ( 1.494)	Data  0.026 ( 0.044)	InnerLoop  0.625 ( 0.629)	Loss 6.3623e-01 (6.4362e-01)	Acc@1  77.96 ( 76.63)
Epoch: [72][40/40]	Time  1.456 ( 1.495)	Data  0.013 ( 0.038)	InnerLoop  0.620 ( 0.635)	Loss 8.6614e-01 (6.6971e-01)	Acc@1  72.92 ( 75.93)
The current update step is 2920
GPU_0_using curriculum 20 with window 20
Epoch: [73][20/40]	Time  1.471 ( 1.500)	Data  0.028 ( 0.039)	InnerLoop  0.618 ( 0.639)	Loss 6.2924e-01 (6.8194e-01)	Acc@1  77.12 ( 75.42)
Epoch: [73][40/40]	Time  1.469 ( 1.500)	Data  0.011 ( 0.039)	InnerLoop  0.633 ( 0.638)	Loss 4.6261e-01 (6.6865e-01)	Acc@1  81.25 ( 75.44)
The current update step is 2960
GPU_0_using curriculum 20 with window 20
Epoch: [74][20/40]	Time  1.468 ( 1.497)	Data  0.027 ( 0.039)	InnerLoop  0.622 ( 0.636)	Loss 5.4297e-01 (6.6903e-01)	Acc@1  81.02 ( 75.04)
Epoch: [74][40/40]	Time  1.459 ( 1.499)	Data  0.012 ( 0.038)	InnerLoop  0.626 ( 0.639)	Loss 6.5777e-01 (6.6036e-01)	Acc@1  75.00 ( 75.59)
The current update step is 3000
The current seed is 9472293879943238282
The current lr is: 0.001
Testing Results:
 *   Acc@1 72.092
 *   Acc@1 72.402
 *   Acc@1 71.026
 *   Acc@1 71.023
 *   Acc@1 70.671
 *   Acc@1 70.846
 *   Acc@1 76.697
 *   Acc@1 76.974
 *   Acc@1 73.566
 *   Acc@1 73.848
 *   Acc@1 72.592
 *   Acc@1 72.273
Training for 300 epoch: 74.39473684210526
Training for 600 epoch: 72.29605263157895
Training for 1000 epoch: 71.63157894736841
Training for 300 epoch: 74.68791666666667
Training for 600 epoch: 72.43583333333333
Training for 1000 epoch: 71.55958333333334
[[74.39473684210526, 72.29605263157895, 71.63157894736841], [74.68791666666667, 72.43583333333333, 71.55958333333334]]
train loss 0.3552299144744873, epoch 74, best loss 0.3552299144744873, best_epoch 74
GPU_0_using curriculum 20 with window 20
Epoch: [75][20/40]	Time  1.474 ( 1.501)	Data  0.025 ( 0.037)	InnerLoop  0.620 ( 0.642)	Loss 8.7959e-01 (6.2226e-01)	Acc@1  70.12 ( 77.11)
Epoch: [75][40/40]	Time  1.465 ( 1.500)	Data  0.013 ( 0.037)	InnerLoop  0.630 ( 0.639)	Loss 5.6436e-01 (6.6369e-01)	Acc@1  79.69 ( 75.58)
The current update step is 3040
GPU_0_using curriculum 20 with window 20
Epoch: [76][20/40]	Time  1.471 ( 1.495)	Data  0.027 ( 0.044)	InnerLoop  0.621 ( 0.629)	Loss 1.0009e+00 (8.1467e-01)	Acc@1  65.82 ( 70.85)
Epoch: [76][40/40]	Time  1.561 ( 1.497)	Data  0.012 ( 0.038)	InnerLoop  0.727 ( 0.636)	Loss 6.8687e-01 (7.4471e-01)	Acc@1  75.52 ( 72.55)
The current update step is 3080
GPU_0_using curriculum 20 with window 20
Epoch: [77][20/40]	Time  1.481 ( 1.498)	Data  0.027 ( 0.039)	InnerLoop  0.627 ( 0.636)	Loss 8.4020e-01 (6.7870e-01)	Acc@1  67.32 ( 75.02)
Epoch: [77][40/40]	Time  1.474 ( 1.499)	Data  0.011 ( 0.038)	InnerLoop  0.640 ( 0.637)	Loss 9.1842e-01 (7.2153e-01)	Acc@1  67.71 ( 73.44)
The current update step is 3120
GPU_0_using curriculum 20 with window 20
Epoch: [78][20/40]	Time  1.486 ( 1.513)	Data  0.028 ( 0.045)	InnerLoop  0.630 ( 0.639)	Loss 5.5209e-01 (7.1532e-01)	Acc@1  80.05 ( 73.56)
Epoch: [78][40/40]	Time  1.466 ( 1.513)	Data  0.012 ( 0.043)	InnerLoop  0.629 ( 0.640)	Loss 6.4550e-01 (7.0590e-01)	Acc@1  77.08 ( 73.85)
The current update step is 3160
GPU_0_using curriculum 20 with window 20
Epoch: [79][20/40]	Time  1.698 ( 1.588)	Data  0.031 ( 0.044)	InnerLoop  0.798 ( 0.683)	Loss 8.1039e-01 (6.8890e-01)	Acc@1  69.73 ( 74.03)
Epoch: [79][40/40]	Time  1.559 ( 1.593)	Data  0.015 ( 0.045)	InnerLoop  0.675 ( 0.683)	Loss 1.0714e+00 (6.8065e-01)	Acc@1  68.75 ( 74.49)
The current update step is 3200
The current seed is 16176260352530432924
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.961
 *   Acc@1 77.269
 *   Acc@1 76.132
 *   Acc@1 76.649
 *   Acc@1 75.697
 *   Acc@1 76.226
 *   Acc@1 72.618
 *   Acc@1 73.242
 *   Acc@1 73.816
 *   Acc@1 73.968
 *   Acc@1 73.000
 *   Acc@1 73.191
Training for 300 epoch: 74.78947368421052
Training for 600 epoch: 74.97368421052632
Training for 1000 epoch: 74.34868421052632
Training for 300 epoch: 75.25541666666666
Training for 600 epoch: 75.30833333333334
Training for 1000 epoch: 74.70833333333333
[[74.78947368421052, 74.97368421052632, 74.34868421052632], [75.25541666666666, 75.30833333333334, 74.70833333333333]]
train loss 0.3803541166305542, epoch 79, best loss 0.3552299144744873, best_epoch 74
GPU_0_using curriculum 20 with window 20
Epoch: [80][20/40]	Time  1.479 ( 1.516)	Data  0.028 ( 0.035)	InnerLoop  0.625 ( 0.650)	Loss 7.2223e-01 (6.0335e-01)	Acc@1  74.35 ( 77.80)
Epoch: [80][40/40]	Time  1.462 ( 1.514)	Data  0.010 ( 0.037)	InnerLoop  0.626 ( 0.647)	Loss 5.6046e-01 (6.0954e-01)	Acc@1  80.73 ( 77.54)
The current update step is 3240
GPU_0_using curriculum 20 with window 20
Epoch: [81][20/40]	Time  1.491 ( 1.503)	Data  0.027 ( 0.033)	InnerLoop  0.630 ( 0.645)	Loss 6.5848e-01 (6.2041e-01)	Acc@1  77.15 ( 77.91)
Epoch: [81][40/40]	Time  1.471 ( 1.503)	Data  0.012 ( 0.035)	InnerLoop  0.634 ( 0.641)	Loss 5.4768e-01 (6.4853e-01)	Acc@1  79.69 ( 76.60)
The current update step is 3280
GPU_0_using curriculum 20 with window 20
Epoch: [82][20/40]	Time  1.595 ( 1.507)	Data  0.027 ( 0.039)	InnerLoop  0.741 ( 0.643)	Loss 1.0486e+00 (7.2412e-01)	Acc@1  71.13 ( 74.38)
Epoch: [82][40/40]	Time  1.465 ( 1.505)	Data  0.010 ( 0.038)	InnerLoop  0.626 ( 0.641)	Loss 4.9936e-01 (6.7452e-01)	Acc@1  84.38 ( 75.63)
The current update step is 3320
GPU_0_using curriculum 20 with window 20
Epoch: [83][20/40]	Time  1.477 ( 1.505)	Data  0.028 ( 0.033)	InnerLoop  0.625 ( 0.645)	Loss 6.8975e-01 (6.6545e-01)	Acc@1  73.37 ( 75.72)
Epoch: [83][40/40]	Time  1.469 ( 1.506)	Data  0.011 ( 0.035)	InnerLoop  0.626 ( 0.644)	Loss 9.3433e-01 (6.6337e-01)	Acc@1  68.23 ( 75.68)
The current update step is 3360
GPU_0_using curriculum 20 with window 20
Epoch: [84][20/40]	Time  1.478 ( 1.500)	Data  0.028 ( 0.039)	InnerLoop  0.627 ( 0.637)	Loss 7.0073e-01 (6.5610e-01)	Acc@1  68.65 ( 74.68)
Epoch: [84][40/40]	Time  1.476 ( 1.501)	Data  0.011 ( 0.035)	InnerLoop  0.637 ( 0.640)	Loss 6.1894e-01 (6.5030e-01)	Acc@1  73.96 ( 75.25)
The current update step is 3400
The current seed is 5333917756508791302
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.171
 *   Acc@1 77.082
 *   Acc@1 76.224
 *   Acc@1 77.587
 *   Acc@1 76.553
 *   Acc@1 77.629
 *   Acc@1 75.447
 *   Acc@1 75.922
 *   Acc@1 72.303
 *   Acc@1 72.442
 *   Acc@1 69.145
 *   Acc@1 69.478
Training for 300 epoch: 75.80921052631578
Training for 600 epoch: 74.26315789473685
Training for 1000 epoch: 72.84868421052632
Training for 300 epoch: 76.50208333333333
Training for 600 epoch: 75.01416666666667
Training for 1000 epoch: 73.55333333333334
[[75.80921052631578, 74.26315789473685, 72.84868421052632], [76.50208333333333, 75.01416666666667, 73.55333333333334]]
train loss 0.3575306156158447, epoch 84, best loss 0.3552299144744873, best_epoch 74
GPU_0_using curriculum 20 with window 20
Epoch: [85][20/40]	Time  1.482 ( 1.497)	Data  0.027 ( 0.039)	InnerLoop  0.627 ( 0.636)	Loss 6.7811e-01 (6.4634e-01)	Acc@1  74.22 ( 75.98)
Epoch: [85][40/40]	Time  1.464 ( 1.501)	Data  0.011 ( 0.035)	InnerLoop  0.626 ( 0.640)	Loss 6.8436e-01 (6.5069e-01)	Acc@1  77.08 ( 76.21)
The current update step is 3440
GPU_0_using curriculum 20 with window 20
Epoch: [86][20/40]	Time  1.594 ( 1.507)	Data  0.026 ( 0.044)	InnerLoop  0.738 ( 0.638)	Loss 5.8066e-01 (6.7869e-01)	Acc@1  79.98 ( 76.02)
Epoch: [86][40/40]	Time  1.477 ( 1.504)	Data  0.012 ( 0.041)	InnerLoop  0.640 ( 0.638)	Loss 7.3709e-01 (6.5284e-01)	Acc@1  75.00 ( 76.48)
The current update step is 3480
GPU_0_using curriculum 20 with window 20
Epoch: [87][20/40]	Time  1.483 ( 1.500)	Data  0.030 ( 0.045)	InnerLoop  0.624 ( 0.631)	Loss 5.7753e-01 (6.2374e-01)	Acc@1  80.21 ( 76.96)
Epoch: [87][40/40]	Time  1.462 ( 1.500)	Data  0.010 ( 0.039)	InnerLoop  0.626 ( 0.637)	Loss 6.5807e-01 (6.3575e-01)	Acc@1  74.48 ( 76.35)
The current update step is 3520
GPU_0_using curriculum 20 with window 20
Epoch: [88][20/40]	Time  1.480 ( 1.508)	Data  0.026 ( 0.039)	InnerLoop  0.626 ( 0.643)	Loss 6.1044e-01 (6.1495e-01)	Acc@1  78.91 ( 77.26)
Epoch: [88][40/40]	Time  1.470 ( 1.505)	Data  0.012 ( 0.038)	InnerLoop  0.625 ( 0.640)	Loss 8.4451e-01 (6.4948e-01)	Acc@1  63.02 ( 75.76)
The current update step is 3560
GPU_0_using curriculum 20 with window 20
Epoch: [89][20/40]	Time  1.476 ( 1.497)	Data  0.028 ( 0.038)	InnerLoop  0.624 ( 0.635)	Loss 7.6091e-01 (6.9458e-01)	Acc@1  72.46 ( 74.60)
Epoch: [89][40/40]	Time  1.475 ( 1.502)	Data  0.012 ( 0.038)	InnerLoop  0.635 ( 0.639)	Loss 4.3562e-01 (6.5799e-01)	Acc@1  85.42 ( 75.72)
The current update step is 3600
The current seed is 6727550166508165343
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.408
 *   Acc@1 76.582
 *   Acc@1 74.842
 *   Acc@1 75.440
 *   Acc@1 74.711
 *   Acc@1 74.728
 *   Acc@1 75.316
 *   Acc@1 75.967
 *   Acc@1 71.289
 *   Acc@1 72.012
 *   Acc@1 70.934
 *   Acc@1 71.635
Training for 300 epoch: 75.86184210526315
Training for 600 epoch: 73.0657894736842
Training for 1000 epoch: 72.82236842105263
Training for 300 epoch: 76.27416666666667
Training for 600 epoch: 73.72583333333333
Training for 1000 epoch: 73.18166666666667
[[75.86184210526315, 73.0657894736842, 72.82236842105263], [76.27416666666667, 73.72583333333333, 73.18166666666667]]
train loss 0.40995613951683046, epoch 89, best loss 0.3552299144744873, best_epoch 74
GPU_0_using curriculum 20 with window 20
Epoch: [90][20/40]	Time  1.499 ( 1.505)	Data  0.028 ( 0.038)	InnerLoop  0.637 ( 0.643)	Loss 7.0893e-01 (6.8608e-01)	Acc@1  71.78 ( 75.40)
Epoch: [90][40/40]	Time  1.458 ( 1.503)	Data  0.012 ( 0.038)	InnerLoop  0.625 ( 0.640)	Loss 5.9810e-01 (6.7023e-01)	Acc@1  76.04 ( 75.91)
The current update step is 3640
GPU_0_using curriculum 20 with window 20
Epoch: [91][20/40]	Time  1.473 ( 1.495)	Data  0.025 ( 0.044)	InnerLoop  0.623 ( 0.628)	Loss 6.5023e-01 (6.7425e-01)	Acc@1  77.60 ( 76.00)
Epoch: [91][40/40]	Time  1.570 ( 1.496)	Data  0.012 ( 0.038)	InnerLoop  0.736 ( 0.636)	Loss 5.4194e-01 (6.3246e-01)	Acc@1  78.12 ( 77.22)
The current update step is 3680
GPU_0_using curriculum 20 with window 20
Epoch: [92][20/40]	Time  1.482 ( 1.495)	Data  0.025 ( 0.038)	InnerLoop  0.625 ( 0.634)	Loss 6.8819e-01 (6.3854e-01)	Acc@1  73.21 ( 76.55)
Epoch: [92][40/40]	Time  1.459 ( 1.497)	Data  0.011 ( 0.038)	InnerLoop  0.627 ( 0.635)	Loss 7.8212e-01 (6.3447e-01)	Acc@1  71.88 ( 76.82)
The current update step is 3720
GPU_0_using curriculum 20 with window 20
Epoch: [93][20/40]	Time  1.471 ( 1.498)	Data  0.027 ( 0.044)	InnerLoop  0.623 ( 0.633)	Loss 6.7496e-01 (6.3521e-01)	Acc@1  74.87 ( 76.64)
Epoch: [93][40/40]	Time  1.469 ( 1.501)	Data  0.010 ( 0.041)	InnerLoop  0.634 ( 0.636)	Loss 8.7454e-01 (6.7555e-01)	Acc@1  70.31 ( 75.11)
The current update step is 3760
GPU_0_using curriculum 20 with window 20
Epoch: [94][20/40]	Time  1.587 ( 1.502)	Data  0.027 ( 0.038)	InnerLoop  0.736 ( 0.641)	Loss 5.7579e-01 (6.9128e-01)	Acc@1  78.06 ( 75.17)
Epoch: [94][40/40]	Time  1.466 ( 1.498)	Data  0.010 ( 0.038)	InnerLoop  0.634 ( 0.638)	Loss 8.4751e-01 (6.6455e-01)	Acc@1  65.62 ( 75.84)
The current update step is 3800
The current seed is 1797995852830492046
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.632
 *   Acc@1 78.197
 *   Acc@1 75.434
 *   Acc@1 75.705
 *   Acc@1 73.592
 *   Acc@1 73.585
 *   Acc@1 70.908
 *   Acc@1 70.960
 *   Acc@1 69.776
 *   Acc@1 70.229
 *   Acc@1 69.605
 *   Acc@1 70.206
Training for 300 epoch: 74.26973684210526
Training for 600 epoch: 72.60526315789474
Training for 1000 epoch: 71.59868421052632
Training for 300 epoch: 74.57833333333333
Training for 600 epoch: 72.96708333333333
Training for 1000 epoch: 71.89541666666666
[[74.26973684210526, 72.60526315789474, 71.59868421052632], [74.57833333333333, 72.96708333333333, 71.89541666666666]]
train loss 0.4292517404556274, epoch 94, best loss 0.3552299144744873, best_epoch 74
GPU_0_using curriculum 20 with window 20
Epoch: [95][20/40]	Time  1.466 ( 1.495)	Data  0.025 ( 0.033)	InnerLoop  0.623 ( 0.641)	Loss 6.9189e-01 (6.8632e-01)	Acc@1  73.89 ( 74.25)
Epoch: [95][40/40]	Time  1.458 ( 1.497)	Data  0.011 ( 0.035)	InnerLoop  0.625 ( 0.641)	Loss 5.9727e-01 (6.6748e-01)	Acc@1  79.17 ( 74.75)
The current update step is 3840
GPU_0_using curriculum 20 with window 20
Epoch: [96][20/40]	Time  1.474 ( 1.493)	Data  0.026 ( 0.032)	InnerLoop  0.621 ( 0.640)	Loss 5.2463e-01 (6.7488e-01)	Acc@1  81.77 ( 75.69)
Epoch: [96][40/40]	Time  1.463 ( 1.493)	Data  0.011 ( 0.035)	InnerLoop  0.626 ( 0.638)	Loss 6.4647e-01 (6.8392e-01)	Acc@1  72.92 ( 74.97)
The current update step is 3880
GPU_0_using curriculum 20 with window 20
Epoch: [97][20/40]	Time  1.672 ( 1.542)	Data  0.031 ( 0.042)	InnerLoop  0.782 ( 0.661)	Loss 8.4274e-01 (7.9536e-01)	Acc@1  65.79 ( 71.58)
Epoch: [97][40/40]	Time  1.523 ( 1.555)	Data  0.012 ( 0.041)	InnerLoop  0.662 ( 0.665)	Loss 6.7610e-01 (7.9953e-01)	Acc@1  71.35 ( 71.37)
The current update step is 3920
GPU_0_using curriculum 20 with window 20
Epoch: [98][20/40]	Time  1.551 ( 1.565)	Data  0.033 ( 0.037)	InnerLoop  0.658 ( 0.675)	Loss 6.2914e-01 (7.0597e-01)	Acc@1  76.60 ( 73.54)
Epoch: [98][40/40]	Time  1.466 ( 1.548)	Data  0.011 ( 0.038)	InnerLoop  0.633 ( 0.666)	Loss 7.3774e-01 (7.3088e-01)	Acc@1  73.96 ( 72.24)
The current update step is 3960
GPU_0_using curriculum 20 with window 20
Epoch: [99][20/40]	Time  1.466 ( 1.493)	Data  0.029 ( 0.038)	InnerLoop  0.616 ( 0.634)	Loss 5.9086e-01 (6.6906e-01)	Acc@1  78.68 ( 74.11)
Epoch: [99][40/40]	Time  1.458 ( 1.493)	Data  0.011 ( 0.034)	InnerLoop  0.629 ( 0.637)	Loss 6.3898e-01 (6.8469e-01)	Acc@1  78.12 ( 73.98)
The current update step is 4000
The current seed is 13196905717451009178
The current lr is: 0.001
Testing Results:
 *   Acc@1 72.974
 *   Acc@1 73.464
 *   Acc@1 68.592
 *   Acc@1 68.716
 *   Acc@1 62.776
 *   Acc@1 63.288
 *   Acc@1 59.184
 *   Acc@1 59.587
 *   Acc@1 56.908
 *   Acc@1 57.108
 *   Acc@1 53.816
 *   Acc@1 54.626
Training for 300 epoch: 66.07894736842105
Training for 600 epoch: 62.75
Training for 1000 epoch: 58.296052631578945
Training for 300 epoch: 66.52583333333334
Training for 600 epoch: 62.91166666666667
Training for 1000 epoch: 58.95666666666666
[[66.07894736842105, 62.75, 58.296052631578945], [66.52583333333334, 62.91166666666667, 58.95666666666666]]
train loss 0.5298432753562927, epoch 99, best loss 0.3552299144744873, best_epoch 74
GPU_0_using curriculum 20 with window 20
Epoch: [100][20/40]	Time  1.476 ( 1.494)	Data  0.028 ( 0.038)	InnerLoop  0.621 ( 0.636)	Loss 7.4286e-01 (6.5605e-01)	Acc@1  69.50 ( 75.41)
Epoch: [100][40/40]	Time  1.448 ( 1.495)	Data  0.010 ( 0.035)	InnerLoop  0.620 ( 0.639)	Loss 6.6825e-01 (7.1711e-01)	Acc@1  75.00 ( 73.75)
The current update step is 4040
GPU_0_using curriculum 20 with window 20
Epoch: [101][20/40]	Time  1.582 ( 1.499)	Data  0.026 ( 0.044)	InnerLoop  0.734 ( 0.635)	Loss 9.4593e-01 (6.2085e-01)	Acc@1  68.75 ( 76.91)
Epoch: [101][40/40]	Time  1.464 ( 1.498)	Data  0.011 ( 0.041)	InnerLoop  0.634 ( 0.636)	Loss 5.2877e-01 (6.3130e-01)	Acc@1  84.38 ( 76.47)
The current update step is 4080
GPU_0_using curriculum 20 with window 20
Epoch: [102][20/40]	Time  1.469 ( 1.492)	Data  0.027 ( 0.044)	InnerLoop  0.623 ( 0.628)	Loss 5.2797e-01 (6.4705e-01)	Acc@1  81.18 ( 76.21)
Epoch: [102][40/40]	Time  1.447 ( 1.492)	Data  0.012 ( 0.037)	InnerLoop  0.619 ( 0.634)	Loss 4.1984e-01 (6.7960e-01)	Acc@1  85.94 ( 75.83)
The current update step is 4120
GPU_0_using curriculum 20 with window 20
Epoch: [103][20/40]	Time  1.468 ( 1.495)	Data  0.026 ( 0.038)	InnerLoop  0.622 ( 0.638)	Loss 8.3177e-01 (6.2927e-01)	Acc@1  66.60 ( 76.14)
Epoch: [103][40/40]	Time  1.463 ( 1.495)	Data  0.011 ( 0.038)	InnerLoop  0.634 ( 0.637)	Loss 4.5195e-01 (6.5947e-01)	Acc@1  81.25 ( 75.53)
The current update step is 4160
GPU_0_using curriculum 20 with window 20
Epoch: [104][20/40]	Time  1.466 ( 1.491)	Data  0.025 ( 0.038)	InnerLoop  0.622 ( 0.634)	Loss 7.0058e-01 (6.7894e-01)	Acc@1  75.91 ( 74.76)
Epoch: [104][40/40]	Time  1.461 ( 1.496)	Data  0.013 ( 0.038)	InnerLoop  0.626 ( 0.637)	Loss 9.5823e-01 (6.4555e-01)	Acc@1  66.15 ( 75.98)
The current update step is 4200
The current seed is 12827848097287144109
The current lr is: 0.001
Testing Results:
 *   Acc@1 74.724
 *   Acc@1 75.338
 *   Acc@1 71.526
 *   Acc@1 72.448
 *   Acc@1 68.776
 *   Acc@1 69.789
 *   Acc@1 68.197
 *   Acc@1 69.013
 *   Acc@1 67.776
 *   Acc@1 68.253
 *   Acc@1 66.474
 *   Acc@1 67.046
Training for 300 epoch: 71.46052631578948
Training for 600 epoch: 69.65131578947368
Training for 1000 epoch: 67.625
Training for 300 epoch: 72.17541666666668
Training for 600 epoch: 70.35041666666666
Training for 1000 epoch: 68.4175
[[71.46052631578948, 69.65131578947368, 67.625], [72.17541666666668, 70.35041666666666, 68.4175]]
train loss 0.48749053597450254, epoch 104, best loss 0.3552299144744873, best_epoch 74
GPU_0_using curriculum 20 with window 20
Epoch: [105][20/40]	Time  1.480 ( 1.497)	Data  0.027 ( 0.038)	InnerLoop  0.627 ( 0.640)	Loss 5.0569e-01 (6.2980e-01)	Acc@1  81.71 ( 77.40)
Epoch: [105][40/40]	Time  1.447 ( 1.495)	Data  0.012 ( 0.038)	InnerLoop  0.620 ( 0.637)	Loss 6.7333e-01 (6.6436e-01)	Acc@1  76.56 ( 76.10)
The current update step is 4240
GPU_0_using curriculum 20 with window 20
Epoch: [106][20/40]	Time  1.468 ( 1.489)	Data  0.027 ( 0.043)	InnerLoop  0.619 ( 0.627)	Loss 6.4777e-01 (6.3037e-01)	Acc@1  76.17 ( 76.85)
Epoch: [106][40/40]	Time  1.561 ( 1.494)	Data  0.012 ( 0.038)	InnerLoop  0.731 ( 0.636)	Loss 6.9994e-01 (6.5080e-01)	Acc@1  72.92 ( 76.02)
The current update step is 4280
GPU_0_using curriculum 20 with window 20
Epoch: [107][20/40]	Time  1.462 ( 1.491)	Data  0.025 ( 0.039)	InnerLoop  0.621 ( 0.634)	Loss 6.7732e-01 (7.0918e-01)	Acc@1  75.20 ( 74.12)
Epoch: [107][40/40]	Time  1.460 ( 1.492)	Data  0.011 ( 0.038)	InnerLoop  0.630 ( 0.635)	Loss 4.7540e-01 (6.7437e-01)	Acc@1  83.85 ( 75.55)
The current update step is 4320
GPU_0_using curriculum 20 with window 20
Epoch: [108][20/40]	Time  1.470 ( 1.496)	Data  0.027 ( 0.043)	InnerLoop  0.623 ( 0.633)	Loss 8.2273e-01 (6.6305e-01)	Acc@1  69.50 ( 76.41)
Epoch: [108][40/40]	Time  1.453 ( 1.494)	Data  0.012 ( 0.040)	InnerLoop  0.625 ( 0.633)	Loss 7.1220e-01 (6.8082e-01)	Acc@1  72.40 ( 75.75)
The current update step is 4360
GPU_0_using curriculum 20 with window 20
Epoch: [109][20/40]	Time  1.577 ( 1.495)	Data  0.025 ( 0.039)	InnerLoop  0.733 ( 0.638)	Loss 6.2272e-01 (6.6928e-01)	Acc@1  77.15 ( 75.62)
Epoch: [109][40/40]	Time  1.459 ( 1.494)	Data  0.010 ( 0.038)	InnerLoop  0.630 ( 0.637)	Loss 7.6990e-01 (6.8209e-01)	Acc@1  68.75 ( 75.37)
The current update step is 4400
The current seed is 16782591022651675704
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.737
 *   Acc@1 76.910
 *   Acc@1 75.566
 *   Acc@1 75.907
 *   Acc@1 74.697
 *   Acc@1 74.710
 *   Acc@1 76.355
 *   Acc@1 76.768
 *   Acc@1 75.961
 *   Acc@1 76.546
 *   Acc@1 73.250
 *   Acc@1 74.154
Training for 300 epoch: 76.54605263157896
Training for 600 epoch: 75.76315789473685
Training for 1000 epoch: 73.97368421052632
Training for 300 epoch: 76.83916666666667
Training for 600 epoch: 76.22666666666666
Training for 1000 epoch: 74.43208333333334
[[76.54605263157896, 75.76315789473685, 73.97368421052632], [76.83916666666667, 76.22666666666666, 74.43208333333334]]
train loss 0.3365939888000488, epoch 109, best loss 0.3365939888000488, best_epoch 109
GPU_0_using curriculum 20 with window 20
Epoch: [110][20/40]	Time  1.466 ( 1.496)	Data  0.025 ( 0.032)	InnerLoop  0.619 ( 0.642)	Loss 8.7287e-01 (7.4119e-01)	Acc@1  70.70 ( 73.02)
Epoch: [110][40/40]	Time  1.465 ( 1.497)	Data  0.010 ( 0.034)	InnerLoop  0.632 ( 0.641)	Loss 5.2502e-01 (7.2519e-01)	Acc@1  80.21 ( 73.34)
The current update step is 4440
GPU_0_using curriculum 20 with window 20
Epoch: [111][20/40]	Time  1.471 ( 1.489)	Data  0.027 ( 0.032)	InnerLoop  0.621 ( 0.639)	Loss 9.2838e-01 (6.9870e-01)	Acc@1  70.44 ( 74.51)
Epoch: [111][40/40]	Time  1.452 ( 1.490)	Data  0.010 ( 0.034)	InnerLoop  0.625 ( 0.636)	Loss 4.8784e-01 (7.0946e-01)	Acc@1  82.81 ( 73.70)
The current update step is 4480
GPU_0_using curriculum 20 with window 20
Epoch: [112][20/40]	Time  1.589 ( 1.498)	Data  0.027 ( 0.038)	InnerLoop  0.738 ( 0.639)	Loss 5.8234e-01 (6.6205e-01)	Acc@1  79.79 ( 76.39)
Epoch: [112][40/40]	Time  1.479 ( 1.499)	Data  0.012 ( 0.038)	InnerLoop  0.630 ( 0.638)	Loss 5.5917e-01 (6.6323e-01)	Acc@1  81.25 ( 76.14)
The current update step is 4520
GPU_0_using curriculum 20 with window 20
Epoch: [113][20/40]	Time  1.473 ( 1.494)	Data  0.027 ( 0.033)	InnerLoop  0.622 ( 0.640)	Loss 5.4181e-01 (7.1105e-01)	Acc@1  79.88 ( 74.72)
Epoch: [113][40/40]	Time  1.461 ( 1.499)	Data  0.010 ( 0.035)	InnerLoop  0.631 ( 0.641)	Loss 5.1853e-01 (7.0164e-01)	Acc@1  81.25 ( 74.98)
The current update step is 4560
GPU_0_using curriculum 20 with window 20
Epoch: [114][20/40]	Time  1.470 ( 1.490)	Data  0.027 ( 0.038)	InnerLoop  0.623 ( 0.633)	Loss 7.9105e-01 (7.3705e-01)	Acc@1  69.82 ( 72.89)
Epoch: [114][40/40]	Time  1.455 ( 1.493)	Data  0.011 ( 0.034)	InnerLoop  0.623 ( 0.638)	Loss 8.8971e-01 (6.8701e-01)	Acc@1  68.75 ( 74.98)
The current update step is 4600
The current seed is 18082512407264726035
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.934
 *   Acc@1 71.390
 *   Acc@1 67.842
 *   Acc@1 68.216
 *   Acc@1 65.118
 *   Acc@1 65.596
 *   Acc@1 76.724
 *   Acc@1 77.186
 *   Acc@1 75.684
 *   Acc@1 75.827
 *   Acc@1 73.658
 *   Acc@1 73.696
Training for 300 epoch: 73.82894736842105
Training for 600 epoch: 71.76315789473685
Training for 1000 epoch: 69.38815789473685
Training for 300 epoch: 74.28791666666666
Training for 600 epoch: 72.02125000000001
Training for 1000 epoch: 69.64583333333334
[[73.82894736842105, 71.76315789473685, 69.38815789473685], [74.28791666666666, 72.02125000000001, 69.64583333333334]]
train loss 0.3671467056274414, epoch 114, best loss 0.3365939888000488, best_epoch 109
GPU_0_using curriculum 20 with window 20
Epoch: [115][20/40]	Time  1.469 ( 1.494)	Data  0.026 ( 0.038)	InnerLoop  0.624 ( 0.637)	Loss 5.4132e-01 (7.1252e-01)	Acc@1  79.85 ( 74.13)
Epoch: [115][40/40]	Time  1.452 ( 1.495)	Data  0.011 ( 0.035)	InnerLoop  0.621 ( 0.640)	Loss 4.7322e-01 (6.9169e-01)	Acc@1  82.29 ( 74.72)
The current update step is 4640
GPU_0_using curriculum 20 with window 20
Epoch: [116][20/40]	Time  1.581 ( 1.500)	Data  0.027 ( 0.044)	InnerLoop  0.735 ( 0.636)	Loss 5.3035e-01 (6.7446e-01)	Acc@1  80.37 ( 74.43)
Epoch: [116][40/40]	Time  1.459 ( 1.498)	Data  0.011 ( 0.041)	InnerLoop  0.628 ( 0.636)	Loss 6.6975e-01 (6.9099e-01)	Acc@1  72.92 ( 74.35)
The current update step is 4680
GPU_0_using curriculum 20 with window 20
Epoch: [117][20/40]	Time  1.474 ( 1.495)	Data  0.026 ( 0.044)	InnerLoop  0.626 ( 0.631)	Loss 8.2913e-01 (6.8271e-01)	Acc@1  72.92 ( 74.23)
Epoch: [117][40/40]	Time  1.460 ( 1.497)	Data  0.011 ( 0.038)	InnerLoop  0.623 ( 0.637)	Loss 5.9787e-01 (6.8920e-01)	Acc@1  76.56 ( 74.30)
The current update step is 4720
GPU_0_using curriculum 20 with window 20
Epoch: [118][20/40]	Time  1.481 ( 1.512)	Data  0.028 ( 0.039)	InnerLoop  0.631 ( 0.648)	Loss 8.1824e-01 (7.1144e-01)	Acc@1  68.91 ( 73.36)
Epoch: [118][40/40]	Time  1.478 ( 1.512)	Data  0.011 ( 0.039)	InnerLoop  0.639 ( 0.646)	Loss 6.7427e-01 (7.0608e-01)	Acc@1  75.52 ( 73.65)
The current update step is 4760
GPU_0_using curriculum 20 with window 20
Epoch: [119][20/40]	Time  1.476 ( 1.505)	Data  0.027 ( 0.039)	InnerLoop  0.625 ( 0.640)	Loss 6.0151e-01 (6.6035e-01)	Acc@1  79.26 ( 76.25)
Epoch: [119][40/40]	Time  1.459 ( 1.505)	Data  0.012 ( 0.039)	InnerLoop  0.628 ( 0.642)	Loss 8.1632e-01 (6.9257e-01)	Acc@1  70.31 ( 75.26)
The current update step is 4800
The current seed is 6045101822274783336
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.618
 *   Acc@1 74.293
 *   Acc@1 61.158
 *   Acc@1 60.483
 *   Acc@1 56.474
 *   Acc@1 56.133
 *   Acc@1 64.947
 *   Acc@1 65.146
 *   Acc@1 61.303
 *   Acc@1 61.346
 *   Acc@1 58.605
 *   Acc@1 58.549
Training for 300 epoch: 69.28289473684211
Training for 600 epoch: 61.23026315789474
Training for 1000 epoch: 57.53947368421053
Training for 300 epoch: 69.71916666666667
Training for 600 epoch: 60.91458333333333
Training for 1000 epoch: 57.340833333333336
[[69.28289473684211, 61.23026315789474, 57.53947368421053], [69.71916666666667, 60.91458333333333, 57.340833333333336]]
train loss 0.7392962341308593, epoch 119, best loss 0.3365939888000488, best_epoch 109
GPU_0_using curriculum 20 with window 20
Epoch: [120][20/40]	Time  1.481 ( 1.503)	Data  0.026 ( 0.037)	InnerLoop  0.628 ( 0.643)	Loss 8.6551e-01 (6.9939e-01)	Acc@1  70.38 ( 74.84)
Epoch: [120][40/40]	Time  1.463 ( 1.502)	Data  0.012 ( 0.037)	InnerLoop  0.626 ( 0.641)	Loss 6.9772e-01 (7.0899e-01)	Acc@1  76.04 ( 74.30)
The current update step is 4840
GPU_0_using curriculum 20 with window 20
Epoch: [121][20/40]	Time  1.480 ( 1.499)	Data  0.025 ( 0.044)	InnerLoop  0.629 ( 0.633)	Loss 5.7358e-01 (7.5852e-01)	Acc@1  77.05 ( 71.91)
Epoch: [121][40/40]	Time  1.569 ( 1.502)	Data  0.011 ( 0.038)	InnerLoop  0.732 ( 0.641)	Loss 7.4495e-01 (7.4577e-01)	Acc@1  72.92 ( 72.18)
The current update step is 4880
GPU_0_using curriculum 20 with window 20
Epoch: [122][20/40]	Time  1.476 ( 1.497)	Data  0.025 ( 0.039)	InnerLoop  0.628 ( 0.636)	Loss 6.1953e-01 (6.6208e-01)	Acc@1  77.64 ( 75.12)
Epoch: [122][40/40]	Time  1.458 ( 1.498)	Data  0.011 ( 0.038)	InnerLoop  0.625 ( 0.637)	Loss 7.3813e-01 (7.0082e-01)	Acc@1  71.35 ( 73.85)
The current update step is 4920
GPU_0_using curriculum 20 with window 20
Epoch: [123][20/40]	Time  1.482 ( 1.507)	Data  0.028 ( 0.044)	InnerLoop  0.629 ( 0.639)	Loss 7.3210e-01 (6.8260e-01)	Acc@1  71.29 ( 74.52)
Epoch: [123][40/40]	Time  1.468 ( 1.506)	Data  0.012 ( 0.041)	InnerLoop  0.634 ( 0.639)	Loss 5.9434e-01 (6.8816e-01)	Acc@1  79.17 ( 74.69)
The current update step is 4960
GPU_0_using curriculum 20 with window 20
Epoch: [124][20/40]	Time  1.620 ( 1.520)	Data  0.027 ( 0.040)	InnerLoop  0.757 ( 0.649)	Loss 5.3994e-01 (6.4493e-01)	Acc@1  79.46 ( 76.25)
Epoch: [124][40/40]	Time  1.468 ( 1.518)	Data  0.013 ( 0.039)	InnerLoop  0.631 ( 0.647)	Loss 7.0550e-01 (6.8540e-01)	Acc@1  72.92 ( 75.25)
The current update step is 5000
The current seed is 16309787473144645380
The current lr is: 0.001
Testing Results:
 *   Acc@1 79.855
 *   Acc@1 79.976
 *   Acc@1 78.868
 *   Acc@1 79.711
 *   Acc@1 79.803
 *   Acc@1 79.975
 *   Acc@1 73.303
 *   Acc@1 73.597
 *   Acc@1 71.566
 *   Acc@1 72.351
 *   Acc@1 70.276
 *   Acc@1 70.088
Training for 300 epoch: 76.57894736842105
Training for 600 epoch: 75.21710526315789
Training for 1000 epoch: 75.03947368421052
Training for 300 epoch: 76.78625
Training for 600 epoch: 76.03083333333333
Training for 1000 epoch: 75.03125
[[76.57894736842105, 75.21710526315789, 75.03947368421052], [76.78625, 76.03083333333333, 75.03125]]
train loss 0.40878379187583924, epoch 124, best loss 0.3365939888000488, best_epoch 109
GPU_0_using curriculum 20 with window 20
Epoch: [125][20/40]	Time  1.474 ( 1.528)	Data  0.029 ( 0.035)	InnerLoop  0.623 ( 0.656)	Loss 6.8379e-01 (6.3355e-01)	Acc@1  75.46 ( 76.84)
Epoch: [125][40/40]	Time  1.461 ( 1.517)	Data  0.012 ( 0.036)	InnerLoop  0.626 ( 0.650)	Loss 8.9681e-01 (6.5205e-01)	Acc@1  61.98 ( 75.84)
The current update step is 5040
GPU_0_using curriculum 20 with window 20
Epoch: [126][20/40]	Time  1.472 ( 1.498)	Data  0.027 ( 0.033)	InnerLoop  0.626 ( 0.644)	Loss 1.0682e+00 (6.5738e-01)	Acc@1  64.84 ( 75.76)
Epoch: [126][40/40]	Time  1.453 ( 1.499)	Data  0.012 ( 0.035)	InnerLoop  0.622 ( 0.640)	Loss 7.3679e-01 (6.4436e-01)	Acc@1  71.88 ( 76.13)
The current update step is 5080
GPU_0_using curriculum 20 with window 20
Epoch: [127][20/40]	Time  1.584 ( 1.503)	Data  0.027 ( 0.039)	InnerLoop  0.734 ( 0.642)	Loss 9.5471e-01 (6.6246e-01)	Acc@1  69.14 ( 75.65)
Epoch: [127][40/40]	Time  1.471 ( 1.503)	Data  0.011 ( 0.038)	InnerLoop  0.634 ( 0.640)	Loss 6.0540e-01 (6.5913e-01)	Acc@1  78.65 ( 75.81)
The current update step is 5120
GPU_0_using curriculum 20 with window 20
Epoch: [128][20/40]	Time  1.477 ( 1.499)	Data  0.029 ( 0.033)	InnerLoop  0.627 ( 0.643)	Loss 6.2853e-01 (6.7870e-01)	Acc@1  75.59 ( 75.30)
Epoch: [128][40/40]	Time  1.466 ( 1.503)	Data  0.011 ( 0.035)	InnerLoop  0.634 ( 0.644)	Loss 5.6125e-01 (6.6303e-01)	Acc@1  78.12 ( 76.03)
The current update step is 5160
GPU_0_using curriculum 20 with window 20
Epoch: [129][20/40]	Time  1.477 ( 1.498)	Data  0.026 ( 0.038)	InnerLoop  0.625 ( 0.638)	Loss 5.3812e-01 (7.1361e-01)	Acc@1  79.39 ( 74.43)
Epoch: [129][40/40]	Time  1.464 ( 1.500)	Data  0.012 ( 0.035)	InnerLoop  0.633 ( 0.641)	Loss 6.2740e-01 (6.8637e-01)	Acc@1  76.04 ( 75.10)
The current update step is 5200
The current seed is 17291373345921921350
The current lr is: 0.001
Testing Results:
 *   Acc@1 60.079
 *   Acc@1 60.448
 *   Acc@1 60.434
 *   Acc@1 60.410
 *   Acc@1 60.013
 *   Acc@1 59.892
 *   Acc@1 77.184
 *   Acc@1 77.679
 *   Acc@1 75.066
 *   Acc@1 75.530
 *   Acc@1 72.829
 *   Acc@1 73.596
Training for 300 epoch: 68.63157894736842
Training for 600 epoch: 67.75
Training for 1000 epoch: 66.42105263157895
Training for 300 epoch: 69.06375
Training for 600 epoch: 67.97
Training for 1000 epoch: 66.74416666666667
[[68.63157894736842, 67.75, 66.42105263157895], [69.06375, 67.97, 66.74416666666667]]
train loss 0.3470806260585785, epoch 129, best loss 0.3365939888000488, best_epoch 109
GPU_0_using curriculum 20 with window 20
Epoch: [130][20/40]	Time  1.464 ( 1.500)	Data  0.026 ( 0.039)	InnerLoop  0.618 ( 0.637)	Loss 6.1186e-01 (6.3548e-01)	Acc@1  76.60 ( 76.47)
Epoch: [130][40/40]	Time  1.510 ( 1.506)	Data  0.014 ( 0.036)	InnerLoop  0.654 ( 0.642)	Loss 6.9950e-01 (6.5432e-01)	Acc@1  70.83 ( 76.23)
The current update step is 5240
GPU_0_using curriculum 20 with window 20
Epoch: [131][20/40]	Time  1.599 ( 1.528)	Data  0.026 ( 0.048)	InnerLoop  0.741 ( 0.647)	Loss 6.4549e-01 (6.7969e-01)	Acc@1  76.07 ( 74.79)
Epoch: [131][40/40]	Time  1.485 ( 1.518)	Data  0.013 ( 0.043)	InnerLoop  0.642 ( 0.644)	Loss 6.3924e-01 (7.1272e-01)	Acc@1  76.04 ( 73.20)
The current update step is 5280
GPU_0_using curriculum 20 with window 20
Epoch: [132][20/40]	Time  1.481 ( 1.505)	Data  0.025 ( 0.046)	InnerLoop  0.626 ( 0.633)	Loss 8.9884e-01 (7.0747e-01)	Acc@1  65.82 ( 72.55)
Epoch: [132][40/40]	Time  1.469 ( 1.508)	Data  0.012 ( 0.039)	InnerLoop  0.635 ( 0.641)	Loss 8.8115e-01 (6.9045e-01)	Acc@1  69.79 ( 73.32)
The current update step is 5320
GPU_0_using curriculum 20 with window 20
Epoch: [133][20/40]	Time  1.490 ( 1.507)	Data  0.026 ( 0.039)	InnerLoop  0.630 ( 0.644)	Loss 7.3613e-01 (7.6680e-01)	Acc@1  71.39 ( 73.31)
Epoch: [133][40/40]	Time  1.460 ( 1.504)	Data  0.011 ( 0.038)	InnerLoop  0.629 ( 0.641)	Loss 7.1443e-01 (7.3093e-01)	Acc@1  71.88 ( 73.74)
The current update step is 5360
GPU_0_using curriculum 20 with window 20
Epoch: [134][20/40]	Time  1.477 ( 1.501)	Data  0.026 ( 0.039)	InnerLoop  0.626 ( 0.637)	Loss 8.6354e-01 (7.4916e-01)	Acc@1  69.01 ( 72.00)
Epoch: [134][40/40]	Time  1.462 ( 1.507)	Data  0.011 ( 0.039)	InnerLoop  0.629 ( 0.642)	Loss 5.4801e-01 (7.8061e-01)	Acc@1  82.81 ( 70.70)
The current update step is 5400
The current seed is 13943895211118892691
The current lr is: 0.001
Testing Results:
 *   Acc@1 63.026
 *   Acc@1 63.623
 *   Acc@1 61.658
 *   Acc@1 62.450
 *   Acc@1 60.934
 *   Acc@1 61.091
 *   Acc@1 65.145
 *   Acc@1 65.609
 *   Acc@1 61.908
 *   Acc@1 61.989
 *   Acc@1 59.092
 *   Acc@1 59.778
Training for 300 epoch: 64.08552631578948
Training for 600 epoch: 61.7828947368421
Training for 1000 epoch: 60.01315789473684
Training for 300 epoch: 64.61583333333334
Training for 600 epoch: 62.21958333333333
Training for 1000 epoch: 60.434583333333336
[[64.08552631578948, 61.7828947368421, 60.01315789473684], [64.61583333333334, 62.21958333333333, 60.434583333333336]]
train loss 0.47585197525024414, epoch 134, best loss 0.3365939888000488, best_epoch 109
GPU_0_using curriculum 20 with window 20
Epoch: [135][20/40]	Time  1.511 ( 1.508)	Data  0.027 ( 0.038)	InnerLoop  0.646 ( 0.644)	Loss 1.4789e+00 (9.5001e-01)	Acc@1  49.77 ( 65.51)
Epoch: [135][40/40]	Time  1.474 ( 1.511)	Data  0.012 ( 0.038)	InnerLoop  0.630 ( 0.644)	Loss 6.8302e-01 (8.9177e-01)	Acc@1  74.48 ( 67.29)
The current update step is 5440
GPU_0_using curriculum 20 with window 20
Epoch: [136][20/40]	Time  1.473 ( 1.500)	Data  0.025 ( 0.044)	InnerLoop  0.626 ( 0.632)	Loss 6.3841e-01 (7.2917e-01)	Acc@1  74.22 ( 73.03)
Epoch: [136][40/40]	Time  1.586 ( 1.509)	Data  0.013 ( 0.038)	InnerLoop  0.748 ( 0.643)	Loss 5.9664e-01 (6.9097e-01)	Acc@1  78.12 ( 74.43)
The current update step is 5480
GPU_0_using curriculum 20 with window 20
Epoch: [137][20/40]	Time  1.485 ( 1.503)	Data  0.026 ( 0.039)	InnerLoop  0.630 ( 0.638)	Loss 8.3397e-01 (6.8422e-01)	Acc@1  71.29 ( 74.82)
Epoch: [137][40/40]	Time  1.463 ( 1.504)	Data  0.013 ( 0.039)	InnerLoop  0.625 ( 0.638)	Loss 5.0973e-01 (6.8813e-01)	Acc@1  79.69 ( 74.41)
The current update step is 5520
GPU_0_using curriculum 20 with window 20
Epoch: [138][20/40]	Time  1.481 ( 1.512)	Data  0.028 ( 0.045)	InnerLoop  0.629 ( 0.640)	Loss 6.2239e-01 (6.4130e-01)	Acc@1  78.03 ( 76.41)
Epoch: [138][40/40]	Time  1.463 ( 1.508)	Data  0.012 ( 0.041)	InnerLoop  0.629 ( 0.640)	Loss 6.6235e-01 (6.6873e-01)	Acc@1  75.52 ( 75.18)
The current update step is 5560
GPU_0_using curriculum 20 with window 20
Epoch: [139][20/40]	Time  1.614 ( 1.510)	Data  0.028 ( 0.040)	InnerLoop  0.749 ( 0.645)	Loss 8.7384e-01 (6.5739e-01)	Acc@1  67.38 ( 75.44)
Epoch: [139][40/40]	Time  1.476 ( 1.508)	Data  0.012 ( 0.039)	InnerLoop  0.635 ( 0.642)	Loss 8.3940e-01 (6.7728e-01)	Acc@1  69.27 ( 74.76)
The current update step is 5600
The current seed is 8214367527197409580
The current lr is: 0.001
Testing Results:
 *   Acc@1 65.987
 *   Acc@1 66.397
 *   Acc@1 62.961
 *   Acc@1 63.057
 *   Acc@1 60.237
 *   Acc@1 60.569
 *   Acc@1 65.987
 *   Acc@1 66.256
 *   Acc@1 60.513
 *   Acc@1 60.576
 *   Acc@1 56.579
 *   Acc@1 56.703
Training for 300 epoch: 65.98684210526316
Training for 600 epoch: 61.73684210526316
Training for 1000 epoch: 58.40789473684211
Training for 300 epoch: 66.32624999999999
Training for 600 epoch: 61.81666666666666
Training for 1000 epoch: 58.63583333333334
[[65.98684210526316, 61.73684210526316, 58.40789473684211], [66.32624999999999, 61.81666666666666, 58.63583333333334]]
train loss 0.5202733623504638, epoch 139, best loss 0.3365939888000488, best_epoch 109
GPU_0_using curriculum 20 with window 20
Epoch: [140][20/40]	Time  1.480 ( 1.505)	Data  0.027 ( 0.033)	InnerLoop  0.630 ( 0.646)	Loss 5.4999e-01 (6.0908e-01)	Acc@1  80.60 ( 77.16)
Epoch: [140][40/40]	Time  1.480 ( 1.508)	Data  0.014 ( 0.035)	InnerLoop  0.638 ( 0.645)	Loss 6.8428e-01 (6.5877e-01)	Acc@1  70.31 ( 75.43)
The current update step is 5640
GPU_0_using curriculum 20 with window 20
Epoch: [141][20/40]	Time  1.468 ( 1.515)	Data  0.026 ( 0.035)	InnerLoop  0.625 ( 0.650)	Loss 5.7550e-01 (6.5738e-01)	Acc@1  78.68 ( 75.85)
Epoch: [141][40/40]	Time  1.463 ( 1.515)	Data  0.013 ( 0.037)	InnerLoop  0.627 ( 0.647)	Loss 4.5366e-01 (6.7490e-01)	Acc@1  81.77 ( 75.33)
The current update step is 5680
GPU_0_using curriculum 20 with window 20
Epoch: [142][20/40]	Time  1.598 ( 1.503)	Data  0.027 ( 0.039)	InnerLoop  0.742 ( 0.642)	Loss 6.8281e-01 (6.7230e-01)	Acc@1  76.43 ( 74.22)
Epoch: [142][40/40]	Time  1.465 ( 1.501)	Data  0.011 ( 0.038)	InnerLoop  0.632 ( 0.640)	Loss 5.6275e-01 (6.6301e-01)	Acc@1  77.08 ( 75.48)
The current update step is 5720
GPU_0_using curriculum 20 with window 20
Epoch: [143][20/40]	Time  1.480 ( 1.497)	Data  0.026 ( 0.032)	InnerLoop  0.627 ( 0.642)	Loss 5.5347e-01 (6.9393e-01)	Acc@1  79.30 ( 74.41)
Epoch: [143][40/40]	Time  1.458 ( 1.502)	Data  0.011 ( 0.035)	InnerLoop  0.627 ( 0.644)	Loss 6.7603e-01 (6.5788e-01)	Acc@1  72.40 ( 75.87)
The current update step is 5760
GPU_0_using curriculum 20 with window 20
Epoch: [144][20/40]	Time  1.491 ( 1.507)	Data  0.029 ( 0.039)	InnerLoop  0.632 ( 0.642)	Loss 7.9897e-01 (6.7167e-01)	Acc@1  72.88 ( 75.21)
Epoch: [144][40/40]	Time  1.473 ( 1.507)	Data  0.013 ( 0.036)	InnerLoop  0.634 ( 0.644)	Loss 6.3785e-01 (6.8430e-01)	Acc@1  76.04 ( 75.00)
The current update step is 5800
The current seed is 14834183657507916190
The current lr is: 0.001
Testing Results:
 *   Acc@1 68.513
 *   Acc@1 68.827
 *   Acc@1 57.618
 *   Acc@1 57.748
 *   Acc@1 54.276
 *   Acc@1 54.326
 *   Acc@1 79.526
 *   Acc@1 79.922
 *   Acc@1 79.447
 *   Acc@1 79.958
 *   Acc@1 79.461
 *   Acc@1 79.871
Training for 300 epoch: 74.01973684210526
Training for 600 epoch: 68.53289473684211
Training for 1000 epoch: 66.86842105263159
Training for 300 epoch: 74.37416666666667
Training for 600 epoch: 68.85291666666666
Training for 1000 epoch: 67.09833333333333
[[74.01973684210526, 68.53289473684211, 66.86842105263159], [74.37416666666667, 68.85291666666666, 67.09833333333333]]
train loss 0.29211228256225585, epoch 144, best loss 0.29211228256225585, best_epoch 144
GPU_0_using curriculum 20 with window 20
Epoch: [145][20/40]	Time  1.479 ( 1.500)	Data  0.027 ( 0.038)	InnerLoop  0.626 ( 0.637)	Loss 6.5041e-01 (6.5304e-01)	Acc@1  74.06 ( 75.97)
Epoch: [145][40/40]	Time  1.465 ( 1.501)	Data  0.010 ( 0.035)	InnerLoop  0.634 ( 0.641)	Loss 5.6138e-01 (6.5180e-01)	Acc@1  79.69 ( 76.15)
The current update step is 5840
GPU_0_using curriculum 20 with window 20
Epoch: [146][20/40]	Time  1.584 ( 1.504)	Data  0.025 ( 0.044)	InnerLoop  0.740 ( 0.638)	Loss 6.5503e-01 (6.8101e-01)	Acc@1  75.07 ( 75.04)
Epoch: [146][40/40]	Time  1.464 ( 1.502)	Data  0.011 ( 0.041)	InnerLoop  0.627 ( 0.638)	Loss 5.4367e-01 (6.7215e-01)	Acc@1  78.65 ( 75.31)
The current update step is 5880
GPU_0_using curriculum 20 with window 20
Epoch: [147][20/40]	Time  1.486 ( 1.499)	Data  0.027 ( 0.044)	InnerLoop  0.635 ( 0.632)	Loss 7.6987e-01 (6.7218e-01)	Acc@1  67.74 ( 75.23)
Epoch: [147][40/40]	Time  1.463 ( 1.499)	Data  0.013 ( 0.038)	InnerLoop  0.628 ( 0.638)	Loss 8.5432e-01 (6.5057e-01)	Acc@1  70.31 ( 76.29)
The current update step is 5920
GPU_0_using curriculum 20 with window 20
Epoch: [148][20/40]	Time  1.479 ( 1.505)	Data  0.028 ( 0.038)	InnerLoop  0.629 ( 0.644)	Loss 5.4006e-01 (6.3799e-01)	Acc@1  80.44 ( 76.76)
Epoch: [148][40/40]	Time  1.465 ( 1.503)	Data  0.010 ( 0.038)	InnerLoop  0.626 ( 0.641)	Loss 7.2707e-01 (6.3206e-01)	Acc@1  69.79 ( 76.98)
The current update step is 5960
GPU_0_using curriculum 20 with window 20
Epoch: [149][20/40]	Time  1.479 ( 1.500)	Data  0.025 ( 0.038)	InnerLoop  0.630 ( 0.638)	Loss 5.5370e-01 (5.9612e-01)	Acc@1  79.95 ( 77.85)
Epoch: [149][40/40]	Time  1.465 ( 1.504)	Data  0.012 ( 0.038)	InnerLoop  0.632 ( 0.641)	Loss 6.3911e-01 (6.1863e-01)	Acc@1  78.12 ( 77.18)
The current update step is 6000
The current seed is 9111345705778597184
The current lr is: 0.001
Testing Results:
 *   Acc@1 74.118
 *   Acc@1 74.840
 *   Acc@1 73.921
 *   Acc@1 74.763
 *   Acc@1 74.105
 *   Acc@1 74.627
 *   Acc@1 78.039
 *   Acc@1 78.272
 *   Acc@1 77.763
 *   Acc@1 78.116
 *   Acc@1 77.895
 *   Acc@1 77.690
Training for 300 epoch: 76.07894736842104
Training for 600 epoch: 75.84210526315789
Training for 1000 epoch: 76.0
Training for 300 epoch: 76.55583333333334
Training for 600 epoch: 76.43916666666667
Training for 1000 epoch: 76.15875
[[76.07894736842104, 75.84210526315789, 76.0], [76.55583333333334, 76.43916666666667, 76.15875]]
train loss 0.30671865577697754, epoch 149, best loss 0.29211228256225585, best_epoch 144
GPU_0_using curriculum 20 with window 20
Epoch: [150][20/40]	Time  1.478 ( 1.503)	Data  0.026 ( 0.038)	InnerLoop  0.623 ( 0.643)	Loss 6.4098e-01 (6.8287e-01)	Acc@1  76.60 ( 74.60)
Epoch: [150][40/40]	Time  1.467 ( 1.502)	Data  0.013 ( 0.038)	InnerLoop  0.633 ( 0.641)	Loss 8.4570e-01 (6.7373e-01)	Acc@1  64.06 ( 75.27)
The current update step is 6040
GPU_0_using curriculum 20 with window 20
Epoch: [151][20/40]	Time  1.479 ( 1.498)	Data  0.025 ( 0.044)	InnerLoop  0.628 ( 0.631)	Loss 6.9353e-01 (7.1059e-01)	Acc@1  74.90 ( 73.62)
Epoch: [151][40/40]	Time  1.567 ( 1.503)	Data  0.012 ( 0.038)	InnerLoop  0.732 ( 0.641)	Loss 9.3527e-01 (6.8863e-01)	Acc@1  60.42 ( 74.35)
The current update step is 6080
GPU_0_using curriculum 20 with window 20
Epoch: [152][20/40]	Time  1.486 ( 1.498)	Data  0.026 ( 0.038)	InnerLoop  0.635 ( 0.638)	Loss 6.1158e-01 (7.0292e-01)	Acc@1  75.78 ( 73.88)
Epoch: [152][40/40]	Time  1.468 ( 1.500)	Data  0.013 ( 0.038)	InnerLoop  0.635 ( 0.638)	Loss 5.7361e-01 (6.6592e-01)	Acc@1  80.21 ( 75.20)
The current update step is 6120
GPU_0_using curriculum 20 with window 20
Epoch: [153][20/40]	Time  1.475 ( 1.507)	Data  0.027 ( 0.045)	InnerLoop  0.625 ( 0.639)	Loss 5.6089e-01 (6.8024e-01)	Acc@1  79.36 ( 74.04)
Epoch: [153][40/40]	Time  1.462 ( 1.503)	Data  0.011 ( 0.041)	InnerLoop  0.631 ( 0.638)	Loss 9.2133e-01 (7.0728e-01)	Acc@1  64.58 ( 73.28)
The current update step is 6160
GPU_0_using curriculum 20 with window 20
Epoch: [154][20/40]	Time  1.587 ( 1.503)	Data  0.026 ( 0.038)	InnerLoop  0.735 ( 0.643)	Loss 7.4160e-01 (6.5142e-01)	Acc@1  75.94 ( 75.95)
Epoch: [154][40/40]	Time  1.472 ( 1.501)	Data  0.013 ( 0.038)	InnerLoop  0.634 ( 0.640)	Loss 5.1215e-01 (6.6540e-01)	Acc@1  83.85 ( 75.45)
The current update step is 6200
The current seed is 1475792740613150959
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.618
 *   Acc@1 76.735
 *   Acc@1 74.408
 *   Acc@1 74.812
 *   Acc@1 73.487
 *   Acc@1 73.864
 *   Acc@1 73.737
 *   Acc@1 73.530
 *   Acc@1 71.118
 *   Acc@1 71.022
 *   Acc@1 69.658
 *   Acc@1 69.852
Training for 300 epoch: 75.17763157894737
Training for 600 epoch: 72.76315789473685
Training for 1000 epoch: 71.57236842105263
Training for 300 epoch: 75.1325
Training for 600 epoch: 72.91749999999999
Training for 1000 epoch: 71.85791666666667
[[75.17763157894737, 72.76315789473685, 71.57236842105263], [75.1325, 72.91749999999999, 71.85791666666667]]
train loss 0.4142922019481659, epoch 154, best loss 0.29211228256225585, best_epoch 144
GPU_0_using curriculum 20 with window 20
Epoch: [155][20/40]	Time  1.486 ( 1.497)	Data  0.028 ( 0.033)	InnerLoop  0.631 ( 0.644)	Loss 6.7146e-01 (6.6803e-01)	Acc@1  75.07 ( 75.92)
Epoch: [155][40/40]	Time  1.459 ( 1.502)	Data  0.011 ( 0.035)	InnerLoop  0.631 ( 0.645)	Loss 8.5416e-01 (7.3410e-01)	Acc@1  68.23 ( 73.28)
The current update step is 6240
GPU_0_using curriculum 20 with window 20
Epoch: [156][20/40]	Time  1.481 ( 1.497)	Data  0.028 ( 0.032)	InnerLoop  0.628 ( 0.643)	Loss 9.0205e-01 (7.0050e-01)	Acc@1  66.47 ( 73.94)
Epoch: [156][40/40]	Time  1.458 ( 1.498)	Data  0.012 ( 0.035)	InnerLoop  0.625 ( 0.640)	Loss 5.5108e-01 (6.9151e-01)	Acc@1  81.77 ( 74.05)
The current update step is 6280
GPU_0_using curriculum 20 with window 20
Epoch: [157][20/40]	Time  1.584 ( 1.501)	Data  0.026 ( 0.039)	InnerLoop  0.736 ( 0.642)	Loss 6.7592e-01 (6.2964e-01)	Acc@1  72.46 ( 76.37)
Epoch: [157][40/40]	Time  1.466 ( 1.500)	Data  0.012 ( 0.038)	InnerLoop  0.627 ( 0.640)	Loss 4.6579e-01 (6.4296e-01)	Acc@1  80.21 ( 75.90)
The current update step is 6320
GPU_0_using curriculum 20 with window 20
Epoch: [158][20/40]	Time  1.475 ( 1.499)	Data  0.027 ( 0.033)	InnerLoop  0.624 ( 0.644)	Loss 6.6414e-01 (7.3048e-01)	Acc@1  74.80 ( 72.62)
Epoch: [158][40/40]	Time  1.447 ( 1.501)	Data  0.011 ( 0.035)	InnerLoop  0.620 ( 0.643)	Loss 7.1869e-01 (7.2136e-01)	Acc@1  76.04 ( 72.81)
The current update step is 6360
GPU_0_using curriculum 20 with window 20
Epoch: [159][20/40]	Time  1.474 ( 1.494)	Data  0.027 ( 0.038)	InnerLoop  0.624 ( 0.635)	Loss 6.0650e-01 (7.0163e-01)	Acc@1  76.89 ( 73.96)
Epoch: [159][40/40]	Time  1.466 ( 1.496)	Data  0.010 ( 0.035)	InnerLoop  0.635 ( 0.639)	Loss 8.0570e-01 (6.7511e-01)	Acc@1  76.56 ( 74.82)
The current update step is 6400
The current seed is 4298744030622557691
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.632
 *   Acc@1 70.676
 *   Acc@1 67.461
 *   Acc@1 67.251
 *   Acc@1 66.105
 *   Acc@1 66.073
 *   Acc@1 70.355
 *   Acc@1 69.959
 *   Acc@1 67.605
 *   Acc@1 67.108
 *   Acc@1 65.026
 *   Acc@1 65.192
Training for 300 epoch: 70.49342105263159
Training for 600 epoch: 67.53289473684211
Training for 1000 epoch: 65.56578947368422
Training for 300 epoch: 70.3175
Training for 600 epoch: 67.17916666666667
Training for 1000 epoch: 65.63208333333333
[[70.49342105263159, 67.53289473684211, 65.56578947368422], [70.3175, 67.17916666666667, 65.63208333333333]]
train loss 0.4341844264984131, epoch 159, best loss 0.29211228256225585, best_epoch 144
GPU_0_using curriculum 20 with window 20
Epoch: [160][20/40]	Time  1.478 ( 1.498)	Data  0.026 ( 0.038)	InnerLoop  0.626 ( 0.636)	Loss 5.8895e-01 (7.0173e-01)	Acc@1  79.04 ( 73.77)
Epoch: [160][40/40]	Time  1.481 ( 1.501)	Data  0.013 ( 0.035)	InnerLoop  0.630 ( 0.640)	Loss 6.1601e-01 (6.8285e-01)	Acc@1  77.08 ( 74.76)
The current update step is 6440
GPU_0_using curriculum 20 with window 20
Epoch: [161][20/40]	Time  1.596 ( 1.507)	Data  0.026 ( 0.045)	InnerLoop  0.739 ( 0.636)	Loss 5.1620e-01 (6.2961e-01)	Acc@1  81.51 ( 76.75)
Epoch: [161][40/40]	Time  1.463 ( 1.510)	Data  0.012 ( 0.042)	InnerLoop  0.627 ( 0.639)	Loss 4.8486e-01 (6.3617e-01)	Acc@1  83.85 ( 76.64)
The current update step is 6480
GPU_0_using curriculum 20 with window 20
Epoch: [162][20/40]	Time  1.473 ( 1.499)	Data  0.026 ( 0.044)	InnerLoop  0.622 ( 0.631)	Loss 6.0129e-01 (6.5103e-01)	Acc@1  77.57 ( 76.22)
Epoch: [162][40/40]	Time  1.466 ( 1.501)	Data  0.011 ( 0.038)	InnerLoop  0.627 ( 0.638)	Loss 5.7601e-01 (6.6927e-01)	Acc@1  80.21 ( 75.51)
The current update step is 6520
GPU_0_using curriculum 20 with window 20
Epoch: [163][20/40]	Time  1.504 ( 1.505)	Data  0.026 ( 0.038)	InnerLoop  0.651 ( 0.643)	Loss 5.6157e-01 (6.7973e-01)	Acc@1  79.39 ( 75.77)
Epoch: [163][40/40]	Time  1.480 ( 1.509)	Data  0.011 ( 0.038)	InnerLoop  0.643 ( 0.643)	Loss 6.3898e-01 (6.6095e-01)	Acc@1  72.40 ( 76.07)
The current update step is 6560
GPU_0_using curriculum 20 with window 20
Epoch: [164][20/40]	Time  1.479 ( 1.503)	Data  0.026 ( 0.039)	InnerLoop  0.627 ( 0.638)	Loss 6.3905e-01 (6.3385e-01)	Acc@1  76.30 ( 76.54)
Epoch: [164][40/40]	Time  1.490 ( 1.508)	Data  0.010 ( 0.038)	InnerLoop  0.656 ( 0.642)	Loss 9.6766e-01 (6.5287e-01)	Acc@1  61.98 ( 76.09)
The current update step is 6600
The current seed is 13946874613970312836
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.066
 *   Acc@1 77.835
 *   Acc@1 72.355
 *   Acc@1 73.292
 *   Acc@1 69.421
 *   Acc@1 70.377
 *   Acc@1 80.803
 *   Acc@1 80.693
 *   Acc@1 79.553
 *   Acc@1 80.112
 *   Acc@1 78.329
 *   Acc@1 78.696
Training for 300 epoch: 78.93421052631578
Training for 600 epoch: 75.95394736842105
Training for 1000 epoch: 73.875
Training for 300 epoch: 79.26416666666665
Training for 600 epoch: 76.70166666666667
Training for 1000 epoch: 74.53625
[[78.93421052631578, 75.95394736842105, 73.875], [79.26416666666665, 76.70166666666667, 74.53625]]
train loss 0.2910481328010559, epoch 164, best loss 0.2910481328010559, best_epoch 164
GPU_0_using curriculum 20 with window 20
Epoch: [165][20/40]	Time  1.487 ( 1.500)	Data  0.028 ( 0.038)	InnerLoop  0.629 ( 0.640)	Loss 6.5392e-01 (6.0245e-01)	Acc@1  70.77 ( 78.02)
Epoch: [165][40/40]	Time  1.457 ( 1.503)	Data  0.012 ( 0.038)	InnerLoop  0.622 ( 0.640)	Loss 6.0208e-01 (6.1113e-01)	Acc@1  77.08 ( 77.37)
The current update step is 6640
GPU_0_using curriculum 20 with window 20
Epoch: [166][20/40]	Time  1.491 ( 1.509)	Data  0.027 ( 0.045)	InnerLoop  0.631 ( 0.635)	Loss 6.3799e-01 (6.6687e-01)	Acc@1  75.88 ( 75.58)
Epoch: [166][40/40]	Time  1.575 ( 1.509)	Data  0.013 ( 0.039)	InnerLoop  0.737 ( 0.642)	Loss 5.5772e-01 (6.5603e-01)	Acc@1  83.33 ( 75.49)
The current update step is 6680
GPU_0_using curriculum 20 with window 20
Epoch: [167][20/40]	Time  1.479 ( 1.496)	Data  0.027 ( 0.038)	InnerLoop  0.629 ( 0.636)	Loss 5.9908e-01 (6.4266e-01)	Acc@1  79.46 ( 76.04)
Epoch: [167][40/40]	Time  1.464 ( 1.497)	Data  0.011 ( 0.038)	InnerLoop  0.633 ( 0.636)	Loss 6.3858e-01 (6.3929e-01)	Acc@1  73.96 ( 76.03)
The current update step is 6720
GPU_0_using curriculum 20 with window 20
Epoch: [168][20/40]	Time  1.478 ( 1.502)	Data  0.028 ( 0.044)	InnerLoop  0.626 ( 0.636)	Loss 7.1514e-01 (6.8237e-01)	Acc@1  69.37 ( 74.81)
Epoch: [168][40/40]	Time  1.453 ( 1.498)	Data  0.011 ( 0.040)	InnerLoop  0.625 ( 0.635)	Loss 7.3961e-01 (6.5361e-01)	Acc@1  76.56 ( 75.88)
The current update step is 6760
GPU_0_using curriculum 20 with window 20
Epoch: [169][20/40]	Time  1.584 ( 1.501)	Data  0.027 ( 0.039)	InnerLoop  0.736 ( 0.641)	Loss 5.6257e-01 (6.2101e-01)	Acc@1  79.30 ( 77.01)
Epoch: [169][40/40]	Time  1.469 ( 1.500)	Data  0.012 ( 0.038)	InnerLoop  0.632 ( 0.639)	Loss 5.5391e-01 (6.2476e-01)	Acc@1  82.81 ( 76.88)
The current update step is 6800
The current seed is 4057185036448538906
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.882
 *   Acc@1 78.355
 *   Acc@1 73.868
 *   Acc@1 74.213
 *   Acc@1 68.263
 *   Acc@1 68.457
 *   Acc@1 60.842
 *   Acc@1 60.563
 *   Acc@1 47.092
 *   Acc@1 47.883
 *   Acc@1 45.132
 *   Acc@1 45.410
Training for 300 epoch: 69.36184210526316
Training for 600 epoch: 60.48026315789474
Training for 1000 epoch: 56.69736842105263
Training for 300 epoch: 69.45916666666668
Training for 600 epoch: 61.047916666666666
Training for 1000 epoch: 56.93333333333333
[[69.36184210526316, 60.48026315789474, 56.69736842105263], [69.45916666666668, 61.047916666666666, 56.93333333333333]]
train loss 0.6607830973625183, epoch 169, best loss 0.2910481328010559, best_epoch 164
GPU_0_using curriculum 20 with window 20
Epoch: [170][20/40]	Time  1.476 ( 1.498)	Data  0.027 ( 0.033)	InnerLoop  0.626 ( 0.642)	Loss 8.1489e-01 (7.3221e-01)	Acc@1  68.33 ( 73.13)
Epoch: [170][40/40]	Time  1.464 ( 1.501)	Data  0.011 ( 0.036)	InnerLoop  0.628 ( 0.642)	Loss 4.6410e-01 (6.8503e-01)	Acc@1  84.38 ( 74.57)
The current update step is 6840
GPU_0_using curriculum 20 with window 20
Epoch: [171][20/40]	Time  1.474 ( 1.493)	Data  0.027 ( 0.033)	InnerLoop  0.624 ( 0.640)	Loss 5.0574e-01 (6.3930e-01)	Acc@1  80.92 ( 76.39)
Epoch: [171][40/40]	Time  1.464 ( 1.497)	Data  0.013 ( 0.035)	InnerLoop  0.627 ( 0.639)	Loss 6.6664e-01 (6.2897e-01)	Acc@1  73.96 ( 76.90)
The current update step is 6880
GPU_0_using curriculum 20 with window 20
Epoch: [172][20/40]	Time  1.592 ( 1.508)	Data  0.028 ( 0.039)	InnerLoop  0.739 ( 0.644)	Loss 5.6915e-01 (6.3392e-01)	Acc@1  79.46 ( 76.12)
Epoch: [172][40/40]	Time  1.478 ( 1.504)	Data  0.012 ( 0.038)	InnerLoop  0.635 ( 0.641)	Loss 6.3879e-01 (6.4391e-01)	Acc@1  76.04 ( 76.38)
The current update step is 6920
GPU_0_using curriculum 20 with window 20
Epoch: [173][20/40]	Time  1.492 ( 1.501)	Data  0.028 ( 0.033)	InnerLoop  0.632 ( 0.644)	Loss 7.3475e-01 (6.5846e-01)	Acc@1  72.79 ( 75.81)
Epoch: [173][40/40]	Time  1.474 ( 1.508)	Data  0.012 ( 0.036)	InnerLoop  0.631 ( 0.645)	Loss 8.2128e-01 (6.4464e-01)	Acc@1  71.88 ( 76.47)
The current update step is 6960
GPU_0_using curriculum 20 with window 20
Epoch: [174][20/40]	Time  1.497 ( 1.507)	Data  0.032 ( 0.040)	InnerLoop  0.632 ( 0.639)	Loss 5.3583e-01 (6.1722e-01)	Acc@1  81.22 ( 77.58)
Epoch: [174][40/40]	Time  1.508 ( 1.514)	Data  0.013 ( 0.036)	InnerLoop  0.649 ( 0.647)	Loss 5.8647e-01 (6.1001e-01)	Acc@1  78.65 ( 77.58)
The current update step is 7000
The current seed is 6010238463523679785
The current lr is: 0.001
Testing Results:
 *   Acc@1 75.382
 *   Acc@1 75.952
 *   Acc@1 78.947
 *   Acc@1 79.013
 *   Acc@1 79.421
 *   Acc@1 79.372
 *   Acc@1 71.737
 *   Acc@1 71.513
 *   Acc@1 71.250
 *   Acc@1 71.276
 *   Acc@1 70.776
 *   Acc@1 70.644
Training for 300 epoch: 73.5592105263158
Training for 600 epoch: 75.09868421052632
Training for 1000 epoch: 75.09868421052632
Training for 300 epoch: 73.7325
Training for 600 epoch: 75.14416666666668
Training for 1000 epoch: 75.00791666666666
[[73.5592105263158, 75.09868421052632, 75.09868421052632], [73.7325, 75.14416666666668, 75.00791666666666]]
train loss 0.3791667852878571, epoch 174, best loss 0.2910481328010559, best_epoch 164
GPU_0_using curriculum 20 with window 20
Epoch: [175][20/40]	Time  1.497 ( 1.524)	Data  0.027 ( 0.040)	InnerLoop  0.636 ( 0.650)	Loss 5.7134e-01 (6.6698e-01)	Acc@1  79.17 ( 75.16)
Epoch: [175][40/40]	Time  1.479 ( 1.527)	Data  0.011 ( 0.037)	InnerLoop  0.634 ( 0.653)	Loss 5.3469e-01 (6.8438e-01)	Acc@1  79.17 ( 75.06)
The current update step is 7040
GPU_0_using curriculum 20 with window 20
Epoch: [176][20/40]	Time  1.602 ( 1.519)	Data  0.026 ( 0.046)	InnerLoop  0.744 ( 0.642)	Loss 5.8481e-01 (5.9144e-01)	Acc@1  78.22 ( 77.82)
Epoch: [176][40/40]	Time  1.476 ( 1.516)	Data  0.011 ( 0.042)	InnerLoop  0.637 ( 0.642)	Loss 5.2833e-01 (6.0778e-01)	Acc@1  81.77 ( 77.19)
The current update step is 7080
GPU_0_using curriculum 20 with window 20
Epoch: [177][20/40]	Time  1.497 ( 1.511)	Data  0.029 ( 0.046)	InnerLoop  0.632 ( 0.635)	Loss 6.0927e-01 (6.2710e-01)	Acc@1  77.38 ( 77.09)
Epoch: [177][40/40]	Time  1.462 ( 1.507)	Data  0.012 ( 0.039)	InnerLoop  0.622 ( 0.639)	Loss 7.2662e-01 (6.2919e-01)	Acc@1  74.48 ( 77.04)
The current update step is 7120
GPU_0_using curriculum 20 with window 20
Epoch: [178][20/40]	Time  1.567 ( 1.529)	Data  0.031 ( 0.041)	InnerLoop  0.665 ( 0.651)	Loss 6.7695e-01 (6.4857e-01)	Acc@1  73.40 ( 76.29)
Epoch: [178][40/40]	Time  1.517 ( 1.530)	Data  0.012 ( 0.040)	InnerLoop  0.655 ( 0.652)	Loss 5.1088e-01 (6.4252e-01)	Acc@1  83.33 ( 76.14)
The current update step is 7160
GPU_0_using curriculum 20 with window 20
Epoch: [179][20/40]	Time  1.503 ( 1.536)	Data  0.028 ( 0.042)	InnerLoop  0.635 ( 0.653)	Loss 8.0578e-01 (5.9332e-01)	Acc@1  72.69 ( 78.06)
Epoch: [179][40/40]	Time  1.510 ( 1.543)	Data  0.012 ( 0.042)	InnerLoop  0.653 ( 0.658)	Loss 4.8054e-01 (6.2147e-01)	Acc@1  83.33 ( 76.88)
The current update step is 7200
The current seed is 10260805199580169603
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.842
 *   Acc@1 78.069
 *   Acc@1 77.645
 *   Acc@1 77.960
 *   Acc@1 77.092
 *   Acc@1 77.143
 *   Acc@1 79.566
 *   Acc@1 80.162
 *   Acc@1 76.908
 *   Acc@1 77.514
 *   Acc@1 72.474
 *   Acc@1 73.155
Training for 300 epoch: 78.70394736842104
Training for 600 epoch: 77.27631578947368
Training for 1000 epoch: 74.78289473684211
Training for 300 epoch: 79.11583333333333
Training for 600 epoch: 77.73708333333333
Training for 1000 epoch: 75.14916666666667
[[78.70394736842104, 77.27631578947368, 74.78289473684211], [79.11583333333333, 77.73708333333333, 75.14916666666667]]
train loss 0.38050947213172914, epoch 179, best loss 0.2910481328010559, best_epoch 164
GPU_0_using curriculum 20 with window 20
Epoch: [180][20/40]	Time  1.537 ( 1.534)	Data  0.030 ( 0.041)	InnerLoop  0.658 ( 0.656)	Loss 5.5422e-01 (6.2578e-01)	Acc@1  80.63 ( 76.80)
Epoch: [180][40/40]	Time  1.502 ( 1.539)	Data  0.014 ( 0.041)	InnerLoop  0.649 ( 0.657)	Loss 7.3978e-01 (6.1848e-01)	Acc@1  77.08 ( 77.22)
The current update step is 7240
GPU_0_using curriculum 20 with window 20
Epoch: [181][20/40]	Time  1.536 ( 1.544)	Data  0.033 ( 0.048)	InnerLoop  0.654 ( 0.653)	Loss 9.6541e-01 (6.1593e-01)	Acc@1  66.96 ( 77.82)
Epoch: [181][40/40]	Time  1.622 ( 1.548)	Data  0.014 ( 0.042)	InnerLoop  0.764 ( 0.662)	Loss 6.6899e-01 (6.3242e-01)	Acc@1  80.21 ( 76.97)
The current update step is 7280
GPU_0_using curriculum 20 with window 20
Epoch: [182][20/40]	Time  1.523 ( 1.540)	Data  0.030 ( 0.042)	InnerLoop  0.649 ( 0.654)	Loss 7.5516e-01 (6.1889e-01)	Acc@1  71.45 ( 77.43)
Epoch: [182][40/40]	Time  1.498 ( 1.542)	Data  0.013 ( 0.042)	InnerLoop  0.644 ( 0.656)	Loss 5.3514e-01 (6.0042e-01)	Acc@1  83.33 ( 78.06)
The current update step is 7320
GPU_0_using curriculum 20 with window 20
Epoch: [183][20/40]	Time  1.546 ( 1.551)	Data  0.032 ( 0.050)	InnerLoop  0.663 ( 0.658)	Loss 5.7534e-01 (6.2802e-01)	Acc@1  79.69 ( 76.78)
Epoch: [183][40/40]	Time  1.500 ( 1.548)	Data  0.011 ( 0.046)	InnerLoop  0.643 ( 0.658)	Loss 5.1715e-01 (6.8670e-01)	Acc@1  77.60 ( 74.81)
The current update step is 7360
GPU_0_using curriculum 20 with window 20
Epoch: [184][20/40]	Time  1.645 ( 1.548)	Data  0.028 ( 0.044)	InnerLoop  0.769 ( 0.662)	Loss 7.3819e-01 (6.5402e-01)	Acc@1  69.69 ( 74.93)
Epoch: [184][40/40]	Time  1.510 ( 1.547)	Data  0.013 ( 0.043)	InnerLoop  0.648 ( 0.661)	Loss 7.5969e-01 (6.5936e-01)	Acc@1  74.48 ( 75.27)
The current update step is 7400
The current seed is 2560521801461626055
The current lr is: 0.001
Testing Results:
 *   Acc@1 80.776
 *   Acc@1 80.862
 *   Acc@1 79.632
 *   Acc@1 79.896
 *   Acc@1 78.395
 *   Acc@1 78.714
 *   Acc@1 73.921
 *   Acc@1 74.474
 *   Acc@1 66.737
 *   Acc@1 66.866
 *   Acc@1 64.316
 *   Acc@1 64.237
Training for 300 epoch: 77.34868421052632
Training for 600 epoch: 73.1842105263158
Training for 1000 epoch: 71.35526315789474
Training for 300 epoch: 77.66833333333332
Training for 600 epoch: 73.38083333333333
Training for 1000 epoch: 71.47583333333333
[[77.34868421052632, 73.1842105263158, 71.35526315789474], [77.66833333333332, 73.38083333333333, 71.47583333333333]]
train loss 0.41600086913108825, epoch 184, best loss 0.2910481328010559, best_epoch 164
GPU_0_using curriculum 20 with window 20
Epoch: [185][20/40]	Time  1.520 ( 1.542)	Data  0.029 ( 0.036)	InnerLoop  0.646 ( 0.663)	Loss 6.7366e-01 (6.6447e-01)	Acc@1  76.04 ( 75.47)
Epoch: [185][40/40]	Time  1.498 ( 1.546)	Data  0.013 ( 0.039)	InnerLoop  0.648 ( 0.664)	Loss 6.6140e-01 (6.3888e-01)	Acc@1  76.56 ( 76.35)
The current update step is 7440
GPU_0_using curriculum 20 with window 20
Epoch: [186][20/40]	Time  1.521 ( 1.540)	Data  0.028 ( 0.035)	InnerLoop  0.645 ( 0.663)	Loss 8.0157e-01 (6.4665e-01)	Acc@1  70.93 ( 75.93)
Epoch: [186][40/40]	Time  1.492 ( 1.543)	Data  0.015 ( 0.038)	InnerLoop  0.641 ( 0.661)	Loss 5.8574e-01 (6.3966e-01)	Acc@1  77.60 ( 75.99)
The current update step is 7480
GPU_0_using curriculum 20 with window 20
Epoch: [187][20/40]	Time  1.641 ( 1.548)	Data  0.031 ( 0.042)	InnerLoop  0.767 ( 0.664)	Loss 6.3554e-01 (6.3759e-01)	Acc@1  76.76 ( 76.20)
Epoch: [187][40/40]	Time  1.513 ( 1.547)	Data  0.012 ( 0.041)	InnerLoop  0.654 ( 0.662)	Loss 6.2867e-01 (6.5986e-01)	Acc@1  79.69 ( 75.28)
The current update step is 7520
GPU_0_using curriculum 20 with window 20
Epoch: [188][20/40]	Time  1.521 ( 1.542)	Data  0.031 ( 0.036)	InnerLoop  0.649 ( 0.664)	Loss 6.2989e-01 (6.2369e-01)	Acc@1  76.20 ( 76.53)
Epoch: [188][40/40]	Time  1.498 ( 1.547)	Data  0.012 ( 0.038)	InnerLoop  0.645 ( 0.665)	Loss 5.5284e-01 (6.3025e-01)	Acc@1  85.94 ( 76.43)
The current update step is 7560
GPU_0_using curriculum 20 with window 20
Epoch: [189][20/40]	Time  1.520 ( 1.543)	Data  0.031 ( 0.042)	InnerLoop  0.642 ( 0.658)	Loss 5.6698e-01 (6.4435e-01)	Acc@1  78.61 ( 75.59)
Epoch: [189][40/40]	Time  1.500 ( 1.543)	Data  0.012 ( 0.038)	InnerLoop  0.645 ( 0.661)	Loss 4.9103e-01 (6.4241e-01)	Acc@1  81.77 ( 75.92)
The current update step is 7600
The current seed is 11973606442493876795
The current lr is: 0.001
Testing Results:
 *   Acc@1 80.039
 *   Acc@1 80.862
 *   Acc@1 78.105
 *   Acc@1 78.849
 *   Acc@1 75.579
 *   Acc@1 76.599
 *   Acc@1 79.987
 *   Acc@1 80.264
 *   Acc@1 78.013
 *   Acc@1 78.410
 *   Acc@1 74.447
 *   Acc@1 75.112
Training for 300 epoch: 80.01315789473685
Training for 600 epoch: 78.05921052631578
Training for 1000 epoch: 75.01315789473685
Training for 300 epoch: 80.56333333333333
Training for 600 epoch: 78.62958333333333
Training for 1000 epoch: 75.85583333333332
[[80.01315789473685, 78.05921052631578, 75.01315789473685], [80.56333333333333, 78.62958333333333, 75.85583333333332]]
train loss 0.3183813737392426, epoch 189, best loss 0.2910481328010559, best_epoch 164
GPU_0_using curriculum 20 with window 20
Epoch: [190][20/40]	Time  1.517 ( 1.544)	Data  0.028 ( 0.042)	InnerLoop  0.644 ( 0.660)	Loss 1.0031e+00 (6.5135e-01)	Acc@1  60.61 ( 75.57)
Epoch: [190][40/40]	Time  1.521 ( 1.548)	Data  0.014 ( 0.039)	InnerLoop  0.662 ( 0.664)	Loss 5.5156e-01 (6.2612e-01)	Acc@1  77.60 ( 76.56)
The current update step is 7640
GPU_0_using curriculum 20 with window 20
Epoch: [191][20/40]	Time  1.647 ( 1.552)	Data  0.028 ( 0.049)	InnerLoop  0.777 ( 0.661)	Loss 6.0113e-01 (6.1760e-01)	Acc@1  75.62 ( 76.99)
Epoch: [191][40/40]	Time  1.515 ( 1.551)	Data  0.014 ( 0.045)	InnerLoop  0.655 ( 0.661)	Loss 5.6720e-01 (6.2807e-01)	Acc@1  78.65 ( 76.82)
The current update step is 7680
GPU_0_using curriculum 20 with window 20
Epoch: [192][20/40]	Time  1.518 ( 1.543)	Data  0.031 ( 0.049)	InnerLoop  0.644 ( 0.652)	Loss 6.5798e-01 (6.1183e-01)	Acc@1  77.25 ( 77.78)
Epoch: [192][40/40]	Time  1.514 ( 1.545)	Data  0.012 ( 0.042)	InnerLoop  0.654 ( 0.659)	Loss 1.1437e+00 (6.2239e-01)	Acc@1  66.67 ( 77.48)
The current update step is 7720
GPU_0_using curriculum 20 with window 20
Epoch: [193][20/40]	Time  1.518 ( 1.548)	Data  0.027 ( 0.042)	InnerLoop  0.644 ( 0.665)	Loss 5.7789e-01 (6.2657e-01)	Acc@1  79.88 ( 77.14)
Epoch: [193][40/40]	Time  1.507 ( 1.549)	Data  0.013 ( 0.042)	InnerLoop  0.649 ( 0.663)	Loss 6.1214e-01 (6.5379e-01)	Acc@1  78.65 ( 76.10)
The current update step is 7760
GPU_0_using curriculum 20 with window 20
Epoch: [194][20/40]	Time  1.521 ( 1.549)	Data  0.029 ( 0.042)	InnerLoop  0.646 ( 0.660)	Loss 6.8955e-01 (6.9809e-01)	Acc@1  75.85 ( 75.40)
Epoch: [194][40/40]	Time  1.508 ( 1.553)	Data  0.012 ( 0.042)	InnerLoop  0.650 ( 0.665)	Loss 6.6268e-01 (6.9200e-01)	Acc@1  73.96 ( 75.11)
The current update step is 7800
The current seed is 9785298372423734712
The current lr is: 0.001
Testing Results:
 *   Acc@1 80.724
 *   Acc@1 81.370
 *   Acc@1 79.237
 *   Acc@1 79.780
 *   Acc@1 78.539
 *   Acc@1 79.103
 *   Acc@1 71.039
 *   Acc@1 71.730
 *   Acc@1 63.171
 *   Acc@1 63.699
 *   Acc@1 60.039
 *   Acc@1 60.501
Training for 300 epoch: 75.88157894736841
Training for 600 epoch: 71.20394736842105
Training for 1000 epoch: 69.28947368421052
Training for 300 epoch: 76.55000000000001
Training for 600 epoch: 71.73958333333333
Training for 1000 epoch: 69.80166666666668
[[75.88157894736841, 71.20394736842105, 69.28947368421052], [76.55000000000001, 71.73958333333333, 69.80166666666668]]
train loss 0.5427633536338806, epoch 194, best loss 0.2910481328010559, best_epoch 164
GPU_0_using curriculum 20 with window 20
Epoch: [195][20/40]	Time  1.551 ( 1.569)	Data  0.030 ( 0.043)	InnerLoop  0.666 ( 0.674)	Loss 5.6547e-01 (6.6534e-01)	Acc@1  79.33 ( 75.29)
Epoch: [195][40/40]	Time  1.508 ( 1.562)	Data  0.015 ( 0.042)	InnerLoop  0.649 ( 0.670)	Loss 5.2653e-01 (6.7986e-01)	Acc@1  79.69 ( 75.15)
The current update step is 7840
GPU_0_using curriculum 20 with window 20
Epoch: [196][20/40]	Time  1.526 ( 1.545)	Data  0.032 ( 0.049)	InnerLoop  0.647 ( 0.653)	Loss 6.7376e-01 (6.4033e-01)	Acc@1  75.23 ( 76.23)
Epoch: [196][40/40]	Time  1.621 ( 1.550)	Data  0.014 ( 0.042)	InnerLoop  0.764 ( 0.662)	Loss 6.2230e-01 (6.4181e-01)	Acc@1  76.04 ( 76.29)
The current update step is 7880
GPU_0_using curriculum 20 with window 20
Epoch: [197][20/40]	Time  1.531 ( 1.549)	Data  0.029 ( 0.042)	InnerLoop  0.657 ( 0.662)	Loss 5.2005e-01 (6.1535e-01)	Acc@1  80.73 ( 77.41)
Epoch: [197][40/40]	Time  1.508 ( 1.551)	Data  0.011 ( 0.042)	InnerLoop  0.650 ( 0.663)	Loss 5.0184e-01 (6.2471e-01)	Acc@1  81.25 ( 77.09)
The current update step is 7920
GPU_0_using curriculum 20 with window 20
Epoch: [198][20/40]	Time  1.524 ( 1.553)	Data  0.029 ( 0.049)	InnerLoop  0.648 ( 0.660)	Loss 5.7848e-01 (6.3632e-01)	Acc@1  78.94 ( 76.24)
Epoch: [198][40/40]	Time  1.508 ( 1.553)	Data  0.011 ( 0.045)	InnerLoop  0.652 ( 0.662)	Loss 9.1489e-01 (6.4845e-01)	Acc@1  72.40 ( 75.99)
The current update step is 7960
GPU_0_using curriculum 20 with window 20
Epoch: [199][20/40]	Time  1.656 ( 1.558)	Data  0.029 ( 0.042)	InnerLoop  0.773 ( 0.670)	Loss 5.9254e-01 (6.0824e-01)	Acc@1  79.30 ( 77.90)
Epoch: [199][40/40]	Time  1.503 ( 1.555)	Data  0.014 ( 0.042)	InnerLoop  0.645 ( 0.666)	Loss 6.4650e-01 (6.2520e-01)	Acc@1  76.04 ( 77.34)
The current update step is 8000
The current seed is 15030460098067106171
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.316
 *   Acc@1 77.101
 *   Acc@1 75.895
 *   Acc@1 76.458
 *   Acc@1 75.263
 *   Acc@1 76.057
 *   Acc@1 71.816
 *   Acc@1 72.434
 *   Acc@1 68.553
 *   Acc@1 68.606
 *   Acc@1 64.974
 *   Acc@1 65.197
Training for 300 epoch: 74.0657894736842
Training for 600 epoch: 72.22368421052632
Training for 1000 epoch: 70.11842105263158
Training for 300 epoch: 74.7675
Training for 600 epoch: 72.53208333333333
Training for 1000 epoch: 70.62666666666667
[[74.0657894736842, 72.22368421052632, 70.11842105263158], [74.7675, 72.53208333333333, 70.62666666666667]]
train loss 0.45588986496925354, epoch 199, best loss 0.2910481328010559, best_epoch 164
GPU_0_using curriculum 20 with window 20
Epoch: [200][20/40]	Time  1.529 ( 1.550)	Data  0.031 ( 0.037)	InnerLoop  0.650 ( 0.666)	Loss 5.2530e-01 (7.0894e-01)	Acc@1  81.38 ( 73.64)
Epoch: [200][40/40]	Time  1.517 ( 1.555)	Data  0.012 ( 0.040)	InnerLoop  0.655 ( 0.668)	Loss 6.9509e-01 (6.6693e-01)	Acc@1  73.44 ( 75.28)
The current update step is 8040
GPU_0_using curriculum 20 with window 20
Epoch: [201][20/40]	Time  1.527 ( 1.550)	Data  0.030 ( 0.036)	InnerLoop  0.652 ( 0.668)	Loss 7.1736e-01 (6.2946e-01)	Acc@1  70.25 ( 76.00)
Epoch: [201][40/40]	Time  1.502 ( 1.551)	Data  0.012 ( 0.039)	InnerLoop  0.642 ( 0.665)	Loss 5.6783e-01 (6.1661e-01)	Acc@1  78.65 ( 76.83)
The current update step is 8080
GPU_0_using curriculum 20 with window 20
Epoch: [202][20/40]	Time  1.654 ( 1.558)	Data  0.032 ( 0.043)	InnerLoop  0.772 ( 0.668)	Loss 6.2772e-01 (6.3723e-01)	Acc@1  73.21 ( 76.47)
Epoch: [202][40/40]	Time  1.509 ( 1.557)	Data  0.014 ( 0.043)	InnerLoop  0.649 ( 0.665)	Loss 5.6975e-01 (6.2088e-01)	Acc@1  80.21 ( 76.94)
The current update step is 8120
GPU_0_using curriculum 20 with window 20
Epoch: [203][20/40]	Time  1.537 ( 1.551)	Data  0.033 ( 0.037)	InnerLoop  0.654 ( 0.667)	Loss 6.0085e-01 (6.3118e-01)	Acc@1  78.48 ( 76.88)
Epoch: [203][40/40]	Time  1.515 ( 1.556)	Data  0.014 ( 0.039)	InnerLoop  0.658 ( 0.670)	Loss 4.1865e-01 (6.3804e-01)	Acc@1  85.42 ( 76.64)
The current update step is 8160
GPU_0_using curriculum 20 with window 20
Epoch: [204][20/40]	Time  1.525 ( 1.549)	Data  0.031 ( 0.043)	InnerLoop  0.645 ( 0.661)	Loss 6.7683e-01 (6.4218e-01)	Acc@1  75.72 ( 76.62)
Epoch: [204][40/40]	Time  1.507 ( 1.551)	Data  0.012 ( 0.040)	InnerLoop  0.650 ( 0.665)	Loss 5.2777e-01 (6.2004e-01)	Acc@1  83.85 ( 77.12)
The current update step is 8200
The current seed is 18064999414469833891
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.118
 *   Acc@1 73.488
 *   Acc@1 69.724
 *   Acc@1 70.363
 *   Acc@1 67.895
 *   Acc@1 68.337
 *   Acc@1 79.645
 *   Acc@1 79.985
 *   Acc@1 74.526
 *   Acc@1 74.573
 *   Acc@1 69.684
 *   Acc@1 69.846
Training for 300 epoch: 76.38157894736841
Training for 600 epoch: 72.125
Training for 1000 epoch: 68.78947368421052
Training for 300 epoch: 76.73666666666666
Training for 600 epoch: 72.46791666666667
Training for 1000 epoch: 69.09125
[[76.38157894736841, 72.125, 68.78947368421052], [76.73666666666666, 72.46791666666667, 69.09125]]
train loss 0.3651207160949707, epoch 204, best loss 0.2910481328010559, best_epoch 164
GPU_0_using curriculum 20 with window 20
Epoch: [205][20/40]	Time  1.530 ( 1.554)	Data  0.032 ( 0.043)	InnerLoop  0.649 ( 0.664)	Loss 5.9190e-01 (6.1880e-01)	Acc@1  76.82 ( 77.72)
Epoch: [205][40/40]	Time  1.500 ( 1.553)	Data  0.012 ( 0.039)	InnerLoop  0.645 ( 0.666)	Loss 6.5576e-01 (6.3493e-01)	Acc@1  74.48 ( 76.91)
The current update step is 8240
GPU_0_using curriculum 20 with window 20
Epoch: [206][20/40]	Time  1.653 ( 1.557)	Data  0.030 ( 0.048)	InnerLoop  0.775 ( 0.661)	Loss 5.6662e-01 (6.5976e-01)	Acc@1  79.26 ( 75.71)
Epoch: [206][40/40]	Time  1.516 ( 1.557)	Data  0.014 ( 0.045)	InnerLoop  0.654 ( 0.663)	Loss 7.5593e-01 (6.2811e-01)	Acc@1  69.27 ( 77.01)
The current update step is 8280
GPU_0_using curriculum 20 with window 20
Epoch: [207][20/40]	Time  1.533 ( 1.550)	Data  0.031 ( 0.049)	InnerLoop  0.651 ( 0.657)	Loss 5.1043e-01 (5.8922e-01)	Acc@1  81.64 ( 78.46)
Epoch: [207][40/40]	Time  1.500 ( 1.552)	Data  0.012 ( 0.042)	InnerLoop  0.642 ( 0.664)	Loss 5.0757e-01 (6.0555e-01)	Acc@1  81.25 ( 77.88)
The current update step is 8320
GPU_0_using curriculum 20 with window 20
Epoch: [208][20/40]	Time  1.537 ( 1.559)	Data  0.030 ( 0.043)	InnerLoop  0.657 ( 0.669)	Loss 5.5015e-01 (6.2778e-01)	Acc@1  80.66 ( 76.88)
Epoch: [208][40/40]	Time  1.514 ( 1.557)	Data  0.012 ( 0.042)	InnerLoop  0.655 ( 0.666)	Loss 5.7360e-01 (6.1994e-01)	Acc@1  78.12 ( 77.13)
The current update step is 8360
GPU_0_using curriculum 20 with window 20
Epoch: [209][20/40]	Time  1.540 ( 1.551)	Data  0.031 ( 0.043)	InnerLoop  0.656 ( 0.662)	Loss 6.1521e-01 (5.6507e-01)	Acc@1  76.66 ( 78.99)
Epoch: [209][40/40]	Time  1.511 ( 1.555)	Data  0.015 ( 0.043)	InnerLoop  0.651 ( 0.666)	Loss 6.8999e-01 (6.0547e-01)	Acc@1  72.92 ( 77.61)
The current update step is 8400
The current seed is 2203677734323814038
The current lr is: 0.001
Testing Results:
 *   Acc@1 79.105
 *   Acc@1 79.726
 *   Acc@1 78.566
 *   Acc@1 78.949
 *   Acc@1 77.000
 *   Acc@1 77.459
 *   Acc@1 75.329
 *   Acc@1 76.017
 *   Acc@1 71.632
 *   Acc@1 72.305
 *   Acc@1 69.132
 *   Acc@1 69.645
Training for 300 epoch: 77.21710526315789
Training for 600 epoch: 75.09868421052632
Training for 1000 epoch: 73.06578947368422
Training for 300 epoch: 77.87125
Training for 600 epoch: 75.62708333333333
Training for 1000 epoch: 73.55208333333333
[[77.21710526315789, 75.09868421052632, 73.06578947368422], [77.87125, 75.62708333333333, 73.55208333333333]]
train loss 0.4236784318447113, epoch 209, best loss 0.2910481328010559, best_epoch 164
GPU_0_using curriculum 20 with window 20
Epoch: [210][20/40]	Time  1.525 ( 1.557)	Data  0.028 ( 0.042)	InnerLoop  0.650 ( 0.669)	Loss 6.0039e-01 (6.1440e-01)	Acc@1  77.25 ( 77.41)
Epoch: [210][40/40]	Time  1.508 ( 1.556)	Data  0.012 ( 0.042)	InnerLoop  0.648 ( 0.667)	Loss 5.5502e-01 (6.1428e-01)	Acc@1  79.69 ( 77.39)
The current update step is 8440
GPU_0_using curriculum 20 with window 20
Epoch: [211][20/40]	Time  1.528 ( 1.550)	Data  0.029 ( 0.049)	InnerLoop  0.648 ( 0.656)	Loss 5.7903e-01 (5.8511e-01)	Acc@1  79.49 ( 78.58)
Epoch: [211][40/40]	Time  1.627 ( 1.555)	Data  0.014 ( 0.042)	InnerLoop  0.772 ( 0.667)	Loss 8.7975e-01 (5.8860e-01)	Acc@1  67.19 ( 78.47)
The current update step is 8480
GPU_0_using curriculum 20 with window 20
Epoch: [212][20/40]	Time  1.541 ( 1.549)	Data  0.031 ( 0.043)	InnerLoop  0.658 ( 0.661)	Loss 5.3902e-01 (5.9477e-01)	Acc@1  80.01 ( 77.98)
Epoch: [212][40/40]	Time  1.513 ( 1.549)	Data  0.013 ( 0.042)	InnerLoop  0.655 ( 0.661)	Loss 8.3647e-01 (6.0060e-01)	Acc@1  68.23 ( 77.81)
The current update step is 8520
GPU_0_using curriculum 20 with window 20
Epoch: [213][20/40]	Time  1.535 ( 1.553)	Data  0.031 ( 0.049)	InnerLoop  0.654 ( 0.661)	Loss 5.0221e-01 (6.4335e-01)	Acc@1  81.67 ( 76.62)
Epoch: [213][40/40]	Time  1.501 ( 1.549)	Data  0.013 ( 0.045)	InnerLoop  0.646 ( 0.660)	Loss 4.5679e-01 (6.3805e-01)	Acc@1  84.38 ( 76.72)
The current update step is 8560
GPU_0_using curriculum 20 with window 20
Epoch: [214][20/40]	Time  1.648 ( 1.550)	Data  0.029 ( 0.042)	InnerLoop  0.758 ( 0.665)	Loss 6.6573e-01 (6.4296e-01)	Acc@1  74.06 ( 75.63)
Epoch: [214][40/40]	Time  1.509 ( 1.550)	Data  0.014 ( 0.042)	InnerLoop  0.650 ( 0.664)	Loss 6.2853e-01 (6.0686e-01)	Acc@1  72.92 ( 77.31)
The current update step is 8600
The current seed is 13694391477603575613
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.434
 *   Acc@1 77.821
 *   Acc@1 74.763
 *   Acc@1 74.546
 *   Acc@1 71.947
 *   Acc@1 72.101
 *   Acc@1 77.000
 *   Acc@1 77.277
 *   Acc@1 74.158
 *   Acc@1 74.468
 *   Acc@1 71.250
 *   Acc@1 71.377
Training for 300 epoch: 77.21710526315789
Training for 600 epoch: 74.46052631578948
Training for 1000 epoch: 71.59868421052632
Training for 300 epoch: 77.54875000000001
Training for 600 epoch: 74.50708333333333
Training for 1000 epoch: 71.73875
[[77.21710526315789, 74.46052631578948, 71.59868421052632], [77.54875000000001, 74.50708333333333, 71.73875]]
train loss 0.37633745589256284, epoch 214, best loss 0.2910481328010559, best_epoch 164
GPU_0_using curriculum 20 with window 20
Epoch: [215][20/40]	Time  1.523 ( 1.544)	Data  0.029 ( 0.036)	InnerLoop  0.647 ( 0.665)	Loss 5.0941e-01 (6.5857e-01)	Acc@1  81.58 ( 75.76)
Epoch: [215][40/40]	Time  1.507 ( 1.548)	Data  0.012 ( 0.039)	InnerLoop  0.652 ( 0.666)	Loss 4.4413e-01 (6.3007e-01)	Acc@1  82.81 ( 76.69)
The current update step is 8640
GPU_0_using curriculum 20 with window 20
Epoch: [216][20/40]	Time  1.523 ( 1.545)	Data  0.030 ( 0.036)	InnerLoop  0.648 ( 0.667)	Loss 5.8074e-01 (6.0233e-01)	Acc@1  78.58 ( 77.99)
Epoch: [216][40/40]	Time  1.512 ( 1.546)	Data  0.014 ( 0.039)	InnerLoop  0.652 ( 0.664)	Loss 5.8299e-01 (5.9140e-01)	Acc@1  79.17 ( 78.28)
The current update step is 8680
GPU_0_using curriculum 20 with window 20
Epoch: [217][20/40]	Time  1.657 ( 1.554)	Data  0.030 ( 0.043)	InnerLoop  0.777 ( 0.667)	Loss 5.9456e-01 (5.8132e-01)	Acc@1  76.46 ( 78.63)
Epoch: [217][40/40]	Time  1.503 ( 1.551)	Data  0.013 ( 0.042)	InnerLoop  0.648 ( 0.665)	Loss 8.3574e-01 (6.1016e-01)	Acc@1  71.88 ( 77.51)
The current update step is 8720
GPU_0_using curriculum 20 with window 20
Epoch: [218][20/40]	Time  1.540 ( 1.545)	Data  0.032 ( 0.036)	InnerLoop  0.653 ( 0.666)	Loss 6.3017e-01 (5.9453e-01)	Acc@1  78.19 ( 78.49)
Epoch: [218][40/40]	Time  1.503 ( 1.549)	Data  0.013 ( 0.039)	InnerLoop  0.647 ( 0.666)	Loss 5.4536e-01 (6.0134e-01)	Acc@1  81.77 ( 77.71)
The current update step is 8760
GPU_0_using curriculum 20 with window 20
Epoch: [219][20/40]	Time  1.536 ( 1.547)	Data  0.031 ( 0.043)	InnerLoop  0.655 ( 0.660)	Loss 5.7343e-01 (5.9417e-01)	Acc@1  79.39 ( 77.92)
Epoch: [219][40/40]	Time  1.507 ( 1.548)	Data  0.013 ( 0.039)	InnerLoop  0.654 ( 0.664)	Loss 4.8396e-01 (5.9593e-01)	Acc@1  80.73 ( 77.96)
The current update step is 8800
The current seed is 3406563549797275765
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.789
 *   Acc@1 72.600
 *   Acc@1 68.342
 *   Acc@1 69.312
 *   Acc@1 64.868
 *   Acc@1 66.186
 *   Acc@1 68.750
 *   Acc@1 68.945
 *   Acc@1 62.842
 *   Acc@1 62.903
 *   Acc@1 60.079
 *   Acc@1 59.953
Training for 300 epoch: 70.26973684210526
Training for 600 epoch: 65.59210526315789
Training for 1000 epoch: 62.473684210526315
Training for 300 epoch: 70.7725
Training for 600 epoch: 66.10708333333334
Training for 1000 epoch: 63.06916666666667
[[70.26973684210526, 65.59210526315789, 62.473684210526315], [70.7725, 66.10708333333334, 63.06916666666667]]
train loss 0.5629688351631165, epoch 219, best loss 0.2910481328010559, best_epoch 164
GPU_0_using curriculum 20 with window 20
Epoch: [220][20/40]	Time  1.529 ( 1.545)	Data  0.032 ( 0.042)	InnerLoop  0.648 ( 0.660)	Loss 6.2540e-01 (6.1346e-01)	Acc@1  76.27 ( 76.95)
Epoch: [220][40/40]	Time  1.505 ( 1.546)	Data  0.013 ( 0.039)	InnerLoop  0.650 ( 0.664)	Loss 5.3026e-01 (6.2852e-01)	Acc@1  79.17 ( 76.67)
The current update step is 8840
GPU_0_using curriculum 20 with window 20
Epoch: [221][20/40]	Time  1.659 ( 1.552)	Data  0.030 ( 0.049)	InnerLoop  0.777 ( 0.660)	Loss 7.7847e-01 (5.9738e-01)	Acc@1  66.99 ( 77.89)
Epoch: [221][40/40]	Time  1.514 ( 1.551)	Data  0.014 ( 0.045)	InnerLoop  0.655 ( 0.661)	Loss 5.7749e-01 (6.1389e-01)	Acc@1  82.29 ( 77.04)
The current update step is 8880
GPU_0_using curriculum 20 with window 20
Epoch: [222][20/40]	Time  1.535 ( 1.545)	Data  0.031 ( 0.049)	InnerLoop  0.653 ( 0.653)	Loss 6.8318e-01 (6.2201e-01)	Acc@1  72.82 ( 76.08)
Epoch: [222][40/40]	Time  1.503 ( 1.546)	Data  0.011 ( 0.042)	InnerLoop  0.650 ( 0.661)	Loss 6.0610e-01 (6.0911e-01)	Acc@1  77.08 ( 77.00)
The current update step is 8920
GPU_0_using curriculum 20 with window 20
Epoch: [223][20/40]	Time  1.531 ( 1.551)	Data  0.031 ( 0.042)	InnerLoop  0.647 ( 0.665)	Loss 6.4584e-01 (5.7067e-01)	Acc@1  73.73 ( 78.95)
Epoch: [223][40/40]	Time  1.501 ( 1.549)	Data  0.013 ( 0.042)	InnerLoop  0.647 ( 0.663)	Loss 5.1858e-01 (6.1257e-01)	Acc@1  78.65 ( 77.73)
The current update step is 8960
GPU_0_using curriculum 20 with window 20
Epoch: [224][20/40]	Time  1.526 ( 1.547)	Data  0.031 ( 0.042)	InnerLoop  0.646 ( 0.661)	Loss 5.0912e-01 (5.8981e-01)	Acc@1  81.41 ( 78.39)
Epoch: [224][40/40]	Time  1.507 ( 1.550)	Data  0.015 ( 0.042)	InnerLoop  0.646 ( 0.663)	Loss 5.6806e-01 (6.0267e-01)	Acc@1  80.73 ( 77.81)
The current update step is 9000
The current seed is 7177114051004974348
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.316
 *   Acc@1 71.620
 *   Acc@1 69.421
 *   Acc@1 69.379
 *   Acc@1 67.263
 *   Acc@1 67.428
 *   Acc@1 78.566
 *   Acc@1 78.799
 *   Acc@1 77.908
 *   Acc@1 78.234
 *   Acc@1 77.684
 *   Acc@1 77.778
Training for 300 epoch: 74.9407894736842
Training for 600 epoch: 73.66447368421052
Training for 1000 epoch: 72.47368421052632
Training for 300 epoch: 75.20958333333334
Training for 600 epoch: 73.80666666666667
Training for 1000 epoch: 72.60291666666666
[[74.9407894736842, 73.66447368421052, 72.47368421052632], [75.20958333333334, 73.80666666666667, 72.60291666666666]]
train loss 0.3106961273670197, epoch 224, best loss 0.2910481328010559, best_epoch 224
GPU_0_using curriculum 20 with window 20
Epoch: [225][20/40]	Time  1.534 ( 1.547)	Data  0.032 ( 0.041)	InnerLoop  0.662 ( 0.665)	Loss 6.0526e-01 (5.7387e-01)	Acc@1  77.28 ( 79.21)
Epoch: [225][40/40]	Time  1.512 ( 1.547)	Data  0.011 ( 0.042)	InnerLoop  0.658 ( 0.662)	Loss 6.9995e-01 (5.8663e-01)	Acc@1  72.92 ( 78.81)
The current update step is 9040
GPU_0_using curriculum 20 with window 20
Epoch: [226][20/40]	Time  1.525 ( 1.542)	Data  0.028 ( 0.049)	InnerLoop  0.646 ( 0.651)	Loss 6.2711e-01 (6.2771e-01)	Acc@1  76.46 ( 76.71)
Epoch: [226][40/40]	Time  1.618 ( 1.548)	Data  0.013 ( 0.043)	InnerLoop  0.765 ( 0.662)	Loss 6.8269e-01 (6.2832e-01)	Acc@1  73.44 ( 76.94)
The current update step is 9080
GPU_0_using curriculum 20 with window 20
Epoch: [227][20/40]	Time  1.524 ( 1.541)	Data  0.029 ( 0.043)	InnerLoop  0.647 ( 0.658)	Loss 5.3215e-01 (5.8311e-01)	Acc@1  80.83 ( 78.71)
Epoch: [227][40/40]	Time  1.502 ( 1.543)	Data  0.014 ( 0.042)	InnerLoop  0.653 ( 0.659)	Loss 7.7463e-01 (6.0308e-01)	Acc@1  68.23 ( 78.19)
The current update step is 9120
GPU_0_using curriculum 20 with window 20
Epoch: [228][20/40]	Time  1.532 ( 1.548)	Data  0.031 ( 0.049)	InnerLoop  0.649 ( 0.657)	Loss 5.3176e-01 (6.4918e-01)	Acc@1  81.18 ( 76.38)
Epoch: [228][40/40]	Time  1.510 ( 1.548)	Data  0.013 ( 0.045)	InnerLoop  0.656 ( 0.658)	Loss 5.7673e-01 (6.5421e-01)	Acc@1  78.12 ( 75.89)
The current update step is 9160
GPU_0_using curriculum 20 with window 20
Epoch: [229][20/40]	Time  1.657 ( 1.551)	Data  0.029 ( 0.043)	InnerLoop  0.779 ( 0.665)	Loss 8.3752e-01 (6.3100e-01)	Acc@1  65.30 ( 76.33)
Epoch: [229][40/40]	Time  1.508 ( 1.549)	Data  0.013 ( 0.042)	InnerLoop  0.647 ( 0.663)	Loss 1.1132e+00 (6.1620e-01)	Acc@1  53.12 ( 76.77)
The current update step is 9200
The current seed is 10065420895692070913
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.211
 *   Acc@1 69.913
 *   Acc@1 70.763
 *   Acc@1 71.448
 *   Acc@1 71.921
 *   Acc@1 72.229
 *   Acc@1 78.211
 *   Acc@1 78.764
 *   Acc@1 76.974
 *   Acc@1 77.222
 *   Acc@1 75.132
 *   Acc@1 75.427
Training for 300 epoch: 73.71052631578948
Training for 600 epoch: 73.86842105263158
Training for 1000 epoch: 73.52631578947368
Training for 300 epoch: 74.33875
Training for 600 epoch: 74.33458333333334
Training for 1000 epoch: 73.82791666666667
[[73.71052631578948, 73.86842105263158, 73.52631578947368], [74.33875, 74.33458333333334, 73.82791666666667]]
train loss 0.3551207501888275, epoch 229, best loss 0.2910481328010559, best_epoch 224
GPU_0_using curriculum 20 with window 20
Epoch: [230][20/40]	Time  1.521 ( 1.543)	Data  0.030 ( 0.037)	InnerLoop  0.649 ( 0.665)	Loss 5.8595e-01 (6.1717e-01)	Acc@1  76.82 ( 77.03)
Epoch: [230][40/40]	Time  1.503 ( 1.549)	Data  0.014 ( 0.039)	InnerLoop  0.649 ( 0.666)	Loss 5.4512e-01 (6.0574e-01)	Acc@1  82.29 ( 77.47)
The current update step is 9240
GPU_0_using curriculum 20 with window 20
Epoch: [231][20/40]	Time  1.527 ( 1.546)	Data  0.030 ( 0.036)	InnerLoop  0.649 ( 0.666)	Loss 8.0270e-01 (5.8374e-01)	Acc@1  68.42 ( 78.42)
Epoch: [231][40/40]	Time  1.499 ( 1.547)	Data  0.013 ( 0.039)	InnerLoop  0.646 ( 0.664)	Loss 5.9991e-01 (5.7885e-01)	Acc@1  81.25 ( 78.44)
The current update step is 9280
GPU_0_using curriculum 20 with window 20
Epoch: [232][20/40]	Time  1.639 ( 1.552)	Data  0.030 ( 0.042)	InnerLoop  0.765 ( 0.667)	Loss 5.2919e-01 (5.7475e-01)	Acc@1  79.82 ( 78.73)
Epoch: [232][40/40]	Time  1.499 ( 1.550)	Data  0.013 ( 0.042)	InnerLoop  0.646 ( 0.663)	Loss 6.6421e-01 (6.1201e-01)	Acc@1  72.40 ( 77.49)
The current update step is 9320
GPU_0_using curriculum 20 with window 20
Epoch: [233][20/40]	Time  1.524 ( 1.546)	Data  0.029 ( 0.036)	InnerLoop  0.648 ( 0.667)	Loss 6.2340e-01 (5.8721e-01)	Acc@1  76.69 ( 77.86)
Epoch: [233][40/40]	Time  1.500 ( 1.550)	Data  0.014 ( 0.039)	InnerLoop  0.646 ( 0.667)	Loss 5.5780e-01 (5.9623e-01)	Acc@1  81.25 ( 77.99)
The current update step is 9360
GPU_0_using curriculum 20 with window 20
Epoch: [234][20/40]	Time  1.521 ( 1.545)	Data  0.029 ( 0.042)	InnerLoop  0.646 ( 0.659)	Loss 9.0129e-01 (6.9339e-01)	Acc@1  68.20 ( 75.52)
Epoch: [234][40/40]	Time  1.511 ( 1.548)	Data  0.014 ( 0.039)	InnerLoop  0.655 ( 0.664)	Loss 5.0838e-01 (6.6598e-01)	Acc@1  83.33 ( 75.38)
The current update step is 9400
The current seed is 3878692206310924055
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.013
 *   Acc@1 73.010
 *   Acc@1 72.829
 *   Acc@1 72.750
 *   Acc@1 72.211
 *   Acc@1 72.612
 *   Acc@1 65.026
 *   Acc@1 65.129
 *   Acc@1 59.408
 *   Acc@1 59.432
 *   Acc@1 57.618
 *   Acc@1 57.618
Training for 300 epoch: 69.01973684210526
Training for 600 epoch: 66.11842105263158
Training for 1000 epoch: 64.91447368421053
Training for 300 epoch: 69.06958333333333
Training for 600 epoch: 66.09125
Training for 1000 epoch: 65.115
[[69.01973684210526, 66.11842105263158, 64.91447368421053], [69.06958333333333, 66.09125, 65.115]]
train loss 0.5569002011299133, epoch 234, best loss 0.2910481328010559, best_epoch 224
GPU_0_using curriculum 20 with window 20
Epoch: [235][20/40]	Time  1.513 ( 1.543)	Data  0.031 ( 0.043)	InnerLoop  0.643 ( 0.657)	Loss 6.6558e-01 (5.8239e-01)	Acc@1  76.30 ( 78.40)
Epoch: [235][40/40]	Time  1.499 ( 1.546)	Data  0.013 ( 0.039)	InnerLoop  0.645 ( 0.662)	Loss 6.6773e-01 (6.1568e-01)	Acc@1  76.56 ( 77.29)
The current update step is 9440
GPU_0_using curriculum 20 with window 20
Epoch: [236][20/40]	Time  1.643 ( 1.549)	Data  0.029 ( 0.049)	InnerLoop  0.769 ( 0.657)	Loss 6.6164e-01 (6.6540e-01)	Acc@1  75.68 ( 74.93)
Epoch: [236][40/40]	Time  1.514 ( 1.548)	Data  0.014 ( 0.046)	InnerLoop  0.652 ( 0.659)	Loss 6.2093e-01 (6.4051e-01)	Acc@1  74.48 ( 75.85)
The current update step is 9480
GPU_0_using curriculum 20 with window 20
Epoch: [237][20/40]	Time  1.516 ( 1.544)	Data  0.030 ( 0.049)	InnerLoop  0.643 ( 0.653)	Loss 6.4302e-01 (6.2133e-01)	Acc@1  75.85 ( 77.31)
Epoch: [237][40/40]	Time  1.510 ( 1.547)	Data  0.012 ( 0.042)	InnerLoop  0.652 ( 0.661)	Loss 4.8134e-01 (6.3402e-01)	Acc@1  80.21 ( 76.31)
The current update step is 9520
GPU_0_using curriculum 20 with window 20
Epoch: [238][20/40]	Time  1.529 ( 1.551)	Data  0.031 ( 0.043)	InnerLoop  0.651 ( 0.665)	Loss 7.0123e-01 (5.7999e-01)	Acc@1  72.33 ( 78.33)
Epoch: [238][40/40]	Time  1.514 ( 1.548)	Data  0.014 ( 0.042)	InnerLoop  0.654 ( 0.662)	Loss 5.5414e-01 (5.9141e-01)	Acc@1  81.77 ( 77.89)
The current update step is 9560
GPU_0_using curriculum 20 with window 20
Epoch: [239][20/40]	Time  1.522 ( 1.543)	Data  0.028 ( 0.042)	InnerLoop  0.647 ( 0.658)	Loss 5.8948e-01 (6.2775e-01)	Acc@1  77.02 ( 76.78)
Epoch: [239][40/40]	Time  1.507 ( 1.549)	Data  0.014 ( 0.042)	InnerLoop  0.652 ( 0.662)	Loss 7.1690e-01 (6.4593e-01)	Acc@1  75.52 ( 76.65)
The current update step is 9600
The current seed is 16142348982777328293
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.697
 *   Acc@1 78.267
 *   Acc@1 74.355
 *   Acc@1 75.096
 *   Acc@1 71.263
 *   Acc@1 72.099
 *   Acc@1 80.329
 *   Acc@1 80.806
 *   Acc@1 78.053
 *   Acc@1 78.717
 *   Acc@1 76.697
 *   Acc@1 77.296
Training for 300 epoch: 79.01315789473685
Training for 600 epoch: 76.20394736842105
Training for 1000 epoch: 73.98026315789474
Training for 300 epoch: 79.53666666666666
Training for 600 epoch: 76.90625
Training for 1000 epoch: 74.69749999999999
[[79.01315789473685, 76.20394736842105, 73.98026315789474], [79.53666666666666, 76.90625, 74.69749999999999]]
train loss 0.31909656140804293, epoch 239, best loss 0.2910481328010559, best_epoch 224
GPU_0_using curriculum 20 with window 20
Epoch: [240][20/40]	Time  1.518 ( 1.551)	Data  0.028 ( 0.042)	InnerLoop  0.647 ( 0.666)	Loss 4.6966e-01 (6.1562e-01)	Acc@1  83.24 ( 77.26)
Epoch: [240][40/40]	Time  1.500 ( 1.549)	Data  0.015 ( 0.042)	InnerLoop  0.642 ( 0.663)	Loss 7.2905e-01 (6.2941e-01)	Acc@1  75.00 ( 76.93)
The current update step is 9640
GPU_0_using curriculum 20 with window 20
Epoch: [241][20/40]	Time  1.520 ( 1.544)	Data  0.029 ( 0.050)	InnerLoop  0.642 ( 0.652)	Loss 7.6868e-01 (6.0173e-01)	Acc@1  70.90 ( 77.52)
Epoch: [241][40/40]	Time  1.624 ( 1.549)	Data  0.013 ( 0.042)	InnerLoop  0.765 ( 0.662)	Loss 4.9483e-01 (6.0956e-01)	Acc@1  81.25 ( 77.46)
The current update step is 9680
GPU_0_using curriculum 20 with window 20
Epoch: [242][20/40]	Time  1.522 ( 1.544)	Data  0.029 ( 0.042)	InnerLoop  0.648 ( 0.660)	Loss 5.1787e-01 (6.0326e-01)	Acc@1  80.34 ( 77.49)
Epoch: [242][40/40]	Time  1.518 ( 1.547)	Data  0.014 ( 0.042)	InnerLoop  0.657 ( 0.660)	Loss 5.1276e-01 (6.1539e-01)	Acc@1  79.69 ( 77.28)
The current update step is 9720
GPU_0_using curriculum 20 with window 20
Epoch: [243][20/40]	Time  1.511 ( 1.555)	Data  0.031 ( 0.050)	InnerLoop  0.639 ( 0.660)	Loss 4.8635e-01 (5.9663e-01)	Acc@1  82.00 ( 78.54)
Epoch: [243][40/40]	Time  1.502 ( 1.548)	Data  0.013 ( 0.046)	InnerLoop  0.650 ( 0.659)	Loss 7.4166e-01 (6.0014e-01)	Acc@1  70.83 ( 78.01)
The current update step is 9760
GPU_0_using curriculum 20 with window 20
Epoch: [244][20/40]	Time  1.657 ( 1.547)	Data  0.033 ( 0.043)	InnerLoop  0.773 ( 0.663)	Loss 4.7567e-01 (6.1753e-01)	Acc@1  82.98 ( 77.33)
Epoch: [244][40/40]	Time  1.507 ( 1.547)	Data  0.015 ( 0.043)	InnerLoop  0.652 ( 0.662)	Loss 6.2656e-01 (5.9074e-01)	Acc@1  72.92 ( 78.31)
The current update step is 9800
The current seed is 11380122619384941392
The current lr is: 0.001
Testing Results:
 *   Acc@1 78.763
 *   Acc@1 79.092
 *   Acc@1 76.276
 *   Acc@1 76.627
 *   Acc@1 74.237
 *   Acc@1 74.319
 *   Acc@1 80.303
 *   Acc@1 80.496
 *   Acc@1 76.684
 *   Acc@1 76.691
 *   Acc@1 73.776
 *   Acc@1 73.710
Training for 300 epoch: 79.53289473684211
Training for 600 epoch: 76.48026315789474
Training for 1000 epoch: 74.00657894736842
Training for 300 epoch: 79.79375
Training for 600 epoch: 76.65916666666666
Training for 1000 epoch: 74.01458333333332
[[79.53289473684211, 76.48026315789474, 74.00657894736842], [79.79375, 76.65916666666666, 74.01458333333332]]
train loss 0.3431482002258301, epoch 244, best loss 0.2910481328010559, best_epoch 224
GPU_0_using curriculum 20 with window 20
Epoch: [245][20/40]	Time  1.517 ( 1.540)	Data  0.029 ( 0.035)	InnerLoop  0.646 ( 0.664)	Loss 5.3200e-01 (5.9788e-01)	Acc@1  80.34 ( 78.13)
Epoch: [245][40/40]	Time  1.504 ( 1.545)	Data  0.012 ( 0.038)	InnerLoop  0.652 ( 0.665)	Loss 5.4497e-01 (5.9721e-01)	Acc@1  79.69 ( 78.00)
The current update step is 9840
GPU_0_using curriculum 20 with window 20
Epoch: [246][20/40]	Time  1.527 ( 1.543)	Data  0.032 ( 0.036)	InnerLoop  0.651 ( 0.666)	Loss 5.9937e-01 (5.9183e-01)	Acc@1  76.76 ( 78.07)
Epoch: [246][40/40]	Time  1.499 ( 1.543)	Data  0.015 ( 0.039)	InnerLoop  0.644 ( 0.663)	Loss 5.6659e-01 (5.8750e-01)	Acc@1  83.85 ( 78.16)
The current update step is 9880
GPU_0_using curriculum 20 with window 20
Epoch: [247][20/40]	Time  1.640 ( 1.549)	Data  0.030 ( 0.043)	InnerLoop  0.770 ( 0.665)	Loss 6.8618e-01 (5.8977e-01)	Acc@1  74.84 ( 78.20)
Epoch: [247][40/40]	Time  1.496 ( 1.547)	Data  0.012 ( 0.042)	InnerLoop  0.645 ( 0.663)	Loss 5.5936e-01 (5.9618e-01)	Acc@1  80.21 ( 77.82)
The current update step is 9920
GPU_0_using curriculum 20 with window 20
Epoch: [248][20/40]	Time  1.511 ( 1.540)	Data  0.031 ( 0.036)	InnerLoop  0.644 ( 0.663)	Loss 5.7014e-01 (6.0214e-01)	Acc@1  79.07 ( 77.56)
Epoch: [248][40/40]	Time  1.504 ( 1.545)	Data  0.013 ( 0.039)	InnerLoop  0.651 ( 0.664)	Loss 7.0457e-01 (6.2304e-01)	Acc@1  72.40 ( 77.05)
The current update step is 9960
GPU_0_using curriculum 20 with window 20
Epoch: [249][20/40]	Time  1.521 ( 1.539)	Data  0.030 ( 0.043)	InnerLoop  0.648 ( 0.657)	Loss 5.9618e-01 (5.8816e-01)	Acc@1  76.24 ( 77.95)
Epoch: [249][40/40]	Time  1.510 ( 1.543)	Data  0.011 ( 0.039)	InnerLoop  0.656 ( 0.663)	Loss 6.1568e-01 (5.7810e-01)	Acc@1  76.56 ( 78.36)
The current update step is 10000
The current seed is 13668595745241990588
The current lr is: 0.001
Testing Results:
 *   Acc@1 79.842
 *   Acc@1 80.402
 *   Acc@1 77.224
 *   Acc@1 77.922
 *   Acc@1 75.105
 *   Acc@1 75.448
 *   Acc@1 81.342
 *   Acc@1 81.539
 *   Acc@1 79.026
 *   Acc@1 79.173
 *   Acc@1 75.974
 *   Acc@1 76.399
Training for 300 epoch: 80.59210526315789
Training for 600 epoch: 78.125
Training for 1000 epoch: 75.53947368421052
Training for 300 epoch: 80.97041666666667
Training for 600 epoch: 78.5475
Training for 1000 epoch: 75.92375000000001
[[80.59210526315789, 78.125, 75.53947368421052], [80.97041666666667, 78.5475, 75.92375000000001]]
train loss 0.31837639656066896, epoch 249, best loss 0.2910481328010559, best_epoch 224
GPU_0_using curriculum 20 with window 20
Epoch: [250][20/40]	Time  1.518 ( 1.544)	Data  0.030 ( 0.043)	InnerLoop  0.646 ( 0.660)	Loss 5.5999e-01 (5.7983e-01)	Acc@1  76.63 ( 78.46)
Epoch: [250][40/40]	Time  1.494 ( 1.544)	Data  0.015 ( 0.039)	InnerLoop  0.644 ( 0.663)	Loss 6.6403e-01 (5.9573e-01)	Acc@1  73.44 ( 77.96)
The current update step is 10040
GPU_0_using curriculum 20 with window 20
Epoch: [251][20/40]	Time  1.649 ( 1.548)	Data  0.030 ( 0.049)	InnerLoop  0.775 ( 0.658)	Loss 6.6940e-01 (5.9862e-01)	Acc@1  73.86 ( 77.76)
Epoch: [251][40/40]	Time  1.510 ( 1.547)	Data  0.012 ( 0.045)	InnerLoop  0.656 ( 0.660)	Loss 6.3809e-01 (6.0812e-01)	Acc@1  70.83 ( 77.54)
The current update step is 10080
GPU_0_using curriculum 20 with window 20
Epoch: [252][20/40]	Time  1.524 ( 1.543)	Data  0.031 ( 0.049)	InnerLoop  0.651 ( 0.654)	Loss 8.3857e-01 (6.1242e-01)	Acc@1  69.37 ( 77.60)
Epoch: [252][40/40]	Time  1.496 ( 1.545)	Data  0.011 ( 0.042)	InnerLoop  0.641 ( 0.661)	Loss 6.5820e-01 (6.1490e-01)	Acc@1  75.00 ( 77.28)
The current update step is 10120
GPU_0_using curriculum 20 with window 20
Epoch: [253][20/40]	Time  1.525 ( 1.548)	Data  0.029 ( 0.042)	InnerLoop  0.654 ( 0.667)	Loss 5.4558e-01 (5.9431e-01)	Acc@1  79.65 ( 78.13)
Epoch: [253][40/40]	Time  1.520 ( 1.548)	Data  0.011 ( 0.041)	InnerLoop  0.658 ( 0.665)	Loss 6.2370e-01 (6.1188e-01)	Acc@1  77.08 ( 77.71)
The current update step is 10160
GPU_0_using curriculum 20 with window 20
Epoch: [254][20/40]	Time  1.519 ( 1.543)	Data  0.028 ( 0.043)	InnerLoop  0.647 ( 0.659)	Loss 5.0143e-01 (6.0984e-01)	Acc@1  81.45 ( 77.27)
Epoch: [254][40/40]	Time  1.500 ( 1.547)	Data  0.012 ( 0.042)	InnerLoop  0.644 ( 0.663)	Loss 5.5612e-01 (6.0058e-01)	Acc@1  80.73 ( 77.91)
The current update step is 10200
The current seed is 13021130132198581348
The current lr is: 0.001
Testing Results:
 *   Acc@1 78.855
 *   Acc@1 79.115
 *   Acc@1 79.026
 *   Acc@1 78.927
 *   Acc@1 78.724
 *   Acc@1 79.006
 *   Acc@1 74.197
 *   Acc@1 74.895
 *   Acc@1 72.855
 *   Acc@1 73.655
 *   Acc@1 71.803
 *   Acc@1 72.156
Training for 300 epoch: 76.52631578947368
Training for 600 epoch: 75.94078947368422
Training for 1000 epoch: 75.26315789473685
Training for 300 epoch: 77.005
Training for 600 epoch: 76.29083333333332
Training for 1000 epoch: 75.58083333333333
[[76.52631578947368, 75.94078947368422, 75.26315789473685], [77.005, 76.29083333333332, 75.58083333333333]]
train loss 0.3598422840118408, epoch 254, best loss 0.2910481328010559, best_epoch 224
GPU_0_using curriculum 20 with window 20
Epoch: [255][20/40]	Time  1.525 ( 1.549)	Data  0.030 ( 0.042)	InnerLoop  0.656 ( 0.666)	Loss 5.3229e-01 (5.9272e-01)	Acc@1  80.83 ( 78.42)
Epoch: [255][40/40]	Time  1.505 ( 1.548)	Data  0.015 ( 0.042)	InnerLoop  0.646 ( 0.664)	Loss 7.6124e-01 (5.9323e-01)	Acc@1  66.15 ( 78.42)
The current update step is 10240
GPU_0_using curriculum 20 with window 20
Epoch: [256][20/40]	Time  1.510 ( 1.541)	Data  0.031 ( 0.048)	InnerLoop  0.640 ( 0.653)	Loss 5.2604e-01 (5.6891e-01)	Acc@1  80.63 ( 78.83)
Epoch: [256][40/40]	Time  1.618 ( 1.548)	Data  0.011 ( 0.042)	InnerLoop  0.766 ( 0.664)	Loss 5.7712e-01 (5.8057e-01)	Acc@1  77.60 ( 78.57)
The current update step is 10280
GPU_0_using curriculum 20 with window 20
Epoch: [257][20/40]	Time  1.514 ( 1.540)	Data  0.029 ( 0.043)	InnerLoop  0.642 ( 0.659)	Loss 5.7473e-01 (5.8209e-01)	Acc@1  78.06 ( 78.27)
Epoch: [257][40/40]	Time  1.502 ( 1.542)	Data  0.012 ( 0.042)	InnerLoop  0.646 ( 0.660)	Loss 6.7651e-01 (5.9886e-01)	Acc@1  76.56 ( 77.88)
The current update step is 10320
GPU_0_using curriculum 20 with window 20
Epoch: [258][20/40]	Time  1.521 ( 1.546)	Data  0.030 ( 0.048)	InnerLoop  0.648 ( 0.659)	Loss 5.4711e-01 (5.9751e-01)	Acc@1  79.82 ( 78.14)
Epoch: [258][40/40]	Time  1.515 ( 1.546)	Data  0.011 ( 0.045)	InnerLoop  0.661 ( 0.660)	Loss 4.8681e-01 (5.8618e-01)	Acc@1  84.38 ( 78.56)
The current update step is 10360
GPU_0_using curriculum 20 with window 20
Epoch: [259][20/40]	Time  1.639 ( 1.548)	Data  0.028 ( 0.043)	InnerLoop  0.768 ( 0.665)	Loss 5.9685e-01 (6.1402e-01)	Acc@1  76.56 ( 77.61)
Epoch: [259][40/40]	Time  1.465 ( 1.537)	Data  0.013 ( 0.041)	InnerLoop  0.631 ( 0.659)	Loss 4.4393e-01 (5.9795e-01)	Acc@1  82.29 ( 78.13)
The current update step is 10400
The current seed is 16295312997098178172
The current lr is: 0.001
Testing Results:
 *   Acc@1 82.276
 *   Acc@1 82.577
 *   Acc@1 81.250
 *   Acc@1 81.620
 *   Acc@1 79.816
 *   Acc@1 79.927
 *   Acc@1 79.276
 *   Acc@1 79.388
 *   Acc@1 78.711
 *   Acc@1 78.558
 *   Acc@1 77.895
 *   Acc@1 77.804
Training for 300 epoch: 80.77631578947368
Training for 600 epoch: 79.98026315789474
Training for 1000 epoch: 78.85526315789474
Training for 300 epoch: 80.9825
Training for 600 epoch: 80.08916666666667
Training for 1000 epoch: 78.86583333333333
[[80.77631578947368, 79.98026315789474, 78.85526315789474], [80.9825, 80.08916666666667, 78.86583333333333]]
train loss 0.30867675895690916, epoch 259, best loss 0.2910481328010559, best_epoch 224
GPU_0_using curriculum 20 with window 20
Epoch: [260][20/40]	Time  1.474 ( 1.498)	Data  0.025 ( 0.032)	InnerLoop  0.625 ( 0.642)	Loss 5.2765e-01 (5.9391e-01)	Acc@1  80.99 ( 78.07)
Epoch: [260][40/40]	Time  1.476 ( 1.503)	Data  0.012 ( 0.035)	InnerLoop  0.633 ( 0.644)	Loss 6.3787e-01 (5.8692e-01)	Acc@1  80.21 ( 78.37)
The current update step is 10440
GPU_0_using curriculum 20 with window 20
Epoch: [261][20/40]	Time  1.497 ( 1.501)	Data  0.027 ( 0.033)	InnerLoop  0.638 ( 0.645)	Loss 5.6514e-01 (5.6987e-01)	Acc@1  78.39 ( 78.89)
Epoch: [261][40/40]	Time  1.474 ( 1.503)	Data  0.013 ( 0.035)	InnerLoop  0.637 ( 0.642)	Loss 5.5757e-01 (5.8960e-01)	Acc@1  80.73 ( 78.26)
The current update step is 10480
GPU_0_using curriculum 20 with window 20
Epoch: [262][20/40]	Time  1.601 ( 1.508)	Data  0.029 ( 0.039)	InnerLoop  0.741 ( 0.646)	Loss 5.5899e-01 (6.0674e-01)	Acc@1  80.79 ( 77.73)
Epoch: [262][40/40]	Time  1.469 ( 1.504)	Data  0.013 ( 0.039)	InnerLoop  0.632 ( 0.642)	Loss 6.3458e-01 (6.2079e-01)	Acc@1  79.17 ( 77.42)
The current update step is 10520
GPU_0_using curriculum 20 with window 20
Epoch: [263][20/40]	Time  1.472 ( 1.495)	Data  0.026 ( 0.033)	InnerLoop  0.625 ( 0.642)	Loss 5.2741e-01 (5.8282e-01)	Acc@1  81.18 ( 79.38)
Epoch: [263][40/40]	Time  1.466 ( 1.500)	Data  0.011 ( 0.035)	InnerLoop  0.630 ( 0.643)	Loss 7.2257e-01 (5.8996e-01)	Acc@1  77.08 ( 78.81)
The current update step is 10560
GPU_0_using curriculum 20 with window 20
Epoch: [264][20/40]	Time  1.483 ( 1.500)	Data  0.028 ( 0.039)	InnerLoop  0.627 ( 0.639)	Loss 5.1292e-01 (5.5619e-01)	Acc@1  80.89 ( 79.71)
Epoch: [264][40/40]	Time  1.475 ( 1.499)	Data  0.014 ( 0.035)	InnerLoop  0.634 ( 0.641)	Loss 6.8016e-01 (5.6371e-01)	Acc@1  75.52 ( 79.57)
The current update step is 10600
The current seed is 3676093129691694176
The current lr is: 0.001
Testing Results:
 *   Acc@1 83.513
 *   Acc@1 82.767
 *   Acc@1 82.579
 *   Acc@1 82.573
 *   Acc@1 81.105
 *   Acc@1 81.316
 *   Acc@1 76.053
 *   Acc@1 76.217
 *   Acc@1 71.434
 *   Acc@1 71.294
 *   Acc@1 66.671
 *   Acc@1 66.901
Training for 300 epoch: 79.78289473684211
Training for 600 epoch: 77.00657894736842
Training for 1000 epoch: 73.88815789473685
Training for 300 epoch: 79.49166666666667
Training for 600 epoch: 76.93333333333334
Training for 1000 epoch: 74.10833333333333
[[79.78289473684211, 77.00657894736842, 73.88815789473685], [79.49166666666667, 76.93333333333334, 74.10833333333333]]
train loss 0.4289419296264648, epoch 264, best loss 0.2910481328010559, best_epoch 224
GPU_0_using curriculum 20 with window 20
Epoch: [265][20/40]	Time  1.478 ( 1.500)	Data  0.025 ( 0.038)	InnerLoop  0.628 ( 0.639)	Loss 8.0402e-01 (5.9027e-01)	Acc@1  72.53 ( 78.47)
Epoch: [265][40/40]	Time  1.460 ( 1.500)	Data  0.010 ( 0.035)	InnerLoop  0.627 ( 0.642)	Loss 7.1226e-01 (6.2260e-01)	Acc@1  77.08 ( 77.15)
The current update step is 10640
GPU_0_using curriculum 20 with window 20
Epoch: [266][20/40]	Time  1.594 ( 1.505)	Data  0.027 ( 0.044)	InnerLoop  0.740 ( 0.638)	Loss 6.0705e-01 (7.0163e-01)	Acc@1  78.74 ( 73.96)
Epoch: [266][40/40]	Time  1.461 ( 1.502)	Data  0.012 ( 0.041)	InnerLoop  0.634 ( 0.638)	Loss 4.7197e-01 (6.6357e-01)	Acc@1  78.65 ( 75.35)
The current update step is 10680
GPU_0_using curriculum 20 with window 20
Epoch: [267][20/40]	Time  1.469 ( 1.498)	Data  0.028 ( 0.044)	InnerLoop  0.623 ( 0.631)	Loss 5.3526e-01 (6.1234e-01)	Acc@1  79.46 ( 77.16)
Epoch: [267][40/40]	Time  1.456 ( 1.498)	Data  0.010 ( 0.038)	InnerLoop  0.623 ( 0.637)	Loss 5.3119e-01 (6.3352e-01)	Acc@1  82.29 ( 77.02)
The current update step is 10720
GPU_0_using curriculum 20 with window 20
Epoch: [268][20/40]	Time  1.482 ( 1.502)	Data  0.027 ( 0.038)	InnerLoop  0.631 ( 0.642)	Loss 6.1951e-01 (7.1071e-01)	Acc@1  77.08 ( 75.57)
Epoch: [268][40/40]	Time  1.460 ( 1.500)	Data  0.012 ( 0.038)	InnerLoop  0.627 ( 0.640)	Loss 6.4834e-01 (6.9256e-01)	Acc@1  70.83 ( 75.55)
The current update step is 10760
GPU_0_using curriculum 20 with window 20
Epoch: [269][20/40]	Time  1.485 ( 1.498)	Data  0.026 ( 0.038)	InnerLoop  0.628 ( 0.637)	Loss 7.3364e-01 (6.9174e-01)	Acc@1  65.17 ( 73.87)
Epoch: [269][40/40]	Time  1.464 ( 1.501)	Data  0.011 ( 0.038)	InnerLoop  0.631 ( 0.640)	Loss 4.6566e-01 (6.5369e-01)	Acc@1  86.98 ( 75.45)
The current update step is 10800
The current seed is 8014756216936843249
The current lr is: 0.001
Testing Results:
 *   Acc@1 79.158
 *   Acc@1 79.104
 *   Acc@1 77.526
 *   Acc@1 77.236
 *   Acc@1 75.013
 *   Acc@1 74.961
 *   Acc@1 77.395
 *   Acc@1 77.734
 *   Acc@1 77.329
 *   Acc@1 77.623
 *   Acc@1 76.724
 *   Acc@1 77.013
Training for 300 epoch: 78.27631578947368
Training for 600 epoch: 77.42763157894737
Training for 1000 epoch: 75.86842105263158
Training for 300 epoch: 78.41916666666667
Training for 600 epoch: 77.42958333333334
Training for 1000 epoch: 75.98666666666666
[[78.27631578947368, 77.42763157894737, 75.86842105263158], [78.41916666666667, 77.42958333333334, 75.98666666666666]]
train loss 0.33392438797950746, epoch 269, best loss 0.2910481328010559, best_epoch 224
GPU_0_using curriculum 20 with window 20
Epoch: [270][20/40]	Time  1.473 ( 1.504)	Data  0.026 ( 0.038)	InnerLoop  0.626 ( 0.643)	Loss 6.2746e-01 (6.1322e-01)	Acc@1  78.78 ( 77.73)
Epoch: [270][40/40]	Time  1.458 ( 1.502)	Data  0.013 ( 0.038)	InnerLoop  0.628 ( 0.640)	Loss 5.6548e-01 (6.1574e-01)	Acc@1  80.73 ( 77.39)
The current update step is 10840
GPU_0_using curriculum 20 with window 20
Epoch: [271][20/40]	Time  1.476 ( 1.496)	Data  0.025 ( 0.044)	InnerLoop  0.628 ( 0.630)	Loss 6.2742e-01 (5.9738e-01)	Acc@1  76.60 ( 78.05)
Epoch: [271][40/40]	Time  1.562 ( 1.501)	Data  0.011 ( 0.038)	InnerLoop  0.735 ( 0.640)	Loss 7.1419e-01 (6.1027e-01)	Acc@1  73.96 ( 77.39)
The current update step is 10880
GPU_0_using curriculum 20 with window 20
Epoch: [272][20/40]	Time  1.473 ( 1.497)	Data  0.025 ( 0.038)	InnerLoop  0.627 ( 0.637)	Loss 7.0448e-01 (7.4523e-01)	Acc@1  68.82 ( 72.54)
Epoch: [272][40/40]	Time  1.460 ( 1.499)	Data  0.010 ( 0.038)	InnerLoop  0.629 ( 0.638)	Loss 1.0915e+00 (7.0500e-01)	Acc@1  63.02 ( 73.80)
The current update step is 10920
GPU_0_using curriculum 20 with window 20
Epoch: [273][20/40]	Time  1.481 ( 1.507)	Data  0.026 ( 0.044)	InnerLoop  0.628 ( 0.640)	Loss 5.0672e-01 (6.2356e-01)	Acc@1  81.32 ( 76.77)
Epoch: [273][40/40]	Time  1.458 ( 1.505)	Data  0.012 ( 0.041)	InnerLoop  0.626 ( 0.640)	Loss 6.8428e-01 (6.2990e-01)	Acc@1  71.88 ( 76.46)
The current update step is 10960
GPU_0_using curriculum 20 with window 20
Epoch: [274][20/40]	Time  1.584 ( 1.505)	Data  0.027 ( 0.039)	InnerLoop  0.730 ( 0.643)	Loss 5.4348e-01 (6.1628e-01)	Acc@1  80.53 ( 77.02)
Epoch: [274][40/40]	Time  1.462 ( 1.504)	Data  0.013 ( 0.038)	InnerLoop  0.627 ( 0.641)	Loss 5.3005e-01 (6.2212e-01)	Acc@1  83.33 ( 77.17)
The current update step is 11000
The current seed is 11367103458536493382
The current lr is: 0.001
Testing Results:
 *   Acc@1 80.934
 *   Acc@1 81.395
 *   Acc@1 79.303
 *   Acc@1 79.867
 *   Acc@1 77.487
 *   Acc@1 78.244
 *   Acc@1 79.500
 *   Acc@1 79.438
 *   Acc@1 77.882
 *   Acc@1 77.933
 *   Acc@1 76.158
 *   Acc@1 76.268
Training for 300 epoch: 80.21710526315789
Training for 600 epoch: 78.59210526315789
Training for 1000 epoch: 76.82236842105263
Training for 300 epoch: 80.41624999999999
Training for 600 epoch: 78.9
Training for 1000 epoch: 77.25625
[[80.21710526315789, 78.59210526315789, 76.82236842105263], [80.41624999999999, 78.9, 77.25625]]
train loss 0.3079106667041779, epoch 274, best loss 0.2910481328010559, best_epoch 224
GPU_0_using curriculum 20 with window 20
Epoch: [275][20/40]	Time  1.492 ( 1.502)	Data  0.026 ( 0.033)	InnerLoop  0.632 ( 0.645)	Loss 5.7942e-01 (5.7954e-01)	Acc@1  78.22 ( 78.58)
Epoch: [275][40/40]	Time  1.458 ( 1.504)	Data  0.011 ( 0.035)	InnerLoop  0.627 ( 0.645)	Loss 6.7461e-01 (5.9678e-01)	Acc@1  72.40 ( 77.95)
The current update step is 11040
GPU_0_using curriculum 20 with window 20
Epoch: [276][20/40]	Time  1.501 ( 1.507)	Data  0.027 ( 0.033)	InnerLoop  0.633 ( 0.647)	Loss 5.1850e-01 (5.8957e-01)	Acc@1  80.73 ( 78.16)
Epoch: [276][40/40]	Time  1.482 ( 1.512)	Data  0.014 ( 0.036)	InnerLoop  0.639 ( 0.646)	Loss 5.8816e-01 (6.0005e-01)	Acc@1  80.21 ( 77.85)
The current update step is 11080
GPU_0_using curriculum 20 with window 20
Epoch: [277][20/40]	Time  1.599 ( 1.514)	Data  0.029 ( 0.040)	InnerLoop  0.747 ( 0.648)	Loss 5.4072e-01 (5.7224e-01)	Acc@1  81.35 ( 79.01)
Epoch: [277][40/40]	Time  1.468 ( 1.508)	Data  0.012 ( 0.039)	InnerLoop  0.631 ( 0.643)	Loss 5.2663e-01 (5.9392e-01)	Acc@1  78.12 ( 77.95)
The current update step is 11120
GPU_0_using curriculum 20 with window 20
Epoch: [278][20/40]	Time  1.492 ( 1.503)	Data  0.029 ( 0.033)	InnerLoop  0.632 ( 0.645)	Loss 6.1607e-01 (5.6059e-01)	Acc@1  76.69 ( 79.00)
Epoch: [278][40/40]	Time  1.479 ( 1.509)	Data  0.012 ( 0.036)	InnerLoop  0.632 ( 0.646)	Loss 5.6809e-01 (5.6637e-01)	Acc@1  78.65 ( 78.81)
The current update step is 11160
GPU_0_using curriculum 20 with window 20
Epoch: [279][20/40]	Time  1.502 ( 1.520)	Data  0.027 ( 0.040)	InnerLoop  0.639 ( 0.648)	Loss 6.0032e-01 (5.8084e-01)	Acc@1  75.98 ( 78.29)
Epoch: [279][40/40]	Time  1.506 ( 1.520)	Data  0.013 ( 0.037)	InnerLoop  0.649 ( 0.651)	Loss 7.2356e-01 (5.7825e-01)	Acc@1  75.00 ( 78.71)
The current update step is 11200
The current seed is 10926275470082438204
The current lr is: 0.001
Testing Results:
 *   Acc@1 81.184
 *   Acc@1 81.295
 *   Acc@1 80.763
 *   Acc@1 81.185
 *   Acc@1 80.263
 *   Acc@1 80.498
 *   Acc@1 79.829
 *   Acc@1 80.012
 *   Acc@1 78.539
 *   Acc@1 78.760
 *   Acc@1 77.355
 *   Acc@1 77.521
Training for 300 epoch: 80.50657894736842
Training for 600 epoch: 79.65131578947367
Training for 1000 epoch: 78.80921052631578
Training for 300 epoch: 80.65333333333334
Training for 600 epoch: 79.9725
Training for 1000 epoch: 79.00916666666666
[[80.50657894736842, 79.65131578947367, 78.80921052631578], [80.65333333333334, 79.9725, 79.00916666666666]]
train loss 0.33074198241233826, epoch 279, best loss 0.2910481328010559, best_epoch 224
GPU_0_using curriculum 20 with window 20
Epoch: [280][20/40]	Time  1.480 ( 1.509)	Data  0.026 ( 0.040)	InnerLoop  0.630 ( 0.643)	Loss 8.5136e-01 (5.8401e-01)	Acc@1  69.34 ( 78.64)
Epoch: [280][40/40]	Time  1.473 ( 1.512)	Data  0.012 ( 0.037)	InnerLoop  0.637 ( 0.647)	Loss 6.9007e-01 (5.7990e-01)	Acc@1  78.12 ( 78.80)
The current update step is 11240
GPU_0_using curriculum 20 with window 20
Epoch: [281][20/40]	Time  1.623 ( 1.518)	Data  0.027 ( 0.046)	InnerLoop  0.756 ( 0.643)	Loss 5.3511e-01 (5.7525e-01)	Acc@1  79.92 ( 78.61)
Epoch: [281][40/40]	Time  1.482 ( 1.517)	Data  0.014 ( 0.042)	InnerLoop  0.638 ( 0.645)	Loss 5.1980e-01 (5.7037e-01)	Acc@1  78.12 ( 79.25)
The current update step is 11280
GPU_0_using curriculum 20 with window 20
Epoch: [282][20/40]	Time  1.481 ( 1.508)	Data  0.026 ( 0.046)	InnerLoop  0.624 ( 0.635)	Loss 5.1930e-01 (5.9763e-01)	Acc@1  82.39 ( 78.41)
Epoch: [282][40/40]	Time  1.484 ( 1.509)	Data  0.011 ( 0.039)	InnerLoop  0.640 ( 0.641)	Loss 5.8108e-01 (5.8787e-01)	Acc@1  78.65 ( 78.64)
The current update step is 11320
GPU_0_using curriculum 20 with window 20
Epoch: [283][20/40]	Time  1.483 ( 1.510)	Data  0.027 ( 0.040)	InnerLoop  0.630 ( 0.645)	Loss 6.0958e-01 (5.6453e-01)	Acc@1  78.81 ( 79.38)
Epoch: [283][40/40]	Time  1.503 ( 1.512)	Data  0.012 ( 0.039)	InnerLoop  0.648 ( 0.644)	Loss 5.6297e-01 (5.6707e-01)	Acc@1  82.29 ( 79.25)
The current update step is 11360
GPU_0_using curriculum 20 with window 20
Epoch: [284][20/40]	Time  1.494 ( 1.528)	Data  0.029 ( 0.042)	InnerLoop  0.633 ( 0.649)	Loss 5.7803e-01 (5.8615e-01)	Acc@1  80.11 ( 78.51)
Epoch: [284][40/40]	Time  1.503 ( 1.533)	Data  0.012 ( 0.041)	InnerLoop  0.652 ( 0.654)	Loss 5.7195e-01 (5.6294e-01)	Acc@1  76.56 ( 79.52)
The current update step is 11400
The current seed is 11666269912311844148
The current lr is: 0.001
Testing Results:
 *   Acc@1 81.145
 *   Acc@1 81.211
 *   Acc@1 79.368
 *   Acc@1 80.022
 *   Acc@1 78.132
 *   Acc@1 78.866
 *   Acc@1 78.145
 *   Acc@1 78.562
 *   Acc@1 73.618
 *   Acc@1 73.721
 *   Acc@1 69.053
 *   Acc@1 69.294
Training for 300 epoch: 79.64473684210526
Training for 600 epoch: 76.49342105263158
Training for 1000 epoch: 73.59210526315789
Training for 300 epoch: 79.88666666666666
Training for 600 epoch: 76.87125
Training for 1000 epoch: 74.08
[[79.64473684210526, 76.49342105263158, 73.59210526315789], [79.88666666666666, 76.87125, 74.08]]
train loss 0.547317226600647, epoch 284, best loss 0.2910481328010559, best_epoch 284
GPU_0_using curriculum 20 with window 20
Epoch: [285][20/40]	Time  1.518 ( 1.545)	Data  0.029 ( 0.041)	InnerLoop  0.641 ( 0.662)	Loss 6.2004e-01 (6.0931e-01)	Acc@1  75.52 ( 77.72)
Epoch: [285][40/40]	Time  1.483 ( 1.541)	Data  0.013 ( 0.041)	InnerLoop  0.635 ( 0.659)	Loss 4.2807e-01 (6.0795e-01)	Acc@1  79.69 ( 77.83)
The current update step is 11440
GPU_0_using curriculum 20 with window 20
Epoch: [286][20/40]	Time  1.501 ( 1.527)	Data  0.028 ( 0.047)	InnerLoop  0.636 ( 0.643)	Loss 5.2059e-01 (5.6261e-01)	Acc@1  80.50 ( 79.79)
Epoch: [286][40/40]	Time  1.612 ( 1.534)	Data  0.015 ( 0.041)	InnerLoop  0.759 ( 0.654)	Loss 5.9966e-01 (5.7502e-01)	Acc@1  76.56 ( 79.17)
The current update step is 11480
GPU_0_using curriculum 20 with window 20
Epoch: [287][20/40]	Time  1.513 ( 1.536)	Data  0.028 ( 0.040)	InnerLoop  0.644 ( 0.655)	Loss 5.3105e-01 (5.9579e-01)	Acc@1  79.26 ( 78.08)
Epoch: [287][40/40]	Time  1.485 ( 1.536)	Data  0.013 ( 0.041)	InnerLoop  0.640 ( 0.655)	Loss 5.7666e-01 (5.8279e-01)	Acc@1  75.52 ( 78.75)
The current update step is 11520
GPU_0_using curriculum 20 with window 20
Epoch: [288][20/40]	Time  1.502 ( 1.537)	Data  0.030 ( 0.046)	InnerLoop  0.640 ( 0.653)	Loss 5.2612e-01 (5.9412e-01)	Acc@1  80.76 ( 78.74)
Epoch: [288][40/40]	Time  1.503 ( 1.533)	Data  0.012 ( 0.043)	InnerLoop  0.651 ( 0.652)	Loss 5.6989e-01 (5.8368e-01)	Acc@1  77.60 ( 78.92)
The current update step is 11560
GPU_0_using curriculum 20 with window 20
Epoch: [289][20/40]	Time  1.629 ( 1.534)	Data  0.028 ( 0.040)	InnerLoop  0.767 ( 0.656)	Loss 5.3257e-01 (5.6692e-01)	Acc@1  79.26 ( 79.13)
Epoch: [289][40/40]	Time  1.501 ( 1.533)	Data  0.015 ( 0.040)	InnerLoop  0.645 ( 0.654)	Loss 6.1908e-01 (5.6210e-01)	Acc@1  76.56 ( 79.47)
The current update step is 11600
The current seed is 8155018086606278194
The current lr is: 0.001
Testing Results:
 *   Acc@1 80.118
 *   Acc@1 80.532
 *   Acc@1 77.961
 *   Acc@1 78.214
 *   Acc@1 74.947
 *   Acc@1 75.211
 *   Acc@1 79.947
 *   Acc@1 80.214
 *   Acc@1 76.500
 *   Acc@1 77.510
 *   Acc@1 74.382
 *   Acc@1 74.915
Training for 300 epoch: 80.03289473684211
Training for 600 epoch: 77.23026315789474
Training for 1000 epoch: 74.66447368421052
Training for 300 epoch: 80.37291666666667
Training for 600 epoch: 77.86208333333335
Training for 1000 epoch: 75.06291666666667
[[80.03289473684211, 77.23026315789474, 74.66447368421052], [80.37291666666667, 77.86208333333335, 75.06291666666667]]
train loss 0.33342987303733823, epoch 289, best loss 0.2910481328010559, best_epoch 284
GPU_0_using curriculum 20 with window 20
Epoch: [290][20/40]	Time  1.507 ( 1.528)	Data  0.027 ( 0.034)	InnerLoop  0.634 ( 0.655)	Loss 6.2447e-01 (5.6542e-01)	Acc@1  76.30 ( 79.26)
Epoch: [290][40/40]	Time  1.489 ( 1.531)	Data  0.012 ( 0.037)	InnerLoop  0.638 ( 0.656)	Loss 5.4696e-01 (5.6870e-01)	Acc@1  80.73 ( 79.10)
The current update step is 11640
GPU_0_using curriculum 20 with window 20
Epoch: [291][20/40]	Time  1.509 ( 1.529)	Data  0.029 ( 0.034)	InnerLoop  0.634 ( 0.657)	Loss 7.9347e-01 (5.9269e-01)	Acc@1  71.68 ( 78.38)
Epoch: [291][40/40]	Time  1.498 ( 1.530)	Data  0.014 ( 0.037)	InnerLoop  0.642 ( 0.654)	Loss 6.1557e-01 (5.6608e-01)	Acc@1  80.21 ( 79.38)
The current update step is 11680
GPU_0_using curriculum 20 with window 20
Epoch: [292][20/40]	Time  1.595 ( 1.532)	Data  0.027 ( 0.041)	InnerLoop  0.737 ( 0.655)	Loss 6.7311e-01 (5.5006e-01)	Acc@1  73.96 ( 80.30)
Epoch: [292][40/40]	Time  1.504 ( 1.533)	Data  0.013 ( 0.040)	InnerLoop  0.644 ( 0.654)	Loss 6.4244e-01 (5.4648e-01)	Acc@1  81.25 ( 80.26)
The current update step is 11720
GPU_0_using curriculum 20 with window 20
Epoch: [293][20/40]	Time  1.523 ( 1.532)	Data  0.029 ( 0.034)	InnerLoop  0.647 ( 0.659)	Loss 6.7542e-01 (5.4907e-01)	Acc@1  74.22 ( 79.59)
Epoch: [293][40/40]	Time  1.490 ( 1.535)	Data  0.013 ( 0.037)	InnerLoop  0.645 ( 0.659)	Loss 5.4098e-01 (5.4232e-01)	Acc@1  78.65 ( 80.07)
The current update step is 11760
GPU_0_using curriculum 20 with window 20
Epoch: [294][20/40]	Time  1.516 ( 1.528)	Data  0.030 ( 0.040)	InnerLoop  0.646 ( 0.650)	Loss 7.6469e-01 (5.8574e-01)	Acc@1  72.10 ( 78.64)
Epoch: [294][40/40]	Time  1.487 ( 1.534)	Data  0.013 ( 0.038)	InnerLoop  0.644 ( 0.656)	Loss 7.0748e-01 (5.8035e-01)	Acc@1  76.04 ( 78.96)
The current update step is 11800
The current seed is 11778246344256874307
The current lr is: 0.001
Testing Results:
 *   Acc@1 79.197
 *   Acc@1 79.378
 *   Acc@1 77.605
 *   Acc@1 77.688
 *   Acc@1 76.329
 *   Acc@1 76.066
 *   Acc@1 79.645
 *   Acc@1 79.732
 *   Acc@1 78.487
 *   Acc@1 78.692
 *   Acc@1 76.382
 *   Acc@1 77.022
Training for 300 epoch: 79.42105263157895
Training for 600 epoch: 78.04605263157896
Training for 1000 epoch: 76.35526315789474
Training for 300 epoch: 79.555
Training for 600 epoch: 78.19
Training for 1000 epoch: 76.54374999999999
[[79.42105263157895, 78.04605263157896, 76.35526315789474], [79.555, 78.19, 76.54374999999999]]
train loss 0.2980929796218872, epoch 294, best loss 0.2910481328010559, best_epoch 284
GPU_0_using curriculum 20 with window 20
Epoch: [295][20/40]	Time  1.487 ( 1.520)	Data  0.028 ( 0.039)	InnerLoop  0.626 ( 0.648)	Loss 6.4351e-01 (6.2756e-01)	Acc@1  72.04 ( 77.52)
Epoch: [295][40/40]	Time  1.486 ( 1.520)	Data  0.012 ( 0.036)	InnerLoop  0.641 ( 0.651)	Loss 5.3984e-01 (6.1261e-01)	Acc@1  79.69 ( 77.96)
The current update step is 11840
GPU_0_using curriculum 20 with window 20
Epoch: [296][20/40]	Time  1.589 ( 1.531)	Data  0.027 ( 0.047)	InnerLoop  0.738 ( 0.649)	Loss 5.5450e-01 (5.6078e-01)	Acc@1  79.13 ( 79.35)
Epoch: [296][40/40]	Time  1.467 ( 1.520)	Data  0.012 ( 0.042)	InnerLoop  0.631 ( 0.645)	Loss 4.7345e-01 (5.5237e-01)	Acc@1  84.38 ( 79.61)
The current update step is 11880
GPU_0_using curriculum 20 with window 20
Epoch: [297][20/40]	Time  1.471 ( 1.497)	Data  0.027 ( 0.045)	InnerLoop  0.626 ( 0.630)	Loss 5.9600e-01 (5.5409e-01)	Acc@1  78.87 ( 79.46)
Epoch: [297][40/40]	Time  1.463 ( 1.498)	Data  0.012 ( 0.038)	InnerLoop  0.623 ( 0.636)	Loss 3.8687e-01 (5.4957e-01)	Acc@1  85.94 ( 79.72)
The current update step is 11920
GPU_0_using curriculum 20 with window 20
Epoch: [298][20/40]	Time  1.480 ( 1.502)	Data  0.027 ( 0.038)	InnerLoop  0.626 ( 0.641)	Loss 5.9369e-01 (5.7273e-01)	Acc@1  79.04 ( 79.03)
Epoch: [298][40/40]	Time  1.459 ( 1.499)	Data  0.011 ( 0.038)	InnerLoop  0.626 ( 0.639)	Loss 4.0835e-01 (5.6190e-01)	Acc@1  82.81 ( 79.29)
The current update step is 11960
GPU_0_using curriculum 20 with window 20
Epoch: [299][20/40]	Time  1.479 ( 1.500)	Data  0.027 ( 0.038)	InnerLoop  0.622 ( 0.637)	Loss 4.7883e-01 (5.6742e-01)	Acc@1  82.58 ( 79.31)
Epoch: [299][40/40]	Time  1.464 ( 1.506)	Data  0.013 ( 0.039)	InnerLoop  0.626 ( 0.642)	Loss 5.1173e-01 (5.6533e-01)	Acc@1  79.17 ( 79.44)
The current update step is 12000
The current seed is 4118745284653957052
The current lr is: 0.001
Testing Results:
 *   Acc@1 79.303
 *   Acc@1 79.552
 *   Acc@1 75.658
 *   Acc@1 75.763
 *   Acc@1 72.816
 *   Acc@1 72.824
 *   Acc@1 81.197
 *   Acc@1 81.950
 *   Acc@1 80.868
 *   Acc@1 81.759
 *   Acc@1 80.171
 *   Acc@1 81.206
Training for 300 epoch: 80.25
Training for 600 epoch: 78.26315789473685
Training for 1000 epoch: 76.49342105263158
Training for 300 epoch: 80.75125
Training for 600 epoch: 78.76083333333334
Training for 1000 epoch: 77.015
[[80.25, 78.26315789473685, 76.49342105263158], [80.75125, 78.76083333333334, 77.015]]
train loss 0.2700935371398926, epoch 299, best loss 0.2700935371398926, best_epoch 299
GPU_0_using curriculum 20 with window 20
Epoch: [300][20/40]	Time  1.478 ( 1.507)	Data  0.026 ( 0.038)	InnerLoop  0.628 ( 0.646)	Loss 5.9774e-01 (5.7631e-01)	Acc@1  78.74 ( 79.13)
Epoch: [300][40/40]	Time  1.465 ( 1.505)	Data  0.012 ( 0.038)	InnerLoop  0.625 ( 0.643)	Loss 5.4729e-01 (5.6889e-01)	Acc@1  82.29 ( 79.27)
The current update step is 12040
GPU_0_using curriculum 20 with window 20
Epoch: [301][20/40]	Time  1.479 ( 1.501)	Data  0.028 ( 0.045)	InnerLoop  0.627 ( 0.633)	Loss 5.1142e-01 (5.8273e-01)	Acc@1  80.40 ( 78.73)
Epoch: [301][40/40]	Time  1.569 ( 1.504)	Data  0.010 ( 0.038)	InnerLoop  0.737 ( 0.642)	Loss 5.4146e-01 (5.7858e-01)	Acc@1  80.73 ( 78.93)
The current update step is 12080
GPU_0_using curriculum 20 with window 20
Epoch: [302][20/40]	Time  1.481 ( 1.502)	Data  0.028 ( 0.039)	InnerLoop  0.631 ( 0.640)	Loss 5.0246e-01 (5.5417e-01)	Acc@1  81.80 ( 79.64)
Epoch: [302][40/40]	Time  1.467 ( 1.502)	Data  0.011 ( 0.039)	InnerLoop  0.636 ( 0.640)	Loss 4.8755e-01 (5.4283e-01)	Acc@1  81.25 ( 80.14)
The current update step is 12120
GPU_0_using curriculum 20 with window 20
Epoch: [303][20/40]	Time  1.486 ( 1.504)	Data  0.029 ( 0.045)	InnerLoop  0.633 ( 0.638)	Loss 4.4331e-01 (5.6816e-01)	Acc@1  84.21 ( 79.67)
Epoch: [303][40/40]	Time  1.472 ( 1.503)	Data  0.012 ( 0.041)	InnerLoop  0.637 ( 0.638)	Loss 4.7318e-01 (5.7401e-01)	Acc@1  82.29 ( 79.37)
The current update step is 12160
GPU_0_using curriculum 20 with window 20
Epoch: [304][20/40]	Time  1.593 ( 1.506)	Data  0.025 ( 0.039)	InnerLoop  0.743 ( 0.644)	Loss 5.1762e-01 (5.7685e-01)	Acc@1  80.73 ( 78.88)
Epoch: [304][40/40]	Time  1.471 ( 1.505)	Data  0.013 ( 0.038)	InnerLoop  0.634 ( 0.643)	Loss 7.1103e-01 (5.5158e-01)	Acc@1  75.52 ( 79.85)
The current update step is 12200
The current seed is 14390246606701872377
The current lr is: 0.001
Testing Results:
 *   Acc@1 81.737
 *   Acc@1 81.879
 *   Acc@1 79.658
 *   Acc@1 80.039
 *   Acc@1 78.566
 *   Acc@1 78.737
 *   Acc@1 78.961
 *   Acc@1 79.183
 *   Acc@1 75.382
 *   Acc@1 75.349
 *   Acc@1 71.855
 *   Acc@1 71.700
Training for 300 epoch: 80.34868421052633
Training for 600 epoch: 77.51973684210526
Training for 1000 epoch: 75.21052631578948
Training for 300 epoch: 80.53083333333333
Training for 600 epoch: 77.69416666666666
Training for 1000 epoch: 75.21833333333333
[[80.34868421052633, 77.51973684210526, 75.21052631578948], [80.53083333333333, 77.69416666666666, 75.21833333333333]]
train loss 0.4456544442653656, epoch 304, best loss 0.2700935371398926, best_epoch 299
GPU_0_using curriculum 20 with window 20
Epoch: [305][20/40]	Time  1.479 ( 1.499)	Data  0.027 ( 0.033)	InnerLoop  0.628 ( 0.645)	Loss 4.8375e-01 (5.4680e-01)	Acc@1  82.68 ( 79.80)
Epoch: [305][40/40]	Time  1.471 ( 1.503)	Data  0.012 ( 0.036)	InnerLoop  0.636 ( 0.645)	Loss 6.6231e-01 (5.6802e-01)	Acc@1  77.08 ( 78.99)
The current update step is 12240
GPU_0_using curriculum 20 with window 20
Epoch: [306][20/40]	Time  1.478 ( 1.499)	Data  0.026 ( 0.033)	InnerLoop  0.631 ( 0.644)	Loss 5.0871e-01 (5.4717e-01)	Acc@1  81.38 ( 80.49)
Epoch: [306][40/40]	Time  1.482 ( 1.501)	Data  0.013 ( 0.035)	InnerLoop  0.642 ( 0.642)	Loss 5.4733e-01 (5.4183e-01)	Acc@1  79.69 ( 80.51)
The current update step is 12280
GPU_0_using curriculum 20 with window 20
Epoch: [307][20/40]	Time  1.625 ( 1.524)	Data  0.027 ( 0.040)	InnerLoop  0.762 ( 0.654)	Loss 5.9821e-01 (5.2898e-01)	Acc@1  74.77 ( 80.69)
Epoch: [307][40/40]	Time  1.468 ( 1.513)	Data  0.013 ( 0.039)	InnerLoop  0.633 ( 0.647)	Loss 5.3839e-01 (5.3885e-01)	Acc@1  79.17 ( 80.31)
The current update step is 12320
GPU_0_using curriculum 20 with window 20
Epoch: [308][20/40]	Time  1.490 ( 1.499)	Data  0.028 ( 0.033)	InnerLoop  0.633 ( 0.645)	Loss 5.2130e-01 (5.6432e-01)	Acc@1  80.76 ( 79.27)
Epoch: [308][40/40]	Time  1.472 ( 1.504)	Data  0.012 ( 0.035)	InnerLoop  0.635 ( 0.645)	Loss 4.9904e-01 (5.7084e-01)	Acc@1  82.29 ( 79.26)
The current update step is 12360
GPU_0_using curriculum 20 with window 20
Epoch: [309][20/40]	Time  1.498 ( 1.502)	Data  0.029 ( 0.038)	InnerLoop  0.639 ( 0.640)	Loss 5.5975e-01 (5.6547e-01)	Acc@1  79.20 ( 79.68)
Epoch: [309][40/40]	Time  1.465 ( 1.502)	Data  0.012 ( 0.035)	InnerLoop  0.633 ( 0.643)	Loss 4.2355e-01 (5.8386e-01)	Acc@1  82.81 ( 79.19)
The current update step is 12400
The current seed is 9638475738009740830
The current lr is: 0.001
Testing Results:
 *   Acc@1 79.553
 *   Acc@1 79.878
 *   Acc@1 78.513
 *   Acc@1 78.434
 *   Acc@1 76.737
 *   Acc@1 77.085
 *   Acc@1 82.671
 *   Acc@1 82.653
 *   Acc@1 82.263
 *   Acc@1 82.544
 *   Acc@1 82.000
 *   Acc@1 82.284
Training for 300 epoch: 81.11184210526315
Training for 600 epoch: 80.38815789473684
Training for 1000 epoch: 79.36842105263159
Training for 300 epoch: 81.26541666666667
Training for 600 epoch: 80.48916666666668
Training for 1000 epoch: 79.68458333333334
[[81.11184210526315, 80.38815789473684, 79.36842105263159], [81.26541666666667, 80.48916666666668, 79.68458333333334]]
train loss 0.2576794367790222, epoch 309, best loss 0.2576794367790222, best_epoch 309
GPU_0_using curriculum 20 with window 20
Epoch: [310][20/40]	Time  1.486 ( 1.498)	Data  0.027 ( 0.038)	InnerLoop  0.627 ( 0.637)	Loss 4.9483e-01 (5.5699e-01)	Acc@1  82.49 ( 79.76)
Epoch: [310][40/40]	Time  1.461 ( 1.501)	Data  0.012 ( 0.035)	InnerLoop  0.627 ( 0.641)	Loss 5.3549e-01 (5.5022e-01)	Acc@1  83.85 ( 80.06)
The current update step is 12440
GPU_0_using curriculum 20 with window 20
Epoch: [311][20/40]	Time  1.601 ( 1.506)	Data  0.026 ( 0.045)	InnerLoop  0.747 ( 0.638)	Loss 5.3330e-01 (5.5988e-01)	Acc@1  80.99 ( 80.06)
Epoch: [311][40/40]	Time  1.464 ( 1.505)	Data  0.013 ( 0.041)	InnerLoop  0.628 ( 0.639)	Loss 5.6092e-01 (5.5258e-01)	Acc@1  78.12 ( 79.95)
The current update step is 12480
GPU_0_using curriculum 20 with window 20
Epoch: [312][20/40]	Time  1.480 ( 1.501)	Data  0.026 ( 0.045)	InnerLoop  0.629 ( 0.633)	Loss 5.2430e-01 (6.0004e-01)	Acc@1  81.54 ( 78.86)
Epoch: [312][40/40]	Time  1.459 ( 1.503)	Data  0.011 ( 0.038)	InnerLoop  0.626 ( 0.640)	Loss 5.3537e-01 (5.8144e-01)	Acc@1  83.33 ( 79.14)
The current update step is 12520
GPU_0_using curriculum 20 with window 20
Epoch: [313][20/40]	Time  1.483 ( 1.505)	Data  0.028 ( 0.039)	InnerLoop  0.627 ( 0.643)	Loss 5.3630e-01 (5.9966e-01)	Acc@1  79.07 ( 77.96)
Epoch: [313][40/40]	Time  1.457 ( 1.506)	Data  0.013 ( 0.038)	InnerLoop  0.629 ( 0.641)	Loss 4.7276e-01 (5.7779e-01)	Acc@1  82.29 ( 78.68)
The current update step is 12560
GPU_0_using curriculum 20 with window 20
Epoch: [314][20/40]	Time  1.501 ( 1.509)	Data  0.026 ( 0.040)	InnerLoop  0.643 ( 0.643)	Loss 5.5314e-01 (5.7883e-01)	Acc@1  79.43 ( 78.61)
Epoch: [314][40/40]	Time  1.511 ( 1.518)	Data  0.013 ( 0.040)	InnerLoop  0.660 ( 0.648)	Loss 5.4978e-01 (5.7323e-01)	Acc@1  77.08 ( 78.85)
The current update step is 12600
The current seed is 13243939776381640232
The current lr is: 0.001
Testing Results:
 *   Acc@1 82.671
 *   Acc@1 83.343
 *   Acc@1 82.539
 *   Acc@1 82.905
 *   Acc@1 81.487
 *   Acc@1 82.096
 *   Acc@1 80.421
 *   Acc@1 80.901
 *   Acc@1 76.974
 *   Acc@1 76.856
 *   Acc@1 73.526
 *   Acc@1 72.847
Training for 300 epoch: 81.54605263157895
Training for 600 epoch: 79.75657894736841
Training for 1000 epoch: 77.50657894736842
Training for 300 epoch: 82.12166666666667
Training for 600 epoch: 79.88041666666666
Training for 1000 epoch: 77.47125
[[81.54605263157895, 79.75657894736841, 77.50657894736842], [82.12166666666667, 79.88041666666666, 77.47125]]
train loss 0.4209733073711395, epoch 314, best loss 0.2576794367790222, best_epoch 309
GPU_0_using curriculum 20 with window 20
Epoch: [315][20/40]	Time  1.505 ( 1.539)	Data  0.029 ( 0.041)	InnerLoop  0.644 ( 0.660)	Loss 5.4256e-01 (5.3889e-01)	Acc@1  81.09 ( 80.64)
Epoch: [315][40/40]	Time  1.498 ( 1.540)	Data  0.014 ( 0.041)	InnerLoop  0.642 ( 0.659)	Loss 5.5439e-01 (5.4323e-01)	Acc@1  77.60 ( 80.22)
The current update step is 12640
GPU_0_using curriculum 20 with window 20
Epoch: [316][20/40]	Time  1.514 ( 1.535)	Data  0.028 ( 0.047)	InnerLoop  0.643 ( 0.648)	Loss 5.5101e-01 (5.3115e-01)	Acc@1  77.57 ( 80.35)
Epoch: [316][40/40]	Time  1.596 ( 1.539)	Data  0.011 ( 0.040)	InnerLoop  0.746 ( 0.658)	Loss 6.2854e-01 (5.5072e-01)	Acc@1  78.12 ( 79.84)
The current update step is 12680
GPU_0_using curriculum 20 with window 20
Epoch: [317][20/40]	Time  1.521 ( 1.536)	Data  0.029 ( 0.042)	InnerLoop  0.646 ( 0.654)	Loss 4.6935e-01 (5.6471e-01)	Acc@1  82.36 ( 79.35)
Epoch: [317][40/40]	Time  1.500 ( 1.537)	Data  0.012 ( 0.041)	InnerLoop  0.650 ( 0.654)	Loss 5.7188e-01 (5.7550e-01)	Acc@1  76.56 ( 79.01)
The current update step is 12720
GPU_0_using curriculum 20 with window 20
Epoch: [318][20/40]	Time  1.507 ( 1.540)	Data  0.029 ( 0.048)	InnerLoop  0.639 ( 0.654)	Loss 5.4646e-01 (5.6483e-01)	Acc@1  80.24 ( 79.61)
Epoch: [318][40/40]	Time  1.505 ( 1.535)	Data  0.013 ( 0.044)	InnerLoop  0.651 ( 0.653)	Loss 4.9471e-01 (5.6475e-01)	Acc@1  80.73 ( 79.62)
The current update step is 12760
GPU_0_using curriculum 20 with window 20
Epoch: [319][20/40]	Time  1.642 ( 1.539)	Data  0.028 ( 0.042)	InnerLoop  0.768 ( 0.659)	Loss 4.8929e-01 (5.5966e-01)	Acc@1  83.11 ( 79.47)
Epoch: [319][40/40]	Time  1.506 ( 1.536)	Data  0.014 ( 0.041)	InnerLoop  0.651 ( 0.656)	Loss 3.9611e-01 (5.5364e-01)	Acc@1  83.85 ( 79.73)
The current update step is 12800
The current seed is 9729166586148454191
The current lr is: 0.001
Testing Results:
 *   Acc@1 79.079
 *   Acc@1 79.503
 *   Acc@1 78.132
 *   Acc@1 78.672
 *   Acc@1 76.882
 *   Acc@1 77.098
 *   Acc@1 79.421
 *   Acc@1 80.302
 *   Acc@1 77.671
 *   Acc@1 78.072
 *   Acc@1 74.737
 *   Acc@1 75.718
Training for 300 epoch: 79.25
Training for 600 epoch: 77.90131578947368
Training for 1000 epoch: 75.8092105263158
Training for 300 epoch: 79.9025
Training for 600 epoch: 78.37166666666667
Training for 1000 epoch: 76.40833333333333
[[79.25, 77.90131578947368, 75.8092105263158], [79.9025, 78.37166666666667, 76.40833333333333]]
train loss 0.31658196778297426, epoch 319, best loss 0.2576794367790222, best_epoch 309
GPU_0_using curriculum 20 with window 20
Epoch: [320][20/40]	Time  1.519 ( 1.527)	Data  0.028 ( 0.035)	InnerLoop  0.645 ( 0.656)	Loss 5.2833e-01 (5.7904e-01)	Acc@1  81.22 ( 79.08)
Epoch: [320][40/40]	Time  1.498 ( 1.531)	Data  0.013 ( 0.037)	InnerLoop  0.647 ( 0.657)	Loss 4.9270e-01 (5.7434e-01)	Acc@1  83.33 ( 79.39)
The current update step is 12840
GPU_0_using curriculum 20 with window 20
Epoch: [321][20/40]	Time  1.504 ( 1.527)	Data  0.029 ( 0.035)	InnerLoop  0.638 ( 0.657)	Loss 5.3862e-01 (5.5664e-01)	Acc@1  80.01 ( 79.89)
Epoch: [321][40/40]	Time  1.481 ( 1.527)	Data  0.012 ( 0.037)	InnerLoop  0.638 ( 0.653)	Loss 6.1954e-01 (5.6340e-01)	Acc@1  76.56 ( 79.46)
The current update step is 12880
GPU_0_using curriculum 20 with window 20
Epoch: [322][20/40]	Time  1.624 ( 1.533)	Data  0.031 ( 0.040)	InnerLoop  0.761 ( 0.657)	Loss 5.5193e-01 (6.0539e-01)	Acc@1  80.89 ( 78.79)
Epoch: [322][40/40]	Time  1.502 ( 1.533)	Data  0.012 ( 0.041)	InnerLoop  0.646 ( 0.654)	Loss 5.5535e-01 (6.0831e-01)	Acc@1  79.17 ( 78.41)
The current update step is 12920
GPU_0_using curriculum 20 with window 20
Epoch: [323][20/40]	Time  1.514 ( 1.530)	Data  0.030 ( 0.035)	InnerLoop  0.643 ( 0.658)	Loss 1.1223e+00 (6.1198e-01)	Acc@1  67.29 ( 78.28)
Epoch: [323][40/40]	Time  1.488 ( 1.537)	Data  0.014 ( 0.037)	InnerLoop  0.636 ( 0.660)	Loss 5.1087e-01 (6.2272e-01)	Acc@1  81.25 ( 77.88)
The current update step is 12960
GPU_0_using curriculum 20 with window 20
Epoch: [324][20/40]	Time  1.516 ( 1.536)	Data  0.030 ( 0.042)	InnerLoop  0.641 ( 0.653)	Loss 5.3349e-01 (5.7135e-01)	Acc@1  79.95 ( 78.54)
Epoch: [324][40/40]	Time  1.481 ( 1.535)	Data  0.014 ( 0.038)	InnerLoop  0.631 ( 0.657)	Loss 5.3248e-01 (5.6713e-01)	Acc@1  79.69 ( 78.88)
The current update step is 13000
The current seed is 17968657449658433211
The current lr is: 0.001
Testing Results:
 *   Acc@1 80.842
 *   Acc@1 81.278
 *   Acc@1 81.342
 *   Acc@1 81.885
 *   Acc@1 80.855
 *   Acc@1 81.518
 *   Acc@1 74.763
 *   Acc@1 75.109
 *   Acc@1 72.250
 *   Acc@1 72.590
 *   Acc@1 70.276
 *   Acc@1 70.668
Training for 300 epoch: 77.80263157894737
Training for 600 epoch: 76.79605263157895
Training for 1000 epoch: 75.56578947368422
Training for 300 epoch: 78.19375
Training for 600 epoch: 77.23750000000001
Training for 1000 epoch: 76.09333333333333
[[77.80263157894737, 76.79605263157895, 75.56578947368422], [78.19375, 77.23750000000001, 76.09333333333333]]
train loss 0.38816479439735413, epoch 324, best loss 0.2576794367790222, best_epoch 309
GPU_0_using curriculum 20 with window 20
Epoch: [325][20/40]	Time  1.490 ( 1.514)	Data  0.027 ( 0.040)	InnerLoop  0.630 ( 0.644)	Loss 5.3612e-01 (5.8417e-01)	Acc@1  79.49 ( 78.56)
Epoch: [325][40/40]	Time  1.466 ( 1.510)	Data  0.011 ( 0.036)	InnerLoop  0.636 ( 0.646)	Loss 6.1652e-01 (5.9812e-01)	Acc@1  78.12 ( 78.00)
The current update step is 13040
GPU_0_using curriculum 20 with window 20
Epoch: [326][20/40]	Time  1.590 ( 1.507)	Data  0.026 ( 0.045)	InnerLoop  0.739 ( 0.639)	Loss 5.4961e-01 (5.8551e-01)	Acc@1  80.50 ( 78.48)
Epoch: [326][40/40]	Time  1.476 ( 1.506)	Data  0.013 ( 0.041)	InnerLoop  0.638 ( 0.640)	Loss 5.7162e-01 (5.6957e-01)	Acc@1  76.56 ( 79.12)
The current update step is 13080
GPU_0_using curriculum 20 with window 20
Epoch: [327][20/40]	Time  1.483 ( 1.501)	Data  0.026 ( 0.045)	InnerLoop  0.632 ( 0.633)	Loss 5.6451e-01 (5.9388e-01)	Acc@1  79.69 ( 78.13)
Epoch: [327][40/40]	Time  1.453 ( 1.501)	Data  0.011 ( 0.039)	InnerLoop  0.623 ( 0.639)	Loss 4.4080e-01 (5.7756e-01)	Acc@1  87.50 ( 78.96)
The current update step is 13120
GPU_0_using curriculum 20 with window 20
Epoch: [328][20/40]	Time  1.473 ( 1.505)	Data  0.026 ( 0.039)	InnerLoop  0.625 ( 0.644)	Loss 5.6210e-01 (5.7237e-01)	Acc@1  80.21 ( 79.22)
Epoch: [328][40/40]	Time  1.461 ( 1.504)	Data  0.012 ( 0.039)	InnerLoop  0.627 ( 0.642)	Loss 5.2022e-01 (5.8341e-01)	Acc@1  82.29 ( 78.74)
The current update step is 13160
GPU_0_using curriculum 20 with window 20
Epoch: [329][20/40]	Time  1.483 ( 1.499)	Data  0.027 ( 0.039)	InnerLoop  0.627 ( 0.639)	Loss 5.2637e-01 (5.6369e-01)	Acc@1  79.82 ( 79.82)
Epoch: [329][40/40]	Time  1.460 ( 1.503)	Data  0.013 ( 0.038)	InnerLoop  0.628 ( 0.641)	Loss 5.6998e-01 (5.6105e-01)	Acc@1  79.17 ( 79.81)
The current update step is 13200
The current seed is 6426002466641741907
The current lr is: 0.001
Testing Results:
 *   Acc@1 79.026
 *   Acc@1 79.203
 *   Acc@1 72.776
 *   Acc@1 72.999
 *   Acc@1 70.526
 *   Acc@1 70.628
 *   Acc@1 75.066
 *   Acc@1 75.761
 *   Acc@1 69.026
 *   Acc@1 69.248
 *   Acc@1 64.553
 *   Acc@1 65.237
Training for 300 epoch: 77.04605263157895
Training for 600 epoch: 70.90131578947368
Training for 1000 epoch: 67.53947368421052
Training for 300 epoch: 77.48166666666667
Training for 600 epoch: 71.12375
Training for 1000 epoch: 67.9325
[[77.04605263157895, 70.90131578947368, 67.53947368421052], [77.48166666666667, 71.12375, 67.9325]]
train loss 0.5305480279445648, epoch 329, best loss 0.2576794367790222, best_epoch 309
GPU_0_using curriculum 20 with window 20
Epoch: [330][20/40]	Time  1.481 ( 1.508)	Data  0.026 ( 0.038)	InnerLoop  0.629 ( 0.646)	Loss 6.1679e-01 (5.7250e-01)	Acc@1  78.19 ( 79.42)
Epoch: [330][40/40]	Time  1.495 ( 1.507)	Data  0.013 ( 0.038)	InnerLoop  0.648 ( 0.644)	Loss 5.4345e-01 (5.7266e-01)	Acc@1  77.08 ( 79.33)
The current update step is 13240
GPU_0_using curriculum 20 with window 20
Epoch: [331][20/40]	Time  1.503 ( 1.517)	Data  0.030 ( 0.047)	InnerLoop  0.637 ( 0.639)	Loss 6.5746e-01 (5.4915e-01)	Acc@1  76.37 ( 80.00)
Epoch: [331][40/40]	Time  1.585 ( 1.512)	Data  0.010 ( 0.040)	InnerLoop  0.746 ( 0.645)	Loss 5.0171e-01 (5.4720e-01)	Acc@1  79.69 ( 80.04)
The current update step is 13280
GPU_0_using curriculum 20 with window 20
Epoch: [332][20/40]	Time  1.475 ( 1.503)	Data  0.026 ( 0.039)	InnerLoop  0.626 ( 0.640)	Loss 5.4043e-01 (5.8312e-01)	Acc@1  80.63 ( 78.68)
Epoch: [332][40/40]	Time  1.474 ( 1.507)	Data  0.011 ( 0.039)	InnerLoop  0.629 ( 0.641)	Loss 5.9231e-01 (5.8791e-01)	Acc@1  80.73 ( 78.50)
The current update step is 13320
GPU_0_using curriculum 20 with window 20
Epoch: [333][20/40]	Time  1.485 ( 1.515)	Data  0.028 ( 0.046)	InnerLoop  0.626 ( 0.642)	Loss 5.4154e-01 (6.2027e-01)	Acc@1  79.36 ( 77.26)
Epoch: [333][40/40]	Time  1.484 ( 1.520)	Data  0.012 ( 0.043)	InnerLoop  0.644 ( 0.646)	Loss 5.9969e-01 (5.9387e-01)	Acc@1  80.73 ( 78.05)
The current update step is 13360
GPU_0_using curriculum 20 with window 20
Epoch: [334][20/40]	Time  1.639 ( 1.540)	Data  0.030 ( 0.041)	InnerLoop  0.768 ( 0.660)	Loss 5.5694e-01 (5.6103e-01)	Acc@1  79.23 ( 79.08)
Epoch: [334][40/40]	Time  1.500 ( 1.537)	Data  0.012 ( 0.040)	InnerLoop  0.649 ( 0.657)	Loss 4.5222e-01 (5.5341e-01)	Acc@1  83.33 ( 79.60)
The current update step is 13400
The current seed is 2546637975550736038
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.658
 *   Acc@1 77.117
 *   Acc@1 75.697
 *   Acc@1 76.106
 *   Acc@1 75.526
 *   Acc@1 75.772
 *   Acc@1 77.789
 *   Acc@1 78.487
 *   Acc@1 75.618
 *   Acc@1 76.287
 *   Acc@1 74.526
 *   Acc@1 75.449
Training for 300 epoch: 77.22368421052632
Training for 600 epoch: 75.65789473684211
Training for 1000 epoch: 75.02631578947368
Training for 300 epoch: 77.80208333333333
Training for 600 epoch: 76.19666666666666
Training for 1000 epoch: 75.61041666666667
[[77.22368421052632, 75.65789473684211, 75.02631578947368], [77.80208333333333, 76.19666666666666, 75.61041666666667]]
train loss 0.4302888423919678, epoch 334, best loss 0.2576794367790222, best_epoch 309
GPU_0_using curriculum 20 with window 20
Epoch: [335][20/40]	Time  1.502 ( 1.530)	Data  0.027 ( 0.035)	InnerLoop  0.636 ( 0.659)	Loss 5.2794e-01 (5.4048e-01)	Acc@1  81.67 ( 80.15)
Epoch: [335][40/40]	Time  1.504 ( 1.536)	Data  0.011 ( 0.037)	InnerLoop  0.655 ( 0.660)	Loss 4.0377e-01 (5.3663e-01)	Acc@1  87.50 ( 80.39)
The current update step is 13440
GPU_0_using curriculum 20 with window 20
Epoch: [336][20/40]	Time  1.508 ( 1.535)	Data  0.028 ( 0.035)	InnerLoop  0.642 ( 0.660)	Loss 7.2069e-01 (5.5586e-01)	Acc@1  75.59 ( 79.67)
Epoch: [336][40/40]	Time  1.507 ( 1.537)	Data  0.014 ( 0.037)	InnerLoop  0.654 ( 0.659)	Loss 6.6941e-01 (5.6428e-01)	Acc@1  77.08 ( 79.33)
The current update step is 13480
GPU_0_using curriculum 20 with window 20
Epoch: [337][20/40]	Time  1.620 ( 1.532)	Data  0.027 ( 0.040)	InnerLoop  0.749 ( 0.656)	Loss 5.2112e-01 (5.7684e-01)	Acc@1  81.35 ( 79.10)
Epoch: [337][40/40]	Time  1.501 ( 1.532)	Data  0.014 ( 0.040)	InnerLoop  0.644 ( 0.654)	Loss 6.0071e-01 (5.6727e-01)	Acc@1  78.65 ( 79.40)
The current update step is 13520
GPU_0_using curriculum 20 with window 20
Epoch: [338][20/40]	Time  1.503 ( 1.530)	Data  0.030 ( 0.035)	InnerLoop  0.645 ( 0.659)	Loss 4.8156e-01 (5.4086e-01)	Acc@1  82.32 ( 80.28)
Epoch: [338][40/40]	Time  1.474 ( 1.532)	Data  0.011 ( 0.037)	InnerLoop  0.636 ( 0.658)	Loss 4.5855e-01 (5.4530e-01)	Acc@1  83.85 ( 80.07)
The current update step is 13560
GPU_0_using curriculum 20 with window 20
Epoch: [339][20/40]	Time  1.522 ( 1.513)	Data  0.030 ( 0.040)	InnerLoop  0.645 ( 0.645)	Loss 5.4804e-01 (5.6785e-01)	Acc@1  80.11 ( 79.32)
Epoch: [339][40/40]	Time  1.484 ( 1.522)	Data  0.011 ( 0.037)	InnerLoop  0.644 ( 0.652)	Loss 4.5885e-01 (5.6860e-01)	Acc@1  86.98 ( 79.23)
The current update step is 13600
The current seed is 8634737409959191369
The current lr is: 0.001
Testing Results:
 *   Acc@1 81.316
 *   Acc@1 82.495
 *   Acc@1 82.053
 *   Acc@1 82.660
 *   Acc@1 81.908
 *   Acc@1 82.510
 *   Acc@1 80.395
 *   Acc@1 80.612
 *   Acc@1 79.671
 *   Acc@1 80.191
 *   Acc@1 79.618
 *   Acc@1 80.032
Training for 300 epoch: 80.85526315789474
Training for 600 epoch: 80.86184210526315
Training for 1000 epoch: 80.76315789473685
Training for 300 epoch: 81.55375000000001
Training for 600 epoch: 81.42541666666666
Training for 1000 epoch: 81.27083333333334
[[80.85526315789474, 80.86184210526315, 80.76315789473685], [81.55375000000001, 81.42541666666666, 81.27083333333334]]
train loss 0.3042920641899109, epoch 339, best loss 0.2576794367790222, best_epoch 309
GPU_0_using curriculum 20 with window 20
Epoch: [340][20/40]	Time  1.508 ( 1.530)	Data  0.025 ( 0.041)	InnerLoop  0.641 ( 0.653)	Loss 5.2441e-01 (5.7964e-01)	Acc@1  80.08 ( 78.42)
Epoch: [340][40/40]	Time  1.482 ( 1.528)	Data  0.013 ( 0.037)	InnerLoop  0.639 ( 0.654)	Loss 5.9362e-01 (5.8715e-01)	Acc@1  77.60 ( 78.44)
The current update step is 13640
GPU_0_using curriculum 20 with window 20
Epoch: [341][20/40]	Time  1.609 ( 1.536)	Data  0.026 ( 0.046)	InnerLoop  0.745 ( 0.653)	Loss 5.1795e-01 (5.7812e-01)	Acc@1  80.83 ( 78.77)
Epoch: [341][40/40]	Time  1.494 ( 1.533)	Data  0.011 ( 0.043)	InnerLoop  0.651 ( 0.653)	Loss 4.3762e-01 (5.6282e-01)	Acc@1  82.81 ( 79.40)
The current update step is 13680
GPU_0_using curriculum 20 with window 20
Epoch: [342][20/40]	Time  1.509 ( 1.530)	Data  0.027 ( 0.047)	InnerLoop  0.643 ( 0.646)	Loss 6.3976e-01 (5.8012e-01)	Acc@1  75.10 ( 79.08)
Epoch: [342][40/40]	Time  1.493 ( 1.533)	Data  0.013 ( 0.041)	InnerLoop  0.642 ( 0.653)	Loss 6.3935e-01 (5.8117e-01)	Acc@1  75.52 ( 78.75)
The current update step is 13720
GPU_0_using curriculum 20 with window 20
Epoch: [343][20/40]	Time  1.511 ( 1.536)	Data  0.027 ( 0.041)	InnerLoop  0.641 ( 0.658)	Loss 6.6718e-01 (5.4333e-01)	Acc@1  74.93 ( 80.42)
Epoch: [343][40/40]	Time  1.497 ( 1.532)	Data  0.013 ( 0.040)	InnerLoop  0.645 ( 0.655)	Loss 6.1528e-01 (5.6203e-01)	Acc@1  77.60 ( 79.52)
The current update step is 13760
GPU_0_using curriculum 20 with window 20
Epoch: [344][20/40]	Time  1.500 ( 1.518)	Data  0.029 ( 0.041)	InnerLoop  0.627 ( 0.646)	Loss 5.0089e-01 (5.9603e-01)	Acc@1  82.10 ( 78.09)
Epoch: [344][40/40]	Time  1.469 ( 1.515)	Data  0.011 ( 0.040)	InnerLoop  0.630 ( 0.646)	Loss 5.1430e-01 (5.7969e-01)	Acc@1  79.69 ( 78.60)
The current update step is 13800
The current seed is 11705498235677502196
The current lr is: 0.001
Testing Results:
 *   Acc@1 81.184
 *   Acc@1 81.114
 *   Acc@1 80.026
 *   Acc@1 80.125
 *   Acc@1 79.382
 *   Acc@1 79.068
 *   Acc@1 80.211
 *   Acc@1 80.989
 *   Acc@1 80.197
 *   Acc@1 80.759
 *   Acc@1 79.434
 *   Acc@1 80.134
Training for 300 epoch: 80.69736842105263
Training for 600 epoch: 80.11184210526315
Training for 1000 epoch: 79.40789473684211
Training for 300 epoch: 81.05166666666666
Training for 600 epoch: 80.44208333333333
Training for 1000 epoch: 79.60125
[[80.69736842105263, 80.11184210526315, 79.40789473684211], [81.05166666666666, 80.44208333333333, 79.60125]]
train loss 0.2876033070802689, epoch 344, best loss 0.2576794367790222, best_epoch 309
GPU_0_using curriculum 20 with window 20
Epoch: [345][20/40]	Time  1.475 ( 1.506)	Data  0.028 ( 0.038)	InnerLoop  0.623 ( 0.643)	Loss 5.4029e-01 (5.6986e-01)	Acc@1  80.66 ( 79.28)
Epoch: [345][40/40]	Time  1.464 ( 1.504)	Data  0.012 ( 0.038)	InnerLoop  0.629 ( 0.641)	Loss 8.6837e-01 (5.6930e-01)	Acc@1  70.83 ( 79.14)
The current update step is 13840
GPU_0_using curriculum 20 with window 20
Epoch: [346][20/40]	Time  1.489 ( 1.500)	Data  0.027 ( 0.045)	InnerLoop  0.629 ( 0.632)	Loss 5.5534e-01 (5.7401e-01)	Acc@1  79.43 ( 78.68)
Epoch: [346][40/40]	Time  1.568 ( 1.503)	Data  0.012 ( 0.038)	InnerLoop  0.737 ( 0.641)	Loss 4.4655e-01 (5.7267e-01)	Acc@1  85.94 ( 78.96)
The current update step is 13880
GPU_0_using curriculum 20 with window 20
Epoch: [347][20/40]	Time  1.474 ( 1.501)	Data  0.025 ( 0.039)	InnerLoop  0.626 ( 0.639)	Loss 4.6762e-01 (5.4127e-01)	Acc@1  83.20 ( 80.13)
Epoch: [347][40/40]	Time  1.465 ( 1.501)	Data  0.011 ( 0.038)	InnerLoop  0.631 ( 0.639)	Loss 4.5411e-01 (5.5932e-01)	Acc@1  79.17 ( 79.41)
The current update step is 13920
GPU_0_using curriculum 20 with window 20
Epoch: [348][20/40]	Time  1.484 ( 1.504)	Data  0.028 ( 0.044)	InnerLoop  0.631 ( 0.638)	Loss 7.0844e-01 (5.5458e-01)	Acc@1  76.33 ( 80.08)
Epoch: [348][40/40]	Time  1.471 ( 1.503)	Data  0.013 ( 0.041)	InnerLoop  0.632 ( 0.638)	Loss 5.3399e-01 (5.6167e-01)	Acc@1  78.65 ( 79.78)
The current update step is 13960
GPU_0_using curriculum 20 with window 20
Epoch: [349][20/40]	Time  1.603 ( 1.506)	Data  0.029 ( 0.039)	InnerLoop  0.744 ( 0.644)	Loss 6.5815e-01 (5.7686e-01)	Acc@1  76.37 ( 79.20)
Epoch: [349][40/40]	Time  1.471 ( 1.504)	Data  0.013 ( 0.039)	InnerLoop  0.631 ( 0.641)	Loss 5.5398e-01 (5.7585e-01)	Acc@1  79.17 ( 79.11)
The current update step is 14000
The current seed is 12794097251037202724
The current lr is: 0.001
Testing Results:
 *   Acc@1 81.987
 *   Acc@1 82.438
 *   Acc@1 81.724
 *   Acc@1 81.873
 *   Acc@1 79.803
 *   Acc@1 80.502
 *   Acc@1 79.868
 *   Acc@1 79.921
 *   Acc@1 78.961
 *   Acc@1 79.315
 *   Acc@1 78.461
 *   Acc@1 78.469
Training for 300 epoch: 80.92763157894737
Training for 600 epoch: 80.34210526315789
Training for 1000 epoch: 79.13157894736842
Training for 300 epoch: 81.17916666666667
Training for 600 epoch: 80.59375
Training for 1000 epoch: 79.48541666666667
[[80.92763157894737, 80.34210526315789, 79.13157894736842], [81.17916666666667, 80.59375, 79.48541666666667]]
train loss 0.3219763263225555, epoch 349, best loss 0.2576794367790222, best_epoch 309
GPU_0_using curriculum 20 with window 20
Epoch: [350][20/40]	Time  1.480 ( 1.512)	Data  0.028 ( 0.034)	InnerLoop  0.628 ( 0.649)	Loss 4.9951e-01 (5.8161e-01)	Acc@1  81.61 ( 78.83)
Epoch: [350][40/40]	Time  1.471 ( 1.510)	Data  0.013 ( 0.036)	InnerLoop  0.631 ( 0.647)	Loss 5.0641e-01 (5.9008e-01)	Acc@1  78.65 ( 78.40)
The current update step is 14040
GPU_0_using curriculum 20 with window 20
Epoch: [351][20/40]	Time  1.492 ( 1.512)	Data  0.029 ( 0.034)	InnerLoop  0.625 ( 0.650)	Loss 5.1506e-01 (5.5434e-01)	Acc@1  81.05 ( 79.63)
Epoch: [351][40/40]	Time  1.467 ( 1.508)	Data  0.012 ( 0.036)	InnerLoop  0.629 ( 0.644)	Loss 5.6396e-01 (5.5341e-01)	Acc@1  77.60 ( 79.71)
The current update step is 14080
GPU_0_using curriculum 20 with window 20
Epoch: [352][20/40]	Time  1.603 ( 1.507)	Data  0.029 ( 0.039)	InnerLoop  0.745 ( 0.645)	Loss 5.3357e-01 (5.7459e-01)	Acc@1  80.05 ( 79.56)
Epoch: [352][40/40]	Time  1.481 ( 1.508)	Data  0.014 ( 0.039)	InnerLoop  0.636 ( 0.644)	Loss 6.0860e-01 (5.6146e-01)	Acc@1  78.65 ( 79.85)
The current update step is 14120
GPU_0_using curriculum 20 with window 20
Epoch: [353][20/40]	Time  1.486 ( 1.513)	Data  0.029 ( 0.034)	InnerLoop  0.627 ( 0.650)	Loss 4.9075e-01 (5.6293e-01)	Acc@1  82.10 ( 79.40)
Epoch: [353][40/40]	Time  1.499 ( 1.525)	Data  0.012 ( 0.037)	InnerLoop  0.644 ( 0.654)	Loss 5.3654e-01 (5.4966e-01)	Acc@1  79.17 ( 79.77)
The current update step is 14160
GPU_0_using curriculum 20 with window 20
Epoch: [354][20/40]	Time  1.514 ( 1.532)	Data  0.028 ( 0.041)	InnerLoop  0.645 ( 0.654)	Loss 5.1051e-01 (5.4758e-01)	Acc@1  81.61 ( 80.37)
Epoch: [354][40/40]	Time  1.515 ( 1.535)	Data  0.012 ( 0.038)	InnerLoop  0.657 ( 0.658)	Loss 6.2948e-01 (5.5408e-01)	Acc@1  83.33 ( 80.17)
The current update step is 14200
The current seed is 10032782404076249532
The current lr is: 0.001
Testing Results:
 *   Acc@1 80.658
 *   Acc@1 80.188
 *   Acc@1 78.368
 *   Acc@1 78.349
 *   Acc@1 77.513
 *   Acc@1 77.387
 *   Acc@1 81.132
 *   Acc@1 80.967
 *   Acc@1 80.921
 *   Acc@1 81.076
 *   Acc@1 80.816
 *   Acc@1 80.727
Training for 300 epoch: 80.89473684210526
Training for 600 epoch: 79.64473684210526
Training for 1000 epoch: 79.16447368421052
Training for 300 epoch: 80.5775
Training for 600 epoch: 79.7125
Training for 1000 epoch: 79.05666666666667
[[80.89473684210526, 79.64473684210526, 79.16447368421052], [80.5775, 79.7125, 79.05666666666667]]
train loss 0.2808151486635208, epoch 354, best loss 0.2576794367790222, best_epoch 309
GPU_0_using curriculum 20 with window 20
Epoch: [355][20/40]	Time  1.506 ( 1.533)	Data  0.029 ( 0.041)	InnerLoop  0.643 ( 0.654)	Loss 5.0029e-01 (5.6458e-01)	Acc@1  82.88 ( 79.86)
Epoch: [355][40/40]	Time  1.502 ( 1.538)	Data  0.012 ( 0.038)	InnerLoop  0.648 ( 0.659)	Loss 5.4272e-01 (5.8311e-01)	Acc@1  79.69 ( 79.32)
The current update step is 14240
GPU_0_using curriculum 20 with window 20
Epoch: [356][20/40]	Time  1.670 ( 1.546)	Data  0.028 ( 0.048)	InnerLoop  0.781 ( 0.658)	Loss 4.9145e-01 (5.9291e-01)	Acc@1  82.29 ( 78.07)
Epoch: [356][40/40]	Time  1.494 ( 1.544)	Data  0.013 ( 0.044)	InnerLoop  0.648 ( 0.658)	Loss 6.8824e-01 (5.7278e-01)	Acc@1  76.56 ( 79.10)
The current update step is 14280
GPU_0_using curriculum 20 with window 20
Epoch: [357][20/40]	Time  1.502 ( 1.536)	Data  0.030 ( 0.048)	InnerLoop  0.638 ( 0.649)	Loss 5.2160e-01 (5.5311e-01)	Acc@1  80.86 ( 79.73)
Epoch: [357][40/40]	Time  1.494 ( 1.534)	Data  0.011 ( 0.041)	InnerLoop  0.641 ( 0.654)	Loss 5.7269e-01 (5.5140e-01)	Acc@1  80.21 ( 79.94)
The current update step is 14320
GPU_0_using curriculum 20 with window 20
Epoch: [358][20/40]	Time  1.515 ( 1.532)	Data  0.028 ( 0.041)	InnerLoop  0.647 ( 0.657)	Loss 4.8549e-01 (5.6162e-01)	Acc@1  82.45 ( 79.14)
Epoch: [358][40/40]	Time  1.490 ( 1.532)	Data  0.011 ( 0.040)	InnerLoop  0.639 ( 0.655)	Loss 5.6170e-01 (5.8285e-01)	Acc@1  80.73 ( 78.22)
The current update step is 14360
GPU_0_using curriculum 20 with window 20
Epoch: [359][20/40]	Time  1.521 ( 1.534)	Data  0.032 ( 0.041)	InnerLoop  0.649 ( 0.657)	Loss 6.5048e-01 (5.9237e-01)	Acc@1  77.02 ( 77.61)
Epoch: [359][40/40]	Time  1.483 ( 1.538)	Data  0.011 ( 0.041)	InnerLoop  0.639 ( 0.659)	Loss 4.7370e-01 (6.0142e-01)	Acc@1  82.81 ( 77.42)
The current update step is 14400
The current seed is 3075762878732613823
The current lr is: 0.001
Testing Results:
 *   Acc@1 80.500
 *   Acc@1 80.540
 *   Acc@1 79.855
 *   Acc@1 79.711
 *   Acc@1 78.539
 *   Acc@1 78.555
 *   Acc@1 80.724
 *   Acc@1 81.075
 *   Acc@1 79.842
 *   Acc@1 79.804
 *   Acc@1 79.421
 *   Acc@1 79.537
Training for 300 epoch: 80.61184210526315
Training for 600 epoch: 79.84868421052632
Training for 1000 epoch: 78.98026315789474
Training for 300 epoch: 80.8075
Training for 600 epoch: 79.7575
Training for 1000 epoch: 79.04583333333333
[[80.61184210526315, 79.84868421052632, 78.98026315789474], [80.8075, 79.7575, 79.04583333333333]]
train loss 0.3046865889072418, epoch 359, best loss 0.2576794367790222, best_epoch 309
GPU_0_using curriculum 20 with window 20
Epoch: [360][20/40]	Time  1.514 ( 1.537)	Data  0.028 ( 0.041)	InnerLoop  0.640 ( 0.659)	Loss 5.7442e-01 (5.8795e-01)	Acc@1  77.31 ( 78.15)
Epoch: [360][40/40]	Time  1.519 ( 1.536)	Data  0.015 ( 0.041)	InnerLoop  0.658 ( 0.656)	Loss 4.5930e-01 (5.9450e-01)	Acc@1  81.77 ( 77.86)
The current update step is 14440
GPU_0_using curriculum 20 with window 20
Epoch: [361][20/40]	Time  1.508 ( 1.529)	Data  0.030 ( 0.046)	InnerLoop  0.634 ( 0.647)	Loss 5.6764e-01 (5.8737e-01)	Acc@1  79.36 ( 78.88)
Epoch: [361][40/40]	Time  1.617 ( 1.536)	Data  0.013 ( 0.040)	InnerLoop  0.761 ( 0.657)	Loss 5.6922e-01 (5.8106e-01)	Acc@1  79.69 ( 78.78)
The current update step is 14480
GPU_0_using curriculum 20 with window 20
Epoch: [362][20/40]	Time  1.511 ( 1.535)	Data  0.027 ( 0.041)	InnerLoop  0.642 ( 0.654)	Loss 5.9917e-01 (5.9538e-01)	Acc@1  78.35 ( 78.13)
Epoch: [362][40/40]	Time  1.508 ( 1.536)	Data  0.011 ( 0.041)	InnerLoop  0.654 ( 0.655)	Loss 6.8762e-01 (5.8701e-01)	Acc@1  71.35 ( 78.71)
The current update step is 14520
GPU_0_using curriculum 20 with window 20
Epoch: [363][20/40]	Time  1.515 ( 1.542)	Data  0.029 ( 0.047)	InnerLoop  0.644 ( 0.655)	Loss 6.4444e-01 (6.2316e-01)	Acc@1  76.01 ( 77.55)
Epoch: [363][40/40]	Time  1.499 ( 1.538)	Data  0.013 ( 0.044)	InnerLoop  0.645 ( 0.655)	Loss 4.4293e-01 (6.0792e-01)	Acc@1  84.38 ( 77.95)
The current update step is 14560
GPU_0_using curriculum 20 with window 20
Epoch: [364][20/40]	Time  1.614 ( 1.529)	Data  0.028 ( 0.040)	InnerLoop  0.753 ( 0.655)	Loss 5.8291e-01 (5.9739e-01)	Acc@1  74.38 ( 77.97)
Epoch: [364][40/40]	Time  1.469 ( 1.524)	Data  0.012 ( 0.040)	InnerLoop  0.636 ( 0.651)	Loss 5.3334e-01 (5.9196e-01)	Acc@1  85.94 ( 78.35)
The current update step is 14600
The current seed is 6494624340379662977
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.987
 *   Acc@1 78.268
 *   Acc@1 76.961
 *   Acc@1 77.817
 *   Acc@1 76.803
 *   Acc@1 77.302
 *   Acc@1 81.105
 *   Acc@1 81.907
 *   Acc@1 80.474
 *   Acc@1 81.580
 *   Acc@1 80.237
 *   Acc@1 80.943
Training for 300 epoch: 79.54605263157896
Training for 600 epoch: 78.71710526315789
Training for 1000 epoch: 78.51973684210526
Training for 300 epoch: 80.08791666666667
Training for 600 epoch: 79.69833333333332
Training for 1000 epoch: 79.1225
[[79.54605263157896, 78.71710526315789, 78.51973684210526], [80.08791666666667, 79.69833333333332, 79.1225]]
train loss 0.2754593330860138, epoch 364, best loss 0.2576794367790222, best_epoch 309
GPU_0_using curriculum 20 with window 20
Epoch: [365][20/40]	Time  1.486 ( 1.504)	Data  0.028 ( 0.033)	InnerLoop  0.626 ( 0.647)	Loss 5.7597e-01 (6.0258e-01)	Acc@1  80.37 ( 78.71)
Epoch: [365][40/40]	Time  1.466 ( 1.508)	Data  0.012 ( 0.035)	InnerLoop  0.632 ( 0.647)	Loss 4.9152e-01 (5.8216e-01)	Acc@1  79.69 ( 78.99)
The current update step is 14640
GPU_0_using curriculum 20 with window 20
Epoch: [366][20/40]	Time  1.485 ( 1.504)	Data  0.027 ( 0.033)	InnerLoop  0.630 ( 0.646)	Loss 6.3054e-01 (5.6740e-01)	Acc@1  75.39 ( 79.03)
Epoch: [366][40/40]	Time  1.455 ( 1.505)	Data  0.011 ( 0.036)	InnerLoop  0.626 ( 0.643)	Loss 5.3599e-01 (5.6929e-01)	Acc@1  81.25 ( 79.06)
The current update step is 14680
GPU_0_using curriculum 20 with window 20
Epoch: [367][20/40]	Time  1.597 ( 1.507)	Data  0.027 ( 0.039)	InnerLoop  0.742 ( 0.645)	Loss 4.9991e-01 (5.6164e-01)	Acc@1  81.97 ( 79.50)
Epoch: [367][40/40]	Time  1.474 ( 1.505)	Data  0.013 ( 0.038)	InnerLoop  0.634 ( 0.642)	Loss 5.3038e-01 (5.6408e-01)	Acc@1  81.25 ( 79.42)
The current update step is 14720
GPU_0_using curriculum 20 with window 20
Epoch: [368][20/40]	Time  1.481 ( 1.501)	Data  0.026 ( 0.032)	InnerLoop  0.630 ( 0.645)	Loss 5.6455e-01 (5.9353e-01)	Acc@1  80.08 ( 78.38)
Epoch: [368][40/40]	Time  1.467 ( 1.505)	Data  0.011 ( 0.035)	InnerLoop  0.632 ( 0.645)	Loss 7.5810e-01 (5.8781e-01)	Acc@1  75.52 ( 78.73)
The current update step is 14760
GPU_0_using curriculum 20 with window 20
Epoch: [369][20/40]	Time  1.478 ( 1.502)	Data  0.028 ( 0.039)	InnerLoop  0.624 ( 0.639)	Loss 5.5162e-01 (5.7427e-01)	Acc@1  79.04 ( 78.62)
Epoch: [369][40/40]	Time  1.463 ( 1.504)	Data  0.010 ( 0.035)	InnerLoop  0.627 ( 0.643)	Loss 4.2669e-01 (5.6617e-01)	Acc@1  82.81 ( 79.19)
The current update step is 14800
The current seed is 16369567142017373094
The current lr is: 0.001
Testing Results:
 *   Acc@1 78.237
 *   Acc@1 79.025
 *   Acc@1 77.145
 *   Acc@1 77.802
 *   Acc@1 75.342
 *   Acc@1 75.922
 *   Acc@1 78.303
 *   Acc@1 78.858
 *   Acc@1 76.711
 *   Acc@1 77.317
 *   Acc@1 75.947
 *   Acc@1 76.481
Training for 300 epoch: 78.26973684210526
Training for 600 epoch: 76.92763157894737
Training for 1000 epoch: 75.64473684210526
Training for 300 epoch: 78.94166666666666
Training for 600 epoch: 77.56
Training for 1000 epoch: 76.20125
[[78.26973684210526, 76.92763157894737, 75.64473684210526], [78.94166666666666, 77.56, 76.20125]]
train loss 0.38155602746009826, epoch 369, best loss 0.2576794367790222, best_epoch 369
GPU_0_using curriculum 20 with window 20
Epoch: [370][20/40]	Time  1.514 ( 1.518)	Data  0.030 ( 0.040)	InnerLoop  0.640 ( 0.646)	Loss 4.8079e-01 (5.6625e-01)	Acc@1  83.17 ( 79.33)
Epoch: [370][40/40]	Time  1.482 ( 1.520)	Data  0.011 ( 0.037)	InnerLoop  0.640 ( 0.650)	Loss 4.8850e-01 (5.7525e-01)	Acc@1  82.29 ( 78.89)
The current update step is 14840
GPU_0_using curriculum 20 with window 20
Epoch: [371][20/40]	Time  1.647 ( 1.528)	Data  0.028 ( 0.046)	InnerLoop  0.768 ( 0.650)	Loss 4.9490e-01 (5.7517e-01)	Acc@1  81.61 ( 79.26)
Epoch: [371][40/40]	Time  1.508 ( 1.533)	Data  0.014 ( 0.043)	InnerLoop  0.657 ( 0.652)	Loss 4.6726e-01 (5.5954e-01)	Acc@1  81.77 ( 79.54)
The current update step is 14880
GPU_0_using curriculum 20 with window 20
Epoch: [372][20/40]	Time  1.511 ( 1.539)	Data  0.028 ( 0.047)	InnerLoop  0.644 ( 0.651)	Loss 5.1595e-01 (5.5592e-01)	Acc@1  81.64 ( 79.73)
Epoch: [372][40/40]	Time  1.507 ( 1.540)	Data  0.014 ( 0.041)	InnerLoop  0.644 ( 0.656)	Loss 5.6859e-01 (5.5221e-01)	Acc@1  79.69 ( 79.76)
The current update step is 14920
GPU_0_using curriculum 20 with window 20
Epoch: [373][20/40]	Time  1.523 ( 1.546)	Data  0.028 ( 0.042)	InnerLoop  0.649 ( 0.665)	Loss 4.7192e-01 (5.2888e-01)	Acc@1  82.75 ( 80.60)
Epoch: [373][40/40]	Time  1.509 ( 1.542)	Data  0.011 ( 0.041)	InnerLoop  0.652 ( 0.661)	Loss 4.8716e-01 (5.3787e-01)	Acc@1  84.90 ( 80.51)
The current update step is 14960
GPU_0_using curriculum 20 with window 20
Epoch: [374][20/40]	Time  1.509 ( 1.533)	Data  0.028 ( 0.041)	InnerLoop  0.643 ( 0.653)	Loss 5.1773e-01 (5.5050e-01)	Acc@1  82.06 ( 79.96)
Epoch: [374][40/40]	Time  1.470 ( 1.537)	Data  0.013 ( 0.041)	InnerLoop  0.635 ( 0.657)	Loss 4.7613e-01 (5.4710e-01)	Acc@1  83.33 ( 80.14)
The current update step is 15000
The current seed is 8820211788171173733
The current lr is: 0.001
Testing Results:
 *   Acc@1 78.579
 *   Acc@1 78.896
 *   Acc@1 76.592
 *   Acc@1 76.963
 *   Acc@1 75.434
 *   Acc@1 75.502
 *   Acc@1 79.750
 *   Acc@1 80.397
 *   Acc@1 79.658
 *   Acc@1 79.785
 *   Acc@1 78.237
 *   Acc@1 79.127
Training for 300 epoch: 79.16447368421052
Training for 600 epoch: 78.125
Training for 1000 epoch: 76.83552631578948
Training for 300 epoch: 79.64666666666666
Training for 600 epoch: 78.37416666666667
Training for 1000 epoch: 77.31416666666667
[[79.16447368421052, 78.125, 76.83552631578948], [79.64666666666666, 78.37416666666667, 77.31416666666667]]
train loss 0.32507250003814697, epoch 374, best loss 0.2576794367790222, best_epoch 369
GPU_0_using curriculum 20 with window 20
Epoch: [375][20/40]	Time  1.511 ( 1.534)	Data  0.027 ( 0.041)	InnerLoop  0.647 ( 0.656)	Loss 5.6500e-01 (5.6849e-01)	Acc@1  78.45 ( 79.41)
Epoch: [375][40/40]	Time  1.491 ( 1.532)	Data  0.013 ( 0.040)	InnerLoop  0.637 ( 0.654)	Loss 5.6378e-01 (5.5383e-01)	Acc@1  79.17 ( 79.72)
The current update step is 15040
GPU_0_using curriculum 20 with window 20
Epoch: [376][20/40]	Time  1.513 ( 1.530)	Data  0.028 ( 0.047)	InnerLoop  0.647 ( 0.647)	Loss 5.0287e-01 (5.3920e-01)	Acc@1  82.45 ( 80.09)
Epoch: [376][40/40]	Time  1.595 ( 1.534)	Data  0.013 ( 0.040)	InnerLoop  0.746 ( 0.656)	Loss 5.3144e-01 (5.4477e-01)	Acc@1  78.65 ( 80.27)
The current update step is 15080
GPU_0_using curriculum 20 with window 20
Epoch: [377][20/40]	Time  1.507 ( 1.526)	Data  0.030 ( 0.042)	InnerLoop  0.643 ( 0.651)	Loss 5.1440e-01 (5.3164e-01)	Acc@1  80.44 ( 80.86)
Epoch: [377][40/40]	Time  1.495 ( 1.530)	Data  0.011 ( 0.041)	InnerLoop  0.653 ( 0.652)	Loss 6.0131e-01 (5.3818e-01)	Acc@1  82.81 ( 80.53)
The current update step is 15120
GPU_0_using curriculum 20 with window 20
Epoch: [378][20/40]	Time  1.511 ( 1.535)	Data  0.029 ( 0.047)	InnerLoop  0.637 ( 0.652)	Loss 6.1016e-01 (5.2933e-01)	Acc@1  77.41 ( 80.66)
Epoch: [378][40/40]	Time  1.503 ( 1.533)	Data  0.014 ( 0.043)	InnerLoop  0.655 ( 0.651)	Loss 5.6707e-01 (5.4033e-01)	Acc@1  78.12 ( 80.30)
The current update step is 15160
GPU_0_using curriculum 20 with window 20
Epoch: [379][20/40]	Time  1.623 ( 1.531)	Data  0.029 ( 0.041)	InnerLoop  0.748 ( 0.655)	Loss 6.1189e-01 (5.3676e-01)	Acc@1  80.08 ( 80.79)
Epoch: [379][40/40]	Time  1.508 ( 1.532)	Data  0.012 ( 0.041)	InnerLoop  0.654 ( 0.654)	Loss 7.2991e-01 (5.5100e-01)	Acc@1  78.12 ( 80.30)
The current update step is 15200
The current seed is 8967195479747082916
The current lr is: 0.001
Testing Results:
 *   Acc@1 75.921
 *   Acc@1 76.003
 *   Acc@1 76.105
 *   Acc@1 76.050
 *   Acc@1 76.382
 *   Acc@1 76.211
 *   Acc@1 80.908
 *   Acc@1 81.033
 *   Acc@1 79.934
 *   Acc@1 80.231
 *   Acc@1 79.184
 *   Acc@1 79.173
Training for 300 epoch: 78.41447368421052
Training for 600 epoch: 78.01973684210526
Training for 1000 epoch: 77.78289473684211
Training for 300 epoch: 78.51833333333333
Training for 600 epoch: 78.14041666666667
Training for 1000 epoch: 77.69208333333333
[[78.41447368421052, 78.01973684210526, 77.78289473684211], [78.51833333333333, 78.14041666666667, 77.69208333333333]]
train loss 0.3034723182678223, epoch 379, best loss 0.2576794367790222, best_epoch 369
GPU_0_using curriculum 20 with window 20
Epoch: [380][20/40]	Time  1.513 ( 1.533)	Data  0.027 ( 0.035)	InnerLoop  0.647 ( 0.659)	Loss 4.7405e-01 (5.7887e-01)	Acc@1  82.98 ( 78.83)
Epoch: [380][40/40]	Time  1.488 ( 1.538)	Data  0.011 ( 0.038)	InnerLoop  0.652 ( 0.660)	Loss 5.6080e-01 (5.6339e-01)	Acc@1  79.17 ( 79.39)
The current update step is 15240
GPU_0_using curriculum 20 with window 20
Epoch: [381][20/40]	Time  1.516 ( 1.531)	Data  0.028 ( 0.035)	InnerLoop  0.645 ( 0.659)	Loss 4.9632e-01 (5.3991e-01)	Acc@1  82.16 ( 80.59)
Epoch: [381][40/40]	Time  1.481 ( 1.527)	Data  0.012 ( 0.037)	InnerLoop  0.637 ( 0.654)	Loss 6.2180e-01 (5.4186e-01)	Acc@1  80.21 ( 80.34)
The current update step is 15280
GPU_0_using curriculum 20 with window 20
Epoch: [382][20/40]	Time  1.605 ( 1.523)	Data  0.028 ( 0.040)	InnerLoop  0.748 ( 0.652)	Loss 5.7919e-01 (5.4101e-01)	Acc@1  79.59 ( 80.38)
Epoch: [382][40/40]	Time  1.466 ( 1.514)	Data  0.011 ( 0.039)	InnerLoop  0.631 ( 0.646)	Loss 5.5878e-01 (5.4486e-01)	Acc@1  78.12 ( 80.17)
The current update step is 15320
GPU_0_using curriculum 20 with window 20
Epoch: [383][20/40]	Time  1.485 ( 1.502)	Data  0.028 ( 0.033)	InnerLoop  0.630 ( 0.645)	Loss 4.5861e-01 (5.3946e-01)	Acc@1  83.43 ( 80.43)
Epoch: [383][40/40]	Time  1.477 ( 1.507)	Data  0.011 ( 0.036)	InnerLoop  0.638 ( 0.646)	Loss 6.2285e-01 (5.4798e-01)	Acc@1  77.08 ( 79.94)
The current update step is 15360
GPU_0_using curriculum 20 with window 20
Epoch: [384][20/40]	Time  1.481 ( 1.505)	Data  0.026 ( 0.039)	InnerLoop  0.631 ( 0.641)	Loss 5.0501e-01 (5.3237e-01)	Acc@1  81.61 ( 80.80)
Epoch: [384][40/40]	Time  1.480 ( 1.505)	Data  0.011 ( 0.036)	InnerLoop  0.639 ( 0.644)	Loss 5.6479e-01 (5.3526e-01)	Acc@1  78.12 ( 80.69)
The current update step is 15400
The current seed is 4237417158496028093
The current lr is: 0.001
Testing Results:
 *   Acc@1 80.842
 *   Acc@1 81.217
 *   Acc@1 79.868
 *   Acc@1 80.118
 *   Acc@1 78.526
 *   Acc@1 79.185
 *   Acc@1 78.263
 *   Acc@1 78.413
 *   Acc@1 77.737
 *   Acc@1 77.993
 *   Acc@1 77.447
 *   Acc@1 77.728
Training for 300 epoch: 79.55263157894737
Training for 600 epoch: 78.80263157894737
Training for 1000 epoch: 77.98684210526315
Training for 300 epoch: 79.815
Training for 600 epoch: 79.05583333333334
Training for 1000 epoch: 78.45666666666668
[[79.55263157894737, 78.80263157894737, 77.98684210526315], [79.815, 79.05583333333334, 78.45666666666668]]
train loss 0.4108497341632843, epoch 384, best loss 0.2576794367790222, best_epoch 369
GPU_0_using curriculum 20 with window 20
Epoch: [385][20/40]	Time  1.482 ( 1.506)	Data  0.025 ( 0.039)	InnerLoop  0.627 ( 0.641)	Loss 5.9784e-01 (5.1680e-01)	Acc@1  77.64 ( 81.42)
Epoch: [385][40/40]	Time  1.462 ( 1.506)	Data  0.011 ( 0.036)	InnerLoop  0.623 ( 0.644)	Loss 4.7794e-01 (5.2222e-01)	Acc@1  82.29 ( 81.13)
The current update step is 15440
GPU_0_using curriculum 20 with window 20
Epoch: [386][20/40]	Time  1.607 ( 1.513)	Data  0.027 ( 0.045)	InnerLoop  0.749 ( 0.641)	Loss 5.0959e-01 (5.4509e-01)	Acc@1  80.63 ( 80.06)
Epoch: [386][40/40]	Time  1.476 ( 1.509)	Data  0.011 ( 0.041)	InnerLoop  0.642 ( 0.642)	Loss 5.2102e-01 (5.3718e-01)	Acc@1  80.21 ( 80.36)
The current update step is 15480
GPU_0_using curriculum 20 with window 20
Epoch: [387][20/40]	Time  1.482 ( 1.503)	Data  0.026 ( 0.044)	InnerLoop  0.628 ( 0.634)	Loss 5.8392e-01 (5.4060e-01)	Acc@1  77.99 ( 80.01)
Epoch: [387][40/40]	Time  1.477 ( 1.507)	Data  0.011 ( 0.039)	InnerLoop  0.634 ( 0.642)	Loss 3.8434e-01 (5.3032e-01)	Acc@1  86.98 ( 80.73)
The current update step is 15520
GPU_0_using curriculum 20 with window 20
Epoch: [388][20/40]	Time  1.482 ( 1.525)	Data  0.027 ( 0.040)	InnerLoop  0.630 ( 0.654)	Loss 6.4370e-01 (5.3414e-01)	Acc@1  76.76 ( 80.65)
Epoch: [388][40/40]	Time  1.489 ( 1.521)	Data  0.013 ( 0.040)	InnerLoop  0.646 ( 0.650)	Loss 5.0004e-01 (5.4053e-01)	Acc@1  82.29 ( 80.51)
The current update step is 15560
GPU_0_using curriculum 20 with window 20
Epoch: [389][20/40]	Time  1.506 ( 1.528)	Data  0.027 ( 0.041)	InnerLoop  0.639 ( 0.650)	Loss 5.0306e-01 (5.2193e-01)	Acc@1  81.41 ( 81.25)
Epoch: [389][40/40]	Time  1.502 ( 1.538)	Data  0.011 ( 0.041)	InnerLoop  0.652 ( 0.656)	Loss 4.3479e-01 (5.3077e-01)	Acc@1  82.81 ( 80.70)
The current update step is 15600
The current seed is 186848316791933469
The current lr is: 0.001
Testing Results:
 *   Acc@1 79.539
 *   Acc@1 79.287
 *   Acc@1 78.987
 *   Acc@1 79.046
 *   Acc@1 77.658
 *   Acc@1 77.899
 *   Acc@1 79.329
 *   Acc@1 79.381
 *   Acc@1 78.276
 *   Acc@1 78.371
 *   Acc@1 77.105
 *   Acc@1 77.422
Training for 300 epoch: 79.43421052631578
Training for 600 epoch: 78.63157894736842
Training for 1000 epoch: 77.38157894736842
Training for 300 epoch: 79.33375
Training for 600 epoch: 78.70833333333334
Training for 1000 epoch: 77.66041666666666
[[79.43421052631578, 78.63157894736842, 77.38157894736842], [79.33375, 78.70833333333334, 77.66041666666666]]
train loss 0.3465651189804077, epoch 389, best loss 0.2576794367790222, best_epoch 369
GPU_0_using curriculum 20 with window 20
Epoch: [390][20/40]	Time  1.495 ( 1.552)	Data  0.027 ( 0.041)	InnerLoop  0.632 ( 0.667)	Loss 5.7820e-01 (5.4307e-01)	Acc@1  79.17 ( 80.15)
Epoch: [390][40/40]	Time  1.510 ( 1.548)	Data  0.013 ( 0.041)	InnerLoop  0.650 ( 0.663)	Loss 5.0538e-01 (5.4249e-01)	Acc@1  82.29 ( 80.14)
The current update step is 15640
GPU_0_using curriculum 20 with window 20
Epoch: [391][20/40]	Time  1.520 ( 1.542)	Data  0.029 ( 0.048)	InnerLoop  0.650 ( 0.652)	Loss 6.3244e-01 (5.6592e-01)	Acc@1  76.60 ( 79.28)
Epoch: [391][40/40]	Time  1.644 ( 1.545)	Data  0.014 ( 0.041)	InnerLoop  0.785 ( 0.662)	Loss 6.7721e-01 (5.4074e-01)	Acc@1  73.44 ( 80.38)
The current update step is 15680
GPU_0_using curriculum 20 with window 20
Epoch: [392][20/40]	Time  1.507 ( 1.537)	Data  0.029 ( 0.041)	InnerLoop  0.645 ( 0.656)	Loss 5.9068e-01 (5.2867e-01)	Acc@1  77.60 ( 80.40)
Epoch: [392][40/40]	Time  1.495 ( 1.534)	Data  0.013 ( 0.041)	InnerLoop  0.649 ( 0.654)	Loss 6.0027e-01 (5.3909e-01)	Acc@1  79.69 ( 79.98)
The current update step is 15720
GPU_0_using curriculum 20 with window 20
Epoch: [393][20/40]	Time  1.509 ( 1.533)	Data  0.028 ( 0.046)	InnerLoop  0.630 ( 0.650)	Loss 5.2220e-01 (5.2779e-01)	Acc@1  81.84 ( 80.88)
Epoch: [393][40/40]	Time  1.499 ( 1.533)	Data  0.011 ( 0.043)	InnerLoop  0.639 ( 0.652)	Loss 1.3215e+00 (5.5284e-01)	Acc@1  61.46 ( 79.74)
The current update step is 15760
GPU_0_using curriculum 20 with window 20
Epoch: [394][20/40]	Time  1.634 ( 1.536)	Data  0.030 ( 0.042)	InnerLoop  0.768 ( 0.657)	Loss 5.4855e-01 (5.6903e-01)	Acc@1  79.46 ( 78.57)
Epoch: [394][40/40]	Time  1.496 ( 1.537)	Data  0.011 ( 0.041)	InnerLoop  0.645 ( 0.657)	Loss 5.4495e-01 (5.8911e-01)	Acc@1  79.17 ( 78.13)
The current update step is 15800
The current seed is 14531829879883557469
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.263
 *   Acc@1 77.464
 *   Acc@1 75.632
 *   Acc@1 75.753
 *   Acc@1 74.921
 *   Acc@1 74.657
 *   Acc@1 80.579
 *   Acc@1 81.098
 *   Acc@1 79.737
 *   Acc@1 79.948
 *   Acc@1 78.474
 *   Acc@1 79.362
Training for 300 epoch: 78.92105263157895
Training for 600 epoch: 77.6842105263158
Training for 1000 epoch: 76.69736842105263
Training for 300 epoch: 79.28125
Training for 600 epoch: 77.85083333333333
Training for 1000 epoch: 77.00958333333332
[[78.92105263157895, 77.6842105263158, 76.69736842105263], [79.28125, 77.85083333333333, 77.00958333333332]]
train loss 0.28287454833984377, epoch 394, best loss 0.2576794367790222, best_epoch 369
GPU_0_using curriculum 20 with window 20
Epoch: [395][20/40]	Time  1.517 ( 1.545)	Data  0.029 ( 0.036)	InnerLoop  0.646 ( 0.665)	Loss 5.5105e-01 (5.9368e-01)	Acc@1  80.70 ( 78.69)
Epoch: [395][40/40]	Time  1.496 ( 1.543)	Data  0.013 ( 0.038)	InnerLoop  0.638 ( 0.663)	Loss 5.6683e-01 (5.8329e-01)	Acc@1  78.12 ( 78.89)
The current update step is 15840
GPU_0_using curriculum 20 with window 20
Epoch: [396][20/40]	Time  1.503 ( 1.527)	Data  0.029 ( 0.035)	InnerLoop  0.638 ( 0.657)	Loss 5.6122e-01 (5.6613e-01)	Acc@1  78.78 ( 79.65)
Epoch: [396][40/40]	Time  1.493 ( 1.532)	Data  0.014 ( 0.038)	InnerLoop  0.645 ( 0.657)	Loss 5.5334e-01 (5.8232e-01)	Acc@1  77.60 ( 79.24)
The current update step is 15880
GPU_0_using curriculum 20 with window 20
Epoch: [397][20/40]	Time  1.639 ( 1.543)	Data  0.030 ( 0.041)	InnerLoop  0.761 ( 0.662)	Loss 5.9729e-01 (5.8469e-01)	Acc@1  75.16 ( 77.97)
Epoch: [397][40/40]	Time  1.504 ( 1.542)	Data  0.014 ( 0.041)	InnerLoop  0.647 ( 0.659)	Loss 5.7048e-01 (5.9144e-01)	Acc@1  80.21 ( 78.27)
The current update step is 15920
GPU_0_using curriculum 20 with window 20
Epoch: [398][20/40]	Time  1.524 ( 1.538)	Data  0.032 ( 0.036)	InnerLoop  0.649 ( 0.661)	Loss 5.9045e-01 (5.6389e-01)	Acc@1  79.26 ( 79.37)
Epoch: [398][40/40]	Time  1.472 ( 1.540)	Data  0.013 ( 0.038)	InnerLoop  0.632 ( 0.661)	Loss 5.7579e-01 (5.5647e-01)	Acc@1  81.77 ( 79.82)
The current update step is 15960
GPU_0_using curriculum 20 with window 20
Epoch: [399][20/40]	Time  1.519 ( 1.534)	Data  0.031 ( 0.041)	InnerLoop  0.643 ( 0.653)	Loss 5.6812e-01 (5.2451e-01)	Acc@1  78.58 ( 80.79)
Epoch: [399][40/40]	Time  1.476 ( 1.529)	Data  0.013 ( 0.038)	InnerLoop  0.633 ( 0.654)	Loss 5.0803e-01 (5.4354e-01)	Acc@1  78.12 ( 80.30)
The current update step is 16000
The current seed is 1402614982974311383
The current lr is: 0.001
Testing Results:
 *   Acc@1 80.724
 *   Acc@1 81.488
 *   Acc@1 80.553
 *   Acc@1 80.840
 *   Acc@1 79.461
 *   Acc@1 79.768
 *   Acc@1 75.684
 *   Acc@1 75.928
 *   Acc@1 73.855
 *   Acc@1 73.722
 *   Acc@1 71.789
 *   Acc@1 71.928
Training for 300 epoch: 78.20394736842105
Training for 600 epoch: 77.20394736842105
Training for 1000 epoch: 75.625
Training for 300 epoch: 78.70833333333333
Training for 600 epoch: 77.28083333333333
Training for 1000 epoch: 75.84833333333333
[[78.20394736842105, 77.20394736842105, 75.625], [78.70833333333333, 77.28083333333333, 75.84833333333333]]
train loss 0.45822580280303954, epoch 399, best loss 0.2576794367790222, best_epoch 369
=== Final results:
{'acc': 81.54605263157895, 'test': [81.54605263157895, 79.75657894736841, 77.50657894736842], 'train': [81.54605263157895, 79.75657894736841, 77.50657894736842], 'ind': 0, 'epoch': 315, 'data': array([[-0.10035373, -0.06410737, -0.02328905, ..., -0.14665104,
         0.02280301, -0.05804049],
       [ 0.03971281,  0.05492638,  0.07246155, ..., -0.24573034,
        -0.03302404,  0.09717482],
       [-0.1287838 ,  0.10316641, -0.03465387, ..., -0.00906881,
         0.15016834, -0.03279026],
       ...,
       [ 0.0241521 ,  0.01229874,  0.02538638, ..., -0.22292992,
        -0.0299221 , -0.01060028],
       [ 0.05190042,  0.06817795, -0.01256053, ..., -0.1298631 ,
        -0.13726188,  0.04740765],
       [-0.08317333,  0.03044346,  0.05189836, ...,  0.02775593,
         0.04221001, -0.02820327]], shape=(80, 768), dtype=float32)}
