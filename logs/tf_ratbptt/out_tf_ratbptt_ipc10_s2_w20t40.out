Torch Seed Specified with rank: 0
Dataset: agnews_emb
Dataset Path: ./scripts
Namespace(seed=0, mp_distributed=False, world_size=1, rank=0, dist_url='tcp://224.66.41.62:23456', dist_backend='nccl', workers=0, gpu=None, root='./scripts', dataset='agnews_emb', arch='text_transformer', width=256, lr=0.001, inner_optim='Adam', outer_optim='Adam', inner_lr=0.001, label_lr_scale=1, num_per_class=10, batch_per_class=8, task_sampler_nc=4, window=20, minwindow=0, totwindow=40, num_train_eval=2, train_y=False, batch_size=2048, eps=1e-08, wd=0, test_freq=5, print_freq=20, start_epoch=0, epochs=150, ddtype='standard', cctype=0, zca=False, wandb=False, clip_coef=0.9, fname='out_tf_ratbptt_ipc10_s2_w20t40', out_dir='./checkpoints', name='agnews_tf_ratbptt_s2_w20t40', comp_aug=False, comp_aug_real=False, syn_strategy='none', real_strategy='none', ckptname='none', limit_train=False, load_ckpt=False, complete_random=False, boost_dd=False, boost_init_from='none', boost_beta=1.0, stage=2, distributed=False, data_root='./scripts/agnews_emb')
==> Preparing data..
None None
Dataset: number of classes: 4
Training set size: 120000
Image size: channel 1, height 768, width 1
Synthetic images, not_single False, keys []
==> Building model..
Initialized data with size, x: torch.Size([40, 768]), y:torch.Size([40])
TextTransformer(
  (input_proj): Linear(in_features=192, out_features=256, bias=True)
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=1024, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=1024, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (cls_head): Linear(in_features=256, out_features=4, bias=True)
)
use data parallel only
GPU_0_using curriculum 20 with window 20
Epoch: [0][20/59]	Time  1.584 ( 1.684)	Data  0.022 ( 0.030)	InnerLoop  0.667 ( 0.736)	Loss 2.2008e+00 (3.6362e+00)	Acc@1  39.45 ( 33.07)
Epoch: [0][40/59]	Time  1.602 ( 1.645)	Data  0.021 ( 0.029)	InnerLoop  0.674 ( 0.709)	Loss 1.6487e+00 (2.6772e+00)	Acc@1  40.09 ( 37.74)
The current update step is 59
GPU_0_using curriculum 20 with window 20
Epoch: [1][20/59]	Time  1.566 ( 1.588)	Data  0.022 ( 0.029)	InnerLoop  0.654 ( 0.674)	Loss 1.1872e+00 (1.3626e+00)	Acc@1  58.79 ( 53.22)
Epoch: [1][40/59]	Time  1.543 ( 1.585)	Data  0.023 ( 0.028)	InnerLoop  0.648 ( 0.672)	Loss 1.0669e+00 (1.3234e+00)	Acc@1  54.83 ( 53.30)
The current update step is 118
GPU_0_using curriculum 20 with window 20
Epoch: [2][20/59]	Time  1.556 ( 1.571)	Data  0.023 ( 0.022)	InnerLoop  0.650 ( 0.670)	Loss 7.6286e-01 (1.0445e+00)	Acc@1  71.88 ( 62.28)
Epoch: [2][40/59]	Time  1.533 ( 1.573)	Data  0.022 ( 0.024)	InnerLoop  0.644 ( 0.669)	Loss 1.1371e+00 (1.0489e+00)	Acc@1  59.38 ( 61.55)
The current update step is 177
GPU_0_using curriculum 20 with window 20
Epoch: [3][20/59]	Time  1.682 ( 1.582)	Data  0.022 ( 0.033)	InnerLoop  0.774 ( 0.666)	Loss 1.2284e+00 (1.0238e+00)	Acc@1  63.62 ( 62.92)
Epoch: [3][40/59]	Time  1.492 ( 1.565)	Data  0.020 ( 0.030)	InnerLoop  0.630 ( 0.662)	Loss 8.6169e-01 (9.7232e-01)	Acc@1  66.85 ( 64.73)
The current update step is 236
GPU_0_using curriculum 20 with window 20
Epoch: [4][20/59]	Time  1.665 ( 1.541)	Data  0.139 ( 0.032)	InnerLoop  0.633 ( 0.652)	Loss 7.0601e-01 (9.6342e-01)	Acc@1  72.46 ( 65.71)
Epoch: [4][40/59]	Time  1.482 ( 1.529)	Data  0.017 ( 0.026)	InnerLoop  0.632 ( 0.652)	Loss 1.1283e+00 (9.7367e-01)	Acc@1  63.13 ( 65.46)
The current update step is 295
The current seed is 8263804195149112579
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.013
 *   Acc@1 73.796
 *   Acc@1 72.539
 *   Acc@1 73.395
 *   Acc@1 72.763
 *   Acc@1 73.559
 *   Acc@1 70.092
 *   Acc@1 70.437
 *   Acc@1 68.803
 *   Acc@1 69.537
 *   Acc@1 68.684
 *   Acc@1 69.389
Training for 300 epoch: 71.55263157894737
Training for 600 epoch: 70.67105263157895
Training for 1000 epoch: 70.72368421052632
Training for 300 epoch: 72.11625000000001
Training for 600 epoch: 71.46583333333334
Training for 1000 epoch: 71.47416666666666
[[71.55263157894737, 70.67105263157895, 70.72368421052632], [72.11625000000001, 71.46583333333334, 71.47416666666666]]
train loss 0.5304936764717102, epoch 4, best loss 0.5304936764717102, best_epoch 4
GPU_0_using curriculum 20 with window 20
Epoch: [5][20/59]	Time  1.480 ( 1.508)	Data  0.017 ( 0.025)	InnerLoop  0.632 ( 0.652)	Loss 6.3179e-01 (8.3204e-01)	Acc@1  77.88 ( 69.84)
Epoch: [5][40/59]	Time  1.461 ( 1.501)	Data  0.019 ( 0.022)	InnerLoop  0.618 ( 0.651)	Loss 1.1515e+00 (8.4642e-01)	Acc@1  64.01 ( 69.66)
The current update step is 354
GPU_0_using curriculum 20 with window 20
Epoch: [6][20/59]	Time  1.478 ( 1.488)	Data  0.021 ( 0.019)	InnerLoop  0.621 ( 0.644)	Loss 6.7941e-01 (9.1556e-01)	Acc@1  74.90 ( 68.09)
Epoch: [6][40/59]	Time  1.465 ( 1.493)	Data  0.018 ( 0.025)	InnerLoop  0.626 ( 0.641)	Loss 6.9873e-01 (9.0574e-01)	Acc@1  75.29 ( 68.20)
The current update step is 413
GPU_0_using curriculum 20 with window 20
Epoch: [7][20/59]	Time  1.456 ( 1.490)	Data  0.018 ( 0.032)	InnerLoop  0.621 ( 0.632)	Loss 7.9201e-01 (7.4307e-01)	Acc@1  69.63 ( 73.73)
Epoch: [7][40/59]	Time  1.458 ( 1.495)	Data  0.020 ( 0.029)	InnerLoop  0.623 ( 0.639)	Loss 6.5503e-01 (7.3923e-01)	Acc@1  75.93 ( 73.57)
The current update step is 472
GPU_0_using curriculum 20 with window 20
Epoch: [8][20/59]	Time  1.480 ( 1.491)	Data  0.021 ( 0.031)	InnerLoop  0.627 ( 0.632)	Loss 6.5333e-01 (7.7924e-01)	Acc@1  75.39 ( 70.49)
Epoch: [8][40/59]	Time  1.465 ( 1.497)	Data  0.021 ( 0.026)	InnerLoop  0.622 ( 0.641)	Loss 6.4300e-01 (8.7518e-01)	Acc@1  76.56 ( 69.29)
The current update step is 531
GPU_0_using curriculum 20 with window 20
Epoch: [9][20/59]	Time  1.458 ( 1.485)	Data  0.018 ( 0.032)	InnerLoop  0.619 ( 0.629)	Loss 6.8698e-01 (8.3320e-01)	Acc@1  72.90 ( 72.55)
Epoch: [9][40/59]	Time  1.578 ( 1.488)	Data  0.020 ( 0.025)	InnerLoop  0.736 ( 0.640)	Loss 5.7455e-01 (8.1217e-01)	Acc@1  79.93 ( 72.58)
The current update step is 590
The current seed is 12821767730809381330
The current lr is: 0.001
Testing Results:
 *   Acc@1 68.789
 *   Acc@1 68.918
 *   Acc@1 69.487
 *   Acc@1 69.072
 *   Acc@1 65.289
 *   Acc@1 65.695
 *   Acc@1 64.645
 *   Acc@1 64.995
 *   Acc@1 65.842
 *   Acc@1 65.276
 *   Acc@1 65.908
 *   Acc@1 66.192
Training for 300 epoch: 66.71710526315789
Training for 600 epoch: 67.66447368421052
Training for 1000 epoch: 65.59868421052632
Training for 300 epoch: 66.95666666666668
Training for 600 epoch: 67.17375000000001
Training for 1000 epoch: 65.94333333333333
[[66.71710526315789, 67.66447368421052, 65.59868421052632], [66.95666666666668, 67.17375000000001, 65.94333333333333]]
train loss 0.4993737615585327, epoch 9, best loss 0.4993737615585327, best_epoch 9
GPU_0_using curriculum 20 with window 20
Epoch: [10][20/59]	Time  1.581 ( 1.494)	Data  0.019 ( 0.025)	InnerLoop  0.735 ( 0.641)	Loss 1.0174e+00 (7.9890e-01)	Acc@1  65.67 ( 71.01)
Epoch: [10][40/59]	Time  1.454 ( 1.492)	Data  0.021 ( 0.022)	InnerLoop  0.614 ( 0.641)	Loss 8.3232e-01 (7.8567e-01)	Acc@1  70.80 ( 70.97)
The current update step is 649
GPU_0_using curriculum 20 with window 20
Epoch: [11][20/59]	Time  1.459 ( 1.483)	Data  0.019 ( 0.031)	InnerLoop  0.619 ( 0.626)	Loss 6.5406e-01 (7.6097e-01)	Acc@1  74.61 ( 71.64)
Epoch: [11][40/59]	Time  1.587 ( 1.486)	Data  0.019 ( 0.028)	InnerLoop  0.730 ( 0.631)	Loss 1.3708e+00 (7.9602e-01)	Acc@1  60.74 ( 70.90)
The current update step is 708
GPU_0_using curriculum 20 with window 20
Epoch: [12][20/59]	Time  1.493 ( 1.484)	Data  0.018 ( 0.025)	InnerLoop  0.635 ( 0.634)	Loss 5.8947e-01 (6.6427e-01)	Acc@1  79.35 ( 75.98)
Epoch: [12][40/59]	Time  1.475 ( 1.487)	Data  0.020 ( 0.025)	InnerLoop  0.624 ( 0.637)	Loss 6.0955e-01 (6.9440e-01)	Acc@1  77.34 ( 75.15)
The current update step is 767
GPU_0_using curriculum 20 with window 20
Epoch: [13][20/59]	Time  1.470 ( 1.481)	Data  0.019 ( 0.031)	InnerLoop  0.628 ( 0.627)	Loss 9.4203e-01 (7.1732e-01)	Acc@1  67.87 ( 74.44)
Epoch: [13][40/59]	Time  1.506 ( 1.485)	Data  0.017 ( 0.028)	InnerLoop  0.621 ( 0.632)	Loss 6.3797e-01 (7.8114e-01)	Acc@1  76.17 ( 72.73)
The current update step is 826
GPU_0_using curriculum 20 with window 20
Epoch: [14][20/59]	Time  1.484 ( 1.488)	Data  0.021 ( 0.032)	InnerLoop  0.636 ( 0.633)	Loss 8.0484e-01 (7.5879e-01)	Acc@1  72.36 ( 73.69)
Epoch: [14][40/59]	Time  1.464 ( 1.487)	Data  0.019 ( 0.029)	InnerLoop  0.625 ( 0.634)	Loss 7.3040e-01 (7.1030e-01)	Acc@1  74.76 ( 75.10)
The current update step is 885
The current seed is 9346364474148762542
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.961
 *   Acc@1 77.913
 *   Acc@1 74.092
 *   Acc@1 74.429
 *   Acc@1 72.421
 *   Acc@1 72.428
 *   Acc@1 62.066
 *   Acc@1 62.188
 *   Acc@1 62.250
 *   Acc@1 62.392
 *   Acc@1 62.776
 *   Acc@1 63.176
Training for 300 epoch: 70.01315789473685
Training for 600 epoch: 68.17105263157895
Training for 1000 epoch: 67.59868421052632
Training for 300 epoch: 70.05083333333333
Training for 600 epoch: 68.41041666666666
Training for 1000 epoch: 67.80208333333333
[[70.01315789473685, 68.17105263157895, 67.59868421052632], [70.05083333333333, 68.41041666666666, 67.80208333333333]]
train loss 0.6206516299247742, epoch 14, best loss 0.4993737615585327, best_epoch 9
GPU_0_using curriculum 20 with window 20
Epoch: [15][20/59]	Time  1.458 ( 1.486)	Data  0.020 ( 0.019)	InnerLoop  0.615 ( 0.639)	Loss 6.6151e-01 (7.1132e-01)	Acc@1  75.93 ( 73.82)
Epoch: [15][40/59]	Time  1.587 ( 1.490)	Data  0.136 ( 0.025)	InnerLoop  0.612 ( 0.636)	Loss 5.7649e-01 (7.0987e-01)	Acc@1  80.27 ( 74.45)
The current update step is 944
GPU_0_using curriculum 20 with window 20
Epoch: [16][20/59]	Time  1.453 ( 1.485)	Data  0.021 ( 0.031)	InnerLoop  0.612 ( 0.628)	Loss 9.5843e-01 (8.1088e-01)	Acc@1  66.55 ( 71.92)
Epoch: [16][40/59]	Time  1.472 ( 1.490)	Data  0.019 ( 0.028)	InnerLoop  0.626 ( 0.634)	Loss 1.2151e+00 (7.9219e-01)	Acc@1  61.47 ( 71.77)
The current update step is 1003
GPU_0_using curriculum 20 with window 20
Epoch: [17][20/59]	Time  1.459 ( 1.480)	Data  0.020 ( 0.032)	InnerLoop  0.617 ( 0.625)	Loss 8.9800e-01 (7.7483e-01)	Acc@1  66.80 ( 71.71)
Epoch: [17][40/59]	Time  1.574 ( 1.486)	Data  0.020 ( 0.026)	InnerLoop  0.730 ( 0.635)	Loss 5.7634e-01 (7.9518e-01)	Acc@1  79.88 ( 71.24)
The current update step is 1062
GPU_0_using curriculum 20 with window 20
Epoch: [18][20/59]	Time  1.459 ( 1.484)	Data  0.016 ( 0.025)	InnerLoop  0.622 ( 0.631)	Loss 7.0134e-01 (8.0473e-01)	Acc@1  75.88 ( 71.08)
Epoch: [18][40/59]	Time  1.592 ( 1.490)	Data  0.021 ( 0.022)	InnerLoop  0.734 ( 0.640)	Loss 7.6451e-01 (7.5174e-01)	Acc@1  70.21 ( 72.56)
The current update step is 1121
GPU_0_using curriculum 20 with window 20
Epoch: [19][20/59]	Time  1.470 ( 1.492)	Data  0.017 ( 0.024)	InnerLoop  0.622 ( 0.637)	Loss 6.9444e-01 (7.4581e-01)	Acc@1  75.34 ( 73.11)
Epoch: [19][40/59]	Time  1.585 ( 1.495)	Data  0.020 ( 0.022)	InnerLoop  0.745 ( 0.644)	Loss 7.8478e-01 (7.4368e-01)	Acc@1  71.63 ( 73.16)
The current update step is 1180
The current seed is 3583003964004348962
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.737
 *   Acc@1 71.236
 *   Acc@1 70.579
 *   Acc@1 70.653
 *   Acc@1 69.118
 *   Acc@1 69.473
 *   Acc@1 73.592
 *   Acc@1 73.094
 *   Acc@1 69.461
 *   Acc@1 69.098
 *   Acc@1 66.724
 *   Acc@1 66.853
Training for 300 epoch: 72.66447368421052
Training for 600 epoch: 70.01973684210526
Training for 1000 epoch: 67.92105263157895
Training for 300 epoch: 72.16499999999999
Training for 600 epoch: 69.87583333333333
Training for 1000 epoch: 68.16333333333333
[[72.66447368421052, 70.01973684210526, 67.92105263157895], [72.16499999999999, 69.87583333333333, 68.16333333333333]]
train loss 0.6753888981819153, epoch 19, best loss 0.4993737615585327, best_epoch 9
GPU_0_using curriculum 20 with window 20
Epoch: [20][20/59]	Time  1.634 ( 1.489)	Data  0.020 ( 0.025)	InnerLoop  0.748 ( 0.641)	Loss 5.4457e-01 (6.6932e-01)	Acc@1  79.79 ( 76.12)
Epoch: [20][40/59]	Time  1.460 ( 1.490)	Data  0.019 ( 0.022)	InnerLoop  0.620 ( 0.643)	Loss 7.5076e-01 (7.2937e-01)	Acc@1  73.83 ( 74.01)
The current update step is 1239
GPU_0_using curriculum 20 with window 20
Epoch: [21][20/59]	Time  1.465 ( 1.487)	Data  0.019 ( 0.031)	InnerLoop  0.631 ( 0.631)	Loss 7.8793e-01 (7.5969e-01)	Acc@1  74.12 ( 73.10)
Epoch: [21][40/59]	Time  1.582 ( 1.492)	Data  0.018 ( 0.028)	InnerLoop  0.739 ( 0.638)	Loss 7.0876e-01 (7.5900e-01)	Acc@1  74.51 ( 73.04)
The current update step is 1298
GPU_0_using curriculum 20 with window 20
Epoch: [22][20/59]	Time  1.478 ( 1.488)	Data  0.019 ( 0.026)	InnerLoop  0.622 ( 0.639)	Loss 9.0097e-01 (8.1684e-01)	Acc@1  64.75 ( 70.63)
Epoch: [22][40/59]	Time  1.453 ( 1.492)	Data  0.018 ( 0.026)	InnerLoop  0.618 ( 0.641)	Loss 1.5456e+00 (7.6894e-01)	Acc@1  55.27 ( 72.04)
The current update step is 1357
GPU_0_using curriculum 20 with window 20
Epoch: [23][20/59]	Time  1.485 ( 1.482)	Data  0.018 ( 0.032)	InnerLoop  0.639 ( 0.629)	Loss 5.2226e-01 (7.3757e-01)	Acc@1  80.91 ( 73.35)
Epoch: [23][40/59]	Time  1.470 ( 1.485)	Data  0.018 ( 0.028)	InnerLoop  0.621 ( 0.634)	Loss 5.9019e-01 (7.4769e-01)	Acc@1  79.74 ( 73.47)
The current update step is 1416
GPU_0_using curriculum 20 with window 20
Epoch: [24][20/59]	Time  1.476 ( 1.487)	Data  0.019 ( 0.032)	InnerLoop  0.633 ( 0.632)	Loss 5.9706e-01 (7.9442e-01)	Acc@1  79.93 ( 72.69)
Epoch: [24][40/59]	Time  1.465 ( 1.490)	Data  0.017 ( 0.028)	InnerLoop  0.628 ( 0.636)	Loss 7.5438e-01 (7.5884e-01)	Acc@1  71.97 ( 73.31)
The current update step is 1475
The current seed is 18082699068702114276
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.934
 *   Acc@1 77.142
 *   Acc@1 74.934
 *   Acc@1 75.368
 *   Acc@1 74.184
 *   Acc@1 74.323
 *   Acc@1 79.671
 *   Acc@1 79.610
 *   Acc@1 78.211
 *   Acc@1 78.307
 *   Acc@1 77.987
 *   Acc@1 78.306
Training for 300 epoch: 78.30263157894737
Training for 600 epoch: 76.57236842105263
Training for 1000 epoch: 76.08552631578948
Training for 300 epoch: 78.37625
Training for 600 epoch: 76.8375
Training for 1000 epoch: 76.31416666666667
[[78.30263157894737, 76.57236842105263, 76.08552631578948], [78.37625, 76.8375, 76.31416666666667]]
train loss 0.3058134133974711, epoch 24, best loss 0.3058134133974711, best_epoch 24
GPU_0_using curriculum 20 with window 20
Epoch: [25][20/59]	Time  1.498 ( 1.488)	Data  0.020 ( 0.019)	InnerLoop  0.626 ( 0.644)	Loss 6.9075e-01 (6.9553e-01)	Acc@1  76.66 ( 74.95)
Epoch: [25][40/59]	Time  1.571 ( 1.496)	Data  0.138 ( 0.025)	InnerLoop  0.618 ( 0.641)	Loss 6.3872e-01 (6.9377e-01)	Acc@1  77.29 ( 75.14)
The current update step is 1534
GPU_0_using curriculum 20 with window 20
Epoch: [26][20/59]	Time  1.468 ( 1.480)	Data  0.020 ( 0.032)	InnerLoop  0.623 ( 0.626)	Loss 7.4102e-01 (7.7806e-01)	Acc@1  73.44 ( 72.19)
Epoch: [26][40/59]	Time  1.474 ( 1.489)	Data  0.019 ( 0.029)	InnerLoop  0.628 ( 0.635)	Loss 6.4395e-01 (7.6962e-01)	Acc@1  74.46 ( 72.58)
The current update step is 1593
GPU_0_using curriculum 20 with window 20
Epoch: [27][20/59]	Time  1.474 ( 1.487)	Data  0.020 ( 0.032)	InnerLoop  0.626 ( 0.630)	Loss 6.9178e-01 (7.2670e-01)	Acc@1  73.68 ( 74.40)
Epoch: [27][40/59]	Time  1.597 ( 1.491)	Data  0.017 ( 0.025)	InnerLoop  0.759 ( 0.639)	Loss 5.5896e-01 (7.0291e-01)	Acc@1  80.62 ( 75.04)
The current update step is 1652
GPU_0_using curriculum 20 with window 20
Epoch: [28][20/59]	Time  1.474 ( 1.486)	Data  0.018 ( 0.026)	InnerLoop  0.633 ( 0.638)	Loss 9.2990e-01 (6.9215e-01)	Acc@1  66.06 ( 74.49)
Epoch: [28][40/59]	Time  1.585 ( 1.494)	Data  0.020 ( 0.022)	InnerLoop  0.741 ( 0.647)	Loss 5.8234e-01 (7.1022e-01)	Acc@1  77.83 ( 74.37)
The current update step is 1711
GPU_0_using curriculum 20 with window 20
Epoch: [29][20/59]	Time  1.493 ( 1.494)	Data  0.018 ( 0.025)	InnerLoop  0.635 ( 0.644)	Loss 5.6180e-01 (7.9118e-01)	Acc@1  79.93 ( 71.42)
Epoch: [29][40/59]	Time  1.602 ( 1.499)	Data  0.019 ( 0.022)	InnerLoop  0.747 ( 0.651)	Loss 1.0397e+00 (7.7738e-01)	Acc@1  59.08 ( 72.02)
The current update step is 1770
The current seed is 2325177286188984693
The current lr is: 0.001
Testing Results:
 *   Acc@1 74.461
 *   Acc@1 75.106
 *   Acc@1 73.671
 *   Acc@1 74.093
 *   Acc@1 72.579
 *   Acc@1 72.642
 *   Acc@1 70.618
 *   Acc@1 71.097
 *   Acc@1 65.921
 *   Acc@1 66.446
 *   Acc@1 64.934
 *   Acc@1 65.073
Training for 300 epoch: 72.53947368421052
Training for 600 epoch: 69.79605263157895
Training for 1000 epoch: 68.75657894736842
Training for 300 epoch: 73.10166666666666
Training for 600 epoch: 70.26958333333334
Training for 1000 epoch: 68.85791666666667
[[72.53947368421052, 69.79605263157895, 68.75657894736842], [73.10166666666666, 70.26958333333334, 68.85791666666667]]
train loss 0.4381287858168284, epoch 29, best loss 0.3058134133974711, best_epoch 24
GPU_0_using curriculum 20 with window 20
Epoch: [30][20/59]	Time  1.603 ( 1.499)	Data  0.019 ( 0.026)	InnerLoop  0.750 ( 0.649)	Loss 5.7771e-01 (6.7090e-01)	Acc@1  79.69 ( 75.20)
Epoch: [30][40/59]	Time  1.462 ( 1.501)	Data  0.018 ( 0.022)	InnerLoop  0.628 ( 0.648)	Loss 6.5249e-01 (7.5973e-01)	Acc@1  79.35 ( 72.86)
The current update step is 1829
GPU_0_using curriculum 20 with window 20
Epoch: [31][20/59]	Time  1.500 ( 1.497)	Data  0.020 ( 0.032)	InnerLoop  0.641 ( 0.638)	Loss 5.5061e-01 (7.3142e-01)	Acc@1  79.35 ( 73.07)
Epoch: [31][40/59]	Time  1.603 ( 1.500)	Data  0.019 ( 0.029)	InnerLoop  0.758 ( 0.644)	Loss 7.1124e-01 (7.8813e-01)	Acc@1  73.14 ( 71.94)
The current update step is 1888
GPU_0_using curriculum 20 with window 20
Epoch: [32][20/59]	Time  1.469 ( 1.495)	Data  0.019 ( 0.026)	InnerLoop  0.626 ( 0.642)	Loss 9.0417e-01 (7.1585e-01)	Acc@1  70.70 ( 74.65)
Epoch: [32][40/59]	Time  1.471 ( 1.498)	Data  0.019 ( 0.025)	InnerLoop  0.627 ( 0.644)	Loss 6.2494e-01 (6.8462e-01)	Acc@1  77.15 ( 75.48)
The current update step is 1947
GPU_0_using curriculum 20 with window 20
Epoch: [33][20/59]	Time  1.472 ( 1.492)	Data  0.018 ( 0.032)	InnerLoop  0.627 ( 0.635)	Loss 6.0130e-01 (6.4175e-01)	Acc@1  78.42 ( 76.35)
Epoch: [33][40/59]	Time  1.473 ( 1.495)	Data  0.020 ( 0.029)	InnerLoop  0.631 ( 0.639)	Loss 6.0370e-01 (6.8843e-01)	Acc@1  76.56 ( 74.78)
The current update step is 2006
GPU_0_using curriculum 20 with window 20
Epoch: [34][20/59]	Time  1.474 ( 1.495)	Data  0.018 ( 0.032)	InnerLoop  0.628 ( 0.637)	Loss 8.8528e-01 (7.5810e-01)	Acc@1  69.43 ( 71.95)
Epoch: [34][40/59]	Time  1.501 ( 1.496)	Data  0.020 ( 0.029)	InnerLoop  0.637 ( 0.638)	Loss 5.7781e-01 (7.0169e-01)	Acc@1  78.91 ( 74.05)
The current update step is 2065
The current seed is 3492103918823702078
The current lr is: 0.001
Testing Results:
 *   Acc@1 75.882
 *   Acc@1 75.463
 *   Acc@1 75.434
 *   Acc@1 75.481
 *   Acc@1 75.276
 *   Acc@1 75.401
 *   Acc@1 76.395
 *   Acc@1 76.596
 *   Acc@1 76.289
 *   Acc@1 76.251
 *   Acc@1 76.000
 *   Acc@1 76.403
Training for 300 epoch: 76.13815789473685
Training for 600 epoch: 75.86184210526315
Training for 1000 epoch: 75.63815789473685
Training for 300 epoch: 76.02916666666667
Training for 600 epoch: 75.86583333333334
Training for 1000 epoch: 75.90208333333334
[[76.13815789473685, 75.86184210526315, 75.63815789473685], [76.02916666666667, 75.86583333333334, 75.90208333333334]]
train loss 0.3462454873402913, epoch 34, best loss 0.3058134133974711, best_epoch 24
GPU_0_using curriculum 20 with window 20
Epoch: [35][20/59]	Time  1.467 ( 1.495)	Data  0.020 ( 0.019)	InnerLoop  0.625 ( 0.648)	Loss 8.6991e-01 (8.0398e-01)	Acc@1  71.83 ( 70.92)
Epoch: [35][40/59]	Time  1.597 ( 1.500)	Data  0.137 ( 0.025)	InnerLoop  0.621 ( 0.645)	Loss 5.8669e-01 (7.2814e-01)	Acc@1  79.20 ( 73.38)
The current update step is 2124
GPU_0_using curriculum 20 with window 20
Epoch: [36][20/59]	Time  1.489 ( 1.497)	Data  0.019 ( 0.031)	InnerLoop  0.627 ( 0.635)	Loss 5.7061e-01 (6.6775e-01)	Acc@1  78.56 ( 76.02)
Epoch: [36][40/59]	Time  1.529 ( 1.499)	Data  0.019 ( 0.028)	InnerLoop  0.636 ( 0.640)	Loss 5.8964e-01 (6.7635e-01)	Acc@1  79.64 ( 75.34)
The current update step is 2183
GPU_0_using curriculum 20 with window 20
Epoch: [37][20/59]	Time  1.477 ( 1.490)	Data  0.020 ( 0.032)	InnerLoop  0.628 ( 0.631)	Loss 9.7313e-01 (7.0469e-01)	Acc@1  67.53 ( 74.57)
Epoch: [37][40/59]	Time  1.594 ( 1.494)	Data  0.018 ( 0.026)	InnerLoop  0.755 ( 0.641)	Loss 1.0358e+00 (7.0518e-01)	Acc@1  63.53 ( 74.86)
The current update step is 2242
GPU_0_using curriculum 20 with window 20
Epoch: [38][20/59]	Time  1.478 ( 1.495)	Data  0.018 ( 0.027)	InnerLoop  0.637 ( 0.639)	Loss 5.9892e-01 (6.6262e-01)	Acc@1  78.81 ( 76.00)
Epoch: [38][40/59]	Time  1.629 ( 1.500)	Data  0.020 ( 0.024)	InnerLoop  0.750 ( 0.645)	Loss 5.8306e-01 (6.6998e-01)	Acc@1  78.66 ( 75.55)
The current update step is 2301
GPU_0_using curriculum 20 with window 20
Epoch: [39][20/59]	Time  1.477 ( 1.491)	Data  0.019 ( 0.026)	InnerLoop  0.623 ( 0.641)	Loss 6.9606e-01 (6.7298e-01)	Acc@1  73.10 ( 75.86)
Epoch: [39][40/59]	Time  1.580 ( 1.497)	Data  0.020 ( 0.023)	InnerLoop  0.742 ( 0.646)	Loss 5.0838e-01 (6.7017e-01)	Acc@1  80.22 ( 75.95)
The current update step is 2360
The current seed is 9339054461244422565
The current lr is: 0.001
Testing Results:
 *   Acc@1 66.684
 *   Acc@1 66.737
 *   Acc@1 65.329
 *   Acc@1 65.414
 *   Acc@1 64.500
 *   Acc@1 64.480
 *   Acc@1 77.447
 *   Acc@1 77.430
 *   Acc@1 65.513
 *   Acc@1 65.056
 *   Acc@1 61.408
 *   Acc@1 61.390
Training for 300 epoch: 72.06578947368422
Training for 600 epoch: 65.42105263157895
Training for 1000 epoch: 62.953947368421055
Training for 300 epoch: 72.08333333333334
Training for 600 epoch: 65.23500000000001
Training for 1000 epoch: 62.935
[[72.06578947368422, 65.42105263157895, 62.953947368421055], [72.08333333333334, 65.23500000000001, 62.935]]
train loss 0.6905238492647807, epoch 39, best loss 0.3058134133974711, best_epoch 24
GPU_0_using curriculum 20 with window 20
Epoch: [40][20/59]	Time  1.572 ( 1.499)	Data  0.017 ( 0.025)	InnerLoop  0.738 ( 0.645)	Loss 7.2493e-01 (6.8965e-01)	Acc@1  71.58 ( 75.22)
Epoch: [40][40/59]	Time  1.463 ( 1.499)	Data  0.019 ( 0.022)	InnerLoop  0.623 ( 0.646)	Loss 8.9672e-01 (7.1289e-01)	Acc@1  64.65 ( 73.78)
The current update step is 2419
GPU_0_using curriculum 20 with window 20
Epoch: [41][20/59]	Time  1.483 ( 1.495)	Data  0.017 ( 0.031)	InnerLoop  0.634 ( 0.632)	Loss 6.0552e-01 (8.0073e-01)	Acc@1  78.56 ( 70.54)
Epoch: [41][40/59]	Time  1.606 ( 1.497)	Data  0.019 ( 0.028)	InnerLoop  0.739 ( 0.637)	Loss 8.4060e-01 (7.7754e-01)	Acc@1  65.04 ( 71.11)
The current update step is 2478
GPU_0_using curriculum 20 with window 20
Epoch: [42][20/59]	Time  1.469 ( 1.488)	Data  0.018 ( 0.026)	InnerLoop  0.624 ( 0.636)	Loss 5.5776e-01 (7.1748e-01)	Acc@1  80.76 ( 75.04)
Epoch: [42][40/59]	Time  1.482 ( 1.490)	Data  0.021 ( 0.026)	InnerLoop  0.638 ( 0.639)	Loss 7.4269e-01 (7.2606e-01)	Acc@1  71.78 ( 74.16)
The current update step is 2537
GPU_0_using curriculum 20 with window 20
Epoch: [43][20/59]	Time  1.466 ( 1.482)	Data  0.018 ( 0.031)	InnerLoop  0.622 ( 0.628)	Loss 5.1198e-01 (6.8041e-01)	Acc@1  82.52 ( 75.47)
Epoch: [43][40/59]	Time  1.462 ( 1.488)	Data  0.018 ( 0.028)	InnerLoop  0.621 ( 0.633)	Loss 7.9139e-01 (6.7348e-01)	Acc@1  69.53 ( 75.46)
The current update step is 2596
GPU_0_using curriculum 20 with window 20
Epoch: [44][20/59]	Time  1.475 ( 1.493)	Data  0.019 ( 0.031)	InnerLoop  0.632 ( 0.632)	Loss 6.6734e-01 (7.1626e-01)	Acc@1  75.93 ( 74.95)
Epoch: [44][40/59]	Time  1.472 ( 1.492)	Data  0.019 ( 0.028)	InnerLoop  0.623 ( 0.635)	Loss 5.0951e-01 (7.2473e-01)	Acc@1  81.45 ( 74.01)
The current update step is 2655
The current seed is 15711539451943079460
The current lr is: 0.001
Testing Results:
 *   Acc@1 72.132
 *   Acc@1 72.218
 *   Acc@1 71.132
 *   Acc@1 71.406
 *   Acc@1 70.303
 *   Acc@1 71.028
 *   Acc@1 73.197
 *   Acc@1 74.071
 *   Acc@1 73.447
 *   Acc@1 73.803
 *   Acc@1 72.447
 *   Acc@1 73.627
Training for 300 epoch: 72.66447368421052
Training for 600 epoch: 72.28947368421052
Training for 1000 epoch: 71.375
Training for 300 epoch: 73.14458333333334
Training for 600 epoch: 72.60458333333332
Training for 1000 epoch: 72.32708333333333
[[72.66447368421052, 72.28947368421052, 71.375], [73.14458333333334, 72.60458333333332, 72.32708333333333]]
train loss 0.3963839690208435, epoch 44, best loss 0.3058134133974711, best_epoch 24
GPU_0_using curriculum 20 with window 20
Epoch: [45][20/59]	Time  1.463 ( 1.490)	Data  0.022 ( 0.019)	InnerLoop  0.616 ( 0.642)	Loss 1.1293e+00 (7.1939e-01)	Acc@1  67.04 ( 73.82)
Epoch: [45][40/59]	Time  1.576 ( 1.493)	Data  0.136 ( 0.025)	InnerLoop  0.617 ( 0.639)	Loss 5.5752e-01 (7.1359e-01)	Acc@1  80.22 ( 74.01)
The current update step is 2714
GPU_0_using curriculum 20 with window 20
Epoch: [46][20/59]	Time  1.464 ( 1.488)	Data  0.020 ( 0.031)	InnerLoop  0.625 ( 0.630)	Loss 6.3427e-01 (7.1394e-01)	Acc@1  77.10 ( 73.68)
Epoch: [46][40/59]	Time  1.472 ( 1.488)	Data  0.018 ( 0.028)	InnerLoop  0.626 ( 0.635)	Loss 6.7061e-01 (6.8860e-01)	Acc@1  76.51 ( 74.92)
The current update step is 2773
GPU_0_using curriculum 20 with window 20
Epoch: [47][20/59]	Time  1.465 ( 1.480)	Data  0.019 ( 0.031)	InnerLoop  0.619 ( 0.627)	Loss 6.8549e-01 (7.0528e-01)	Acc@1  72.07 ( 74.34)
Epoch: [47][40/59]	Time  1.575 ( 1.484)	Data  0.018 ( 0.025)	InnerLoop  0.740 ( 0.637)	Loss 5.3241e-01 (7.0483e-01)	Acc@1  81.69 ( 74.57)
The current update step is 2832
GPU_0_using curriculum 20 with window 20
Epoch: [48][20/59]	Time  1.505 ( 1.488)	Data  0.021 ( 0.025)	InnerLoop  0.640 ( 0.640)	Loss 5.4704e-01 (6.8283e-01)	Acc@1  80.66 ( 74.51)
Epoch: [48][40/59]	Time  1.589 ( 1.491)	Data  0.018 ( 0.022)	InnerLoop  0.750 ( 0.644)	Loss 5.4651e-01 (6.9229e-01)	Acc@1  81.15 ( 74.38)
The current update step is 2891
GPU_0_using curriculum 20 with window 20
Epoch: [49][20/59]	Time  1.472 ( 1.486)	Data  0.019 ( 0.025)	InnerLoop  0.630 ( 0.637)	Loss 5.4111e-01 (7.0353e-01)	Acc@1  82.67 ( 73.96)
Epoch: [49][40/59]	Time  1.633 ( 1.495)	Data  0.020 ( 0.023)	InnerLoop  0.758 ( 0.645)	Loss 6.7210e-01 (6.8618e-01)	Acc@1  72.02 ( 74.58)
The current update step is 2950
The current seed is 4623627184410155500
The current lr is: 0.001
Testing Results:
 *   Acc@1 52.132
 *   Acc@1 52.944
 *   Acc@1 50.303
 *   Acc@1 50.892
 *   Acc@1 48.013
 *   Acc@1 48.502
 *   Acc@1 69.276
 *   Acc@1 69.615
 *   Acc@1 66.895
 *   Acc@1 67.572
 *   Acc@1 63.882
 *   Acc@1 64.302
Training for 300 epoch: 60.703947368421055
Training for 600 epoch: 58.598684210526315
Training for 1000 epoch: 55.94736842105263
Training for 300 epoch: 61.279583333333335
Training for 600 epoch: 59.23166666666667
Training for 1000 epoch: 56.40208333333333
[[60.703947368421055, 58.598684210526315, 55.94736842105263], [61.279583333333335, 59.23166666666667, 56.40208333333333]]
train loss 0.5242366965611776, epoch 49, best loss 0.3058134133974711, best_epoch 24
GPU_0_using curriculum 20 with window 20
Epoch: [50][20/59]	Time  1.589 ( 1.499)	Data  0.018 ( 0.025)	InnerLoop  0.747 ( 0.648)	Loss 8.7584e-01 (1.0308e+00)	Acc@1  62.79 ( 63.21)
Epoch: [50][40/59]	Time  1.489 ( 1.496)	Data  0.020 ( 0.022)	InnerLoop  0.627 ( 0.647)	Loss 7.3985e-01 (9.4455e-01)	Acc@1  75.39 ( 65.43)
The current update step is 3009
GPU_0_using curriculum 20 with window 20
Epoch: [51][20/59]	Time  1.472 ( 1.489)	Data  0.021 ( 0.031)	InnerLoop  0.630 ( 0.634)	Loss 1.0004e+00 (8.3183e-01)	Acc@1  64.01 ( 69.86)
Epoch: [51][40/59]	Time  1.595 ( 1.497)	Data  0.019 ( 0.028)	InnerLoop  0.750 ( 0.640)	Loss 7.1966e-01 (8.0633e-01)	Acc@1  70.21 ( 70.70)
The current update step is 3068
GPU_0_using curriculum 20 with window 20
Epoch: [52][20/59]	Time  1.470 ( 1.487)	Data  0.019 ( 0.025)	InnerLoop  0.630 ( 0.639)	Loss 6.7264e-01 (6.8724e-01)	Acc@1  75.68 ( 75.67)
Epoch: [52][40/59]	Time  1.468 ( 1.493)	Data  0.019 ( 0.025)	InnerLoop  0.630 ( 0.643)	Loss 7.2793e-01 (7.9118e-01)	Acc@1  70.56 ( 71.76)
The current update step is 3127
GPU_0_using curriculum 20 with window 20
Epoch: [53][20/59]	Time  1.477 ( 1.489)	Data  0.018 ( 0.032)	InnerLoop  0.636 ( 0.633)	Loss 6.7088e-01 (6.7747e-01)	Acc@1  74.71 ( 75.31)
Epoch: [53][40/59]	Time  1.470 ( 1.494)	Data  0.018 ( 0.028)	InnerLoop  0.631 ( 0.637)	Loss 7.3213e-01 (6.7216e-01)	Acc@1  73.14 ( 75.51)
The current update step is 3186
GPU_0_using curriculum 20 with window 20
Epoch: [54][20/59]	Time  1.473 ( 1.485)	Data  0.019 ( 0.031)	InnerLoop  0.628 ( 0.631)	Loss 7.9437e-01 (7.4819e-01)	Acc@1  74.32 ( 72.67)
Epoch: [54][40/59]	Time  1.465 ( 1.486)	Data  0.020 ( 0.028)	InnerLoop  0.626 ( 0.635)	Loss 7.2759e-01 (7.0766e-01)	Acc@1  76.12 ( 74.20)
The current update step is 3245
The current seed is 1674826500554581450
The current lr is: 0.001
Testing Results:
 *   Acc@1 72.145
 *   Acc@1 72.382
 *   Acc@1 70.724
 *   Acc@1 71.106
 *   Acc@1 70.434
 *   Acc@1 70.357
 *   Acc@1 71.395
 *   Acc@1 71.732
 *   Acc@1 68.382
 *   Acc@1 68.959
 *   Acc@1 67.368
 *   Acc@1 67.872
Training for 300 epoch: 71.76973684210526
Training for 600 epoch: 69.55263157894737
Training for 1000 epoch: 68.90131578947368
Training for 300 epoch: 72.05666666666667
Training for 600 epoch: 70.0325
Training for 1000 epoch: 69.11416666666668
[[71.76973684210526, 69.55263157894737, 68.90131578947368], [72.05666666666667, 70.0325, 69.11416666666668]]
train loss 0.4285755839983622, epoch 54, best loss 0.3058134133974711, best_epoch 24
GPU_0_using curriculum 20 with window 20
Epoch: [55][20/59]	Time  1.466 ( 1.484)	Data  0.021 ( 0.019)	InnerLoop  0.622 ( 0.644)	Loss 6.4464e-01 (7.4286e-01)	Acc@1  75.88 ( 73.05)
Epoch: [55][40/59]	Time  1.580 ( 1.490)	Data  0.139 ( 0.025)	InnerLoop  0.615 ( 0.640)	Loss 6.3068e-01 (6.9847e-01)	Acc@1  77.39 ( 74.76)
The current update step is 3304
GPU_0_using curriculum 20 with window 20
Epoch: [56][20/59]	Time  1.464 ( 1.489)	Data  0.019 ( 0.032)	InnerLoop  0.628 ( 0.630)	Loss 5.9347e-01 (6.2189e-01)	Acc@1  78.27 ( 77.68)
Epoch: [56][40/59]	Time  1.462 ( 1.492)	Data  0.021 ( 0.028)	InnerLoop  0.622 ( 0.638)	Loss 5.4657e-01 (6.8149e-01)	Acc@1  80.96 ( 75.02)
The current update step is 3363
GPU_0_using curriculum 20 with window 20
Epoch: [57][20/59]	Time  1.479 ( 1.492)	Data  0.021 ( 0.032)	InnerLoop  0.625 ( 0.632)	Loss 7.9810e-01 (7.1478e-01)	Acc@1  69.24 ( 73.73)
Epoch: [57][40/59]	Time  1.581 ( 1.495)	Data  0.021 ( 0.026)	InnerLoop  0.739 ( 0.641)	Loss 6.4264e-01 (6.8396e-01)	Acc@1  74.02 ( 75.02)
The current update step is 3422
GPU_0_using curriculum 20 with window 20
Epoch: [58][20/59]	Time  1.466 ( 1.487)	Data  0.019 ( 0.026)	InnerLoop  0.632 ( 0.640)	Loss 6.9808e-01 (6.9961e-01)	Acc@1  74.17 ( 74.76)
Epoch: [58][40/59]	Time  1.588 ( 1.488)	Data  0.017 ( 0.022)	InnerLoop  0.743 ( 0.645)	Loss 6.4812e-01 (7.2807e-01)	Acc@1  76.66 ( 73.72)
The current update step is 3481
GPU_0_using curriculum 20 with window 20
Epoch: [59][20/59]	Time  1.470 ( 1.483)	Data  0.019 ( 0.025)	InnerLoop  0.625 ( 0.636)	Loss 7.0564e-01 (7.0764e-01)	Acc@1  73.39 ( 74.24)
Epoch: [59][40/59]	Time  1.574 ( 1.490)	Data  0.018 ( 0.022)	InnerLoop  0.739 ( 0.645)	Loss 6.1808e-01 (7.0683e-01)	Acc@1  77.73 ( 73.85)
The current update step is 3540
The current seed is 2231049547870982428
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.263
 *   Acc@1 76.673
 *   Acc@1 72.658
 *   Acc@1 73.190
 *   Acc@1 72.461
 *   Acc@1 72.891
 *   Acc@1 70.605
 *   Acc@1 70.577
 *   Acc@1 69.671
 *   Acc@1 69.877
 *   Acc@1 67.395
 *   Acc@1 67.255
Training for 300 epoch: 73.43421052631578
Training for 600 epoch: 71.16447368421052
Training for 1000 epoch: 69.92763157894737
Training for 300 epoch: 73.625
Training for 600 epoch: 71.53333333333333
Training for 1000 epoch: 70.07291666666666
[[73.43421052631578, 71.16447368421052, 69.92763157894737], [73.625, 71.53333333333333, 70.07291666666666]]
train loss 0.43654876144727073, epoch 59, best loss 0.3058134133974711, best_epoch 24
GPU_0_using curriculum 20 with window 20
Epoch: [60][20/59]	Time  1.584 ( 1.494)	Data  0.017 ( 0.025)	InnerLoop  0.744 ( 0.641)	Loss 7.1516e-01 (6.3738e-01)	Acc@1  74.46 ( 76.52)
Epoch: [60][40/59]	Time  1.451 ( 1.490)	Data  0.019 ( 0.022)	InnerLoop  0.618 ( 0.641)	Loss 6.3944e-01 (6.4588e-01)	Acc@1  75.73 ( 75.96)
The current update step is 3599
GPU_0_using curriculum 20 with window 20
Epoch: [61][20/59]	Time  1.458 ( 1.484)	Data  0.017 ( 0.031)	InnerLoop  0.619 ( 0.629)	Loss 5.7323e-01 (7.0180e-01)	Acc@1  78.96 ( 74.44)
Epoch: [61][40/59]	Time  1.610 ( 1.488)	Data  0.018 ( 0.028)	InnerLoop  0.755 ( 0.636)	Loss 6.2155e-01 (7.3093e-01)	Acc@1  77.83 ( 74.28)
The current update step is 3658
GPU_0_using curriculum 20 with window 20
Epoch: [62][20/59]	Time  1.479 ( 1.490)	Data  0.018 ( 0.025)	InnerLoop  0.627 ( 0.638)	Loss 6.5246e-01 (6.8277e-01)	Acc@1  74.85 ( 75.48)
Epoch: [62][40/59]	Time  1.478 ( 1.493)	Data  0.018 ( 0.025)	InnerLoop  0.623 ( 0.640)	Loss 8.2419e-01 (6.8208e-01)	Acc@1  70.07 ( 75.09)
The current update step is 3717
GPU_0_using curriculum 20 with window 20
Epoch: [63][20/59]	Time  1.464 ( 1.489)	Data  0.018 ( 0.031)	InnerLoop  0.625 ( 0.631)	Loss 6.4811e-01 (6.9627e-01)	Acc@1  74.85 ( 74.38)
Epoch: [63][40/59]	Time  1.467 ( 1.488)	Data  0.016 ( 0.028)	InnerLoop  0.636 ( 0.634)	Loss 6.2169e-01 (6.6058e-01)	Acc@1  76.86 ( 75.78)
The current update step is 3776
GPU_0_using curriculum 20 with window 20
Epoch: [64][20/59]	Time  1.486 ( 1.497)	Data  0.021 ( 0.032)	InnerLoop  0.642 ( 0.639)	Loss 5.5192e-01 (7.0196e-01)	Acc@1  80.66 ( 74.02)
Epoch: [64][40/59]	Time  1.467 ( 1.497)	Data  0.021 ( 0.029)	InnerLoop  0.627 ( 0.641)	Loss 6.0073e-01 (7.1049e-01)	Acc@1  77.88 ( 73.65)
The current update step is 3835
The current seed is 3048508173984051917
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.895
 *   Acc@1 72.034
 *   Acc@1 67.697
 *   Acc@1 67.733
 *   Acc@1 66.000
 *   Acc@1 65.901
 *   Acc@1 62.421
 *   Acc@1 62.218
 *   Acc@1 61.803
 *   Acc@1 61.332
 *   Acc@1 63.513
 *   Acc@1 63.475
Training for 300 epoch: 67.15789473684211
Training for 600 epoch: 64.75
Training for 1000 epoch: 64.75657894736842
Training for 300 epoch: 67.12583333333333
Training for 600 epoch: 64.5325
Training for 1000 epoch: 64.68791666666667
[[67.15789473684211, 64.75, 64.75657894736842], [67.12583333333333, 64.5325, 64.68791666666667]]
train loss 0.5379911244074503, epoch 64, best loss 0.3058134133974711, best_epoch 24
GPU_0_using curriculum 20 with window 20
Epoch: [65][20/59]	Time  1.465 ( 1.491)	Data  0.020 ( 0.019)	InnerLoop  0.626 ( 0.645)	Loss 6.1311e-01 (6.1244e-01)	Acc@1  77.69 ( 77.36)
Epoch: [65][40/59]	Time  1.593 ( 1.493)	Data  0.137 ( 0.025)	InnerLoop  0.629 ( 0.641)	Loss 8.1159e-01 (6.6391e-01)	Acc@1  71.24 ( 75.72)
The current update step is 3894
GPU_0_using curriculum 20 with window 20
Epoch: [66][20/59]	Time  1.465 ( 1.485)	Data  0.021 ( 0.031)	InnerLoop  0.624 ( 0.631)	Loss 6.7232e-01 (5.9558e-01)	Acc@1  74.56 ( 78.14)
Epoch: [66][40/59]	Time  1.473 ( 1.490)	Data  0.020 ( 0.028)	InnerLoop  0.627 ( 0.638)	Loss 6.9588e-01 (6.1328e-01)	Acc@1  76.27 ( 77.51)
The current update step is 3953
GPU_0_using curriculum 20 with window 20
Epoch: [67][20/59]	Time  1.500 ( 1.485)	Data  0.019 ( 0.030)	InnerLoop  0.638 ( 0.633)	Loss 6.0773e-01 (6.3439e-01)	Acc@1  78.08 ( 76.70)
Epoch: [67][40/59]	Time  1.575 ( 1.490)	Data  0.020 ( 0.024)	InnerLoop  0.741 ( 0.643)	Loss 6.3794e-01 (6.7170e-01)	Acc@1  75.98 ( 75.68)
The current update step is 4012
GPU_0_using curriculum 20 with window 20
Epoch: [68][20/59]	Time  1.465 ( 1.490)	Data  0.019 ( 0.025)	InnerLoop  0.626 ( 0.640)	Loss 5.1557e-01 (6.3070e-01)	Acc@1  82.62 ( 76.54)
Epoch: [68][40/59]	Time  1.589 ( 1.494)	Data  0.021 ( 0.022)	InnerLoop  0.745 ( 0.646)	Loss 5.6905e-01 (6.3883e-01)	Acc@1  80.13 ( 76.68)
The current update step is 4071
GPU_0_using curriculum 20 with window 20
Epoch: [69][20/59]	Time  1.457 ( 1.488)	Data  0.019 ( 0.025)	InnerLoop  0.624 ( 0.642)	Loss 6.8345e-01 (7.0561e-01)	Acc@1  77.20 ( 74.86)
Epoch: [69][40/59]	Time  1.604 ( 1.495)	Data  0.020 ( 0.022)	InnerLoop  0.749 ( 0.648)	Loss 7.8736e-01 (6.9660e-01)	Acc@1  74.37 ( 75.74)
The current update step is 4130
The current seed is 2774428815112230138
The current lr is: 0.001
Testing Results:
 *   Acc@1 72.908
 *   Acc@1 73.436
 *   Acc@1 73.934
 *   Acc@1 74.179
 *   Acc@1 73.921
 *   Acc@1 74.067
 *   Acc@1 79.697
 *   Acc@1 80.041
 *   Acc@1 76.342
 *   Acc@1 76.357
 *   Acc@1 73.842
 *   Acc@1 73.642
Training for 300 epoch: 76.30263157894737
Training for 600 epoch: 75.13815789473685
Training for 1000 epoch: 73.88157894736841
Training for 300 epoch: 76.73833333333334
Training for 600 epoch: 75.26791666666666
Training for 1000 epoch: 73.85458333333332
[[76.30263157894737, 75.13815789473685, 73.88157894736841], [76.73833333333334, 75.26791666666666, 73.85458333333332]]
train loss 0.3487757874965668, epoch 69, best loss 0.3058134133974711, best_epoch 24
GPU_0_using curriculum 20 with window 20
Epoch: [70][20/59]	Time  1.585 ( 1.491)	Data  0.019 ( 0.026)	InnerLoop  0.742 ( 0.644)	Loss 6.1661e-01 (6.6828e-01)	Acc@1  78.42 ( 75.90)
Epoch: [70][40/59]	Time  1.470 ( 1.490)	Data  0.020 ( 0.023)	InnerLoop  0.625 ( 0.645)	Loss 5.4799e-01 (6.5083e-01)	Acc@1  80.18 ( 76.25)
The current update step is 4189
GPU_0_using curriculum 20 with window 20
Epoch: [71][20/59]	Time  1.480 ( 1.498)	Data  0.020 ( 0.032)	InnerLoop  0.630 ( 0.636)	Loss 5.4988e-01 (7.0522e-01)	Acc@1  79.93 ( 74.34)
Epoch: [71][40/59]	Time  1.591 ( 1.503)	Data  0.018 ( 0.028)	InnerLoop  0.747 ( 0.642)	Loss 6.1720e-01 (7.0521e-01)	Acc@1  79.15 ( 74.41)
The current update step is 4248
GPU_0_using curriculum 20 with window 20
Epoch: [72][20/59]	Time  1.471 ( 1.487)	Data  0.021 ( 0.026)	InnerLoop  0.635 ( 0.638)	Loss 7.6285e-01 (6.7721e-01)	Acc@1  71.14 ( 75.30)
Epoch: [72][40/59]	Time  1.468 ( 1.489)	Data  0.020 ( 0.026)	InnerLoop  0.623 ( 0.640)	Loss 8.8832e-01 (6.6374e-01)	Acc@1  64.50 ( 75.93)
The current update step is 4307
GPU_0_using curriculum 20 with window 20
Epoch: [73][20/59]	Time  1.453 ( 1.487)	Data  0.019 ( 0.032)	InnerLoop  0.620 ( 0.633)	Loss 6.9885e-01 (6.1714e-01)	Acc@1  73.93 ( 77.46)
Epoch: [73][40/59]	Time  1.478 ( 1.493)	Data  0.017 ( 0.029)	InnerLoop  0.635 ( 0.639)	Loss 6.2244e-01 (6.2401e-01)	Acc@1  77.98 ( 77.40)
The current update step is 4366
GPU_0_using curriculum 20 with window 20
Epoch: [74][20/59]	Time  1.517 ( 1.494)	Data  0.018 ( 0.032)	InnerLoop  0.650 ( 0.636)	Loss 5.1149e-01 (7.6236e-01)	Acc@1  82.57 ( 72.77)
Epoch: [74][40/59]	Time  1.483 ( 1.495)	Data  0.018 ( 0.028)	InnerLoop  0.647 ( 0.640)	Loss 1.1803e+00 (7.1059e-01)	Acc@1  66.31 ( 74.92)
The current update step is 4425
The current seed is 7739867708717267394
The current lr is: 0.001
Testing Results:
 *   Acc@1 78.632
 *   Acc@1 79.279
 *   Acc@1 77.368
 *   Acc@1 77.763
 *   Acc@1 75.382
 *   Acc@1 76.219
 *   Acc@1 70.921
 *   Acc@1 71.298
 *   Acc@1 71.132
 *   Acc@1 72.014
 *   Acc@1 72.237
 *   Acc@1 73.159
Training for 300 epoch: 74.77631578947368
Training for 600 epoch: 74.25
Training for 1000 epoch: 73.8092105263158
Training for 300 epoch: 75.28875
Training for 600 epoch: 74.88833333333334
Training for 1000 epoch: 74.68916666666667
[[74.77631578947368, 74.25, 73.8092105263158], [75.28875, 74.88833333333334, 74.68916666666667]]
train loss 0.37907385665575666, epoch 74, best loss 0.3058134133974711, best_epoch 24
GPU_0_using curriculum 20 with window 20
Epoch: [75][20/59]	Time  1.459 ( 1.488)	Data  0.018 ( 0.019)	InnerLoop  0.618 ( 0.648)	Loss 6.7047e-01 (6.5838e-01)	Acc@1  73.10 ( 75.91)
Epoch: [75][40/59]	Time  1.600 ( 1.493)	Data  0.139 ( 0.025)	InnerLoop  0.623 ( 0.644)	Loss 1.2074e+00 (6.8890e-01)	Acc@1  50.68 ( 74.20)
The current update step is 4484
GPU_0_using curriculum 20 with window 20
Epoch: [76][20/59]	Time  1.488 ( 1.485)	Data  0.022 ( 0.031)	InnerLoop  0.626 ( 0.631)	Loss 5.7862e-01 (6.9418e-01)	Acc@1  79.10 ( 74.51)
Epoch: [76][40/59]	Time  1.468 ( 1.490)	Data  0.017 ( 0.028)	InnerLoop  0.633 ( 0.638)	Loss 8.2843e-01 (6.9695e-01)	Acc@1  69.14 ( 74.43)
The current update step is 4543
GPU_0_using curriculum 20 with window 20
Epoch: [77][20/59]	Time  1.455 ( 1.485)	Data  0.019 ( 0.031)	InnerLoop  0.621 ( 0.633)	Loss 5.1863e-01 (6.0654e-01)	Acc@1  81.20 ( 77.63)
Epoch: [77][40/59]	Time  1.589 ( 1.490)	Data  0.020 ( 0.025)	InnerLoop  0.754 ( 0.642)	Loss 6.4760e-01 (6.5500e-01)	Acc@1  75.20 ( 76.02)
The current update step is 4602
GPU_0_using curriculum 20 with window 20
Epoch: [78][20/59]	Time  1.487 ( 1.489)	Data  0.018 ( 0.026)	InnerLoop  0.626 ( 0.639)	Loss 5.9596e-01 (7.3313e-01)	Acc@1  78.47 ( 74.05)
Epoch: [78][40/59]	Time  1.580 ( 1.492)	Data  0.021 ( 0.023)	InnerLoop  0.740 ( 0.644)	Loss 5.6182e-01 (7.0852e-01)	Acc@1  78.27 ( 74.09)
The current update step is 4661
GPU_0_using curriculum 20 with window 20
Epoch: [79][20/59]	Time  1.467 ( 1.487)	Data  0.019 ( 0.025)	InnerLoop  0.623 ( 0.638)	Loss 8.4733e-01 (7.1389e-01)	Acc@1  67.19 ( 72.94)
Epoch: [79][40/59]	Time  1.589 ( 1.490)	Data  0.022 ( 0.022)	InnerLoop  0.752 ( 0.644)	Loss 4.8686e-01 (7.4472e-01)	Acc@1  82.52 ( 72.86)
The current update step is 4720
The current seed is 12374480814815789557
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.026
 *   Acc@1 76.776
 *   Acc@1 76.395
 *   Acc@1 76.409
 *   Acc@1 76.671
 *   Acc@1 76.707
 *   Acc@1 73.908
 *   Acc@1 74.147
 *   Acc@1 75.882
 *   Acc@1 76.257
 *   Acc@1 76.737
 *   Acc@1 76.903
Training for 300 epoch: 75.46710526315789
Training for 600 epoch: 76.13815789473685
Training for 1000 epoch: 76.70394736842105
Training for 300 epoch: 75.46166666666667
Training for 600 epoch: 76.33333333333333
Training for 1000 epoch: 76.805
[[75.46710526315789, 76.13815789473685, 76.70394736842105], [75.46166666666667, 76.33333333333333, 76.805]]
train loss 0.3839296864668528, epoch 79, best loss 0.3058134133974711, best_epoch 24
GPU_0_using curriculum 20 with window 20
Epoch: [80][20/59]	Time  1.612 ( 1.487)	Data  0.019 ( 0.025)	InnerLoop  0.749 ( 0.642)	Loss 7.1281e-01 (7.6007e-01)	Acc@1  71.97 ( 72.58)
Epoch: [80][40/59]	Time  1.457 ( 1.490)	Data  0.018 ( 0.023)	InnerLoop  0.624 ( 0.645)	Loss 6.9382e-01 (7.4361e-01)	Acc@1  74.85 ( 72.98)
The current update step is 4779
GPU_0_using curriculum 20 with window 20
Epoch: [81][20/59]	Time  1.470 ( 1.486)	Data  0.018 ( 0.032)	InnerLoop  0.633 ( 0.632)	Loss 7.5015e-01 (7.2936e-01)	Acc@1  72.07 ( 74.76)
Epoch: [81][40/59]	Time  1.573 ( 1.488)	Data  0.020 ( 0.029)	InnerLoop  0.735 ( 0.636)	Loss 5.4462e-01 (7.0776e-01)	Acc@1  80.27 ( 75.00)
The current update step is 4838
GPU_0_using curriculum 20 with window 20
Epoch: [82][20/59]	Time  1.497 ( 1.483)	Data  0.020 ( 0.025)	InnerLoop  0.620 ( 0.637)	Loss 6.6172e-01 (7.0244e-01)	Acc@1  75.15 ( 74.61)
Epoch: [82][40/59]	Time  1.465 ( 1.489)	Data  0.019 ( 0.025)	InnerLoop  0.621 ( 0.641)	Loss 9.5346e-01 (7.3610e-01)	Acc@1  66.06 ( 73.25)
The current update step is 4897
GPU_0_using curriculum 20 with window 20
Epoch: [83][20/59]	Time  1.462 ( 1.483)	Data  0.020 ( 0.031)	InnerLoop  0.623 ( 0.631)	Loss 7.1879e-01 (7.2484e-01)	Acc@1  74.71 ( 73.26)
Epoch: [83][40/59]	Time  1.477 ( 1.487)	Data  0.019 ( 0.028)	InnerLoop  0.620 ( 0.635)	Loss 6.8692e-01 (7.1413e-01)	Acc@1  73.49 ( 73.46)
The current update step is 4956
GPU_0_using curriculum 20 with window 20
Epoch: [84][20/59]	Time  1.452 ( 1.489)	Data  0.017 ( 0.031)	InnerLoop  0.617 ( 0.633)	Loss 6.1533e-01 (6.3990e-01)	Acc@1  77.20 ( 76.69)
Epoch: [84][40/59]	Time  1.473 ( 1.488)	Data  0.020 ( 0.028)	InnerLoop  0.625 ( 0.635)	Loss 6.0166e-01 (6.4687e-01)	Acc@1  77.78 ( 76.01)
The current update step is 5015
The current seed is 7538747532818178090
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.316
 *   Acc@1 76.324
 *   Acc@1 76.408
 *   Acc@1 76.299
 *   Acc@1 75.961
 *   Acc@1 76.272
 *   Acc@1 78.184
 *   Acc@1 78.962
 *   Acc@1 78.092
 *   Acc@1 78.654
 *   Acc@1 77.921
 *   Acc@1 78.445
Training for 300 epoch: 77.25
Training for 600 epoch: 77.25
Training for 1000 epoch: 76.94078947368422
Training for 300 epoch: 77.64291666666668
Training for 600 epoch: 77.47666666666666
Training for 1000 epoch: 77.35833333333332
[[77.25, 77.25, 76.94078947368422], [77.64291666666668, 77.47666666666666, 77.35833333333332]]
train loss 0.3353584077358246, epoch 84, best loss 0.3058134133974711, best_epoch 84
GPU_0_using curriculum 20 with window 20
Epoch: [85][20/59]	Time  1.465 ( 1.485)	Data  0.020 ( 0.019)	InnerLoop  0.629 ( 0.643)	Loss 6.2995e-01 (6.7922e-01)	Acc@1  77.98 ( 76.09)
Epoch: [85][40/59]	Time  1.580 ( 1.490)	Data  0.138 ( 0.025)	InnerLoop  0.622 ( 0.641)	Loss 5.4370e-01 (6.7753e-01)	Acc@1  78.76 ( 75.74)
The current update step is 5074
GPU_0_using curriculum 20 with window 20
Epoch: [86][20/59]	Time  1.475 ( 1.488)	Data  0.021 ( 0.031)	InnerLoop  0.624 ( 0.633)	Loss 5.3055e-01 (6.8958e-01)	Acc@1  81.69 ( 75.39)
Epoch: [86][40/59]	Time  1.468 ( 1.492)	Data  0.019 ( 0.028)	InnerLoop  0.619 ( 0.639)	Loss 8.2108e-01 (6.6569e-01)	Acc@1  68.51 ( 75.90)
The current update step is 5133
GPU_0_using curriculum 20 with window 20
Epoch: [87][20/59]	Time  1.501 ( 1.485)	Data  0.019 ( 0.032)	InnerLoop  0.646 ( 0.631)	Loss 5.8311e-01 (7.0241e-01)	Acc@1  78.32 ( 74.05)
Epoch: [87][40/59]	Time  1.604 ( 1.488)	Data  0.018 ( 0.025)	InnerLoop  0.748 ( 0.641)	Loss 6.3554e-01 (6.5196e-01)	Acc@1  75.93 ( 76.02)
The current update step is 5192
GPU_0_using curriculum 20 with window 20
Epoch: [88][20/59]	Time  1.461 ( 1.485)	Data  0.019 ( 0.026)	InnerLoop  0.625 ( 0.635)	Loss 9.5608e-01 (6.6862e-01)	Acc@1  65.33 ( 76.01)
Epoch: [88][40/59]	Time  1.582 ( 1.489)	Data  0.019 ( 0.022)	InnerLoop  0.742 ( 0.642)	Loss 5.8189e-01 (6.4027e-01)	Acc@1  78.32 ( 76.73)
The current update step is 5251
GPU_0_using curriculum 20 with window 20
Epoch: [89][20/59]	Time  1.459 ( 1.481)	Data  0.021 ( 0.024)	InnerLoop  0.620 ( 0.634)	Loss 5.2415e-01 (6.2922e-01)	Acc@1  79.93 ( 77.18)
Epoch: [89][40/59]	Time  1.586 ( 1.486)	Data  0.019 ( 0.022)	InnerLoop  0.744 ( 0.642)	Loss 4.9994e-01 (6.2509e-01)	Acc@1  81.64 ( 76.95)
The current update step is 5310
The current seed is 2042563019415074705
The current lr is: 0.001
Testing Results:
 *   Acc@1 74.382
 *   Acc@1 74.304
 *   Acc@1 72.539
 *   Acc@1 72.585
 *   Acc@1 71.697
 *   Acc@1 72.123
 *   Acc@1 77.724
 *   Acc@1 78.555
 *   Acc@1 77.355
 *   Acc@1 77.860
 *   Acc@1 76.618
 *   Acc@1 77.518
Training for 300 epoch: 76.05263157894737
Training for 600 epoch: 74.94736842105263
Training for 1000 epoch: 74.15789473684211
Training for 300 epoch: 76.42958333333334
Training for 600 epoch: 75.2225
Training for 1000 epoch: 74.82041666666666
[[76.05263157894737, 74.94736842105263, 74.15789473684211], [76.42958333333334, 75.2225, 74.82041666666666]]
train loss 0.31795897421836855, epoch 89, best loss 0.3058134133974711, best_epoch 84
GPU_0_using curriculum 20 with window 20
Epoch: [90][20/59]	Time  1.580 ( 1.488)	Data  0.017 ( 0.025)	InnerLoop  0.741 ( 0.643)	Loss 7.2294e-01 (6.7657e-01)	Acc@1  73.49 ( 75.27)
Epoch: [90][40/59]	Time  1.471 ( 1.487)	Data  0.018 ( 0.022)	InnerLoop  0.632 ( 0.643)	Loss 6.6942e-01 (6.8506e-01)	Acc@1  75.54 ( 74.74)
The current update step is 5369
GPU_0_using curriculum 20 with window 20
Epoch: [91][20/59]	Time  1.472 ( 1.481)	Data  0.020 ( 0.031)	InnerLoop  0.633 ( 0.627)	Loss 7.0352e-01 (6.3996e-01)	Acc@1  76.03 ( 76.76)
Epoch: [91][40/59]	Time  1.587 ( 1.489)	Data  0.020 ( 0.028)	InnerLoop  0.748 ( 0.635)	Loss 1.2173e+00 (6.5380e-01)	Acc@1  64.01 ( 76.40)
The current update step is 5428
GPU_0_using curriculum 20 with window 20
Epoch: [92][20/59]	Time  1.468 ( 1.485)	Data  0.017 ( 0.026)	InnerLoop  0.631 ( 0.634)	Loss 7.2499e-01 (6.7749e-01)	Acc@1  70.02 ( 75.09)
Epoch: [92][40/59]	Time  1.467 ( 1.486)	Data  0.020 ( 0.025)	InnerLoop  0.623 ( 0.639)	Loss 7.1945e-01 (6.8660e-01)	Acc@1  74.32 ( 74.86)
The current update step is 5487
GPU_0_using curriculum 20 with window 20
Epoch: [93][20/59]	Time  1.464 ( 1.482)	Data  0.017 ( 0.031)	InnerLoop  0.625 ( 0.627)	Loss 5.8447e-01 (6.6976e-01)	Acc@1  79.00 ( 76.19)
Epoch: [93][40/59]	Time  1.473 ( 1.486)	Data  0.017 ( 0.028)	InnerLoop  0.628 ( 0.632)	Loss 1.0789e+00 (6.8746e-01)	Acc@1  68.90 ( 75.66)
The current update step is 5546
GPU_0_using curriculum 20 with window 20
Epoch: [94][20/59]	Time  1.454 ( 1.484)	Data  0.018 ( 0.031)	InnerLoop  0.622 ( 0.627)	Loss 5.1299e-01 (6.7345e-01)	Acc@1  81.40 ( 76.00)
Epoch: [94][40/59]	Time  1.458 ( 1.484)	Data  0.020 ( 0.028)	InnerLoop  0.617 ( 0.631)	Loss 4.6226e-01 (6.4899e-01)	Acc@1  82.57 ( 76.48)
The current update step is 5605
The current seed is 8782518537501332735
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.474
 *   Acc@1 72.120
 *   Acc@1 71.145
 *   Acc@1 71.517
 *   Acc@1 69.382
 *   Acc@1 69.720
 *   Acc@1 64.974
 *   Acc@1 64.961
 *   Acc@1 61.658
 *   Acc@1 61.789
 *   Acc@1 54.132
 *   Acc@1 53.979
Training for 300 epoch: 68.22368421052632
Training for 600 epoch: 66.40131578947368
Training for 1000 epoch: 61.756578947368425
Training for 300 epoch: 68.54041666666666
Training for 600 epoch: 66.65333333333334
Training for 1000 epoch: 61.84958333333333
[[68.22368421052632, 66.40131578947368, 61.756578947368425], [68.54041666666666, 66.65333333333334, 61.84958333333333]]
train loss 0.7674839324951171, epoch 94, best loss 0.3058134133974711, best_epoch 84
GPU_0_using curriculum 20 with window 20
Epoch: [95][20/59]	Time  1.465 ( 1.490)	Data  0.020 ( 0.019)	InnerLoop  0.629 ( 0.647)	Loss 6.9715e-01 (6.2543e-01)	Acc@1  74.37 ( 77.13)
Epoch: [95][40/59]	Time  1.583 ( 1.495)	Data  0.134 ( 0.025)	InnerLoop  0.625 ( 0.644)	Loss 8.2702e-01 (6.4057e-01)	Acc@1  68.90 ( 76.30)
The current update step is 5664
GPU_0_using curriculum 20 with window 20
Epoch: [96][20/59]	Time  1.473 ( 1.486)	Data  0.021 ( 0.032)	InnerLoop  0.625 ( 0.631)	Loss 6.9518e-01 (6.5714e-01)	Acc@1  71.88 ( 75.58)
Epoch: [96][40/59]	Time  1.470 ( 1.491)	Data  0.019 ( 0.028)	InnerLoop  0.624 ( 0.639)	Loss 6.3135e-01 (6.4357e-01)	Acc@1  77.83 ( 76.18)
The current update step is 5723
GPU_0_using curriculum 20 with window 20
Epoch: [97][20/59]	Time  1.480 ( 1.491)	Data  0.019 ( 0.032)	InnerLoop  0.641 ( 0.633)	Loss 1.1549e+00 (7.0931e-01)	Acc@1  64.94 ( 74.73)
Epoch: [97][40/59]	Time  1.600 ( 1.498)	Data  0.019 ( 0.025)	InnerLoop  0.749 ( 0.644)	Loss 6.3016e-01 (6.8463e-01)	Acc@1  77.39 ( 74.87)
The current update step is 5782
GPU_0_using curriculum 20 with window 20
Epoch: [98][20/59]	Time  1.466 ( 1.493)	Data  0.020 ( 0.026)	InnerLoop  0.627 ( 0.637)	Loss 5.4677e-01 (6.5034e-01)	Acc@1  79.93 ( 76.35)
Epoch: [98][40/59]	Time  1.587 ( 1.495)	Data  0.020 ( 0.023)	InnerLoop  0.744 ( 0.644)	Loss 5.5127e-01 (6.5191e-01)	Acc@1  81.59 ( 75.94)
The current update step is 5841
GPU_0_using curriculum 20 with window 20
Epoch: [99][20/59]	Time  1.463 ( 1.489)	Data  0.017 ( 0.025)	InnerLoop  0.625 ( 0.641)	Loss 5.3347e-01 (6.6387e-01)	Acc@1  79.93 ( 75.47)
Epoch: [99][40/59]	Time  1.586 ( 1.492)	Data  0.021 ( 0.022)	InnerLoop  0.744 ( 0.647)	Loss 6.5685e-01 (6.5501e-01)	Acc@1  76.86 ( 75.63)
The current update step is 5900
The current seed is 4381881561003845183
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.684
 *   Acc@1 78.437
 *   Acc@1 77.145
 *   Acc@1 78.017
 *   Acc@1 77.618
 *   Acc@1 78.082
 *   Acc@1 75.908
 *   Acc@1 76.576
 *   Acc@1 76.184
 *   Acc@1 76.252
 *   Acc@1 75.408
 *   Acc@1 75.530
Training for 300 epoch: 76.79605263157896
Training for 600 epoch: 76.66447368421052
Training for 1000 epoch: 76.51315789473685
Training for 300 epoch: 77.50625
Training for 600 epoch: 77.13499999999999
Training for 1000 epoch: 76.80583333333334
[[76.79605263157896, 76.66447368421052, 76.51315789473685], [77.50625, 77.13499999999999, 76.80583333333334]]
train loss 0.31690935969352724, epoch 99, best loss 0.3058134133974711, best_epoch 84
GPU_0_using curriculum 20 with window 20
Epoch: [100][20/59]	Time  1.620 ( 1.505)	Data  0.017 ( 0.024)	InnerLoop  0.755 ( 0.651)	Loss 5.7284e-01 (6.0708e-01)	Acc@1  79.25 ( 77.20)
Epoch: [100][40/59]	Time  1.479 ( 1.503)	Data  0.018 ( 0.022)	InnerLoop  0.631 ( 0.651)	Loss 5.7460e-01 (6.0227e-01)	Acc@1  78.42 ( 77.81)
The current update step is 5959
GPU_0_using curriculum 20 with window 20
Epoch: [101][20/59]	Time  1.470 ( 1.496)	Data  0.019 ( 0.031)	InnerLoop  0.626 ( 0.635)	Loss 6.7680e-01 (6.6448e-01)	Acc@1  74.22 ( 76.28)
Epoch: [101][40/59]	Time  1.578 ( 1.500)	Data  0.019 ( 0.028)	InnerLoop  0.744 ( 0.644)	Loss 5.5889e-01 (6.6334e-01)	Acc@1  79.64 ( 75.88)
The current update step is 6018
GPU_0_using curriculum 20 with window 20
Epoch: [102][20/59]	Time  1.498 ( 1.493)	Data  0.019 ( 0.025)	InnerLoop  0.645 ( 0.640)	Loss 5.9540e-01 (5.8571e-01)	Acc@1  76.71 ( 78.42)
Epoch: [102][40/59]	Time  1.476 ( 1.498)	Data  0.020 ( 0.025)	InnerLoop  0.630 ( 0.644)	Loss 6.2854e-01 (6.3405e-01)	Acc@1  76.27 ( 77.06)
The current update step is 6077
GPU_0_using curriculum 20 with window 20
Epoch: [103][20/59]	Time  1.497 ( 1.494)	Data  0.020 ( 0.031)	InnerLoop  0.625 ( 0.635)	Loss 5.7707e-01 (6.5584e-01)	Acc@1  77.05 ( 76.37)
Epoch: [103][40/59]	Time  1.472 ( 1.498)	Data  0.019 ( 0.028)	InnerLoop  0.628 ( 0.640)	Loss 7.3034e-01 (6.6071e-01)	Acc@1  75.68 ( 75.80)
The current update step is 6136
GPU_0_using curriculum 20 with window 20
Epoch: [104][20/59]	Time  1.499 ( 1.494)	Data  0.018 ( 0.031)	InnerLoop  0.643 ( 0.637)	Loss 6.6911e-01 (6.3982e-01)	Acc@1  75.49 ( 76.52)
Epoch: [104][40/59]	Time  1.468 ( 1.495)	Data  0.017 ( 0.028)	InnerLoop  0.628 ( 0.641)	Loss 5.5441e-01 (6.6899e-01)	Acc@1  79.49 ( 75.61)
The current update step is 6195
The current seed is 14219155722525571440
The current lr is: 0.001
Testing Results:
 *   Acc@1 75.158
 *   Acc@1 74.721
 *   Acc@1 71.316
 *   Acc@1 70.713
 *   Acc@1 68.671
 *   Acc@1 68.125
 *   Acc@1 70.447
 *   Acc@1 70.567
 *   Acc@1 68.013
 *   Acc@1 68.354
 *   Acc@1 66.645
 *   Acc@1 66.988
Training for 300 epoch: 72.80263157894737
Training for 600 epoch: 69.66447368421052
Training for 1000 epoch: 67.65789473684211
Training for 300 epoch: 72.64375
Training for 600 epoch: 69.53375
Training for 1000 epoch: 67.55666666666667
[[72.80263157894737, 69.66447368421052, 67.65789473684211], [72.64375, 69.53375, 67.55666666666667]]
train loss 0.542780259958903, epoch 104, best loss 0.3058134133974711, best_epoch 84
GPU_0_using curriculum 20 with window 20
Epoch: [105][20/59]	Time  1.477 ( 1.495)	Data  0.021 ( 0.019)	InnerLoop  0.631 ( 0.650)	Loss 5.7123e-01 (6.4260e-01)	Acc@1  78.42 ( 75.93)
Epoch: [105][40/59]	Time  1.582 ( 1.502)	Data  0.137 ( 0.025)	InnerLoop  0.617 ( 0.647)	Loss 7.1338e-01 (6.6132e-01)	Acc@1  74.95 ( 75.44)
The current update step is 6254
GPU_0_using curriculum 20 with window 20
Epoch: [106][20/59]	Time  1.470 ( 1.495)	Data  0.019 ( 0.031)	InnerLoop  0.627 ( 0.639)	Loss 5.6266e-01 (6.1985e-01)	Acc@1  81.88 ( 77.61)
Epoch: [106][40/59]	Time  1.481 ( 1.498)	Data  0.020 ( 0.028)	InnerLoop  0.632 ( 0.644)	Loss 5.8567e-01 (6.2631e-01)	Acc@1  76.81 ( 77.12)
The current update step is 6313
GPU_0_using curriculum 20 with window 20
Epoch: [107][20/59]	Time  1.478 ( 1.493)	Data  0.019 ( 0.031)	InnerLoop  0.637 ( 0.639)	Loss 6.1972e-01 (5.9773e-01)	Acc@1  77.73 ( 77.65)
Epoch: [107][40/59]	Time  1.584 ( 1.500)	Data  0.019 ( 0.025)	InnerLoop  0.744 ( 0.648)	Loss 5.2864e-01 (5.9956e-01)	Acc@1  80.22 ( 77.78)
The current update step is 6372
GPU_0_using curriculum 20 with window 20
Epoch: [108][20/59]	Time  1.454 ( 1.490)	Data  0.019 ( 0.026)	InnerLoop  0.619 ( 0.639)	Loss 6.4806e-01 (6.1425e-01)	Acc@1  77.20 ( 77.69)
Epoch: [108][40/59]	Time  1.577 ( 1.499)	Data  0.019 ( 0.022)	InnerLoop  0.740 ( 0.647)	Loss 4.9722e-01 (6.0004e-01)	Acc@1  81.74 ( 78.28)
The current update step is 6431
GPU_0_using curriculum 20 with window 20
Epoch: [109][20/59]	Time  1.479 ( 1.494)	Data  0.020 ( 0.025)	InnerLoop  0.633 ( 0.640)	Loss 5.4571e-01 (6.0688e-01)	Acc@1  81.54 ( 78.00)
Epoch: [109][40/59]	Time  1.654 ( 1.499)	Data  0.018 ( 0.022)	InnerLoop  0.754 ( 0.647)	Loss 6.8944e-01 (6.1479e-01)	Acc@1  75.00 ( 77.46)
The current update step is 6490
The current seed is 4577223708661261691
The current lr is: 0.001
Testing Results:
 *   Acc@1 75.000
 *   Acc@1 75.198
 *   Acc@1 71.908
 *   Acc@1 72.343
 *   Acc@1 69.908
 *   Acc@1 70.157
 *   Acc@1 74.842
 *   Acc@1 75.005
 *   Acc@1 73.553
 *   Acc@1 73.860
 *   Acc@1 72.434
 *   Acc@1 72.535
Training for 300 epoch: 74.92105263157895
Training for 600 epoch: 72.73026315789474
Training for 1000 epoch: 71.17105263157896
Training for 300 epoch: 75.10166666666666
Training for 600 epoch: 73.10125
Training for 1000 epoch: 71.34625
[[74.92105263157895, 72.73026315789474, 71.17105263157896], [75.10166666666666, 73.10125, 71.34625]]
train loss 0.41944224810600284, epoch 109, best loss 0.3058134133974711, best_epoch 84
GPU_0_using curriculum 20 with window 20
Epoch: [110][20/59]	Time  1.583 ( 1.500)	Data  0.017 ( 0.025)	InnerLoop  0.749 ( 0.647)	Loss 5.9553e-01 (7.4757e-01)	Acc@1  77.44 ( 72.79)
Epoch: [110][40/59]	Time  1.475 ( 1.496)	Data  0.018 ( 0.022)	InnerLoop  0.630 ( 0.647)	Loss 6.1811e-01 (7.5973e-01)	Acc@1  78.12 ( 72.26)
The current update step is 6549
GPU_0_using curriculum 20 with window 20
Epoch: [111][20/59]	Time  1.495 ( 1.488)	Data  0.022 ( 0.033)	InnerLoop  0.626 ( 0.631)	Loss 5.0842e-01 (6.4680e-01)	Acc@1  81.98 ( 75.94)
Epoch: [111][40/59]	Time  1.617 ( 1.492)	Data  0.025 ( 0.029)	InnerLoop  0.738 ( 0.638)	Loss 5.7724e-01 (6.2402e-01)	Acc@1  77.49 ( 76.86)
The current update step is 6608
GPU_0_using curriculum 20 with window 20
Epoch: [112][20/59]	Time  1.488 ( 1.494)	Data  0.019 ( 0.026)	InnerLoop  0.645 ( 0.643)	Loss 5.2699e-01 (6.8684e-01)	Acc@1  80.71 ( 75.63)
Epoch: [112][40/59]	Time  1.476 ( 1.497)	Data  0.021 ( 0.026)	InnerLoop  0.629 ( 0.646)	Loss 5.4397e-01 (6.6404e-01)	Acc@1  80.08 ( 75.91)
The current update step is 6667
GPU_0_using curriculum 20 with window 20
Epoch: [113][20/59]	Time  1.468 ( 1.489)	Data  0.018 ( 0.032)	InnerLoop  0.632 ( 0.636)	Loss 5.6726e-01 (6.5142e-01)	Acc@1  78.86 ( 76.13)
Epoch: [113][40/59]	Time  1.456 ( 1.490)	Data  0.018 ( 0.029)	InnerLoop  0.622 ( 0.639)	Loss 7.9220e-01 (6.3373e-01)	Acc@1  75.93 ( 77.09)
The current update step is 6726
GPU_0_using curriculum 20 with window 20
Epoch: [114][20/59]	Time  1.464 ( 1.489)	Data  0.020 ( 0.031)	InnerLoop  0.626 ( 0.633)	Loss 5.6733e-01 (5.9698e-01)	Acc@1  81.05 ( 78.44)
Epoch: [114][40/59]	Time  1.469 ( 1.492)	Data  0.017 ( 0.028)	InnerLoop  0.630 ( 0.636)	Loss 6.1147e-01 (6.1447e-01)	Acc@1  77.25 ( 77.74)
The current update step is 6785
The current seed is 11358107259578674657
The current lr is: 0.001
Testing Results:
 *   Acc@1 79.684
 *   Acc@1 80.823
 *   Acc@1 77.724
 *   Acc@1 77.953
 *   Acc@1 75.763
 *   Acc@1 76.418
 *   Acc@1 78.132
 *   Acc@1 78.197
 *   Acc@1 77.184
 *   Acc@1 77.301
 *   Acc@1 76.632
 *   Acc@1 77.264
Training for 300 epoch: 78.90789473684211
Training for 600 epoch: 77.45394736842105
Training for 1000 epoch: 76.19736842105263
Training for 300 epoch: 79.51
Training for 600 epoch: 77.62708333333333
Training for 1000 epoch: 76.84083333333334
[[78.90789473684211, 77.45394736842105, 76.19736842105263], [79.51, 77.62708333333333, 76.84083333333334]]
train loss 0.3266182113806407, epoch 114, best loss 0.3058134133974711, best_epoch 84
GPU_0_using curriculum 20 with window 20
Epoch: [115][20/59]	Time  1.473 ( 1.489)	Data  0.021 ( 0.019)	InnerLoop  0.628 ( 0.646)	Loss 6.5089e-01 (6.3215e-01)	Acc@1  77.00 ( 76.38)
Epoch: [115][40/59]	Time  1.587 ( 1.494)	Data  0.142 ( 0.025)	InnerLoop  0.622 ( 0.644)	Loss 5.5589e-01 (6.0525e-01)	Acc@1  79.05 ( 77.62)
The current update step is 6844
GPU_0_using curriculum 20 with window 20
Epoch: [116][20/59]	Time  1.466 ( 1.491)	Data  0.020 ( 0.031)	InnerLoop  0.624 ( 0.633)	Loss 5.1152e-01 (6.1952e-01)	Acc@1  81.74 ( 77.12)
Epoch: [116][40/59]	Time  1.475 ( 1.494)	Data  0.022 ( 0.028)	InnerLoop  0.632 ( 0.640)	Loss 5.2936e-01 (6.0966e-01)	Acc@1  81.69 ( 77.34)
The current update step is 6903
GPU_0_using curriculum 20 with window 20
Epoch: [117][20/59]	Time  1.461 ( 1.485)	Data  0.019 ( 0.032)	InnerLoop  0.623 ( 0.631)	Loss 9.0210e-01 (6.5198e-01)	Acc@1  63.13 ( 75.76)
Epoch: [117][40/59]	Time  1.620 ( 1.493)	Data  0.019 ( 0.025)	InnerLoop  0.745 ( 0.642)	Loss 6.0200e-01 (6.2165e-01)	Acc@1  80.22 ( 77.15)
The current update step is 6962
GPU_0_using curriculum 20 with window 20
Epoch: [118][20/59]	Time  1.459 ( 1.488)	Data  0.019 ( 0.026)	InnerLoop  0.621 ( 0.639)	Loss 5.8056e-01 (6.0704e-01)	Acc@1  78.08 ( 77.81)
Epoch: [118][40/59]	Time  1.590 ( 1.492)	Data  0.021 ( 0.022)	InnerLoop  0.746 ( 0.645)	Loss 1.0633e+00 (6.2615e-01)	Acc@1  69.09 ( 77.26)
The current update step is 7021
GPU_0_using curriculum 20 with window 20
Epoch: [119][20/59]	Time  1.474 ( 1.487)	Data  0.020 ( 0.025)	InnerLoop  0.631 ( 0.639)	Loss 9.2338e-01 (6.5120e-01)	Acc@1  66.50 ( 76.48)
Epoch: [119][40/59]	Time  1.597 ( 1.494)	Data  0.022 ( 0.022)	InnerLoop  0.752 ( 0.646)	Loss 6.4575e-01 (6.5784e-01)	Acc@1  75.88 ( 75.55)
The current update step is 7080
The current seed is 16082920506668176866
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.882
 *   Acc@1 71.748
 *   Acc@1 66.342
 *   Acc@1 66.998
 *   Acc@1 65.355
 *   Acc@1 65.783
 *   Acc@1 78.658
 *   Acc@1 79.444
 *   Acc@1 75.842
 *   Acc@1 76.645
 *   Acc@1 73.303
 *   Acc@1 74.191
Training for 300 epoch: 74.76973684210526
Training for 600 epoch: 71.09210526315789
Training for 1000 epoch: 69.32894736842105
Training for 300 epoch: 75.59583333333333
Training for 600 epoch: 71.82166666666666
Training for 1000 epoch: 69.98708333333333
[[74.76973684210526, 71.09210526315789, 69.32894736842105], [75.59583333333333, 71.82166666666666, 69.98708333333333]]
train loss 0.35225209415753683, epoch 119, best loss 0.3058134133974711, best_epoch 84
GPU_0_using curriculum 20 with window 20
Epoch: [120][20/59]	Time  1.606 ( 1.495)	Data  0.023 ( 0.025)	InnerLoop  0.744 ( 0.645)	Loss 6.4322e-01 (6.5050e-01)	Acc@1  74.61 ( 75.52)
Epoch: [120][40/59]	Time  1.475 ( 1.494)	Data  0.020 ( 0.022)	InnerLoop  0.625 ( 0.646)	Loss 6.9070e-01 (6.6468e-01)	Acc@1  74.61 ( 75.14)
The current update step is 7139
GPU_0_using curriculum 20 with window 20
Epoch: [121][20/59]	Time  1.483 ( 1.485)	Data  0.019 ( 0.031)	InnerLoop  0.632 ( 0.633)	Loss 5.3324e-01 (6.2067e-01)	Acc@1  82.76 ( 77.36)
Epoch: [121][40/59]	Time  1.593 ( 1.492)	Data  0.018 ( 0.028)	InnerLoop  0.735 ( 0.640)	Loss 7.6260e-01 (6.2209e-01)	Acc@1  72.41 ( 77.35)
The current update step is 7198
GPU_0_using curriculum 20 with window 20
Epoch: [122][20/59]	Time  1.465 ( 1.495)	Data  0.019 ( 0.025)	InnerLoop  0.625 ( 0.644)	Loss 6.0091e-01 (6.2198e-01)	Acc@1  76.95 ( 77.12)
Epoch: [122][40/59]	Time  1.468 ( 1.499)	Data  0.017 ( 0.025)	InnerLoop  0.629 ( 0.648)	Loss 5.6156e-01 (6.2722e-01)	Acc@1  78.91 ( 76.90)
The current update step is 7257
GPU_0_using curriculum 20 with window 20
Epoch: [123][20/59]	Time  1.467 ( 1.494)	Data  0.018 ( 0.031)	InnerLoop  0.626 ( 0.637)	Loss 5.8326e-01 (5.9559e-01)	Acc@1  79.05 ( 78.37)
Epoch: [123][40/59]	Time  1.475 ( 1.496)	Data  0.018 ( 0.028)	InnerLoop  0.626 ( 0.639)	Loss 1.1453e+00 (6.1921e-01)	Acc@1  62.94 ( 77.64)
The current update step is 7316
GPU_0_using curriculum 20 with window 20
Epoch: [124][20/59]	Time  1.468 ( 1.483)	Data  0.020 ( 0.031)	InnerLoop  0.625 ( 0.632)	Loss 5.3563e-01 (6.5730e-01)	Acc@1  80.71 ( 76.84)
Epoch: [124][40/59]	Time  1.462 ( 1.487)	Data  0.021 ( 0.028)	InnerLoop  0.619 ( 0.636)	Loss 6.2845e-01 (6.7221e-01)	Acc@1  77.10 ( 76.35)
The current update step is 7375
The current seed is 13711030007033177738
The current lr is: 0.001
Testing Results:
 *   Acc@1 74.987
 *   Acc@1 75.960
 *   Acc@1 73.408
 *   Acc@1 74.085
 *   Acc@1 72.579
 *   Acc@1 72.956
 *   Acc@1 66.724
 *   Acc@1 66.675
 *   Acc@1 66.145
 *   Acc@1 66.226
 *   Acc@1 65.500
 *   Acc@1 65.673
Training for 300 epoch: 70.85526315789474
Training for 600 epoch: 69.77631578947368
Training for 1000 epoch: 69.03947368421052
Training for 300 epoch: 71.3175
Training for 600 epoch: 70.15541666666667
Training for 1000 epoch: 69.31458333333333
[[70.85526315789474, 69.77631578947368, 69.03947368421052], [71.3175, 70.15541666666667, 69.31458333333333]]
train loss 0.5654276522636413, epoch 124, best loss 0.3058134133974711, best_epoch 84
GPU_0_using curriculum 20 with window 20
Epoch: [125][20/59]	Time  1.465 ( 1.487)	Data  0.020 ( 0.019)	InnerLoop  0.624 ( 0.644)	Loss 5.0088e-01 (6.2000e-01)	Acc@1  82.91 ( 77.18)
Epoch: [125][40/59]	Time  1.589 ( 1.493)	Data  0.137 ( 0.025)	InnerLoop  0.630 ( 0.642)	Loss 6.2143e-01 (6.2248e-01)	Acc@1  71.92 ( 76.83)
The current update step is 7434
GPU_0_using curriculum 20 with window 20
Epoch: [126][20/59]	Time  1.486 ( 1.487)	Data  0.020 ( 0.032)	InnerLoop  0.627 ( 0.632)	Loss 5.2364e-01 (6.2701e-01)	Acc@1  80.42 ( 76.92)
Epoch: [126][40/59]	Time  1.463 ( 1.491)	Data  0.018 ( 0.028)	InnerLoop  0.624 ( 0.639)	Loss 5.6783e-01 (6.1662e-01)	Acc@1  79.83 ( 77.24)
The current update step is 7493
GPU_0_using curriculum 20 with window 20
Epoch: [127][20/59]	Time  1.463 ( 1.487)	Data  0.019 ( 0.031)	InnerLoop  0.625 ( 0.631)	Loss 5.6193e-01 (6.5363e-01)	Acc@1  80.22 ( 77.07)
Epoch: [127][40/59]	Time  1.620 ( 1.493)	Data  0.020 ( 0.025)	InnerLoop  0.756 ( 0.642)	Loss 7.3266e-01 (6.5866e-01)	Acc@1  75.29 ( 76.49)
The current update step is 7552
GPU_0_using curriculum 20 with window 20
Epoch: [128][20/59]	Time  1.465 ( 1.490)	Data  0.019 ( 0.025)	InnerLoop  0.628 ( 0.641)	Loss 7.3877e-01 (6.4786e-01)	Acc@1  70.65 ( 75.75)
Epoch: [128][40/59]	Time  1.600 ( 1.494)	Data  0.020 ( 0.022)	InnerLoop  0.741 ( 0.647)	Loss 6.6472e-01 (6.7693e-01)	Acc@1  75.88 ( 74.86)
The current update step is 7611
GPU_0_using curriculum 20 with window 20
Epoch: [129][20/59]	Time  1.487 ( 1.487)	Data  0.017 ( 0.025)	InnerLoop  0.629 ( 0.640)	Loss 1.0074e+00 (6.9837e-01)	Acc@1  59.77 ( 73.99)
Epoch: [129][40/59]	Time  1.588 ( 1.492)	Data  0.018 ( 0.021)	InnerLoop  0.751 ( 0.646)	Loss 5.6810e-01 (6.7320e-01)	Acc@1  78.56 ( 75.06)
The current update step is 7670
The current seed is 10626824388211885594
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.329
 *   Acc@1 73.257
 *   Acc@1 71.789
 *   Acc@1 71.513
 *   Acc@1 70.079
 *   Acc@1 70.053
 *   Acc@1 78.566
 *   Acc@1 78.704
 *   Acc@1 75.671
 *   Acc@1 75.953
 *   Acc@1 71.658
 *   Acc@1 71.817
Training for 300 epoch: 75.94736842105263
Training for 600 epoch: 73.73026315789474
Training for 1000 epoch: 70.86842105263159
Training for 300 epoch: 75.98083333333332
Training for 600 epoch: 73.7325
Training for 1000 epoch: 70.93541666666667
[[75.94736842105263, 73.73026315789474, 70.86842105263159], [75.98083333333332, 73.7325, 70.93541666666667]]
train loss 0.4477051630020142, epoch 129, best loss 0.3058134133974711, best_epoch 84
GPU_0_using curriculum 20 with window 20
Epoch: [130][20/59]	Time  1.580 ( 1.490)	Data  0.017 ( 0.024)	InnerLoop  0.745 ( 0.644)	Loss 7.0411e-01 (6.6218e-01)	Acc@1  68.95 ( 76.04)
Epoch: [130][40/59]	Time  1.460 ( 1.490)	Data  0.018 ( 0.021)	InnerLoop  0.625 ( 0.644)	Loss 5.7186e-01 (6.3934e-01)	Acc@1  79.20 ( 76.88)
The current update step is 7729
GPU_0_using curriculum 20 with window 20
Epoch: [131][20/59]	Time  1.467 ( 1.491)	Data  0.019 ( 0.031)	InnerLoop  0.629 ( 0.633)	Loss 5.7012e-01 (6.1062e-01)	Acc@1  79.44 ( 77.42)
Epoch: [131][40/59]	Time  1.583 ( 1.494)	Data  0.020 ( 0.028)	InnerLoop  0.746 ( 0.639)	Loss 5.0338e-01 (5.9949e-01)	Acc@1  82.47 ( 78.18)
The current update step is 7788
GPU_0_using curriculum 20 with window 20
Epoch: [132][20/59]	Time  1.460 ( 1.489)	Data  0.019 ( 0.025)	InnerLoop  0.622 ( 0.640)	Loss 5.0132e-01 (6.4268e-01)	Acc@1  81.30 ( 76.74)
Epoch: [132][40/59]	Time  1.464 ( 1.493)	Data  0.018 ( 0.025)	InnerLoop  0.627 ( 0.643)	Loss 6.3435e-01 (6.3203e-01)	Acc@1  76.46 ( 77.29)
The current update step is 7847
GPU_0_using curriculum 20 with window 20
Epoch: [133][20/59]	Time  1.462 ( 1.490)	Data  0.020 ( 0.031)	InnerLoop  0.625 ( 0.632)	Loss 5.2153e-01 (5.7122e-01)	Acc@1  79.79 ( 79.07)
Epoch: [133][40/59]	Time  1.473 ( 1.491)	Data  0.018 ( 0.028)	InnerLoop  0.631 ( 0.636)	Loss 4.7529e-01 (5.9603e-01)	Acc@1  82.81 ( 78.20)
The current update step is 7906
GPU_0_using curriculum 20 with window 20
Epoch: [134][20/59]	Time  1.466 ( 1.485)	Data  0.018 ( 0.031)	InnerLoop  0.629 ( 0.633)	Loss 4.7987e-01 (6.2688e-01)	Acc@1  83.20 ( 77.11)
Epoch: [134][40/59]	Time  1.471 ( 1.487)	Data  0.017 ( 0.028)	InnerLoop  0.633 ( 0.636)	Loss 5.4591e-01 (6.2000e-01)	Acc@1  81.59 ( 77.49)
The current update step is 7965
The current seed is 3816442992849229763
The current lr is: 0.001
Testing Results:
 *   Acc@1 80.211
 *   Acc@1 80.389
 *   Acc@1 78.276
 *   Acc@1 78.490
 *   Acc@1 77.395
 *   Acc@1 77.429
 *   Acc@1 78.171
 *   Acc@1 78.409
 *   Acc@1 74.895
 *   Acc@1 75.081
 *   Acc@1 73.079
 *   Acc@1 73.634
Training for 300 epoch: 79.19078947368422
Training for 600 epoch: 76.58552631578948
Training for 1000 epoch: 75.23684210526315
Training for 300 epoch: 79.39916666666667
Training for 600 epoch: 76.78541666666666
Training for 1000 epoch: 75.53166666666667
[[79.19078947368422, 76.58552631578948, 75.23684210526315], [79.39916666666667, 76.78541666666666, 75.53166666666667]]
train loss 0.5132156021912893, epoch 134, best loss 0.3058134133974711, best_epoch 84
GPU_0_using curriculum 20 with window 20
Epoch: [135][20/59]	Time  1.467 ( 1.494)	Data  0.020 ( 0.019)	InnerLoop  0.629 ( 0.650)	Loss 5.5222e-01 (6.0919e-01)	Acc@1  80.13 ( 77.44)
Epoch: [135][40/59]	Time  1.609 ( 1.496)	Data  0.139 ( 0.025)	InnerLoop  0.622 ( 0.645)	Loss 5.3532e-01 (5.8946e-01)	Acc@1  79.39 ( 78.46)
The current update step is 8024
GPU_0_using curriculum 20 with window 20
Epoch: [136][20/59]	Time  1.475 ( 1.489)	Data  0.021 ( 0.031)	InnerLoop  0.633 ( 0.633)	Loss 5.4152e-01 (5.7740e-01)	Acc@1  80.27 ( 78.40)
Epoch: [136][40/59]	Time  1.469 ( 1.492)	Data  0.018 ( 0.028)	InnerLoop  0.625 ( 0.639)	Loss 8.4249e-01 (5.8279e-01)	Acc@1  70.17 ( 78.46)
The current update step is 8083
GPU_0_using curriculum 20 with window 20
Epoch: [137][20/59]	Time  1.494 ( 1.496)	Data  0.019 ( 0.031)	InnerLoop  0.644 ( 0.637)	Loss 5.0987e-01 (5.9363e-01)	Acc@1  82.13 ( 78.75)
Epoch: [137][40/59]	Time  1.593 ( 1.499)	Data  0.019 ( 0.025)	InnerLoop  0.742 ( 0.646)	Loss 7.1621e-01 (6.2503e-01)	Acc@1  75.63 ( 77.69)
The current update step is 8142
GPU_0_using curriculum 20 with window 20
Epoch: [138][20/59]	Time  1.470 ( 1.495)	Data  0.020 ( 0.025)	InnerLoop  0.629 ( 0.640)	Loss 5.9806e-01 (6.0879e-01)	Acc@1  75.63 ( 77.81)
Epoch: [138][40/59]	Time  1.609 ( 1.501)	Data  0.021 ( 0.022)	InnerLoop  0.742 ( 0.648)	Loss 6.0593e-01 (6.1423e-01)	Acc@1  79.44 ( 77.57)
The current update step is 8201
GPU_0_using curriculum 20 with window 20
Epoch: [139][20/59]	Time  1.464 ( 1.490)	Data  0.017 ( 0.025)	InnerLoop  0.629 ( 0.642)	Loss 5.5800e-01 (5.9864e-01)	Acc@1  76.81 ( 78.19)
Epoch: [139][40/59]	Time  1.595 ( 1.500)	Data  0.019 ( 0.021)	InnerLoop  0.750 ( 0.649)	Loss 6.2246e-01 (6.0428e-01)	Acc@1  75.00 ( 77.97)
The current update step is 8260
The current seed is 7334571432257100968
The current lr is: 0.001
Testing Results:
 *   Acc@1 79.842
 *   Acc@1 80.544
 *   Acc@1 77.368
 *   Acc@1 77.847
 *   Acc@1 74.855
 *   Acc@1 75.313
 *   Acc@1 68.197
 *   Acc@1 68.554
 *   Acc@1 62.645
 *   Acc@1 62.532
 *   Acc@1 59.763
 *   Acc@1 59.955
Training for 300 epoch: 74.01973684210526
Training for 600 epoch: 70.00657894736841
Training for 1000 epoch: 67.3092105263158
Training for 300 epoch: 74.54916666666666
Training for 600 epoch: 70.18958333333333
Training for 1000 epoch: 67.63416666666666
[[74.01973684210526, 70.00657894736841, 67.3092105263158], [74.54916666666666, 70.18958333333333, 67.63416666666666]]
train loss 0.7533778752644856, epoch 139, best loss 0.3058134133974711, best_epoch 84
GPU_0_using curriculum 20 with window 20
Epoch: [140][20/59]	Time  1.615 ( 1.506)	Data  0.024 ( 0.025)	InnerLoop  0.753 ( 0.646)	Loss 6.7032e-01 (6.2446e-01)	Acc@1  74.90 ( 77.37)
Epoch: [140][40/59]	Time  1.494 ( 1.503)	Data  0.021 ( 0.022)	InnerLoop  0.630 ( 0.647)	Loss 5.1097e-01 (6.0330e-01)	Acc@1  80.32 ( 77.80)
The current update step is 8319
GPU_0_using curriculum 20 with window 20
Epoch: [141][20/59]	Time  1.473 ( 1.495)	Data  0.020 ( 0.031)	InnerLoop  0.626 ( 0.635)	Loss 5.4769e-01 (5.8322e-01)	Acc@1  79.93 ( 78.57)
Epoch: [141][40/59]	Time  1.587 ( 1.498)	Data  0.020 ( 0.028)	InnerLoop  0.743 ( 0.641)	Loss 6.0086e-01 (5.7919e-01)	Acc@1  77.20 ( 78.59)
The current update step is 8378
GPU_0_using curriculum 20 with window 20
Epoch: [142][20/59]	Time  1.495 ( 1.494)	Data  0.017 ( 0.025)	InnerLoop  0.633 ( 0.641)	Loss 5.3188e-01 (6.7486e-01)	Acc@1  81.05 ( 76.30)
Epoch: [142][40/59]	Time  1.494 ( 1.498)	Data  0.019 ( 0.025)	InnerLoop  0.652 ( 0.645)	Loss 5.5036e-01 (6.3419e-01)	Acc@1  79.98 ( 77.09)
The current update step is 8437
GPU_0_using curriculum 20 with window 20
Epoch: [143][20/59]	Time  1.479 ( 1.497)	Data  0.021 ( 0.031)	InnerLoop  0.629 ( 0.634)	Loss 5.6645e-01 (5.9536e-01)	Acc@1  80.27 ( 77.81)
Epoch: [143][40/59]	Time  1.480 ( 1.496)	Data  0.019 ( 0.028)	InnerLoop  0.634 ( 0.638)	Loss 7.5539e-01 (5.9295e-01)	Acc@1  68.12 ( 77.74)
The current update step is 8496
GPU_0_using curriculum 20 with window 20
Epoch: [144][20/59]	Time  1.492 ( 1.491)	Data  0.019 ( 0.032)	InnerLoop  0.636 ( 0.634)	Loss 5.5207e-01 (5.9066e-01)	Acc@1  81.59 ( 78.35)
Epoch: [144][40/59]	Time  1.480 ( 1.494)	Data  0.020 ( 0.029)	InnerLoop  0.630 ( 0.640)	Loss 5.6325e-01 (5.9147e-01)	Acc@1  78.52 ( 78.17)
The current update step is 8555
The current seed is 10578292692997159089
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.724
 *   Acc@1 70.110
 *   Acc@1 67.539
 *   Acc@1 68.410
 *   Acc@1 65.132
 *   Acc@1 65.952
 *   Acc@1 76.750
 *   Acc@1 76.846
 *   Acc@1 77.092
 *   Acc@1 77.132
 *   Acc@1 76.842
 *   Acc@1 77.267
Training for 300 epoch: 73.23684210526315
Training for 600 epoch: 72.3157894736842
Training for 1000 epoch: 70.98684210526315
Training for 300 epoch: 73.47791666666666
Training for 600 epoch: 72.77125
Training for 1000 epoch: 71.60958333333333
[[73.23684210526315, 72.3157894736842, 70.98684210526315], [73.47791666666666, 72.77125, 71.60958333333333]]
train loss 0.3872376577059428, epoch 144, best loss 0.3058134133974711, best_epoch 144
GPU_0_using curriculum 20 with window 20
Epoch: [145][20/59]	Time  1.484 ( 1.498)	Data  0.021 ( 0.019)	InnerLoop  0.626 ( 0.651)	Loss 6.3381e-01 (5.9615e-01)	Acc@1  76.22 ( 78.44)
Epoch: [145][40/59]	Time  1.583 ( 1.503)	Data  0.137 ( 0.025)	InnerLoop  0.625 ( 0.648)	Loss 5.6399e-01 (5.9640e-01)	Acc@1  80.13 ( 78.34)
The current update step is 8614
GPU_0_using curriculum 20 with window 20
Epoch: [146][20/59]	Time  1.479 ( 1.501)	Data  0.022 ( 0.032)	InnerLoop  0.635 ( 0.638)	Loss 5.2311e-01 (6.2432e-01)	Acc@1  82.37 ( 76.47)
Epoch: [146][40/59]	Time  1.463 ( 1.504)	Data  0.019 ( 0.029)	InnerLoop  0.621 ( 0.643)	Loss 6.2547e-01 (6.5711e-01)	Acc@1  77.44 ( 75.75)
The current update step is 8673
GPU_0_using curriculum 20 with window 20
Epoch: [147][20/59]	Time  1.475 ( 1.490)	Data  0.019 ( 0.032)	InnerLoop  0.631 ( 0.633)	Loss 5.2839e-01 (6.0368e-01)	Acc@1  79.54 ( 77.55)
Epoch: [147][40/59]	Time  1.589 ( 1.497)	Data  0.021 ( 0.026)	InnerLoop  0.742 ( 0.644)	Loss 6.7772e-01 (5.9014e-01)	Acc@1  75.29 ( 78.42)
The current update step is 8732
GPU_0_using curriculum 20 with window 20
Epoch: [148][20/59]	Time  1.487 ( 1.494)	Data  0.018 ( 0.026)	InnerLoop  0.644 ( 0.642)	Loss 5.1603e-01 (5.9852e-01)	Acc@1  80.96 ( 78.37)
Epoch: [148][40/59]	Time  1.598 ( 1.500)	Data  0.018 ( 0.023)	InnerLoop  0.745 ( 0.649)	Loss 5.5458e-01 (5.8321e-01)	Acc@1  78.76 ( 78.80)
The current update step is 8791
GPU_0_using curriculum 20 with window 20
Epoch: [149][20/59]	Time  1.476 ( 1.499)	Data  0.020 ( 0.027)	InnerLoop  0.636 ( 0.642)	Loss 6.4218e-01 (5.9965e-01)	Acc@1  77.29 ( 78.12)
Epoch: [149][40/59]	Time  1.594 ( 1.502)	Data  0.021 ( 0.023)	InnerLoop  0.749 ( 0.649)	Loss 8.1809e-01 (6.0870e-01)	Acc@1  73.83 ( 78.12)
The current update step is 8850
The current seed is 15452742034066583541
The current lr is: 0.001
Testing Results:
 *   Acc@1 79.987
 *   Acc@1 80.527
 *   Acc@1 79.750
 *   Acc@1 80.550
 *   Acc@1 79.763
 *   Acc@1 80.249
 *   Acc@1 74.289
 *   Acc@1 75.023
 *   Acc@1 73.592
 *   Acc@1 74.058
 *   Acc@1 73.368
 *   Acc@1 73.775
Training for 300 epoch: 77.13815789473685
Training for 600 epoch: 76.67105263157895
Training for 1000 epoch: 76.5657894736842
Training for 300 epoch: 77.775
Training for 600 epoch: 77.30375000000001
Training for 1000 epoch: 77.01208333333334
[[77.13815789473685, 76.67105263157895, 76.5657894736842], [77.775, 77.30375000000001, 77.01208333333334]]
train loss 0.377182377020518, epoch 149, best loss 0.3058134133974711, best_epoch 144
=== Final results:
{'acc': 79.19078947368422, 'test': [79.19078947368422, 76.58552631578948, 75.23684210526315], 'train': [79.19078947368422, 76.58552631578948, 75.23684210526315], 'ind': 0, 'epoch': 135, 'data': array([[-0.06820592, -0.06248623,  0.02732707, ...,  0.11357104,
        -0.0073897 ,  0.02738987],
       [-0.09649505,  0.03213036, -0.00435172, ..., -0.09332408,
        -0.01531596,  0.02461623],
       [-0.01738901,  0.07901923, -0.03061556, ..., -0.0664596 ,
         0.05510183, -0.05653333],
       ...,
       [ 0.04856817,  0.10200802, -0.07835432, ..., -0.08170569,
         0.06090514,  0.06039545],
       [-0.09576661,  0.00338621, -0.14597124, ..., -0.00269479,
        -0.1103443 , -0.09385885],
       [ 0.00899632, -0.04931819, -0.03887435, ..., -0.03129289,
        -0.1124085 , -0.08523405]], shape=(40, 768), dtype=float32)}
