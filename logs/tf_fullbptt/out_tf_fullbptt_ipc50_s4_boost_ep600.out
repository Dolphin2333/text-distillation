Torch Seed Specified with rank: 0
Dataset: agnews_emb
Dataset Path: ./scripts
Namespace(seed=0, mp_distributed=False, world_size=1, rank=0, dist_url='tcp://224.66.41.62:23456', dist_backend='nccl', workers=0, gpu=None, root='./scripts', dataset='agnews_emb', arch='text_transformer', width=256, lr=0.002, inner_optim='Adam', outer_optim='Adam', inner_lr=0.0015, label_lr_scale=1, num_per_class=50, batch_per_class=20, task_sampler_nc=6, window=40, minwindow=0, totwindow=40, num_train_eval=4, train_y=False, batch_size=4096, eps=1e-08, wd=0, test_freq=5, print_freq=20, start_epoch=0, epochs=600, ddtype='standard', cctype=0, zca=False, wandb=False, clip_coef=0.9, fname='out_tf_fullbptt_ipc50_s4_boost_ep600', out_dir='./checkpoints', name='agnews_tf_fullbptt_s4_boost_ep600', comp_aug=False, comp_aug_real=False, syn_strategy='none', real_strategy='none', ckptname='none', limit_train=False, load_ckpt=False, complete_random=False, boost_dd=True, boost_init_from='checkpoints/out_tf_fullbptt_ipc20_s3.h5', boost_beta=1.0, stage=4, distributed=False, data_root='./scripts/agnews_emb')
==> Preparing data..
None None
Dataset: number of classes: 4
Training set size: 120000
Image size: channel 1, height 768, width 1
Boost-DD warm start from checkpoints/out_tf_fullbptt_ipc20_s3.h5
Boost-DD: warmed start prev_ipc=20 per class; curr_ipc=50 per class; num_classes=4
Synthetic images, not_single False, keys []
==> Building model..
Initialized data with size, x: torch.Size([200, 768]), y:torch.Size([200])
TextTransformer(
  (input_proj): Linear(in_features=192, out_features=256, bias=True)
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=1024, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=1024, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (cls_head): Linear(in_features=256, out_features=4, bias=True)
)
use data parallel only
GPU_0_using curriculum 40 with window 40
Epoch: [0][20/30]	Time  1.614 ( 1.717)	Data  0.040 ( 0.056)	InnerLoop  0.680 ( 0.750)	Loss 1.5193e+00 (2.1089e+00)	Acc@1  53.30 ( 44.34)
The current update step is 30
GPU_0_using curriculum 40 with window 40
Epoch: [1][20/30]	Time  1.605 ( 1.626)	Data  0.041 ( 0.064)	InnerLoop  0.674 ( 0.678)	Loss 9.8290e-01 (1.1181e+00)	Acc@1  61.77 ( 54.62)
The current update step is 60
GPU_0_using curriculum 40 with window 40
Epoch: [2][20/30]	Time  1.724 ( 1.625)	Data  0.041 ( 0.071)	InnerLoop  0.794 ( 0.672)	Loss 9.9839e-01 (1.0945e+00)	Acc@1  60.42 ( 58.92)
The current update step is 90
GPU_0_using curriculum 40 with window 40
Epoch: [3][20/30]	Time  1.594 ( 1.607)	Data  0.037 ( 0.052)	InnerLoop  0.672 ( 0.680)	Loss 8.3221e-01 (8.3122e-01)	Acc@1  67.94 ( 69.18)
The current update step is 120
GPU_0_using curriculum 40 with window 40
Epoch: [4][20/30]	Time  1.588 ( 1.603)	Data  0.043 ( 0.058)	InnerLoop  0.667 ( 0.672)	Loss 8.3680e-01 (9.0693e-01)	Acc@1  70.09 ( 67.14)
The current update step is 150
The current seed is 16444776951795641193
The current lr is: 0.0015
Testing Results:
 *   Acc@1 53.355
 *   Acc@1 53.919
 *   Acc@1 53.316
 *   Acc@1 53.870
 *   Acc@1 52.882
 *   Acc@1 53.612
 *   Acc@1 56.434
 *   Acc@1 56.503
 *   Acc@1 55.237
 *   Acc@1 55.679
 *   Acc@1 54.921
 *   Acc@1 55.333
 *   Acc@1 57.421
 *   Acc@1 56.887
 *   Acc@1 59.368
 *   Acc@1 58.712
 *   Acc@1 61.171
 *   Acc@1 60.583
 *   Acc@1 56.961
 *   Acc@1 57.040
 *   Acc@1 56.763
 *   Acc@1 57.087
 *   Acc@1 56.737
 *   Acc@1 56.727
Training for 300 epoch: 56.04276315789474
Training for 600 epoch: 56.17105263157895
Training for 1000 epoch: 56.42763157894736
Training for 300 epoch: 56.087291666666665
Training for 600 epoch: 56.33708333333333
Training for 1000 epoch: 56.563541666666666
[[56.04276315789474, 56.17105263157895, 56.42763157894736], [56.087291666666665, 56.33708333333333, 56.563541666666666]]
train loss 0.6960866252899169, epoch 4, best loss 0.6960866252899169, best_epoch 4
GPU_0_using curriculum 40 with window 40
Epoch: [5][20/30]	Time  1.697 ( 1.604)	Data  0.163 ( 0.070)	InnerLoop  0.656 ( 0.664)	Loss 6.9139e-01 (8.5837e-01)	Acc@1  73.66 ( 69.65)
The current update step is 180
GPU_0_using curriculum 40 with window 40
Epoch: [6][20/30]	Time  1.701 ( 1.606)	Data  0.041 ( 0.060)	InnerLoop  0.778 ( 0.674)	Loss 6.6405e-01 (7.3322e-01)	Acc@1  72.58 ( 72.35)
The current update step is 210
GPU_0_using curriculum 40 with window 40
Epoch: [7][20/30]	Time  1.535 ( 1.567)	Data  0.039 ( 0.051)	InnerLoop  0.648 ( 0.666)	Loss 6.0074e-01 (6.8066e-01)	Acc@1  79.13 ( 75.36)
The current update step is 240
GPU_0_using curriculum 40 with window 40
Epoch: [8][20/30]	Time  1.527 ( 1.561)	Data  0.038 ( 0.056)	InnerLoop  0.642 ( 0.658)	Loss 8.1991e-01 (6.8120e-01)	Acc@1  68.29 ( 76.26)
The current update step is 270
GPU_0_using curriculum 40 with window 40
Epoch: [9][20/30]	Time  1.544 ( 1.547)	Data  0.037 ( 0.045)	InnerLoop  0.656 ( 0.663)	Loss 6.1821e-01 (7.8819e-01)	Acc@1  76.56 ( 70.86)
The current update step is 300
The current seed is 8936331044798045115
The current lr is: 0.0015
Testing Results:
 *   Acc@1 54.987
 *   Acc@1 55.314
 *   Acc@1 55.303
 *   Acc@1 55.204
 *   Acc@1 55.395
 *   Acc@1 55.494
 *   Acc@1 70.750
 *   Acc@1 71.247
 *   Acc@1 71.526
 *   Acc@1 71.604
 *   Acc@1 71.461
 *   Acc@1 71.565
 *   Acc@1 58.355
 *   Acc@1 58.497
 *   Acc@1 58.579
 *   Acc@1 58.178
 *   Acc@1 57.987
 *   Acc@1 58.150
 *   Acc@1 59.053
 *   Acc@1 59.797
 *   Acc@1 59.408
 *   Acc@1 60.060
 *   Acc@1 59.724
 *   Acc@1 59.895
Training for 300 epoch: 60.786184210526315
Training for 600 epoch: 61.203947368421055
Training for 1000 epoch: 61.141447368421055
Training for 300 epoch: 61.21354166666667
Training for 600 epoch: 61.26145833333334
Training for 1000 epoch: 61.27604166666667
[[60.786184210526315, 61.203947368421055, 61.141447368421055], [61.21354166666667, 61.26145833333334, 61.27604166666667]]
train loss 0.49882749444643654, epoch 9, best loss 0.49882749444643654, best_epoch 9
GPU_0_using curriculum 40 with window 40
Epoch: [10][20/30]	Time  1.613 ( 1.547)	Data  0.161 ( 0.069)	InnerLoop  0.625 ( 0.646)	Loss 7.1574e-01 (7.2868e-01)	Acc@1  74.29 ( 73.57)
The current update step is 330
GPU_0_using curriculum 40 with window 40
Epoch: [11][20/30]	Time  1.685 ( 1.565)	Data  0.042 ( 0.058)	InnerLoop  0.790 ( 0.669)	Loss 9.5440e-01 (8.0698e-01)	Acc@1  66.82 ( 69.75)
The current update step is 360
GPU_0_using curriculum 40 with window 40
Epoch: [12][20/30]	Time  1.592 ( 1.564)	Data  0.046 ( 0.053)	InnerLoop  0.670 ( 0.670)	Loss 6.7140e-01 (8.0477e-01)	Acc@1  74.71 ( 71.56)
The current update step is 390
GPU_0_using curriculum 40 with window 40
Epoch: [13][20/30]	Time  1.516 ( 1.558)	Data  0.039 ( 0.059)	InnerLoop  0.646 ( 0.661)	Loss 7.1664e-01 (6.7385e-01)	Acc@1  72.46 ( 74.73)
The current update step is 420
GPU_0_using curriculum 40 with window 40
Epoch: [14][20/30]	Time  1.507 ( 1.542)	Data  0.038 ( 0.044)	InnerLoop  0.644 ( 0.667)	Loss 6.0163e-01 (5.9432e-01)	Acc@1  78.22 ( 78.92)
The current update step is 450
The current seed is 5846246866694162131
The current lr is: 0.0015
Testing Results:
 *   Acc@1 63.184
 *   Acc@1 63.233
 *   Acc@1 63.711
 *   Acc@1 64.133
 *   Acc@1 64.908
 *   Acc@1 65.128
 *   Acc@1 58.421
 *   Acc@1 58.792
 *   Acc@1 60.395
 *   Acc@1 59.622
 *   Acc@1 59.842
 *   Acc@1 59.713
 *   Acc@1 61.961
 *   Acc@1 62.193
 *   Acc@1 61.789
 *   Acc@1 61.998
 *   Acc@1 61.184
 *   Acc@1 61.992
 *   Acc@1 64.750
 *   Acc@1 65.510
 *   Acc@1 63.697
 *   Acc@1 64.737
 *   Acc@1 63.526
 *   Acc@1 64.305
Training for 300 epoch: 62.078947368421055
Training for 600 epoch: 62.39802631578947
Training for 1000 epoch: 62.36513157894737
Training for 300 epoch: 62.431875000000005
Training for 600 epoch: 62.62229166666667
Training for 1000 epoch: 62.78479166666667
[[62.078947368421055, 62.39802631578947, 62.36513157894737], [62.431875000000005, 62.62229166666667, 62.78479166666667]]
train loss 0.47850504325230914, epoch 14, best loss 0.47850504325230914, best_epoch 14
GPU_0_using curriculum 40 with window 40
Epoch: [15][20/30]	Time  1.609 ( 1.546)	Data  0.157 ( 0.069)	InnerLoop  0.628 ( 0.645)	Loss 7.1153e-01 (6.0616e-01)	Acc@1  76.07 ( 77.94)
The current update step is 480
GPU_0_using curriculum 40 with window 40
Epoch: [16][20/30]	Time  1.609 ( 1.535)	Data  0.035 ( 0.056)	InnerLoop  0.755 ( 0.652)	Loss 6.3905e-01 (5.9780e-01)	Acc@1  76.76 ( 78.56)
The current update step is 510
GPU_0_using curriculum 40 with window 40
Epoch: [17][20/30]	Time  1.502 ( 1.527)	Data  0.041 ( 0.050)	InnerLoop  0.632 ( 0.650)	Loss 5.6133e-01 (5.8740e-01)	Acc@1  80.86 ( 79.04)
The current update step is 540
GPU_0_using curriculum 40 with window 40
Epoch: [18][20/30]	Time  1.531 ( 1.558)	Data  0.041 ( 0.059)	InnerLoop  0.652 ( 0.658)	Loss 6.7418e-01 (6.3433e-01)	Acc@1  76.93 ( 77.34)
The current update step is 570
GPU_0_using curriculum 40 with window 40
Epoch: [19][20/30]	Time  1.508 ( 1.531)	Data  0.039 ( 0.045)	InnerLoop  0.637 ( 0.656)	Loss 5.8050e-01 (6.3481e-01)	Acc@1  80.32 ( 76.65)
The current update step is 600
The current seed is 1018637968203280237
The current lr is: 0.0015
Testing Results:
 *   Acc@1 46.053
 *   Acc@1 47.360
 *   Acc@1 46.158
 *   Acc@1 46.328
 *   Acc@1 46.000
 *   Acc@1 46.144
 *   Acc@1 40.882
 *   Acc@1 41.360
 *   Acc@1 41.013
 *   Acc@1 41.548
 *   Acc@1 41.053
 *   Acc@1 41.602
 *   Acc@1 58.658
 *   Acc@1 58.328
 *   Acc@1 57.697
 *   Acc@1 57.969
 *   Acc@1 57.961
 *   Acc@1 58.070
 *   Acc@1 65.355
 *   Acc@1 65.708
 *   Acc@1 64.842
 *   Acc@1 65.541
 *   Acc@1 64.934
 *   Acc@1 65.692
Training for 300 epoch: 52.73684210526316
Training for 600 epoch: 52.42763157894736
Training for 1000 epoch: 52.486842105263165
Training for 300 epoch: 53.18895833333333
Training for 600 epoch: 52.846666666666664
Training for 1000 epoch: 52.877291666666665
[[52.73684210526316, 52.42763157894736, 52.486842105263165], [53.18895833333333, 52.846666666666664, 52.877291666666665]]
train loss 0.4201258092244466, epoch 19, best loss 0.4201258092244466, best_epoch 19
GPU_0_using curriculum 40 with window 40
Epoch: [20][20/30]	Time  1.611 ( 1.539)	Data  0.158 ( 0.069)	InnerLoop  0.627 ( 0.641)	Loss 5.6278e-01 (6.6279e-01)	Acc@1  78.54 ( 75.50)
The current update step is 630
GPU_0_using curriculum 40 with window 40
Epoch: [21][20/30]	Time  1.627 ( 1.532)	Data  0.040 ( 0.057)	InnerLoop  0.758 ( 0.650)	Loss 5.1333e-01 (6.1853e-01)	Acc@1  81.84 ( 77.64)
The current update step is 660
GPU_0_using curriculum 40 with window 40
Epoch: [22][20/30]	Time  1.494 ( 1.523)	Data  0.038 ( 0.050)	InnerLoop  0.628 ( 0.646)	Loss 5.0697e-01 (5.9666e-01)	Acc@1  82.37 ( 78.14)
The current update step is 690
GPU_0_using curriculum 40 with window 40
Epoch: [23][20/30]	Time  1.497 ( 1.525)	Data  0.038 ( 0.055)	InnerLoop  0.632 ( 0.644)	Loss 4.7907e-01 (5.6381e-01)	Acc@1  83.96 ( 79.91)
The current update step is 720
GPU_0_using curriculum 40 with window 40
Epoch: [24][20/30]	Time  1.499 ( 1.526)	Data  0.039 ( 0.044)	InnerLoop  0.632 ( 0.656)	Loss 5.8223e-01 (5.8362e-01)	Acc@1  79.15 ( 79.17)
The current update step is 750
The current seed is 3183293465164967312
The current lr is: 0.0015
Testing Results:
 *   Acc@1 40.000
 *   Acc@1 41.010
 *   Acc@1 40.776
 *   Acc@1 41.578
 *   Acc@1 40.539
 *   Acc@1 41.929
 *   Acc@1 31.329
 *   Acc@1 31.486
 *   Acc@1 33.211
 *   Acc@1 33.515
 *   Acc@1 34.697
 *   Acc@1 34.789
 *   Acc@1 64.737
 *   Acc@1 65.857
 *   Acc@1 65.382
 *   Acc@1 66.112
 *   Acc@1 65.697
 *   Acc@1 66.420
 *   Acc@1 46.592
 *   Acc@1 46.668
 *   Acc@1 46.461
 *   Acc@1 46.717
 *   Acc@1 46.974
 *   Acc@1 46.943
Training for 300 epoch: 45.66447368421053
Training for 600 epoch: 46.45723684210526
Training for 1000 epoch: 46.97697368421052
Training for 300 epoch: 46.25520833333334
Training for 600 epoch: 46.98041666666666
Training for 1000 epoch: 47.52041666666666
[[45.66447368421053, 46.45723684210526, 46.97697368421052], [46.25520833333334, 46.98041666666666, 47.52041666666666]]
train loss 1.0103822572072347, epoch 24, best loss 0.4201258092244466, best_epoch 19
GPU_0_using curriculum 40 with window 40
Epoch: [25][20/30]	Time  1.611 ( 1.533)	Data  0.154 ( 0.068)	InnerLoop  0.628 ( 0.638)	Loss 8.4290e-01 (6.0265e-01)	Acc@1  68.60 ( 78.73)
The current update step is 780
GPU_0_using curriculum 40 with window 40
Epoch: [26][20/30]	Time  1.602 ( 1.560)	Data  0.041 ( 0.060)	InnerLoop  0.737 ( 0.662)	Loss 5.6107e-01 (6.3366e-01)	Acc@1  80.74 ( 77.76)
The current update step is 810
GPU_0_using curriculum 40 with window 40
Epoch: [27][20/30]	Time  1.496 ( 1.526)	Data  0.039 ( 0.051)	InnerLoop  0.627 ( 0.649)	Loss 8.1836e-01 (6.2610e-01)	Acc@1  72.05 ( 78.11)
The current update step is 840
GPU_0_using curriculum 40 with window 40
Epoch: [28][20/30]	Time  1.503 ( 1.524)	Data  0.039 ( 0.055)	InnerLoop  0.635 ( 0.645)	Loss 5.5153e-01 (5.8989e-01)	Acc@1  80.15 ( 79.08)
The current update step is 870
GPU_0_using curriculum 40 with window 40
Epoch: [29][20/30]	Time  1.494 ( 1.524)	Data  0.038 ( 0.044)	InnerLoop  0.630 ( 0.653)	Loss 6.4781e-01 (6.1094e-01)	Acc@1  73.39 ( 77.66)
The current update step is 900
The current seed is 8607797256087549606
The current lr is: 0.0015
Testing Results:
 *   Acc@1 54.632
 *   Acc@1 54.936
 *   Acc@1 52.618
 *   Acc@1 52.669
 *   Acc@1 51.816
 *   Acc@1 52.393
 *   Acc@1 41.539
 *   Acc@1 41.323
 *   Acc@1 42.342
 *   Acc@1 42.485
 *   Acc@1 45.000
 *   Acc@1 44.760
 *   Acc@1 55.803
 *   Acc@1 56.392
 *   Acc@1 54.895
 *   Acc@1 55.553
 *   Acc@1 54.026
 *   Acc@1 54.861
 *   Acc@1 57.618
 *   Acc@1 58.634
 *   Acc@1 56.671
 *   Acc@1 57.569
 *   Acc@1 56.053
 *   Acc@1 57.036
Training for 300 epoch: 52.39802631578947
Training for 600 epoch: 51.631578947368425
Training for 1000 epoch: 51.72368421052632
Training for 300 epoch: 52.82124999999999
Training for 600 epoch: 52.06916666666667
Training for 1000 epoch: 52.262499999999996
[[52.39802631578947, 51.631578947368425, 51.72368421052632], [52.82124999999999, 52.06916666666667, 52.262499999999996]]
train loss 0.6730985071500143, epoch 29, best loss 0.4201258092244466, best_epoch 19
GPU_0_using curriculum 40 with window 40
Epoch: [30][20/30]	Time  1.613 ( 1.534)	Data  0.159 ( 0.069)	InnerLoop  0.626 ( 0.637)	Loss 6.1495e-01 (6.0984e-01)	Acc@1  78.39 ( 78.47)
The current update step is 930
GPU_0_using curriculum 40 with window 40
Epoch: [31][20/30]	Time  1.612 ( 1.528)	Data  0.035 ( 0.055)	InnerLoop  0.754 ( 0.648)	Loss 5.6875e-01 (6.1008e-01)	Acc@1  81.03 ( 78.60)
The current update step is 960
GPU_0_using curriculum 40 with window 40
Epoch: [32][20/30]	Time  1.540 ( 1.533)	Data  0.041 ( 0.051)	InnerLoop  0.645 ( 0.653)	Loss 9.1181e-01 (5.9809e-01)	Acc@1  65.72 ( 78.76)
The current update step is 990
GPU_0_using curriculum 40 with window 40
Epoch: [33][20/30]	Time  1.502 ( 1.524)	Data  0.041 ( 0.056)	InnerLoop  0.629 ( 0.642)	Loss 5.2754e-01 (6.4875e-01)	Acc@1  81.23 ( 75.90)
The current update step is 1020
GPU_0_using curriculum 40 with window 40
Epoch: [34][20/30]	Time  1.495 ( 1.530)	Data  0.038 ( 0.044)	InnerLoop  0.632 ( 0.658)	Loss 5.5333e-01 (5.7095e-01)	Acc@1  79.91 ( 79.84)
The current update step is 1050
The current seed is 17773045389834515353
The current lr is: 0.0015
Testing Results:
 *   Acc@1 58.763
 *   Acc@1 58.971
 *   Acc@1 58.803
 *   Acc@1 59.021
 *   Acc@1 58.829
 *   Acc@1 59.321
 *   Acc@1 62.421
 *   Acc@1 63.258
 *   Acc@1 62.895
 *   Acc@1 63.386
 *   Acc@1 63.026
 *   Acc@1 63.339
 *   Acc@1 48.921
 *   Acc@1 49.177
 *   Acc@1 49.355
 *   Acc@1 49.744
 *   Acc@1 49.079
 *   Acc@1 49.879
 *   Acc@1 49.132
 *   Acc@1 49.852
 *   Acc@1 49.461
 *   Acc@1 49.932
 *   Acc@1 50.526
 *   Acc@1 51.075
Training for 300 epoch: 54.80921052631579
Training for 600 epoch: 55.12828947368421
Training for 1000 epoch: 55.36513157894737
Training for 300 epoch: 55.314375
Training for 600 epoch: 55.520833333333336
Training for 1000 epoch: 55.90354166666667
[[54.80921052631579, 55.12828947368421, 55.36513157894737], [55.314375, 55.520833333333336, 55.90354166666667]]
train loss 0.6674041018486023, epoch 34, best loss 0.4201258092244466, best_epoch 19
GPU_0_using curriculum 40 with window 40
Epoch: [35][20/30]	Time  1.605 ( 1.525)	Data  0.156 ( 0.067)	InnerLoop  0.618 ( 0.633)	Loss 5.6081e-01 (5.8643e-01)	Acc@1  81.20 ( 79.86)
The current update step is 1080
GPU_0_using curriculum 40 with window 40
Epoch: [36][20/30]	Time  1.618 ( 1.539)	Data  0.035 ( 0.057)	InnerLoop  0.747 ( 0.650)	Loss 6.6338e-01 (5.6394e-01)	Acc@1  78.20 ( 79.87)
The current update step is 1110
GPU_0_using curriculum 40 with window 40
Epoch: [37][20/30]	Time  1.499 ( 1.520)	Data  0.042 ( 0.049)	InnerLoop  0.627 ( 0.646)	Loss 4.6407e-01 (5.6416e-01)	Acc@1  83.94 ( 79.87)
The current update step is 1140
GPU_0_using curriculum 40 with window 40
Epoch: [38][20/30]	Time  1.513 ( 1.530)	Data  0.039 ( 0.057)	InnerLoop  0.637 ( 0.645)	Loss 4.9538e-01 (5.5452e-01)	Acc@1  81.23 ( 80.15)
The current update step is 1170
GPU_0_using curriculum 40 with window 40
Epoch: [39][20/30]	Time  1.505 ( 1.523)	Data  0.041 ( 0.043)	InnerLoop  0.632 ( 0.655)	Loss 5.4193e-01 (5.5810e-01)	Acc@1  81.84 ( 80.23)
The current update step is 1200
The current seed is 11867721518387269122
The current lr is: 0.0015
Testing Results:
 *   Acc@1 52.000
 *   Acc@1 52.123
 *   Acc@1 52.645
 *   Acc@1 53.145
 *   Acc@1 52.987
 *   Acc@1 53.568
 *   Acc@1 34.368
 *   Acc@1 35.189
 *   Acc@1 34.684
 *   Acc@1 35.526
 *   Acc@1 34.447
 *   Acc@1 35.513
 *   Acc@1 36.171
 *   Acc@1 36.737
 *   Acc@1 36.961
 *   Acc@1 37.316
 *   Acc@1 36.842
 *   Acc@1 37.169
 *   Acc@1 53.276
 *   Acc@1 53.761
 *   Acc@1 53.684
 *   Acc@1 54.333
 *   Acc@1 53.750
 *   Acc@1 54.597
Training for 300 epoch: 43.953947368421055
Training for 600 epoch: 44.493421052631575
Training for 1000 epoch: 44.50657894736842
Training for 300 epoch: 44.45229166666667
Training for 600 epoch: 45.079791666666665
Training for 1000 epoch: 45.21208333333334
[[43.953947368421055, 44.493421052631575, 44.50657894736842], [44.45229166666667, 45.079791666666665, 45.21208333333334]]
train loss 0.6880507250785828, epoch 39, best loss 0.4201258092244466, best_epoch 19
GPU_0_using curriculum 40 with window 40
Epoch: [40][20/30]	Time  1.625 ( 1.541)	Data  0.161 ( 0.069)	InnerLoop  0.631 ( 0.643)	Loss 5.6858e-01 (6.5340e-01)	Acc@1  79.86 ( 76.48)
The current update step is 1230
GPU_0_using curriculum 40 with window 40
Epoch: [41][20/30]	Time  1.614 ( 1.528)	Data  0.039 ( 0.056)	InnerLoop  0.748 ( 0.647)	Loss 6.5569e-01 (6.3806e-01)	Acc@1  76.32 ( 76.89)
The current update step is 1260
GPU_0_using curriculum 40 with window 40
Epoch: [42][20/30]	Time  1.495 ( 1.524)	Data  0.038 ( 0.049)	InnerLoop  0.631 ( 0.649)	Loss 7.0192e-01 (6.2790e-01)	Acc@1  74.10 ( 77.47)
The current update step is 1290
GPU_0_using curriculum 40 with window 40
Epoch: [43][20/30]	Time  1.517 ( 1.559)	Data  0.044 ( 0.059)	InnerLoop  0.637 ( 0.661)	Loss 5.1304e-01 (5.6519e-01)	Acc@1  82.15 ( 79.81)
The current update step is 1320
GPU_0_using curriculum 40 with window 40
Epoch: [44][20/30]	Time  1.499 ( 1.520)	Data  0.040 ( 0.045)	InnerLoop  0.633 ( 0.650)	Loss 8.5232e-01 (5.8184e-01)	Acc@1  71.17 ( 79.19)
The current update step is 1350
The current seed is 5184528148139690528
The current lr is: 0.0015
Testing Results:
 *   Acc@1 58.737
 *   Acc@1 59.230
 *   Acc@1 58.987
 *   Acc@1 59.824
 *   Acc@1 59.368
 *   Acc@1 60.078
 *   Acc@1 55.816
 *   Acc@1 55.476
 *   Acc@1 57.053
 *   Acc@1 57.250
 *   Acc@1 58.671
 *   Acc@1 58.610
 *   Acc@1 70.421
 *   Acc@1 70.578
 *   Acc@1 70.737
 *   Acc@1 70.731
 *   Acc@1 71.184
 *   Acc@1 71.185
 *   Acc@1 56.737
 *   Acc@1 57.188
 *   Acc@1 57.250
 *   Acc@1 57.614
 *   Acc@1 58.118
 *   Acc@1 58.053
Training for 300 epoch: 60.42763157894736
Training for 600 epoch: 61.006578947368425
Training for 1000 epoch: 61.83552631578947
Training for 300 epoch: 60.617916666666666
Training for 600 epoch: 61.35479166666667
Training for 1000 epoch: 61.981458333333336
[[60.42763157894736, 61.006578947368425, 61.83552631578947], [60.617916666666666, 61.35479166666667, 61.981458333333336]]
train loss 0.5111360737164815, epoch 44, best loss 0.4201258092244466, best_epoch 19
GPU_0_using curriculum 40 with window 40
Epoch: [45][20/30]	Time  1.508 ( 1.525)	Data  0.041 ( 0.057)	InnerLoop  0.640 ( 0.643)	Loss 4.5896e-01 (5.5851e-01)	Acc@1  83.42 ( 79.61)
The current update step is 1380
GPU_0_using curriculum 40 with window 40
Epoch: [46][20/30]	Time  1.613 ( 1.531)	Data  0.157 ( 0.063)	InnerLoop  0.628 ( 0.644)	Loss 5.3636e-01 (5.5411e-01)	Acc@1  80.54 ( 80.47)
The current update step is 1410
GPU_0_using curriculum 40 with window 40
Epoch: [47][20/30]	Time  1.498 ( 1.533)	Data  0.038 ( 0.039)	InnerLoop  0.628 ( 0.665)	Loss 5.2156e-01 (6.0127e-01)	Acc@1  82.93 ( 78.84)
The current update step is 1440
GPU_0_using curriculum 40 with window 40
Epoch: [48][20/30]	Time  1.509 ( 1.531)	Data  0.040 ( 0.051)	InnerLoop  0.638 ( 0.653)	Loss 5.9106e-01 (5.5430e-01)	Acc@1  77.56 ( 80.13)
The current update step is 1470
GPU_0_using curriculum 40 with window 40
Epoch: [49][20/30]	Time  1.497 ( 1.528)	Data  0.043 ( 0.064)	InnerLoop  0.631 ( 0.638)	Loss 7.5604e-01 (5.7657e-01)	Acc@1  73.44 ( 79.42)
The current update step is 1500
The current seed is 1454463142423981497
The current lr is: 0.0015
Testing Results:
 *   Acc@1 35.592
 *   Acc@1 35.153
 *   Acc@1 34.711
 *   Acc@1 34.026
 *   Acc@1 33.987
 *   Acc@1 33.466
 *   Acc@1 33.711
 *   Acc@1 34.369
 *   Acc@1 35.513
 *   Acc@1 35.947
 *   Acc@1 36.355
 *   Acc@1 36.536
 *   Acc@1 54.368
 *   Acc@1 54.513
 *   Acc@1 52.487
 *   Acc@1 53.112
 *   Acc@1 52.553
 *   Acc@1 53.146
 *   Acc@1 51.263
 *   Acc@1 51.487
 *   Acc@1 48.526
 *   Acc@1 49.050
 *   Acc@1 48.053
 *   Acc@1 48.439
Training for 300 epoch: 43.73355263157895
Training for 600 epoch: 42.809210526315795
Training for 1000 epoch: 42.73684210526316
Training for 300 epoch: 43.88041666666667
Training for 600 epoch: 43.03375
Training for 1000 epoch: 42.89666666666667
[[43.73355263157895, 42.809210526315795, 42.73684210526316], [43.88041666666667, 43.03375, 42.89666666666667]]
train loss 0.7549552529970804, epoch 49, best loss 0.4201258092244466, best_epoch 19
GPU_0_using curriculum 40 with window 40
Epoch: [50][20/30]	Time  1.482 ( 1.526)	Data  0.036 ( 0.051)	InnerLoop  0.623 ( 0.651)	Loss 5.4049e-01 (5.3401e-01)	Acc@1  81.42 ( 81.20)
The current update step is 1530
GPU_0_using curriculum 40 with window 40
Epoch: [51][20/30]	Time  1.491 ( 1.524)	Data  0.036 ( 0.062)	InnerLoop  0.632 ( 0.639)	Loss 5.4899e-01 (5.8270e-01)	Acc@1  79.15 ( 78.97)
The current update step is 1560
GPU_0_using curriculum 40 with window 40
Epoch: [52][20/30]	Time  1.498 ( 1.548)	Data  0.039 ( 0.052)	InnerLoop  0.630 ( 0.660)	Loss 5.5134e-01 (5.9855e-01)	Acc@1  80.71 ( 78.48)
The current update step is 1590
GPU_0_using curriculum 40 with window 40
Epoch: [53][20/30]	Time  1.505 ( 1.524)	Data  0.037 ( 0.067)	InnerLoop  0.638 ( 0.633)	Loss 4.8596e-01 (5.3928e-01)	Acc@1  83.45 ( 80.89)
The current update step is 1620
GPU_0_using curriculum 40 with window 40
Epoch: [54][20/30]	Time  1.493 ( 1.554)	Data  0.040 ( 0.072)	InnerLoop  0.627 ( 0.648)	Loss 5.2006e-01 (5.5524e-01)	Acc@1  80.69 ( 79.72)
The current update step is 1650
The current seed is 17387919008931662104
The current lr is: 0.0015
Testing Results:
 *   Acc@1 39.250
 *   Acc@1 38.684
 *   Acc@1 43.250
 *   Acc@1 43.013
 *   Acc@1 47.158
 *   Acc@1 46.318
 *   Acc@1 66.039
 *   Acc@1 65.658
 *   Acc@1 50.934
 *   Acc@1 50.873
 *   Acc@1 50.855
 *   Acc@1 51.190
 *   Acc@1 66.868
 *   Acc@1 66.270
 *   Acc@1 66.395
 *   Acc@1 66.094
 *   Acc@1 66.368
 *   Acc@1 66.095
 *   Acc@1 52.908
 *   Acc@1 53.318
 *   Acc@1 53.250
 *   Acc@1 54.117
 *   Acc@1 54.447
 *   Acc@1 54.694
Training for 300 epoch: 56.26644736842105
Training for 600 epoch: 53.45723684210526
Training for 1000 epoch: 54.70723684210527
Training for 300 epoch: 55.982708333333335
Training for 600 epoch: 53.52458333333334
Training for 1000 epoch: 54.574374999999996
[[56.26644736842105, 53.45723684210526, 54.70723684210527], [55.982708333333335, 53.52458333333334, 54.574374999999996]]
train loss 0.6210036259333293, epoch 54, best loss 0.4201258092244466, best_epoch 19
GPU_0_using curriculum 40 with window 40
Epoch: [55][20/30]	Time  1.498 ( 1.529)	Data  0.038 ( 0.061)	InnerLoop  0.632 ( 0.642)	Loss 5.3546e-01 (6.3141e-01)	Acc@1  80.30 ( 77.96)
The current update step is 1680
GPU_0_using curriculum 40 with window 40
Epoch: [56][20/30]	Time  1.490 ( 1.563)	Data  0.037 ( 0.072)	InnerLoop  0.631 ( 0.649)	Loss 4.9973e-01 (5.7896e-01)	Acc@1  82.59 ( 79.19)
The current update step is 1710
GPU_0_using curriculum 40 with window 40
Epoch: [57][20/30]	Time  1.490 ( 1.526)	Data  0.037 ( 0.063)	InnerLoop  0.631 ( 0.639)	Loss 5.8596e-01 (6.4733e-01)	Acc@1  77.64 ( 76.20)
The current update step is 1740
GPU_0_using curriculum 40 with window 40
Epoch: [58][20/30]	Time  1.508 ( 1.524)	Data  0.038 ( 0.062)	InnerLoop  0.641 ( 0.636)	Loss 6.0876e-01 (5.8239e-01)	Acc@1  77.66 ( 78.87)
The current update step is 1770
GPU_0_using curriculum 40 with window 40
Epoch: [59][20/30]	Time  1.501 ( 1.530)	Data  0.037 ( 0.055)	InnerLoop  0.634 ( 0.648)	Loss 5.0139e-01 (5.8049e-01)	Acc@1  82.08 ( 79.16)
The current update step is 1800
The current seed is 3952383434828424985
The current lr is: 0.0015
Testing Results:
 *   Acc@1 62.329
 *   Acc@1 62.642
 *   Acc@1 63.395
 *   Acc@1 63.601
 *   Acc@1 64.184
 *   Acc@1 64.241
 *   Acc@1 38.842
 *   Acc@1 39.262
 *   Acc@1 44.789
 *   Acc@1 45.111
 *   Acc@1 45.316
 *   Acc@1 45.764
 *   Acc@1 49.882
 *   Acc@1 49.369
 *   Acc@1 41.145
 *   Acc@1 40.955
 *   Acc@1 40.408
 *   Acc@1 40.465
 *   Acc@1 59.855
 *   Acc@1 60.455
 *   Acc@1 51.382
 *   Acc@1 51.381
 *   Acc@1 51.697
 *   Acc@1 51.637
Training for 300 epoch: 52.72697368421053
Training for 600 epoch: 50.17763157894736
Training for 1000 epoch: 50.401315789473685
Training for 300 epoch: 52.93208333333334
Training for 600 epoch: 50.261875
Training for 1000 epoch: 50.526666666666664
[[52.72697368421053, 50.17763157894736, 50.401315789473685], [52.93208333333334, 50.261875, 50.526666666666664]]
train loss 0.777063917096456, epoch 59, best loss 0.4201258092244466, best_epoch 19
GPU_0_using curriculum 40 with window 40
Epoch: [60][20/30]	Time  1.624 ( 1.536)	Data  0.160 ( 0.068)	InnerLoop  0.633 ( 0.639)	Loss 4.4849e-01 (5.7373e-01)	Acc@1  84.30 ( 79.65)
The current update step is 1830
GPU_0_using curriculum 40 with window 40
Epoch: [61][20/30]	Time  1.615 ( 1.529)	Data  0.037 ( 0.056)	InnerLoop  0.751 ( 0.646)	Loss 4.7444e-01 (5.9999e-01)	Acc@1  83.96 ( 79.03)
The current update step is 1860
GPU_0_using curriculum 40 with window 40
Epoch: [62][20/30]	Time  1.490 ( 1.520)	Data  0.037 ( 0.050)	InnerLoop  0.628 ( 0.648)	Loss 5.5393e-01 (5.9413e-01)	Acc@1  80.44 ( 79.09)
The current update step is 1890
GPU_0_using curriculum 40 with window 40
Epoch: [63][20/30]	Time  1.500 ( 1.520)	Data  0.040 ( 0.056)	InnerLoop  0.635 ( 0.640)	Loss 5.2463e-01 (5.4632e-01)	Acc@1  80.49 ( 80.78)
The current update step is 1920
GPU_0_using curriculum 40 with window 40
Epoch: [64][20/30]	Time  1.538 ( 1.547)	Data  0.042 ( 0.047)	InnerLoop  0.660 ( 0.663)	Loss 6.9764e-01 (5.7330e-01)	Acc@1  72.71 ( 79.59)
The current update step is 1950
The current seed is 5745955677631455472
The current lr is: 0.0015
Testing Results:
 *   Acc@1 46.145
 *   Acc@1 45.523
 *   Acc@1 44.842
 *   Acc@1 44.606
 *   Acc@1 44.618
 *   Acc@1 43.994
 *   Acc@1 36.132
 *   Acc@1 36.388
 *   Acc@1 35.263
 *   Acc@1 35.298
 *   Acc@1 34.474
 *   Acc@1 34.797
 *   Acc@1 57.816
 *   Acc@1 58.373
 *   Acc@1 57.803
 *   Acc@1 58.174
 *   Acc@1 58.197
 *   Acc@1 58.001
 *   Acc@1 52.750
 *   Acc@1 53.020
 *   Acc@1 53.105
 *   Acc@1 53.615
 *   Acc@1 53.816
 *   Acc@1 54.013
Training for 300 epoch: 48.21052631578947
Training for 600 epoch: 47.75328947368421
Training for 1000 epoch: 47.776315789473685
Training for 300 epoch: 48.325833333333335
Training for 600 epoch: 47.92333333333333
Training for 1000 epoch: 47.701458333333335
[[48.21052631578947, 47.75328947368421, 47.776315789473685], [48.325833333333335, 47.92333333333333, 47.701458333333335]]
train loss 0.48576352122624716, epoch 64, best loss 0.4201258092244466, best_epoch 19
GPU_0_using curriculum 40 with window 40
Epoch: [65][20/30]	Time  1.499 ( 1.518)	Data  0.041 ( 0.057)	InnerLoop  0.627 ( 0.637)	Loss 4.6458e-01 (5.3088e-01)	Acc@1  83.25 ( 80.93)
The current update step is 1980
GPU_0_using curriculum 40 with window 40
Epoch: [66][20/30]	Time  1.609 ( 1.525)	Data  0.156 ( 0.061)	InnerLoop  0.626 ( 0.638)	Loss 4.9123e-01 (5.4954e-01)	Acc@1  81.98 ( 80.51)
The current update step is 2010
GPU_0_using curriculum 40 with window 40
Epoch: [67][20/30]	Time  1.499 ( 1.523)	Data  0.036 ( 0.037)	InnerLoop  0.636 ( 0.661)	Loss 5.3952e-01 (5.5346e-01)	Acc@1  81.93 ( 80.41)
The current update step is 2040
GPU_0_using curriculum 40 with window 40
Epoch: [68][20/30]	Time  1.492 ( 1.540)	Data  0.039 ( 0.052)	InnerLoop  0.623 ( 0.653)	Loss 5.7779e-01 (5.8117e-01)	Acc@1  77.54 ( 79.22)
The current update step is 2070
GPU_0_using curriculum 40 with window 40
Epoch: [69][20/30]	Time  1.495 ( 1.532)	Data  0.040 ( 0.062)	InnerLoop  0.627 ( 0.641)	Loss 5.6127e-01 (6.0280e-01)	Acc@1  79.08 ( 78.45)
The current update step is 2100
The current seed is 7204533773761557922
The current lr is: 0.0015
Testing Results:
 *   Acc@1 60.882
 *   Acc@1 60.403
 *   Acc@1 60.987
 *   Acc@1 60.656
 *   Acc@1 61.895
 *   Acc@1 61.330
 *   Acc@1 38.513
 *   Acc@1 39.138
 *   Acc@1 34.342
 *   Acc@1 34.372
 *   Acc@1 55.000
 *   Acc@1 54.374
 *   Acc@1 54.487
 *   Acc@1 55.024
 *   Acc@1 55.737
 *   Acc@1 56.608
 *   Acc@1 55.816
 *   Acc@1 57.362
 *   Acc@1 41.171
 *   Acc@1 42.136
 *   Acc@1 41.382
 *   Acc@1 42.026
 *   Acc@1 41.737
 *   Acc@1 42.233
Training for 300 epoch: 48.763157894736835
Training for 600 epoch: 48.11184210526316
Training for 1000 epoch: 53.61184210526316
Training for 300 epoch: 49.17520833333333
Training for 600 epoch: 48.41520833333333
Training for 1000 epoch: 53.82479166666667
[[48.763157894736835, 48.11184210526316, 53.61184210526316], [49.17520833333333, 48.41520833333333, 53.82479166666667]]
train loss 1.085590375773112, epoch 69, best loss 0.4201258092244466, best_epoch 19
GPU_0_using curriculum 40 with window 40
Epoch: [70][20/30]	Time  1.494 ( 1.531)	Data  0.038 ( 0.050)	InnerLoop  0.630 ( 0.652)	Loss 6.1113e-01 (5.5885e-01)	Acc@1  77.83 ( 80.50)
The current update step is 2130
GPU_0_using curriculum 40 with window 40
Epoch: [71][20/30]	Time  1.595 ( 1.553)	Data  0.042 ( 0.064)	InnerLoop  0.676 ( 0.651)	Loss 5.5204e-01 (5.9179e-01)	Acc@1  79.91 ( 78.45)
The current update step is 2160
GPU_0_using curriculum 40 with window 40
Epoch: [72][20/30]	Time  1.506 ( 1.528)	Data  0.037 ( 0.049)	InnerLoop  0.637 ( 0.652)	Loss 6.6530e-01 (5.4165e-01)	Acc@1  75.46 ( 80.42)
The current update step is 2190
GPU_0_using curriculum 40 with window 40
Epoch: [73][20/30]	Time  1.489 ( 1.525)	Data  0.037 ( 0.069)	InnerLoop  0.630 ( 0.633)	Loss 5.7371e-01 (5.1941e-01)	Acc@1  77.71 ( 81.76)
The current update step is 2220
GPU_0_using curriculum 40 with window 40
Epoch: [74][20/30]	Time  1.506 ( 1.530)	Data  0.038 ( 0.068)	InnerLoop  0.637 ( 0.637)	Loss 5.0312e-01 (6.0837e-01)	Acc@1  82.54 ( 79.22)
The current update step is 2250
The current seed is 8863501703717885018
The current lr is: 0.0015
Testing Results:
 *   Acc@1 59.289
 *   Acc@1 60.032
 *   Acc@1 60.579
 *   Acc@1 61.273
 *   Acc@1 62.684
 *   Acc@1 62.661
 *   Acc@1 68.276
 *   Acc@1 68.504
 *   Acc@1 68.237
 *   Acc@1 68.007
 *   Acc@1 67.895
 *   Acc@1 67.851
 *   Acc@1 58.671
 *   Acc@1 59.005
 *   Acc@1 58.961
 *   Acc@1 59.627
 *   Acc@1 59.513
 *   Acc@1 59.944
 *   Acc@1 59.382
 *   Acc@1 60.297
 *   Acc@1 60.368
 *   Acc@1 61.107
 *   Acc@1 60.447
 *   Acc@1 61.347
Training for 300 epoch: 61.4046052631579
Training for 600 epoch: 62.03618421052632
Training for 1000 epoch: 62.63486842105263
Training for 300 epoch: 61.95958333333333
Training for 600 epoch: 62.50354166666666
Training for 1000 epoch: 62.95083333333333
[[61.4046052631579, 62.03618421052632, 62.63486842105263], [61.95958333333333, 62.50354166666666, 62.95083333333333]]
train loss 0.6310603311856587, epoch 74, best loss 0.4201258092244466, best_epoch 19
GPU_0_using curriculum 40 with window 40
Epoch: [75][20/30]	Time  1.497 ( 1.538)	Data  0.040 ( 0.063)	InnerLoop  0.631 ( 0.648)	Loss 5.7506e-01 (5.7871e-01)	Acc@1  79.35 ( 79.34)
The current update step is 2280
GPU_0_using curriculum 40 with window 40
Epoch: [76][20/30]	Time  1.497 ( 1.535)	Data  0.039 ( 0.070)	InnerLoop  0.632 ( 0.635)	Loss 5.0520e-01 (6.6518e-01)	Acc@1  82.47 ( 76.02)
The current update step is 2310
GPU_0_using curriculum 40 with window 40
Epoch: [77][20/30]	Time  1.506 ( 1.529)	Data  0.041 ( 0.062)	InnerLoop  0.639 ( 0.640)	Loss 5.1189e-01 (5.5361e-01)	Acc@1  82.47 ( 80.03)
The current update step is 2340
GPU_0_using curriculum 40 with window 40
Epoch: [78][20/30]	Time  1.569 ( 1.529)	Data  0.043 ( 0.062)	InnerLoop  0.674 ( 0.640)	Loss 4.9472e-01 (5.4231e-01)	Acc@1  82.30 ( 80.55)
The current update step is 2370
GPU_0_using curriculum 40 with window 40
Epoch: [79][20/30]	Time  1.501 ( 1.529)	Data  0.039 ( 0.056)	InnerLoop  0.635 ( 0.646)	Loss 5.4774e-01 (6.4102e-01)	Acc@1  79.81 ( 77.18)
The current update step is 2400
The current seed is 13046252344196603489
The current lr is: 0.0015
Testing Results:
 *   Acc@1 59.224
 *   Acc@1 60.014
 *   Acc@1 59.434
 *   Acc@1 59.899
 *   Acc@1 58.671
 *   Acc@1 59.285
 *   Acc@1 65.013
 *   Acc@1 65.281
 *   Acc@1 64.237
 *   Acc@1 64.892
 *   Acc@1 64.237
 *   Acc@1 65.097
 *   Acc@1 58.368
 *   Acc@1 59.023
 *   Acc@1 60.618
 *   Acc@1 61.300
 *   Acc@1 60.461
 *   Acc@1 61.169
 *   Acc@1 62.987
 *   Acc@1 63.193
 *   Acc@1 61.961
 *   Acc@1 62.125
 *   Acc@1 61.618
 *   Acc@1 61.558
Training for 300 epoch: 61.39802631578947
Training for 600 epoch: 61.56250000000001
Training for 1000 epoch: 61.246710526315795
Training for 300 epoch: 61.8775
Training for 600 epoch: 62.05416666666666
Training for 1000 epoch: 61.77729166666667
[[61.39802631578947, 61.56250000000001, 61.246710526315795], [61.8775, 62.05416666666666, 61.77729166666667]]
train loss 0.5423509631792705, epoch 79, best loss 0.4201258092244466, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [80][20/30]	Time  1.609 ( 1.530)	Data  0.157 ( 0.067)	InnerLoop  0.624 ( 0.637)	Loss 5.1162e-01 (6.1091e-01)	Acc@1  82.15 ( 78.37)
The current update step is 2430
GPU_0_using curriculum 40 with window 40
Epoch: [81][20/30]	Time  1.607 ( 1.545)	Data  0.038 ( 0.058)	InnerLoop  0.747 ( 0.658)	Loss 6.6100e-01 (5.5424e-01)	Acc@1  74.44 ( 80.32)
The current update step is 2460
GPU_0_using curriculum 40 with window 40
Epoch: [82][20/30]	Time  1.499 ( 1.523)	Data  0.038 ( 0.050)	InnerLoop  0.628 ( 0.647)	Loss 6.6075e-01 (5.6365e-01)	Acc@1  78.74 ( 80.08)
The current update step is 2490
GPU_0_using curriculum 40 with window 40
Epoch: [83][20/30]	Time  1.504 ( 1.524)	Data  0.040 ( 0.056)	InnerLoop  0.634 ( 0.643)	Loss 6.3694e-01 (5.5064e-01)	Acc@1  76.90 ( 80.22)
The current update step is 2520
GPU_0_using curriculum 40 with window 40
Epoch: [84][20/30]	Time  1.568 ( 1.552)	Data  0.046 ( 0.047)	InnerLoop  0.679 ( 0.668)	Loss 4.6928e-01 (5.3440e-01)	Acc@1  83.25 ( 81.03)
The current update step is 2550
The current seed is 9872485174957788517
The current lr is: 0.0015
Testing Results:
 *   Acc@1 39.263
 *   Acc@1 39.760
 *   Acc@1 37.776
 *   Acc@1 38.578
 *   Acc@1 37.592
 *   Acc@1 38.453
 *   Acc@1 47.947
 *   Acc@1 48.698
 *   Acc@1 48.342
 *   Acc@1 49.021
 *   Acc@1 48.605
 *   Acc@1 49.127
 *   Acc@1 60.184
 *   Acc@1 60.476
 *   Acc@1 59.013
 *   Acc@1 59.589
 *   Acc@1 59.513
 *   Acc@1 59.549
 *   Acc@1 49.250
 *   Acc@1 49.659
 *   Acc@1 49.408
 *   Acc@1 49.676
 *   Acc@1 49.474
 *   Acc@1 49.861
Training for 300 epoch: 49.161184210526315
Training for 600 epoch: 48.63486842105264
Training for 1000 epoch: 48.796052631578945
Training for 300 epoch: 49.64833333333333
Training for 600 epoch: 49.215833333333336
Training for 1000 epoch: 49.24729166666667
[[49.161184210526315, 48.63486842105264, 48.796052631578945], [49.64833333333333, 49.215833333333336, 49.24729166666667]]
train loss 0.925756244913737, epoch 84, best loss 0.4201258092244466, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [85][20/30]	Time  1.513 ( 1.526)	Data  0.039 ( 0.056)	InnerLoop  0.646 ( 0.643)	Loss 5.1928e-01 (5.7471e-01)	Acc@1  80.44 ( 79.35)
The current update step is 2580
GPU_0_using curriculum 40 with window 40
Epoch: [86][20/30]	Time  1.610 ( 1.529)	Data  0.160 ( 0.062)	InnerLoop  0.627 ( 0.642)	Loss 4.6590e-01 (5.7383e-01)	Acc@1  83.54 ( 79.44)
The current update step is 2610
GPU_0_using curriculum 40 with window 40
Epoch: [87][20/30]	Time  1.519 ( 1.555)	Data  0.040 ( 0.040)	InnerLoop  0.641 ( 0.675)	Loss 5.6362e-01 (6.4642e-01)	Acc@1  80.08 ( 77.39)
The current update step is 2640
GPU_0_using curriculum 40 with window 40
Epoch: [88][20/30]	Time  1.496 ( 1.523)	Data  0.039 ( 0.050)	InnerLoop  0.633 ( 0.649)	Loss 5.4393e-01 (5.8653e-01)	Acc@1  80.64 ( 78.96)
The current update step is 2670
GPU_0_using curriculum 40 with window 40
Epoch: [89][20/30]	Time  1.493 ( 1.524)	Data  0.039 ( 0.063)	InnerLoop  0.629 ( 0.636)	Loss 5.2139e-01 (5.5924e-01)	Acc@1  81.25 ( 79.64)
The current update step is 2700
The current seed is 2688752082464354844
The current lr is: 0.0015
Testing Results:
 *   Acc@1 35.816
 *   Acc@1 35.284
 *   Acc@1 38.237
 *   Acc@1 37.996
 *   Acc@1 40.039
 *   Acc@1 39.426
 *   Acc@1 53.013
 *   Acc@1 53.024
 *   Acc@1 50.618
 *   Acc@1 50.750
 *   Acc@1 50.513
 *   Acc@1 50.450
 *   Acc@1 29.513
 *   Acc@1 29.701
 *   Acc@1 31.316
 *   Acc@1 31.493
 *   Acc@1 32.908
 *   Acc@1 33.157
 *   Acc@1 40.539
 *   Acc@1 40.527
 *   Acc@1 39.618
 *   Acc@1 39.946
 *   Acc@1 40.724
 *   Acc@1 40.805
Training for 300 epoch: 39.7203947368421
Training for 600 epoch: 39.94736842105263
Training for 1000 epoch: 41.046052631578945
Training for 300 epoch: 39.63395833333333
Training for 600 epoch: 40.04625
Training for 1000 epoch: 40.959583333333335
[[39.7203947368421, 39.94736842105263, 41.046052631578945], [39.63395833333333, 40.04625, 40.959583333333335]]
train loss 0.8046317637761434, epoch 89, best loss 0.4201258092244466, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [90][20/30]	Time  1.496 ( 1.523)	Data  0.036 ( 0.050)	InnerLoop  0.630 ( 0.647)	Loss 5.3175e-01 (5.5888e-01)	Acc@1  81.79 ( 80.46)
The current update step is 2730
GPU_0_using curriculum 40 with window 40
Epoch: [91][20/30]	Time  1.495 ( 1.524)	Data  0.036 ( 0.062)	InnerLoop  0.632 ( 0.638)	Loss 4.9787e-01 (5.3889e-01)	Acc@1  81.52 ( 80.96)
The current update step is 2760
GPU_0_using curriculum 40 with window 40
Epoch: [92][20/30]	Time  1.528 ( 1.531)	Data  0.045 ( 0.051)	InnerLoop  0.639 ( 0.651)	Loss 5.0270e-01 (6.0295e-01)	Acc@1  82.06 ( 78.21)
The current update step is 2790
GPU_0_using curriculum 40 with window 40
Epoch: [93][20/30]	Time  1.489 ( 1.522)	Data  0.037 ( 0.067)	InnerLoop  0.628 ( 0.630)	Loss 4.9669e-01 (5.5072e-01)	Acc@1  82.52 ( 80.41)
The current update step is 2820
GPU_0_using curriculum 40 with window 40
Epoch: [94][20/30]	Time  1.488 ( 1.531)	Data  0.037 ( 0.069)	InnerLoop  0.625 ( 0.636)	Loss 6.0515e-01 (5.9557e-01)	Acc@1  78.08 ( 78.35)
The current update step is 2850
The current seed is 17401379717727152557
The current lr is: 0.0015
Testing Results:
 *   Acc@1 73.171
 *   Acc@1 73.334
 *   Acc@1 72.579
 *   Acc@1 73.213
 *   Acc@1 72.776
 *   Acc@1 73.004
 *   Acc@1 49.605
 *   Acc@1 49.413
 *   Acc@1 49.434
 *   Acc@1 49.297
 *   Acc@1 48.355
 *   Acc@1 48.531
 *   Acc@1 35.434
 *   Acc@1 34.809
 *   Acc@1 35.842
 *   Acc@1 35.364
 *   Acc@1 36.276
 *   Acc@1 35.858
 *   Acc@1 64.039
 *   Acc@1 64.287
 *   Acc@1 51.579
 *   Acc@1 51.392
 *   Acc@1 51.816
 *   Acc@1 52.195
Training for 300 epoch: 55.5625
Training for 600 epoch: 52.358552631578945
Training for 1000 epoch: 52.30592105263158
Training for 300 epoch: 55.46083333333333
Training for 600 epoch: 52.31666666666666
Training for 1000 epoch: 52.396874999999994
[[55.5625, 52.358552631578945, 52.30592105263158], [55.46083333333333, 52.31666666666666, 52.396874999999994]]
train loss 0.7338704317728678, epoch 94, best loss 0.4201258092244466, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [95][20/30]	Time  1.501 ( 1.528)	Data  0.039 ( 0.061)	InnerLoop  0.636 ( 0.643)	Loss 4.6651e-01 (5.4741e-01)	Acc@1  82.84 ( 80.34)
The current update step is 2880
GPU_0_using curriculum 40 with window 40
Epoch: [96][20/30]	Time  1.495 ( 1.526)	Data  0.038 ( 0.069)	InnerLoop  0.630 ( 0.631)	Loss 5.3438e-01 (5.7291e-01)	Acc@1  80.86 ( 79.68)
The current update step is 2910
GPU_0_using curriculum 40 with window 40
Epoch: [97][20/30]	Time  1.491 ( 1.534)	Data  0.037 ( 0.062)	InnerLoop  0.631 ( 0.642)	Loss 5.1745e-01 (5.7950e-01)	Acc@1  81.25 ( 78.62)
The current update step is 2940
GPU_0_using curriculum 40 with window 40
Epoch: [98][20/30]	Time  1.501 ( 1.523)	Data  0.041 ( 0.062)	InnerLoop  0.634 ( 0.637)	Loss 5.4449e-01 (5.2272e-01)	Acc@1  80.52 ( 81.05)
The current update step is 2970
GPU_0_using curriculum 40 with window 40
Epoch: [99][20/30]	Time  1.516 ( 1.551)	Data  0.041 ( 0.058)	InnerLoop  0.639 ( 0.655)	Loss 4.5202e-01 (5.1213e-01)	Acc@1  83.98 ( 81.49)
The current update step is 3000
The current seed is 11530500602804521390
The current lr is: 0.0015
Testing Results:
 *   Acc@1 44.105
 *   Acc@1 44.298
 *   Acc@1 44.092
 *   Acc@1 44.734
 *   Acc@1 44.211
 *   Acc@1 44.723
 *   Acc@1 42.882
 *   Acc@1 42.864
 *   Acc@1 42.776
 *   Acc@1 43.256
 *   Acc@1 43.500
 *   Acc@1 43.366
 *   Acc@1 58.329
 *   Acc@1 58.248
 *   Acc@1 58.539
 *   Acc@1 58.858
 *   Acc@1 59.013
 *   Acc@1 59.047
 *   Acc@1 46.711
 *   Acc@1 46.485
 *   Acc@1 44.618
 *   Acc@1 45.308
 *   Acc@1 44.803
 *   Acc@1 45.081
Training for 300 epoch: 48.006578947368425
Training for 600 epoch: 47.506578947368425
Training for 1000 epoch: 47.881578947368425
Training for 300 epoch: 47.97395833333333
Training for 600 epoch: 48.039166666666674
Training for 1000 epoch: 48.05437499999999
[[48.006578947368425, 47.506578947368425, 47.881578947368425], [47.97395833333333, 48.039166666666674, 48.05437499999999]]
train loss 1.0443460189183553, epoch 99, best loss 0.4201258092244466, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [100][20/30]	Time  1.682 ( 1.546)	Data  0.162 ( 0.068)	InnerLoop  0.641 ( 0.642)	Loss 4.8818e-01 (4.9002e-01)	Acc@1  83.01 ( 82.46)
The current update step is 3030
GPU_0_using curriculum 40 with window 40
Epoch: [101][20/30]	Time  1.617 ( 1.532)	Data  0.038 ( 0.056)	InnerLoop  0.748 ( 0.650)	Loss 4.4926e-01 (5.5610e-01)	Acc@1  84.25 ( 80.23)
The current update step is 3060
GPU_0_using curriculum 40 with window 40
Epoch: [102][20/30]	Time  1.492 ( 1.527)	Data  0.038 ( 0.051)	InnerLoop  0.627 ( 0.649)	Loss 5.2329e-01 (5.5138e-01)	Acc@1  81.08 ( 80.26)
The current update step is 3090
GPU_0_using curriculum 40 with window 40
Epoch: [103][20/30]	Time  1.504 ( 1.556)	Data  0.039 ( 0.059)	InnerLoop  0.634 ( 0.659)	Loss 4.2733e-01 (5.4225e-01)	Acc@1  85.57 ( 80.65)
The current update step is 3120
GPU_0_using curriculum 40 with window 40
Epoch: [104][20/30]	Time  1.504 ( 1.524)	Data  0.039 ( 0.044)	InnerLoop  0.633 ( 0.655)	Loss 9.2850e-01 (5.6974e-01)	Acc@1  65.72 ( 79.80)
The current update step is 3150
The current seed is 3190562728398566934
The current lr is: 0.0015
Testing Results:
 *   Acc@1 44.368
 *   Acc@1 44.467
 *   Acc@1 44.987
 *   Acc@1 44.631
 *   Acc@1 45.118
 *   Acc@1 44.813
 *   Acc@1 30.566
 *   Acc@1 31.015
 *   Acc@1 30.947
 *   Acc@1 31.538
 *   Acc@1 31.224
 *   Acc@1 31.804
 *   Acc@1 58.987
 *   Acc@1 58.784
 *   Acc@1 58.539
 *   Acc@1 58.926
 *   Acc@1 59.013
 *   Acc@1 59.192
 *   Acc@1 42.645
 *   Acc@1 42.501
 *   Acc@1 42.974
 *   Acc@1 42.977
 *   Acc@1 43.053
 *   Acc@1 43.358
Training for 300 epoch: 44.141447368421055
Training for 600 epoch: 44.36184210526315
Training for 1000 epoch: 44.60197368421053
Training for 300 epoch: 44.19166666666666
Training for 600 epoch: 44.51770833333333
Training for 1000 epoch: 44.791875000000005
[[44.141447368421055, 44.36184210526315, 44.60197368421053], [44.19166666666666, 44.51770833333333, 44.791875000000005]]
train loss 0.9900078547795613, epoch 104, best loss 0.4201258092244466, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [105][20/30]	Time  1.509 ( 1.526)	Data  0.040 ( 0.057)	InnerLoop  0.639 ( 0.643)	Loss 5.4440e-01 (5.8128e-01)	Acc@1  80.66 ( 79.32)
The current update step is 3180
GPU_0_using curriculum 40 with window 40
Epoch: [106][20/30]	Time  1.750 ( 1.553)	Data  0.180 ( 0.064)	InnerLoop  0.697 ( 0.655)	Loss 6.7318e-01 (6.0882e-01)	Acc@1  74.24 ( 78.29)
The current update step is 3210
GPU_0_using curriculum 40 with window 40
Epoch: [107][20/30]	Time  1.494 ( 1.522)	Data  0.039 ( 0.038)	InnerLoop  0.628 ( 0.662)	Loss 5.7476e-01 (5.9524e-01)	Acc@1  80.03 ( 78.90)
The current update step is 3240
GPU_0_using curriculum 40 with window 40
Epoch: [108][20/30]	Time  1.512 ( 1.525)	Data  0.038 ( 0.050)	InnerLoop  0.639 ( 0.649)	Loss 4.7208e-01 (5.4426e-01)	Acc@1  84.01 ( 80.52)
The current update step is 3270
GPU_0_using curriculum 40 with window 40
Epoch: [109][20/30]	Time  1.509 ( 1.523)	Data  0.039 ( 0.062)	InnerLoop  0.638 ( 0.636)	Loss 5.2235e-01 (5.2303e-01)	Acc@1  82.08 ( 81.72)
The current update step is 3300
The current seed is 13602247293320992769
The current lr is: 0.0015
Testing Results:
 *   Acc@1 50.868
 *   Acc@1 51.534
 *   Acc@1 52.039
 *   Acc@1 53.265
 *   Acc@1 53.618
 *   Acc@1 54.470
 *   Acc@1 32.355
 *   Acc@1 32.844
 *   Acc@1 33.618
 *   Acc@1 33.885
 *   Acc@1 34.237
 *   Acc@1 34.651
 *   Acc@1 47.211
 *   Acc@1 47.230
 *   Acc@1 56.776
 *   Acc@1 57.645
 *   Acc@1 59.395
 *   Acc@1 60.720
 *   Acc@1 34.776
 *   Acc@1 35.183
 *   Acc@1 32.145
 *   Acc@1 32.608
 *   Acc@1 31.342
 *   Acc@1 31.818
Training for 300 epoch: 41.30263157894737
Training for 600 epoch: 43.64473684210526
Training for 1000 epoch: 44.64802631578947
Training for 300 epoch: 41.697916666666664
Training for 600 epoch: 44.35062500000001
Training for 1000 epoch: 45.414791666666666
[[41.30263157894737, 43.64473684210526, 44.64802631578947], [41.697916666666664, 44.35062500000001, 45.414791666666666]]
train loss 0.8766082522074381, epoch 109, best loss 0.4201258092244466, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [110][20/30]	Time  1.494 ( 1.523)	Data  0.039 ( 0.051)	InnerLoop  0.628 ( 0.648)	Loss 7.3080e-01 (5.4929e-01)	Acc@1  76.56 ( 80.90)
The current update step is 3330
GPU_0_using curriculum 40 with window 40
Epoch: [111][20/30]	Time  1.492 ( 1.558)	Data  0.036 ( 0.066)	InnerLoop  0.626 ( 0.652)	Loss 5.9915e-01 (5.6298e-01)	Acc@1  77.25 ( 80.20)
The current update step is 3360
GPU_0_using curriculum 40 with window 40
Epoch: [112][20/30]	Time  1.488 ( 1.516)	Data  0.038 ( 0.049)	InnerLoop  0.621 ( 0.643)	Loss 5.2190e-01 (5.1905e-01)	Acc@1  81.49 ( 81.45)
The current update step is 3390
GPU_0_using curriculum 40 with window 40
Epoch: [113][20/30]	Time  1.498 ( 1.549)	Data  0.038 ( 0.070)	InnerLoop  0.634 ( 0.641)	Loss 4.5690e-01 (5.5111e-01)	Acc@1  83.86 ( 80.41)
The current update step is 3420
GPU_0_using curriculum 40 with window 40
Epoch: [114][20/30]	Time  1.501 ( 1.525)	Data  0.039 ( 0.069)	InnerLoop  0.632 ( 0.634)	Loss 4.4566e-01 (5.0663e-01)	Acc@1  84.33 ( 82.28)
The current update step is 3450
The current seed is 16959439530365913687
The current lr is: 0.0015
Testing Results:
 *   Acc@1 58.250
 *   Acc@1 59.133
 *   Acc@1 56.553
 *   Acc@1 57.282
 *   Acc@1 55.434
 *   Acc@1 55.727
 *   Acc@1 72.829
 *   Acc@1 73.539
 *   Acc@1 73.987
 *   Acc@1 74.628
 *   Acc@1 73.539
 *   Acc@1 74.605
 *   Acc@1 58.474
 *   Acc@1 58.742
 *   Acc@1 56.829
 *   Acc@1 56.797
 *   Acc@1 56.763
 *   Acc@1 56.953
 *   Acc@1 60.132
 *   Acc@1 59.824
 *   Acc@1 61.474
 *   Acc@1 60.846
 *   Acc@1 61.421
 *   Acc@1 61.259
Training for 300 epoch: 62.42105263157894
Training for 600 epoch: 62.210526315789465
Training for 1000 epoch: 61.78947368421052
Training for 300 epoch: 62.809583333333336
Training for 600 epoch: 62.38833333333333
Training for 1000 epoch: 62.136250000000004
[[62.42105263157894, 62.210526315789465, 61.78947368421052], [62.809583333333336, 62.38833333333333, 62.136250000000004]]
train loss 0.49982607029279075, epoch 114, best loss 0.4201258092244466, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [115][20/30]	Time  1.497 ( 1.535)	Data  0.039 ( 0.063)	InnerLoop  0.631 ( 0.646)	Loss 6.6528e-01 (5.5302e-01)	Acc@1  77.44 ( 80.75)
The current update step is 3480
GPU_0_using curriculum 40 with window 40
Epoch: [116][20/30]	Time  1.510 ( 1.518)	Data  0.040 ( 0.067)	InnerLoop  0.637 ( 0.625)	Loss 6.1469e-01 (5.5889e-01)	Acc@1  75.32 ( 80.23)
The current update step is 3510
GPU_0_using curriculum 40 with window 40
Epoch: [117][20/30]	Time  1.495 ( 1.552)	Data  0.040 ( 0.064)	InnerLoop  0.630 ( 0.651)	Loss 4.9706e-01 (5.2066e-01)	Acc@1  82.30 ( 81.63)
The current update step is 3540
GPU_0_using curriculum 40 with window 40
Epoch: [118][20/30]	Time  1.502 ( 1.525)	Data  0.037 ( 0.062)	InnerLoop  0.634 ( 0.637)	Loss 5.0278e-01 (5.4962e-01)	Acc@1  82.23 ( 79.98)
The current update step is 3570
GPU_0_using curriculum 40 with window 40
Epoch: [119][20/30]	Time  1.508 ( 1.524)	Data  0.039 ( 0.056)	InnerLoop  0.638 ( 0.641)	Loss 5.1222e-01 (5.0241e-01)	Acc@1  82.28 ( 82.29)
The current update step is 3600
The current seed is 17373202973856116390
The current lr is: 0.0015
Testing Results:
 *   Acc@1 36.829
 *   Acc@1 37.346
 *   Acc@1 36.329
 *   Acc@1 36.670
 *   Acc@1 36.053
 *   Acc@1 36.368
 *   Acc@1 64.355
 *   Acc@1 64.830
 *   Acc@1 64.434
 *   Acc@1 64.787
 *   Acc@1 65.395
 *   Acc@1 65.468
 *   Acc@1 53.447
 *   Acc@1 54.382
 *   Acc@1 55.171
 *   Acc@1 56.310
 *   Acc@1 57.000
 *   Acc@1 58.140
 *   Acc@1 50.868
 *   Acc@1 50.671
 *   Acc@1 50.487
 *   Acc@1 50.328
 *   Acc@1 50.408
 *   Acc@1 50.233
Training for 300 epoch: 51.37500000000001
Training for 600 epoch: 51.60526315789473
Training for 1000 epoch: 52.213815789473685
Training for 300 epoch: 51.80708333333334
Training for 600 epoch: 52.02374999999999
Training for 1000 epoch: 52.552291666666676
[[51.37500000000001, 51.60526315789473, 52.213815789473685], [51.80708333333334, 52.02374999999999, 52.552291666666676]]
train loss 0.6437859057108561, epoch 119, best loss 0.4201258092244466, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [120][20/30]	Time  1.618 ( 1.546)	Data  0.154 ( 0.068)	InnerLoop  0.634 ( 0.645)	Loss 5.6953e-01 (5.6240e-01)	Acc@1  80.69 ( 80.08)
The current update step is 3630
GPU_0_using curriculum 40 with window 40
Epoch: [121][20/30]	Time  1.621 ( 1.545)	Data  0.037 ( 0.056)	InnerLoop  0.754 ( 0.659)	Loss 7.0214e-01 (5.2459e-01)	Acc@1  72.66 ( 81.23)
The current update step is 3660
GPU_0_using curriculum 40 with window 40
Epoch: [122][20/30]	Time  1.492 ( 1.526)	Data  0.038 ( 0.050)	InnerLoop  0.627 ( 0.650)	Loss 5.8566e-01 (5.5145e-01)	Acc@1  78.69 ( 80.52)
The current update step is 3690
GPU_0_using curriculum 40 with window 40
Epoch: [123][20/30]	Time  1.495 ( 1.545)	Data  0.037 ( 0.058)	InnerLoop  0.630 ( 0.657)	Loss 5.8844e-01 (5.4023e-01)	Acc@1  77.78 ( 80.53)
The current update step is 3720
GPU_0_using curriculum 40 with window 40
Epoch: [124][20/30]	Time  1.495 ( 1.522)	Data  0.038 ( 0.044)	InnerLoop  0.629 ( 0.651)	Loss 5.1306e-01 (5.4955e-01)	Acc@1  81.64 ( 80.67)
The current update step is 3750
The current seed is 4718819184690288682
The current lr is: 0.0015
Testing Results:
 *   Acc@1 48.750
 *   Acc@1 48.551
 *   Acc@1 49.724
 *   Acc@1 49.474
 *   Acc@1 49.605
 *   Acc@1 49.508
 *   Acc@1 73.250
 *   Acc@1 73.544
 *   Acc@1 73.500
 *   Acc@1 73.786
 *   Acc@1 73.500
 *   Acc@1 74.062
 *   Acc@1 63.526
 *   Acc@1 64.067
 *   Acc@1 61.921
 *   Acc@1 62.953
 *   Acc@1 62.289
 *   Acc@1 63.124
 *   Acc@1 51.763
 *   Acc@1 52.716
 *   Acc@1 51.145
 *   Acc@1 52.112
 *   Acc@1 51.342
 *   Acc@1 51.981
Training for 300 epoch: 59.32236842105264
Training for 600 epoch: 59.07236842105263
Training for 1000 epoch: 59.18421052631579
Training for 300 epoch: 59.719375
Training for 600 epoch: 59.581041666666664
Training for 1000 epoch: 59.66875
[[59.32236842105264, 59.07236842105263, 59.18421052631579], [59.719375, 59.581041666666664, 59.66875]]
train loss 0.6513862747510274, epoch 124, best loss 0.4201258092244466, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [125][20/30]	Time  1.490 ( 1.551)	Data  0.038 ( 0.057)	InnerLoop  0.627 ( 0.654)	Loss 5.9875e-01 (5.5129e-01)	Acc@1  78.37 ( 80.57)
The current update step is 3780
GPU_0_using curriculum 40 with window 40
Epoch: [126][20/30]	Time  1.614 ( 1.539)	Data  0.158 ( 0.063)	InnerLoop  0.627 ( 0.647)	Loss 5.3921e-01 (5.6234e-01)	Acc@1  80.03 ( 79.97)
The current update step is 3810
GPU_0_using curriculum 40 with window 40
Epoch: [127][20/30]	Time  1.508 ( 1.533)	Data  0.038 ( 0.038)	InnerLoop  0.638 ( 0.667)	Loss 6.7499e-01 (5.9604e-01)	Acc@1  73.46 ( 79.04)
The current update step is 3840
GPU_0_using curriculum 40 with window 40
Epoch: [128][20/30]	Time  1.520 ( 1.538)	Data  0.041 ( 0.051)	InnerLoop  0.641 ( 0.658)	Loss 4.7021e-01 (5.5149e-01)	Acc@1  83.20 ( 80.14)
The current update step is 3870
GPU_0_using curriculum 40 with window 40
Epoch: [129][20/30]	Time  1.509 ( 1.532)	Data  0.040 ( 0.062)	InnerLoop  0.643 ( 0.644)	Loss 4.9364e-01 (5.1815e-01)	Acc@1  81.62 ( 81.48)
The current update step is 3900
The current seed is 1708922702846131053
The current lr is: 0.0015
Testing Results:
 *   Acc@1 50.395
 *   Acc@1 51.182
 *   Acc@1 52.066
 *   Acc@1 52.083
 *   Acc@1 52.539
 *   Acc@1 52.898
 *   Acc@1 55.789
 *   Acc@1 55.481
 *   Acc@1 57.645
 *   Acc@1 57.575
 *   Acc@1 58.105
 *   Acc@1 57.900
 *   Acc@1 67.447
 *   Acc@1 67.523
 *   Acc@1 61.803
 *   Acc@1 61.791
 *   Acc@1 61.605
 *   Acc@1 61.878
 *   Acc@1 65.645
 *   Acc@1 66.131
 *   Acc@1 65.197
 *   Acc@1 65.619
 *   Acc@1 63.553
 *   Acc@1 64.632
Training for 300 epoch: 59.81907894736842
Training for 600 epoch: 59.17763157894737
Training for 1000 epoch: 58.95065789473684
Training for 300 epoch: 60.079166666666666
Training for 600 epoch: 59.26708333333333
Training for 1000 epoch: 59.32729166666667
[[59.81907894736842, 59.17763157894737, 58.95065789473684], [60.079166666666666, 59.26708333333333, 59.32729166666667]]
train loss 0.43486211915016176, epoch 129, best loss 0.4201258092244466, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [130][20/30]	Time  1.504 ( 1.530)	Data  0.041 ( 0.051)	InnerLoop  0.627 ( 0.648)	Loss 5.8184e-01 (5.3075e-01)	Acc@1  76.78 ( 80.94)
The current update step is 3930
GPU_0_using curriculum 40 with window 40
Epoch: [131][20/30]	Time  1.492 ( 1.524)	Data  0.037 ( 0.062)	InnerLoop  0.628 ( 0.636)	Loss 5.5545e-01 (5.3388e-01)	Acc@1  80.76 ( 81.21)
The current update step is 3960
GPU_0_using curriculum 40 with window 40
Epoch: [132][20/30]	Time  1.495 ( 1.540)	Data  0.038 ( 0.050)	InnerLoop  0.627 ( 0.655)	Loss 5.1504e-01 (5.2897e-01)	Acc@1  81.18 ( 81.22)
The current update step is 3990
GPU_0_using curriculum 40 with window 40
Epoch: [133][20/30]	Time  1.505 ( 1.528)	Data  0.039 ( 0.069)	InnerLoop  0.635 ( 0.631)	Loss 5.3940e-01 (4.9980e-01)	Acc@1  80.71 ( 82.17)
The current update step is 4020
GPU_0_using curriculum 40 with window 40
Epoch: [134][20/30]	Time  1.492 ( 1.528)	Data  0.038 ( 0.069)	InnerLoop  0.626 ( 0.633)	Loss 6.0531e-01 (5.1292e-01)	Acc@1  78.98 ( 81.34)
The current update step is 4050
The current seed is 15387362502396423881
The current lr is: 0.0015
Testing Results:
 *   Acc@1 60.211
 *   Acc@1 60.308
 *   Acc@1 61.447
 *   Acc@1 61.594
 *   Acc@1 61.934
 *   Acc@1 62.318
 *   Acc@1 59.342
 *   Acc@1 58.872
 *   Acc@1 42.395
 *   Acc@1 41.336
 *   Acc@1 41.092
 *   Acc@1 40.072
 *   Acc@1 60.513
 *   Acc@1 61.449
 *   Acc@1 60.947
 *   Acc@1 62.014
 *   Acc@1 61.316
 *   Acc@1 61.841
 *   Acc@1 71.092
 *   Acc@1 72.132
 *   Acc@1 71.368
 *   Acc@1 71.980
 *   Acc@1 71.079
 *   Acc@1 71.843
Training for 300 epoch: 62.78947368421053
Training for 600 epoch: 59.03947368421052
Training for 1000 epoch: 58.85526315789474
Training for 300 epoch: 63.19020833333333
Training for 600 epoch: 59.23104166666667
Training for 1000 epoch: 59.01854166666667
[[62.78947368421053, 59.03947368421052, 58.85526315789474], [63.19020833333333, 59.23104166666667, 59.01854166666667]]
train loss 0.28784357541402184, epoch 134, best loss 0.28784357541402184, best_epoch 134
GPU_0_using curriculum 40 with window 40
Epoch: [135][20/30]	Time  1.513 ( 1.541)	Data  0.039 ( 0.062)	InnerLoop  0.641 ( 0.646)	Loss 4.8801e-01 (5.2052e-01)	Acc@1  82.67 ( 81.51)
The current update step is 4080
GPU_0_using curriculum 40 with window 40
Epoch: [136][20/30]	Time  1.494 ( 1.524)	Data  0.038 ( 0.068)	InnerLoop  0.627 ( 0.630)	Loss 4.7715e-01 (5.2782e-01)	Acc@1  82.52 ( 81.60)
The current update step is 4110
GPU_0_using curriculum 40 with window 40
Epoch: [137][20/30]	Time  1.499 ( 1.525)	Data  0.038 ( 0.061)	InnerLoop  0.634 ( 0.636)	Loss 4.8090e-01 (5.4433e-01)	Acc@1  82.47 ( 80.89)
The current update step is 4140
GPU_0_using curriculum 40 with window 40
Epoch: [138][20/30]	Time  1.534 ( 1.537)	Data  0.040 ( 0.063)	InnerLoop  0.654 ( 0.643)	Loss 4.7709e-01 (5.3063e-01)	Acc@1  83.28 ( 81.35)
The current update step is 4170
GPU_0_using curriculum 40 with window 40
Epoch: [139][20/30]	Time  1.503 ( 1.533)	Data  0.037 ( 0.056)	InnerLoop  0.634 ( 0.644)	Loss 5.1434e-01 (5.2351e-01)	Acc@1  82.47 ( 81.66)
The current update step is 4200
The current seed is 4757672870420133206
The current lr is: 0.0015
Testing Results:
 *   Acc@1 46.947
 *   Acc@1 47.097
 *   Acc@1 47.171
 *   Acc@1 47.913
 *   Acc@1 46.961
 *   Acc@1 48.212
 *   Acc@1 49.000
 *   Acc@1 49.974
 *   Acc@1 49.447
 *   Acc@1 50.407
 *   Acc@1 49.947
 *   Acc@1 50.788
 *   Acc@1 61.605
 *   Acc@1 61.743
 *   Acc@1 61.079
 *   Acc@1 60.996
 *   Acc@1 60.789
 *   Acc@1 60.539
 *   Acc@1 63.053
 *   Acc@1 62.425
 *   Acc@1 63.592
 *   Acc@1 62.900
 *   Acc@1 63.329
 *   Acc@1 63.148
Training for 300 epoch: 55.151315789473685
Training for 600 epoch: 55.32236842105263
Training for 1000 epoch: 55.256578947368425
Training for 300 epoch: 55.30979166666667
Training for 600 epoch: 55.55375
Training for 1000 epoch: 55.671875
[[55.151315789473685, 55.32236842105263, 55.256578947368425], [55.30979166666667, 55.55375, 55.671875]]
train loss 0.6070017972310384, epoch 139, best loss 0.28784357541402184, best_epoch 134
GPU_0_using curriculum 40 with window 40
Epoch: [140][20/30]	Time  1.626 ( 1.544)	Data  0.157 ( 0.068)	InnerLoop  0.634 ( 0.643)	Loss 5.6341e-01 (5.5428e-01)	Acc@1  80.54 ( 80.47)
The current update step is 4230
GPU_0_using curriculum 40 with window 40
Epoch: [141][20/30]	Time  1.613 ( 1.532)	Data  0.037 ( 0.056)	InnerLoop  0.747 ( 0.647)	Loss 5.7225e-01 (5.2408e-01)	Acc@1  80.47 ( 81.34)
The current update step is 4260
GPU_0_using curriculum 40 with window 40
Epoch: [142][20/30]	Time  1.499 ( 1.533)	Data  0.039 ( 0.050)	InnerLoop  0.635 ( 0.653)	Loss 5.3814e-01 (5.4956e-01)	Acc@1  79.81 ( 80.39)
The current update step is 4290
GPU_0_using curriculum 40 with window 40
Epoch: [143][20/30]	Time  1.498 ( 1.525)	Data  0.038 ( 0.056)	InnerLoop  0.629 ( 0.641)	Loss 5.2005e-01 (5.3619e-01)	Acc@1  81.74 ( 80.88)
The current update step is 4320
GPU_0_using curriculum 40 with window 40
Epoch: [144][20/30]	Time  1.529 ( 1.532)	Data  0.040 ( 0.045)	InnerLoop  0.641 ( 0.658)	Loss 4.8931e-01 (5.3362e-01)	Acc@1  82.10 ( 81.16)
The current update step is 4350
The current seed is 11838056303579363024
The current lr is: 0.0015
Testing Results:
 *   Acc@1 60.421
 *   Acc@1 61.224
 *   Acc@1 72.816
 *   Acc@1 73.438
 *   Acc@1 73.132
 *   Acc@1 73.772
 *   Acc@1 64.658
 *   Acc@1 65.036
 *   Acc@1 64.658
 *   Acc@1 65.188
 *   Acc@1 65.197
 *   Acc@1 65.503
 *   Acc@1 39.000
 *   Acc@1 38.817
 *   Acc@1 39.934
 *   Acc@1 39.910
 *   Acc@1 40.987
 *   Acc@1 40.634
 *   Acc@1 50.671
 *   Acc@1 51.032
 *   Acc@1 51.237
 *   Acc@1 51.416
 *   Acc@1 51.276
 *   Acc@1 51.981
Training for 300 epoch: 53.6875
Training for 600 epoch: 57.16118421052631
Training for 1000 epoch: 57.648026315789465
Training for 300 epoch: 54.02708333333333
Training for 600 epoch: 57.48791666666666
Training for 1000 epoch: 57.97270833333333
[[53.6875, 57.16118421052631, 57.648026315789465], [54.02708333333333, 57.48791666666666, 57.97270833333333]]
train loss 0.6503794121424357, epoch 144, best loss 0.28784357541402184, best_epoch 134
GPU_0_using curriculum 40 with window 40
Epoch: [145][20/30]	Time  1.496 ( 1.539)	Data  0.038 ( 0.057)	InnerLoop  0.627 ( 0.648)	Loss 5.3603e-01 (5.6769e-01)	Acc@1  81.54 ( 79.81)
The current update step is 4380
GPU_0_using curriculum 40 with window 40
Epoch: [146][20/30]	Time  1.643 ( 1.534)	Data  0.165 ( 0.061)	InnerLoop  0.646 ( 0.646)	Loss 5.9706e-01 (5.5730e-01)	Acc@1  77.15 ( 79.56)
The current update step is 4410
GPU_0_using curriculum 40 with window 40
Epoch: [147][20/30]	Time  1.513 ( 1.536)	Data  0.039 ( 0.038)	InnerLoop  0.630 ( 0.667)	Loss 5.5051e-01 (5.1948e-01)	Acc@1  81.52 ( 81.50)
The current update step is 4440
GPU_0_using curriculum 40 with window 40
Epoch: [148][20/30]	Time  1.498 ( 1.530)	Data  0.037 ( 0.050)	InnerLoop  0.635 ( 0.650)	Loss 4.8891e-01 (4.9908e-01)	Acc@1  83.50 ( 82.33)
The current update step is 4470
GPU_0_using curriculum 40 with window 40
Epoch: [149][20/30]	Time  1.509 ( 1.551)	Data  0.038 ( 0.064)	InnerLoop  0.639 ( 0.649)	Loss 4.5757e-01 (4.8126e-01)	Acc@1  83.37 ( 83.18)
The current update step is 4500
The current seed is 14874557569294280831
The current lr is: 0.0015
Testing Results:
 *   Acc@1 55.434
 *   Acc@1 55.432
 *   Acc@1 58.605
 *   Acc@1 58.402
 *   Acc@1 59.289
 *   Acc@1 58.753
 *   Acc@1 50.592
 *   Acc@1 50.354
 *   Acc@1 48.368
 *   Acc@1 48.520
 *   Acc@1 47.816
 *   Acc@1 47.178
 *   Acc@1 57.013
 *   Acc@1 57.227
 *   Acc@1 54.184
 *   Acc@1 54.527
 *   Acc@1 54.987
 *   Acc@1 55.480
 *   Acc@1 71.763
 *   Acc@1 72.612
 *   Acc@1 71.750
 *   Acc@1 72.172
 *   Acc@1 71.171
 *   Acc@1 72.258
Training for 300 epoch: 58.700657894736835
Training for 600 epoch: 58.22697368421053
Training for 1000 epoch: 58.315789473684205
Training for 300 epoch: 58.90645833333333
Training for 600 epoch: 58.405208333333334
Training for 1000 epoch: 58.417500000000004
[[58.700657894736835, 58.22697368421053, 58.315789473684205], [58.90645833333333, 58.405208333333334, 58.417500000000004]]
train loss 0.38555432850519816, epoch 149, best loss 0.28784357541402184, best_epoch 134
GPU_0_using curriculum 40 with window 40
Epoch: [150][20/30]	Time  1.510 ( 1.547)	Data  0.038 ( 0.050)	InnerLoop  0.642 ( 0.661)	Loss 5.7793e-01 (5.0571e-01)	Acc@1  79.49 ( 82.03)
The current update step is 4530
GPU_0_using curriculum 40 with window 40
Epoch: [151][20/30]	Time  1.503 ( 1.546)	Data  0.037 ( 0.064)	InnerLoop  0.631 ( 0.647)	Loss 4.6956e-01 (5.0681e-01)	Acc@1  84.77 ( 81.56)
The current update step is 4560
GPU_0_using curriculum 40 with window 40
Epoch: [152][20/30]	Time  1.509 ( 1.530)	Data  0.038 ( 0.049)	InnerLoop  0.638 ( 0.654)	Loss 5.1121e-01 (4.8698e-01)	Acc@1  82.20 ( 82.94)
The current update step is 4590
GPU_0_using curriculum 40 with window 40
Epoch: [153][20/30]	Time  1.498 ( 1.531)	Data  0.037 ( 0.068)	InnerLoop  0.633 ( 0.635)	Loss 4.9661e-01 (5.2174e-01)	Acc@1  83.15 ( 81.58)
The current update step is 4620
GPU_0_using curriculum 40 with window 40
Epoch: [154][20/30]	Time  1.507 ( 1.543)	Data  0.039 ( 0.070)	InnerLoop  0.635 ( 0.644)	Loss 4.9269e-01 (5.0775e-01)	Acc@1  82.67 ( 81.88)
The current update step is 4650
The current seed is 4062135361814433858
The current lr is: 0.0015
Testing Results:
 *   Acc@1 65.487
 *   Acc@1 66.190
 *   Acc@1 66.553
 *   Acc@1 66.996
 *   Acc@1 66.316
 *   Acc@1 66.837
 *   Acc@1 55.132
 *   Acc@1 55.013
 *   Acc@1 54.750
 *   Acc@1 54.835
 *   Acc@1 55.013
 *   Acc@1 54.937
 *   Acc@1 74.039
 *   Acc@1 74.603
 *   Acc@1 74.579
 *   Acc@1 75.049
 *   Acc@1 74.803
 *   Acc@1 75.199
 *   Acc@1 74.526
 *   Acc@1 74.442
 *   Acc@1 55.500
 *   Acc@1 55.232
 *   Acc@1 55.000
 *   Acc@1 55.392
Training for 300 epoch: 67.29605263157895
Training for 600 epoch: 62.84539473684211
Training for 1000 epoch: 62.7828947368421
Training for 300 epoch: 67.561875
Training for 600 epoch: 63.02791666666667
Training for 1000 epoch: 63.09104166666667
[[67.29605263157895, 62.84539473684211, 62.7828947368421], [67.561875, 63.02791666666667, 63.09104166666667]]
train loss 0.6374375566800435, epoch 154, best loss 0.28784357541402184, best_epoch 134
GPU_0_using curriculum 40 with window 40
Epoch: [155][20/30]	Time  1.500 ( 1.530)	Data  0.038 ( 0.061)	InnerLoop  0.630 ( 0.641)	Loss 5.0323e-01 (5.0104e-01)	Acc@1  82.47 ( 82.39)
The current update step is 4680
GPU_0_using curriculum 40 with window 40
Epoch: [156][20/30]	Time  1.512 ( 1.534)	Data  0.040 ( 0.069)	InnerLoop  0.637 ( 0.636)	Loss 4.2065e-01 (5.1422e-01)	Acc@1  85.64 ( 81.81)
The current update step is 4710
GPU_0_using curriculum 40 with window 40
Epoch: [157][20/30]	Time  1.507 ( 1.526)	Data  0.039 ( 0.063)	InnerLoop  0.634 ( 0.636)	Loss 4.4085e-01 (4.8383e-01)	Acc@1  85.03 ( 82.84)
The current update step is 4740
GPU_0_using curriculum 40 with window 40
Epoch: [158][20/30]	Time  1.482 ( 1.518)	Data  0.037 ( 0.062)	InnerLoop  0.622 ( 0.632)	Loss 5.1184e-01 (4.8784e-01)	Acc@1  81.35 ( 82.94)
The current update step is 4770
GPU_0_using curriculum 40 with window 40
Epoch: [159][20/30]	Time  1.491 ( 1.531)	Data  0.038 ( 0.056)	InnerLoop  0.630 ( 0.646)	Loss 4.7259e-01 (5.3612e-01)	Acc@1  83.57 ( 81.32)
The current update step is 4800
The current seed is 4094715577824001778
The current lr is: 0.0015
Testing Results:
 *   Acc@1 52.434
 *   Acc@1 52.699
 *   Acc@1 51.000
 *   Acc@1 51.141
 *   Acc@1 49.868
 *   Acc@1 49.873
 *   Acc@1 60.763
 *   Acc@1 60.899
 *   Acc@1 60.197
 *   Acc@1 60.006
 *   Acc@1 58.658
 *   Acc@1 58.903
 *   Acc@1 53.158
 *   Acc@1 53.867
 *   Acc@1 55.487
 *   Acc@1 55.667
 *   Acc@1 55.605
 *   Acc@1 56.194
 *   Acc@1 52.645
 *   Acc@1 53.761
 *   Acc@1 53.368
 *   Acc@1 53.896
 *   Acc@1 53.329
 *   Acc@1 53.897
Training for 300 epoch: 54.75
Training for 600 epoch: 55.01315789473684
Training for 1000 epoch: 54.36513157894737
Training for 300 epoch: 55.30645833333333
Training for 600 epoch: 55.1775
Training for 1000 epoch: 54.71666666666667
[[54.75, 55.01315789473684, 54.36513157894737], [55.30645833333333, 55.1775, 54.71666666666667]]
train loss 0.4987524943033854, epoch 159, best loss 0.28784357541402184, best_epoch 134
GPU_0_using curriculum 40 with window 40
Epoch: [160][20/30]	Time  1.628 ( 1.536)	Data  0.158 ( 0.068)	InnerLoop  0.634 ( 0.639)	Loss 5.6033e-01 (5.2031e-01)	Acc@1  80.37 ( 81.78)
The current update step is 4830
GPU_0_using curriculum 40 with window 40
Epoch: [161][20/30]	Time  1.624 ( 1.533)	Data  0.042 ( 0.057)	InnerLoop  0.756 ( 0.651)	Loss 5.0138e-01 (4.9635e-01)	Acc@1  81.84 ( 82.27)
The current update step is 4860
GPU_0_using curriculum 40 with window 40
Epoch: [162][20/30]	Time  1.498 ( 1.537)	Data  0.039 ( 0.052)	InnerLoop  0.632 ( 0.654)	Loss 5.2621e-01 (5.2412e-01)	Acc@1  80.66 ( 81.58)
The current update step is 4890
GPU_0_using curriculum 40 with window 40
Epoch: [163][20/30]	Time  1.520 ( 1.546)	Data  0.040 ( 0.059)	InnerLoop  0.642 ( 0.654)	Loss 5.1146e-01 (5.1216e-01)	Acc@1  81.62 ( 81.85)
The current update step is 4920
GPU_0_using curriculum 40 with window 40
Epoch: [164][20/30]	Time  1.499 ( 1.525)	Data  0.039 ( 0.044)	InnerLoop  0.634 ( 0.656)	Loss 4.8734e-01 (5.3934e-01)	Acc@1  81.40 ( 81.32)
The current update step is 4950
The current seed is 12562942052223933441
The current lr is: 0.0015
Testing Results:
 *   Acc@1 62.329
 *   Acc@1 62.797
 *   Acc@1 61.974
 *   Acc@1 62.663
 *   Acc@1 61.961
 *   Acc@1 62.502
 *   Acc@1 55.303
 *   Acc@1 55.950
 *   Acc@1 56.829
 *   Acc@1 56.950
 *   Acc@1 57.303
 *   Acc@1 56.956
 *   Acc@1 58.434
 *   Acc@1 58.845
 *   Acc@1 60.066
 *   Acc@1 60.769
 *   Acc@1 60.724
 *   Acc@1 61.058
 *   Acc@1 61.671
 *   Acc@1 61.822
 *   Acc@1 64.461
 *   Acc@1 64.963
 *   Acc@1 64.711
 *   Acc@1 65.097
Training for 300 epoch: 59.434210526315795
Training for 600 epoch: 60.83223684210527
Training for 1000 epoch: 61.174342105263165
Training for 300 epoch: 59.85333333333333
Training for 600 epoch: 61.33604166666667
Training for 1000 epoch: 61.403124999999996
[[59.434210526315795, 60.83223684210527, 61.174342105263165], [59.85333333333333, 61.33604166666667, 61.403124999999996]]
train loss 0.6141944044113159, epoch 164, best loss 0.28784357541402184, best_epoch 134
GPU_0_using curriculum 40 with window 40
Epoch: [165][20/30]	Time  1.490 ( 1.525)	Data  0.040 ( 0.056)	InnerLoop  0.625 ( 0.644)	Loss 5.0029e-01 (5.2968e-01)	Acc@1  82.13 ( 81.26)
The current update step is 4980
GPU_0_using curriculum 40 with window 40
Epoch: [166][20/30]	Time  1.616 ( 1.528)	Data  0.156 ( 0.061)	InnerLoop  0.632 ( 0.641)	Loss 4.6451e-01 (5.1376e-01)	Acc@1  84.57 ( 82.15)
The current update step is 5010
GPU_0_using curriculum 40 with window 40
Epoch: [167][20/30]	Time  1.500 ( 1.541)	Data  0.039 ( 0.038)	InnerLoop  0.634 ( 0.672)	Loss 5.8016e-01 (5.2322e-01)	Acc@1  79.22 ( 81.22)
The current update step is 5040
GPU_0_using curriculum 40 with window 40
Epoch: [168][20/30]	Time  1.503 ( 1.529)	Data  0.039 ( 0.051)	InnerLoop  0.633 ( 0.649)	Loss 5.0408e-01 (5.2763e-01)	Acc@1  81.67 ( 81.22)
The current update step is 5070
GPU_0_using curriculum 40 with window 40
Epoch: [169][20/30]	Time  1.511 ( 1.530)	Data  0.039 ( 0.062)	InnerLoop  0.636 ( 0.639)	Loss 5.1392e-01 (5.1239e-01)	Acc@1  81.69 ( 82.02)
The current update step is 5100
The current seed is 3072025060144850592
The current lr is: 0.0015
Testing Results:
 *   Acc@1 51.855
 *   Acc@1 51.769
 *   Acc@1 54.513
 *   Acc@1 54.592
 *   Acc@1 55.776
 *   Acc@1 55.972
 *   Acc@1 56.118
 *   Acc@1 56.405
 *   Acc@1 63.342
 *   Acc@1 63.494
 *   Acc@1 61.395
 *   Acc@1 62.222
 *   Acc@1 70.474
 *   Acc@1 70.700
 *   Acc@1 71.250
 *   Acc@1 71.331
 *   Acc@1 72.092
 *   Acc@1 71.808
 *   Acc@1 55.855
 *   Acc@1 55.933
 *   Acc@1 53.987
 *   Acc@1 53.547
 *   Acc@1 53.224
 *   Acc@1 53.447
Training for 300 epoch: 58.57565789473685
Training for 600 epoch: 60.77302631578947
Training for 1000 epoch: 60.62171052631578
Training for 300 epoch: 58.701875
Training for 600 epoch: 60.74083333333334
Training for 1000 epoch: 60.862291666666664
[[58.57565789473685, 60.77302631578947, 60.62171052631578], [58.701875, 60.74083333333334, 60.862291666666664]]
train loss 0.7061061307589213, epoch 169, best loss 0.28784357541402184, best_epoch 134
GPU_0_using curriculum 40 with window 40
Epoch: [170][20/30]	Time  1.523 ( 1.532)	Data  0.038 ( 0.050)	InnerLoop  0.644 ( 0.654)	Loss 6.0210e-01 (5.2091e-01)	Acc@1  77.98 ( 81.44)
The current update step is 5130
GPU_0_using curriculum 40 with window 40
Epoch: [171][20/30]	Time  1.510 ( 1.551)	Data  0.036 ( 0.063)	InnerLoop  0.639 ( 0.648)	Loss 5.0205e-01 (5.3552e-01)	Acc@1  83.50 ( 81.08)
The current update step is 5160
GPU_0_using curriculum 40 with window 40
Epoch: [172][20/30]	Time  1.489 ( 1.526)	Data  0.038 ( 0.050)	InnerLoop  0.627 ( 0.650)	Loss 4.5057e-01 (5.1511e-01)	Acc@1  84.20 ( 81.94)
The current update step is 5190
GPU_0_using curriculum 40 with window 40
Epoch: [173][20/30]	Time  1.510 ( 1.526)	Data  0.039 ( 0.067)	InnerLoop  0.638 ( 0.633)	Loss 4.5511e-01 (5.0165e-01)	Acc@1  84.81 ( 82.54)
The current update step is 5220
GPU_0_using curriculum 40 with window 40
Epoch: [174][20/30]	Time  1.497 ( 1.535)	Data  0.040 ( 0.069)	InnerLoop  0.630 ( 0.639)	Loss 6.6550e-01 (5.2542e-01)	Acc@1  76.22 ( 81.73)
The current update step is 5250
The current seed is 13542827469215140808
The current lr is: 0.0015
Testing Results:
 *   Acc@1 76.974
 *   Acc@1 77.350
 *   Acc@1 75.671
 *   Acc@1 75.977
 *   Acc@1 75.039
 *   Acc@1 75.301
 *   Acc@1 56.618
 *   Acc@1 56.648
 *   Acc@1 60.776
 *   Acc@1 60.290
 *   Acc@1 62.118
 *   Acc@1 61.518
 *   Acc@1 25.947
 *   Acc@1 25.590
 *   Acc@1 29.513
 *   Acc@1 29.768
 *   Acc@1 30.316
 *   Acc@1 30.058
 *   Acc@1 74.263
 *   Acc@1 74.050
 *   Acc@1 73.789
 *   Acc@1 73.474
 *   Acc@1 73.763
 *   Acc@1 73.297
Training for 300 epoch: 58.450657894736835
Training for 600 epoch: 59.9375
Training for 1000 epoch: 60.309210526315795
Training for 300 epoch: 58.40958333333333
Training for 600 epoch: 59.87729166666667
Training for 1000 epoch: 60.04375
[[58.450657894736835, 59.9375, 60.309210526315795], [58.40958333333333, 59.87729166666667, 60.04375]]
train loss 0.40027243498166404, epoch 174, best loss 0.28784357541402184, best_epoch 134
GPU_0_using curriculum 40 with window 40
Epoch: [175][20/30]	Time  1.507 ( 1.534)	Data  0.037 ( 0.062)	InnerLoop  0.640 ( 0.644)	Loss 5.1454e-01 (5.1702e-01)	Acc@1  82.45 ( 81.93)
The current update step is 5280
GPU_0_using curriculum 40 with window 40
Epoch: [176][20/30]	Time  1.505 ( 1.560)	Data  0.041 ( 0.072)	InnerLoop  0.637 ( 0.649)	Loss 7.7738e-01 (5.4807e-01)	Acc@1  71.22 ( 80.40)
The current update step is 5310
GPU_0_using curriculum 40 with window 40
Epoch: [177][20/30]	Time  1.496 ( 1.524)	Data  0.038 ( 0.062)	InnerLoop  0.630 ( 0.635)	Loss 4.5194e-01 (5.1805e-01)	Acc@1  84.72 ( 81.91)
The current update step is 5340
GPU_0_using curriculum 40 with window 40
Epoch: [178][20/30]	Time  1.497 ( 1.540)	Data  0.038 ( 0.064)	InnerLoop  0.630 ( 0.646)	Loss 4.6086e-01 (5.4753e-01)	Acc@1  83.40 ( 80.33)
The current update step is 5370
GPU_0_using curriculum 40 with window 40
Epoch: [179][20/30]	Time  1.524 ( 1.527)	Data  0.040 ( 0.056)	InnerLoop  0.646 ( 0.644)	Loss 5.4407e-01 (5.3434e-01)	Acc@1  81.76 ( 81.06)
The current update step is 5400
The current seed is 10658579363699302627
The current lr is: 0.0015
Testing Results:
 *   Acc@1 61.908
 *   Acc@1 61.637
 *   Acc@1 60.711
 *   Acc@1 61.116
 *   Acc@1 60.684
 *   Acc@1 60.629
 *   Acc@1 58.987
 *   Acc@1 59.440
 *   Acc@1 58.974
 *   Acc@1 59.441
 *   Acc@1 58.803
 *   Acc@1 59.237
 *   Acc@1 58.211
 *   Acc@1 58.496
 *   Acc@1 58.105
 *   Acc@1 58.047
 *   Acc@1 58.132
 *   Acc@1 58.012
 *   Acc@1 61.618
 *   Acc@1 61.328
 *   Acc@1 54.803
 *   Acc@1 54.108
 *   Acc@1 54.513
 *   Acc@1 54.432
Training for 300 epoch: 60.18092105263158
Training for 600 epoch: 58.14802631578947
Training for 1000 epoch: 58.0328947368421
Training for 300 epoch: 60.22520833333333
Training for 600 epoch: 58.17812500000001
Training for 1000 epoch: 58.0775
[[60.18092105263158, 58.14802631578947, 58.0328947368421], [60.22520833333333, 58.17812500000001, 58.0775]]
train loss 0.698256263256073, epoch 179, best loss 0.28784357541402184, best_epoch 134
GPU_0_using curriculum 40 with window 40
Epoch: [180][20/30]	Time  1.614 ( 1.541)	Data  0.155 ( 0.070)	InnerLoop  0.630 ( 0.643)	Loss 5.3057e-01 (5.2261e-01)	Acc@1  81.01 ( 81.86)
The current update step is 5430
GPU_0_using curriculum 40 with window 40
Epoch: [181][20/30]	Time  1.628 ( 1.534)	Data  0.036 ( 0.055)	InnerLoop  0.761 ( 0.652)	Loss 5.7278e-01 (4.9965e-01)	Acc@1  79.86 ( 82.55)
The current update step is 5460
GPU_0_using curriculum 40 with window 40
Epoch: [182][20/30]	Time  1.531 ( 1.544)	Data  0.039 ( 0.052)	InnerLoop  0.639 ( 0.658)	Loss 5.0170e-01 (5.2560e-01)	Acc@1  82.01 ( 81.54)
The current update step is 5490
GPU_0_using curriculum 40 with window 40
Epoch: [183][20/30]	Time  1.497 ( 1.523)	Data  0.038 ( 0.055)	InnerLoop  0.630 ( 0.642)	Loss 5.5389e-01 (5.1936e-01)	Acc@1  79.27 ( 81.67)
The current update step is 5520
GPU_0_using curriculum 40 with window 40
Epoch: [184][20/30]	Time  1.509 ( 1.526)	Data  0.039 ( 0.045)	InnerLoop  0.640 ( 0.656)	Loss 5.2431e-01 (4.9736e-01)	Acc@1  81.25 ( 82.53)
The current update step is 5550
The current seed is 15304411690353339809
The current lr is: 0.0015
Testing Results:
 *   Acc@1 52.605
 *   Acc@1 53.711
 *   Acc@1 52.171
 *   Acc@1 52.310
 *   Acc@1 54.342
 *   Acc@1 54.918
 *   Acc@1 55.671
 *   Acc@1 56.276
 *   Acc@1 56.395
 *   Acc@1 56.812
 *   Acc@1 56.184
 *   Acc@1 56.781
 *   Acc@1 50.697
 *   Acc@1 50.972
 *   Acc@1 63.658
 *   Acc@1 64.227
 *   Acc@1 62.079
 *   Acc@1 63.084
 *   Acc@1 46.868
 *   Acc@1 46.586
 *   Acc@1 62.158
 *   Acc@1 61.905
 *   Acc@1 36.987
 *   Acc@1 37.667
Training for 300 epoch: 51.46052631578947
Training for 600 epoch: 58.5953947368421
Training for 1000 epoch: 52.39802631578947
Training for 300 epoch: 51.88625
Training for 600 epoch: 58.81333333333334
Training for 1000 epoch: 53.1125
[[51.46052631578947, 58.5953947368421, 52.39802631578947], [51.88625, 58.81333333333334, 53.1125]]
train loss 0.9859863558769226, epoch 184, best loss 0.28784357541402184, best_epoch 134
GPU_0_using curriculum 40 with window 40
Epoch: [185][20/30]	Time  1.504 ( 1.529)	Data  0.043 ( 0.057)	InnerLoop  0.629 ( 0.645)	Loss 5.3766e-01 (5.1998e-01)	Acc@1  82.15 ( 81.79)
The current update step is 5580
GPU_0_using curriculum 40 with window 40
Epoch: [186][20/30]	Time  1.651 ( 1.552)	Data  0.164 ( 0.064)	InnerLoop  0.643 ( 0.654)	Loss 4.6133e-01 (5.1380e-01)	Acc@1  83.54 ( 81.75)
The current update step is 5610
GPU_0_using curriculum 40 with window 40
Epoch: [187][20/30]	Time  1.495 ( 1.527)	Data  0.041 ( 0.040)	InnerLoop  0.630 ( 0.661)	Loss 4.9036e-01 (5.1743e-01)	Acc@1  80.98 ( 81.76)
The current update step is 5640
GPU_0_using curriculum 40 with window 40
Epoch: [188][20/30]	Time  1.501 ( 1.530)	Data  0.042 ( 0.053)	InnerLoop  0.631 ( 0.651)	Loss 5.0394e-01 (5.0564e-01)	Acc@1  82.20 ( 82.04)
The current update step is 5670
GPU_0_using curriculum 40 with window 40
Epoch: [189][20/30]	Time  1.508 ( 1.541)	Data  0.043 ( 0.065)	InnerLoop  0.637 ( 0.643)	Loss 4.5325e-01 (4.9215e-01)	Acc@1  84.99 ( 82.70)
The current update step is 5700
The current seed is 16930123264786607917
The current lr is: 0.0015
Testing Results:
 *   Acc@1 69.250
 *   Acc@1 69.135
 *   Acc@1 69.579
 *   Acc@1 69.709
 *   Acc@1 70.382
 *   Acc@1 70.252
 *   Acc@1 62.947
 *   Acc@1 63.032
 *   Acc@1 62.592
 *   Acc@1 62.729
 *   Acc@1 62.579
 *   Acc@1 62.782
 *   Acc@1 70.474
 *   Acc@1 71.085
 *   Acc@1 71.526
 *   Acc@1 71.885
 *   Acc@1 71.539
 *   Acc@1 72.169
 *   Acc@1 46.855
 *   Acc@1 47.570
 *   Acc@1 48.776
 *   Acc@1 49.800
 *   Acc@1 48.961
 *   Acc@1 49.748
Training for 300 epoch: 62.381578947368425
Training for 600 epoch: 63.11842105263159
Training for 1000 epoch: 63.36513157894737
Training for 300 epoch: 62.705625
Training for 600 epoch: 63.530833333333334
Training for 1000 epoch: 63.73770833333333
[[62.381578947368425, 63.11842105263159, 63.36513157894737], [62.705625, 63.530833333333334, 63.73770833333333]]
train loss 0.8149211518287659, epoch 189, best loss 0.28784357541402184, best_epoch 134
GPU_0_using curriculum 40 with window 40
Epoch: [190][20/30]	Time  1.502 ( 1.543)	Data  0.039 ( 0.051)	InnerLoop  0.634 ( 0.658)	Loss 5.4373e-01 (4.9944e-01)	Acc@1  79.64 ( 82.72)
The current update step is 5730
GPU_0_using curriculum 40 with window 40
Epoch: [191][20/30]	Time  1.485 ( 1.531)	Data  0.037 ( 0.063)	InnerLoop  0.625 ( 0.640)	Loss 4.9080e-01 (5.0302e-01)	Acc@1  82.30 ( 81.87)
The current update step is 5760
GPU_0_using curriculum 40 with window 40
Epoch: [192][20/30]	Time  1.492 ( 1.558)	Data  0.041 ( 0.052)	InnerLoop  0.623 ( 0.664)	Loss 5.4230e-01 (4.8375e-01)	Acc@1  82.13 ( 82.80)
The current update step is 5790
GPU_0_using curriculum 40 with window 40
Epoch: [193][20/30]	Time  1.492 ( 1.520)	Data  0.038 ( 0.068)	InnerLoop  0.632 ( 0.628)	Loss 4.5027e-01 (4.8670e-01)	Acc@1  84.30 ( 83.04)
The current update step is 5820
GPU_0_using curriculum 40 with window 40
Epoch: [194][20/30]	Time  1.496 ( 1.540)	Data  0.038 ( 0.070)	InnerLoop  0.629 ( 0.640)	Loss 5.8992e-01 (4.9659e-01)	Acc@1  79.98 ( 82.77)
The current update step is 5850
The current seed is 10854248305686281732
The current lr is: 0.0015
Testing Results:
 *   Acc@1 59.263
 *   Acc@1 59.623
 *   Acc@1 56.184
 *   Acc@1 55.935
 *   Acc@1 55.908
 *   Acc@1 56.240
 *   Acc@1 60.066
 *   Acc@1 60.883
 *   Acc@1 60.382
 *   Acc@1 60.895
 *   Acc@1 60.526
 *   Acc@1 61.133
 *   Acc@1 52.658
 *   Acc@1 52.722
 *   Acc@1 54.921
 *   Acc@1 54.838
 *   Acc@1 55.066
 *   Acc@1 55.182
 *   Acc@1 36.145
 *   Acc@1 36.443
 *   Acc@1 37.079
 *   Acc@1 36.722
 *   Acc@1 37.053
 *   Acc@1 36.801
Training for 300 epoch: 52.0328947368421
Training for 600 epoch: 52.141447368421055
Training for 1000 epoch: 52.13815789473684
Training for 300 epoch: 52.41770833333333
Training for 600 epoch: 52.09770833333334
Training for 1000 epoch: 52.33895833333334
[[52.0328947368421, 52.141447368421055, 52.13815789473684], [52.41770833333333, 52.09770833333334, 52.33895833333334]]
train loss 1.2328392707188924, epoch 194, best loss 0.28784357541402184, best_epoch 194
GPU_0_using curriculum 40 with window 40
Epoch: [195][20/30]	Time  1.497 ( 1.533)	Data  0.036 ( 0.063)	InnerLoop  0.632 ( 0.642)	Loss 6.3223e-01 (5.2762e-01)	Acc@1  78.96 ( 81.12)
The current update step is 5880
GPU_0_using curriculum 40 with window 40
Epoch: [196][20/30]	Time  1.506 ( 1.526)	Data  0.038 ( 0.068)	InnerLoop  0.636 ( 0.631)	Loss 4.4130e-01 (5.0269e-01)	Acc@1  84.25 ( 82.64)
The current update step is 5910
GPU_0_using curriculum 40 with window 40
Epoch: [197][20/30]	Time  1.503 ( 1.528)	Data  0.040 ( 0.062)	InnerLoop  0.636 ( 0.639)	Loss 5.3759e-01 (5.4611e-01)	Acc@1  81.23 ( 81.02)
The current update step is 5940
GPU_0_using curriculum 40 with window 40
Epoch: [198][20/30]	Time  1.490 ( 1.521)	Data  0.039 ( 0.062)	InnerLoop  0.625 ( 0.634)	Loss 5.4792e-01 (4.9927e-01)	Acc@1  80.18 ( 82.34)
The current update step is 5970
GPU_0_using curriculum 40 with window 40
Epoch: [199][20/30]	Time  1.555 ( 1.522)	Data  0.040 ( 0.056)	InnerLoop  0.650 ( 0.638)	Loss 5.0869e-01 (5.2541e-01)	Acc@1  83.74 ( 81.46)
The current update step is 6000
The current seed is 6681805087220054890
The current lr is: 0.0015
Testing Results:
 *   Acc@1 16.000
 *   Acc@1 15.918
 *   Acc@1 19.092
 *   Acc@1 19.225
 *   Acc@1 19.237
 *   Acc@1 19.717
 *   Acc@1 60.987
 *   Acc@1 61.372
 *   Acc@1 63.171
 *   Acc@1 63.629
 *   Acc@1 62.961
 *   Acc@1 63.617
 *   Acc@1 68.197
 *   Acc@1 67.307
 *   Acc@1 67.934
 *   Acc@1 66.930
 *   Acc@1 67.395
 *   Acc@1 66.838
 *   Acc@1 55.395
 *   Acc@1 56.113
 *   Acc@1 55.921
 *   Acc@1 56.403
 *   Acc@1 56.355
 *   Acc@1 56.733
Training for 300 epoch: 50.14473684210526
Training for 600 epoch: 51.52960526315789
Training for 1000 epoch: 51.48684210526316
Training for 300 epoch: 50.17750000000001
Training for 600 epoch: 51.546666666666674
Training for 1000 epoch: 51.72625000000001
[[50.14473684210526, 51.52960526315789, 51.48684210526316], [50.17750000000001, 51.546666666666674, 51.72625000000001]]
train loss 0.6376602281888326, epoch 199, best loss 0.28784357541402184, best_epoch 194
GPU_0_using curriculum 40 with window 40
Epoch: [200][20/30]	Time  1.696 ( 1.540)	Data  0.170 ( 0.068)	InnerLoop  0.676 ( 0.642)	Loss 4.9931e-01 (5.3320e-01)	Acc@1  82.69 ( 80.65)
The current update step is 6030
GPU_0_using curriculum 40 with window 40
Epoch: [201][20/30]	Time  1.606 ( 1.528)	Data  0.036 ( 0.056)	InnerLoop  0.747 ( 0.650)	Loss 4.7491e-01 (5.2958e-01)	Acc@1  83.72 ( 81.59)
The current update step is 6060
GPU_0_using curriculum 40 with window 40
Epoch: [202][20/30]	Time  1.497 ( 1.521)	Data  0.039 ( 0.050)	InnerLoop  0.629 ( 0.646)	Loss 7.1486e-01 (5.2720e-01)	Acc@1  72.97 ( 81.48)
The current update step is 6090
GPU_0_using curriculum 40 with window 40
Epoch: [203][20/30]	Time  1.499 ( 1.523)	Data  0.039 ( 0.055)	InnerLoop  0.634 ( 0.642)	Loss 4.4448e-01 (4.9260e-01)	Acc@1  84.13 ( 82.85)
The current update step is 6120
GPU_0_using curriculum 40 with window 40
Epoch: [204][20/30]	Time  1.500 ( 1.536)	Data  0.039 ( 0.046)	InnerLoop  0.637 ( 0.660)	Loss 4.7877e-01 (4.9527e-01)	Acc@1  83.86 ( 82.56)
The current update step is 6150
The current seed is 13253263363502402932
The current lr is: 0.0015
Testing Results:
 *   Acc@1 67.224
 *   Acc@1 67.872
 *   Acc@1 67.566
 *   Acc@1 68.224
 *   Acc@1 67.750
 *   Acc@1 68.491
 *   Acc@1 57.882
 *   Acc@1 57.447
 *   Acc@1 55.447
 *   Acc@1 55.337
 *   Acc@1 56.092
 *   Acc@1 56.151
 *   Acc@1 59.487
 *   Acc@1 59.518
 *   Acc@1 60.079
 *   Acc@1 60.138
 *   Acc@1 59.882
 *   Acc@1 59.877
 *   Acc@1 72.263
 *   Acc@1 72.565
 *   Acc@1 71.961
 *   Acc@1 72.653
 *   Acc@1 72.171
 *   Acc@1 72.774
Training for 300 epoch: 64.21381578947368
Training for 600 epoch: 63.76315789473684
Training for 1000 epoch: 63.973684210526315
Training for 300 epoch: 64.350625
Training for 600 epoch: 64.08791666666667
Training for 1000 epoch: 64.323125
[[64.21381578947368, 63.76315789473684, 63.973684210526315], [64.350625, 64.08791666666667, 64.323125]]
train loss 0.33477143789927166, epoch 204, best loss 0.28784357541402184, best_epoch 194
GPU_0_using curriculum 40 with window 40
Epoch: [205][20/30]	Time  1.525 ( 1.540)	Data  0.043 ( 0.058)	InnerLoop  0.651 ( 0.651)	Loss 4.7706e-01 (5.0577e-01)	Acc@1  83.72 ( 82.10)
The current update step is 6180
GPU_0_using curriculum 40 with window 40
Epoch: [206][20/30]	Time  1.624 ( 1.540)	Data  0.159 ( 0.062)	InnerLoop  0.631 ( 0.650)	Loss 4.8829e-01 (4.9644e-01)	Acc@1  82.35 ( 82.53)
The current update step is 6210
GPU_0_using curriculum 40 with window 40
Epoch: [207][20/30]	Time  1.485 ( 1.524)	Data  0.037 ( 0.037)	InnerLoop  0.626 ( 0.663)	Loss 4.5456e-01 (5.0778e-01)	Acc@1  84.84 ( 82.39)
The current update step is 6240
GPU_0_using curriculum 40 with window 40
Epoch: [208][20/30]	Time  1.517 ( 1.533)	Data  0.039 ( 0.051)	InnerLoop  0.636 ( 0.653)	Loss 4.5187e-01 (5.0631e-01)	Acc@1  84.28 ( 82.24)
The current update step is 6270
GPU_0_using curriculum 40 with window 40
Epoch: [209][20/30]	Time  1.507 ( 1.530)	Data  0.039 ( 0.062)	InnerLoop  0.639 ( 0.640)	Loss 5.5106e-01 (5.3332e-01)	Acc@1  79.27 ( 81.25)
The current update step is 6300
The current seed is 3117230430401042673
The current lr is: 0.0015
Testing Results:
 *   Acc@1 49.539
 *   Acc@1 49.748
 *   Acc@1 50.592
 *   Acc@1 50.703
 *   Acc@1 51.395
 *   Acc@1 51.528
 *   Acc@1 65.855
 *   Acc@1 66.624
 *   Acc@1 64.184
 *   Acc@1 64.427
 *   Acc@1 63.987
 *   Acc@1 64.248
 *   Acc@1 74.539
 *   Acc@1 75.624
 *   Acc@1 74.592
 *   Acc@1 75.573
 *   Acc@1 74.329
 *   Acc@1 75.493
 *   Acc@1 58.645
 *   Acc@1 59.046
 *   Acc@1 59.487
 *   Acc@1 59.705
 *   Acc@1 60.079
 *   Acc@1 59.862
Training for 300 epoch: 62.14473684210526
Training for 600 epoch: 62.213815789473685
Training for 1000 epoch: 62.44736842105263
Training for 300 epoch: 62.760625000000005
Training for 600 epoch: 62.60187499999999
Training for 1000 epoch: 62.782916666666665
[[62.14473684210526, 62.213815789473685, 62.44736842105263], [62.760625000000005, 62.60187499999999, 62.782916666666665]]
train loss 0.796688890838623, epoch 209, best loss 0.28784357541402184, best_epoch 194
GPU_0_using curriculum 40 with window 40
Epoch: [210][20/30]	Time  1.554 ( 1.543)	Data  0.039 ( 0.051)	InnerLoop  0.649 ( 0.660)	Loss 4.9117e-01 (5.0728e-01)	Acc@1  83.11 ( 81.86)
The current update step is 6330
GPU_0_using curriculum 40 with window 40
Epoch: [211][20/30]	Time  1.496 ( 1.531)	Data  0.035 ( 0.062)	InnerLoop  0.634 ( 0.641)	Loss 5.0345e-01 (5.2030e-01)	Acc@1  82.76 ( 81.55)
The current update step is 6360
GPU_0_using curriculum 40 with window 40
Epoch: [212][20/30]	Time  1.484 ( 1.512)	Data  0.038 ( 0.049)	InnerLoop  0.624 ( 0.644)	Loss 4.3867e-01 (5.0358e-01)	Acc@1  84.81 ( 81.98)
The current update step is 6390
GPU_0_using curriculum 40 with window 40
Epoch: [213][20/30]	Time  1.502 ( 1.528)	Data  0.041 ( 0.068)	InnerLoop  0.637 ( 0.633)	Loss 4.7724e-01 (5.0838e-01)	Acc@1  83.42 ( 81.91)
The current update step is 6420
GPU_0_using curriculum 40 with window 40
Epoch: [214][20/30]	Time  1.492 ( 1.525)	Data  0.037 ( 0.067)	InnerLoop  0.626 ( 0.634)	Loss 6.2861e-01 (4.9423e-01)	Acc@1  77.81 ( 82.55)
The current update step is 6450
The current seed is 7359299346309174577
The current lr is: 0.0015
Testing Results:
 *   Acc@1 71.053
 *   Acc@1 71.683
 *   Acc@1 55.632
 *   Acc@1 55.442
 *   Acc@1 55.289
 *   Acc@1 55.314
 *   Acc@1 47.211
 *   Acc@1 47.938
 *   Acc@1 49.145
 *   Acc@1 49.868
 *   Acc@1 50.000
 *   Acc@1 50.419
 *   Acc@1 69.276
 *   Acc@1 69.487
 *   Acc@1 70.158
 *   Acc@1 70.043
 *   Acc@1 69.579
 *   Acc@1 70.250
 *   Acc@1 78.039
 *   Acc@1 78.640
 *   Acc@1 77.961
 *   Acc@1 78.817
 *   Acc@1 78.132
 *   Acc@1 79.039
Training for 300 epoch: 66.39473684210526
Training for 600 epoch: 63.223684210526315
Training for 1000 epoch: 63.25
Training for 300 epoch: 66.93729166666667
Training for 600 epoch: 63.54270833333334
Training for 1000 epoch: 63.75562500000001
[[66.39473684210526, 63.223684210526315, 63.25], [66.93729166666667, 63.54270833333334, 63.75562500000001]]
train loss 0.2624552794933319, epoch 214, best loss 0.2624552794933319, best_epoch 214
GPU_0_using curriculum 40 with window 40
Epoch: [215][20/30]	Time  1.491 ( 1.520)	Data  0.037 ( 0.060)	InnerLoop  0.635 ( 0.639)	Loss 4.7970e-01 (4.8792e-01)	Acc@1  83.23 ( 82.90)
The current update step is 6480
GPU_0_using curriculum 40 with window 40
Epoch: [216][20/30]	Time  1.483 ( 1.513)	Data  0.038 ( 0.067)	InnerLoop  0.624 ( 0.627)	Loss 6.0127e-01 (4.9376e-01)	Acc@1  78.20 ( 82.57)
The current update step is 6510
GPU_0_using curriculum 40 with window 40
Epoch: [217][20/30]	Time  1.489 ( 1.523)	Data  0.035 ( 0.062)	InnerLoop  0.633 ( 0.636)	Loss 4.9678e-01 (4.8894e-01)	Acc@1  82.64 ( 82.84)
The current update step is 6540
GPU_0_using curriculum 40 with window 40
Epoch: [218][20/30]	Time  1.487 ( 1.515)	Data  0.037 ( 0.060)	InnerLoop  0.626 ( 0.634)	Loss 4.1750e-01 (4.9747e-01)	Acc@1  85.21 ( 82.61)
The current update step is 6570
GPU_0_using curriculum 40 with window 40
Epoch: [219][20/30]	Time  1.494 ( 1.514)	Data  0.036 ( 0.054)	InnerLoop  0.632 ( 0.638)	Loss 4.5627e-01 (4.8458e-01)	Acc@1  82.98 ( 83.07)
The current update step is 6600
The current seed is 15411895403022373773
The current lr is: 0.0015
Testing Results:
 *   Acc@1 55.671
 *   Acc@1 56.653
 *   Acc@1 57.487
 *   Acc@1 58.477
 *   Acc@1 57.461
 *   Acc@1 57.910
 *   Acc@1 60.605
 *   Acc@1 61.310
 *   Acc@1 61.711
 *   Acc@1 62.597
 *   Acc@1 63.197
 *   Acc@1 63.876
 *   Acc@1 76.303
 *   Acc@1 76.457
 *   Acc@1 75.461
 *   Acc@1 75.941
 *   Acc@1 75.158
 *   Acc@1 75.636
 *   Acc@1 57.013
 *   Acc@1 57.319
 *   Acc@1 57.197
 *   Acc@1 57.469
 *   Acc@1 56.711
 *   Acc@1 57.415
Training for 300 epoch: 62.39802631578947
Training for 600 epoch: 62.963815789473685
Training for 1000 epoch: 63.131578947368425
Training for 300 epoch: 62.93479166666667
Training for 600 epoch: 63.62083333333333
Training for 1000 epoch: 63.70916666666667
[[62.39802631578947, 62.963815789473685, 63.131578947368425], [62.93479166666667, 63.62083333333333, 63.70916666666667]]
train loss 0.734703616364797, epoch 219, best loss 0.2624552794933319, best_epoch 214
GPU_0_using curriculum 40 with window 40
Epoch: [220][20/30]	Time  1.600 ( 1.519)	Data  0.150 ( 0.065)	InnerLoop  0.627 ( 0.633)	Loss 5.1231e-01 (4.8997e-01)	Acc@1  81.79 ( 82.66)
The current update step is 6630
GPU_0_using curriculum 40 with window 40
Epoch: [221][20/30]	Time  1.657 ( 1.560)	Data  0.040 ( 0.058)	InnerLoop  0.768 ( 0.663)	Loss 4.0876e-01 (4.5369e-01)	Acc@1  85.86 ( 84.14)
The current update step is 6660
GPU_0_using curriculum 40 with window 40
Epoch: [222][20/30]	Time  1.492 ( 1.514)	Data  0.037 ( 0.049)	InnerLoop  0.626 ( 0.645)	Loss 4.7752e-01 (4.8343e-01)	Acc@1  83.06 ( 83.03)
The current update step is 6690
GPU_0_using curriculum 40 with window 40
Epoch: [223][20/30]	Time  1.485 ( 1.519)	Data  0.038 ( 0.056)	InnerLoop  0.618 ( 0.640)	Loss 5.9685e-01 (5.1106e-01)	Acc@1  78.93 ( 81.66)
The current update step is 6720
GPU_0_using curriculum 40 with window 40
Epoch: [224][20/30]	Time  1.499 ( 1.520)	Data  0.039 ( 0.043)	InnerLoop  0.635 ( 0.653)	Loss 4.1443e-01 (4.7397e-01)	Acc@1  86.06 ( 83.36)
The current update step is 6750
The current seed is 10733921834477532104
The current lr is: 0.0015
Testing Results:
 *   Acc@1 73.250
 *   Acc@1 73.478
 *   Acc@1 73.395
 *   Acc@1 73.769
 *   Acc@1 73.039
 *   Acc@1 73.753
 *   Acc@1 64.882
 *   Acc@1 65.027
 *   Acc@1 63.303
 *   Acc@1 63.921
 *   Acc@1 63.013
 *   Acc@1 63.457
 *   Acc@1 66.434
 *   Acc@1 67.068
 *   Acc@1 67.303
 *   Acc@1 67.915
 *   Acc@1 67.474
 *   Acc@1 68.033
 *   Acc@1 65.776
 *   Acc@1 65.643
 *   Acc@1 65.711
 *   Acc@1 65.871
 *   Acc@1 66.592
 *   Acc@1 66.372
Training for 300 epoch: 67.58552631578948
Training for 600 epoch: 67.42763157894737
Training for 1000 epoch: 67.52960526315789
Training for 300 epoch: 67.80395833333333
Training for 600 epoch: 67.86895833333334
Training for 1000 epoch: 67.90375
[[67.58552631578948, 67.42763157894737, 67.52960526315789], [67.80395833333333, 67.86895833333334, 67.90375]]
train loss 0.4906508385340373, epoch 224, best loss 0.2624552794933319, best_epoch 214
GPU_0_using curriculum 40 with window 40
Epoch: [225][20/30]	Time  1.492 ( 1.523)	Data  0.039 ( 0.056)	InnerLoop  0.628 ( 0.643)	Loss 5.4055e-01 (4.9108e-01)	Acc@1  81.08 ( 82.44)
The current update step is 6780
GPU_0_using curriculum 40 with window 40
Epoch: [226][20/30]	Time  1.609 ( 1.525)	Data  0.159 ( 0.063)	InnerLoop  0.621 ( 0.637)	Loss 4.2002e-01 (4.7633e-01)	Acc@1  85.23 ( 83.54)
The current update step is 6810
GPU_0_using curriculum 40 with window 40
Epoch: [227][20/30]	Time  1.542 ( 1.568)	Data  0.044 ( 0.043)	InnerLoop  0.654 ( 0.681)	Loss 4.5134e-01 (4.7978e-01)	Acc@1  84.38 ( 83.05)
The current update step is 6840
GPU_0_using curriculum 40 with window 40
Epoch: [228][20/30]	Time  1.480 ( 1.546)	Data  0.038 ( 0.053)	InnerLoop  0.621 ( 0.658)	Loss 4.2516e-01 (4.9223e-01)	Acc@1  86.06 ( 82.68)
The current update step is 6870
GPU_0_using curriculum 40 with window 40
Epoch: [229][20/30]	Time  1.485 ( 1.513)	Data  0.040 ( 0.061)	InnerLoop  0.626 ( 0.631)	Loss 5.3610e-01 (4.7981e-01)	Acc@1  82.35 ( 83.10)
The current update step is 6900
The current seed is 14965130022010707691
The current lr is: 0.0015
Testing Results:
 *   Acc@1 56.737
 *   Acc@1 56.961
 *   Acc@1 55.855
 *   Acc@1 55.843
 *   Acc@1 55.013
 *   Acc@1 55.167
 *   Acc@1 66.553
 *   Acc@1 66.768
 *   Acc@1 67.263
 *   Acc@1 67.417
 *   Acc@1 67.697
 *   Acc@1 67.766
 *   Acc@1 48.579
 *   Acc@1 47.637
 *   Acc@1 48.342
 *   Acc@1 47.471
 *   Acc@1 49.408
 *   Acc@1 48.538
 *   Acc@1 62.250
 *   Acc@1 61.532
 *   Acc@1 63.566
 *   Acc@1 63.167
 *   Acc@1 63.987
 *   Acc@1 63.825
Training for 300 epoch: 58.52960526315789
Training for 600 epoch: 58.756578947368425
Training for 1000 epoch: 59.026315789473685
Training for 300 epoch: 58.22458333333333
Training for 600 epoch: 58.47416666666667
Training for 1000 epoch: 58.82395833333334
[[58.52960526315789, 58.756578947368425, 59.026315789473685], [58.22458333333333, 58.47416666666667, 58.82395833333334]]
train loss 0.6430234200795492, epoch 229, best loss 0.2624552794933319, best_epoch 214
GPU_0_using curriculum 40 with window 40
Epoch: [230][20/30]	Time  1.486 ( 1.511)	Data  0.035 ( 0.048)	InnerLoop  0.629 ( 0.643)	Loss 5.2326e-01 (5.6087e-01)	Acc@1  80.86 ( 80.28)
The current update step is 6930
GPU_0_using curriculum 40 with window 40
Epoch: [231][20/30]	Time  1.486 ( 1.507)	Data  0.036 ( 0.060)	InnerLoop  0.626 ( 0.628)	Loss 5.7498e-01 (5.3672e-01)	Acc@1  78.86 ( 80.76)
The current update step is 6960
GPU_0_using curriculum 40 with window 40
Epoch: [232][20/30]	Time  1.481 ( 1.511)	Data  0.037 ( 0.048)	InnerLoop  0.625 ( 0.641)	Loss 4.9097e-01 (5.2804e-01)	Acc@1  82.86 ( 81.44)
The current update step is 6990
GPU_0_using curriculum 40 with window 40
Epoch: [233][20/30]	Time  1.486 ( 1.510)	Data  0.039 ( 0.066)	InnerLoop  0.624 ( 0.625)	Loss 4.9727e-01 (5.4588e-01)	Acc@1  83.13 ( 80.84)
The current update step is 7020
GPU_0_using curriculum 40 with window 40
Epoch: [234][20/30]	Time  1.483 ( 1.514)	Data  0.038 ( 0.066)	InnerLoop  0.626 ( 0.628)	Loss 4.6949e-01 (5.0162e-01)	Acc@1  83.69 ( 82.27)
The current update step is 7050
The current seed is 2579843230897241252
The current lr is: 0.0015
Testing Results:
 *   Acc@1 66.750
 *   Acc@1 67.218
 *   Acc@1 66.355
 *   Acc@1 66.226
 *   Acc@1 66.592
 *   Acc@1 65.844
 *   Acc@1 71.474
 *   Acc@1 71.978
 *   Acc@1 71.526
 *   Acc@1 72.188
 *   Acc@1 71.579
 *   Acc@1 72.332
 *   Acc@1 71.579
 *   Acc@1 71.580
 *   Acc@1 72.184
 *   Acc@1 72.498
 *   Acc@1 72.105
 *   Acc@1 72.569
 *   Acc@1 61.342
 *   Acc@1 60.890
 *   Acc@1 59.789
 *   Acc@1 59.188
 *   Acc@1 58.526
 *   Acc@1 58.529
Training for 300 epoch: 67.78618421052632
Training for 600 epoch: 67.46381578947368
Training for 1000 epoch: 67.20065789473685
Training for 300 epoch: 67.91645833333332
Training for 600 epoch: 67.52479166666666
Training for 1000 epoch: 67.31875
[[67.78618421052632, 67.46381578947368, 67.20065789473685], [67.91645833333332, 67.52479166666666, 67.31875]]
train loss 0.5356949378649394, epoch 234, best loss 0.2624552794933319, best_epoch 214
GPU_0_using curriculum 40 with window 40
Epoch: [235][20/30]	Time  1.483 ( 1.519)	Data  0.038 ( 0.061)	InnerLoop  0.622 ( 0.638)	Loss 4.8148e-01 (5.0672e-01)	Acc@1  82.89 ( 81.82)
The current update step is 7080
GPU_0_using curriculum 40 with window 40
Epoch: [236][20/30]	Time  1.491 ( 1.511)	Data  0.039 ( 0.068)	InnerLoop  0.630 ( 0.623)	Loss 5.7601e-01 (5.8102e-01)	Acc@1  76.46 ( 78.56)
The current update step is 7110
GPU_0_using curriculum 40 with window 40
Epoch: [237][20/30]	Time  1.483 ( 1.509)	Data  0.036 ( 0.060)	InnerLoop  0.625 ( 0.630)	Loss 5.4312e-01 (5.9336e-01)	Acc@1  79.66 ( 79.10)
The current update step is 7140
GPU_0_using curriculum 40 with window 40
Epoch: [238][20/30]	Time  1.487 ( 1.510)	Data  0.037 ( 0.061)	InnerLoop  0.627 ( 0.631)	Loss 8.4049e-01 (5.8245e-01)	Acc@1  68.95 ( 78.73)
The current update step is 7170
GPU_0_using curriculum 40 with window 40
Epoch: [239][20/30]	Time  1.494 ( 1.511)	Data  0.036 ( 0.054)	InnerLoop  0.633 ( 0.637)	Loss 5.0402e-01 (5.3339e-01)	Acc@1  80.42 ( 81.39)
The current update step is 7200
The current seed is 2763555079137152710
The current lr is: 0.0015
Testing Results:
 *   Acc@1 74.250
 *   Acc@1 74.959
 *   Acc@1 73.974
 *   Acc@1 74.522
 *   Acc@1 74.158
 *   Acc@1 74.720
 *   Acc@1 71.671
 *   Acc@1 71.834
 *   Acc@1 70.355
 *   Acc@1 70.454
 *   Acc@1 69.868
 *   Acc@1 70.080
 *   Acc@1 70.053
 *   Acc@1 69.989
 *   Acc@1 69.618
 *   Acc@1 69.705
 *   Acc@1 69.566
 *   Acc@1 69.361
 *   Acc@1 60.737
 *   Acc@1 61.140
 *   Acc@1 58.158
 *   Acc@1 58.111
 *   Acc@1 58.934
 *   Acc@1 58.784
Training for 300 epoch: 69.17763157894737
Training for 600 epoch: 68.02631578947367
Training for 1000 epoch: 68.13157894736842
Training for 300 epoch: 69.48062499999999
Training for 600 epoch: 68.198125
Training for 1000 epoch: 68.23625000000001
[[69.17763157894737, 68.02631578947367, 68.13157894736842], [69.48062499999999, 68.198125, 68.23625000000001]]
train loss 0.7552235679944356, epoch 239, best loss 0.2624552794933319, best_epoch 214
GPU_0_using curriculum 40 with window 40
Epoch: [240][20/30]	Time  1.601 ( 1.515)	Data  0.151 ( 0.065)	InnerLoop  0.624 ( 0.629)	Loss 5.4116e-01 (5.1530e-01)	Acc@1  80.13 ( 81.31)
The current update step is 7230
GPU_0_using curriculum 40 with window 40
Epoch: [241][20/30]	Time  1.603 ( 1.519)	Data  0.035 ( 0.054)	InnerLoop  0.747 ( 0.645)	Loss 5.2094e-01 (5.0087e-01)	Acc@1  81.76 ( 82.16)
The current update step is 7260
GPU_0_using curriculum 40 with window 40
Epoch: [242][20/30]	Time  1.492 ( 1.515)	Data  0.038 ( 0.049)	InnerLoop  0.627 ( 0.643)	Loss 4.4072e-01 (4.8036e-01)	Acc@1  84.35 ( 83.36)
The current update step is 7290
GPU_0_using curriculum 40 with window 40
Epoch: [243][20/30]	Time  1.495 ( 1.513)	Data  0.038 ( 0.054)	InnerLoop  0.629 ( 0.638)	Loss 4.8640e-01 (4.8191e-01)	Acc@1  83.94 ( 82.97)
The current update step is 7320
GPU_0_using curriculum 40 with window 40
Epoch: [244][20/30]	Time  1.489 ( 1.513)	Data  0.038 ( 0.043)	InnerLoop  0.625 ( 0.648)	Loss 4.4571e-01 (5.2912e-01)	Acc@1  84.30 ( 80.77)
The current update step is 7350
The current seed is 93233254879951561
The current lr is: 0.0015
Testing Results:
 *   Acc@1 70.145
 *   Acc@1 70.388
 *   Acc@1 70.724
 *   Acc@1 71.226
 *   Acc@1 71.355
 *   Acc@1 71.873
 *   Acc@1 70.197
 *   Acc@1 70.284
 *   Acc@1 69.947
 *   Acc@1 70.012
 *   Acc@1 69.579
 *   Acc@1 69.991
 *   Acc@1 65.868
 *   Acc@1 65.278
 *   Acc@1 65.513
 *   Acc@1 65.179
 *   Acc@1 65.632
 *   Acc@1 65.149
 *   Acc@1 71.553
 *   Acc@1 71.614
 *   Acc@1 54.355
 *   Acc@1 53.869
 *   Acc@1 52.776
 *   Acc@1 52.198
Training for 300 epoch: 69.44078947368422
Training for 600 epoch: 65.13486842105263
Training for 1000 epoch: 64.83552631578948
Training for 300 epoch: 69.39104166666667
Training for 600 epoch: 65.07145833333334
Training for 1000 epoch: 64.80291666666668
[[69.44078947368422, 65.13486842105263, 64.83552631578948], [69.39104166666667, 65.07145833333334, 64.80291666666668]]
train loss 0.9447478994369507, epoch 244, best loss 0.2624552794933319, best_epoch 214
GPU_0_using curriculum 40 with window 40
Epoch: [245][20/30]	Time  1.495 ( 1.520)	Data  0.038 ( 0.055)	InnerLoop  0.631 ( 0.643)	Loss 4.6390e-01 (5.2982e-01)	Acc@1  83.96 ( 81.38)
The current update step is 7380
GPU_0_using curriculum 40 with window 40
Epoch: [246][20/30]	Time  1.625 ( 1.523)	Data  0.153 ( 0.060)	InnerLoop  0.633 ( 0.641)	Loss 4.2472e-01 (5.2062e-01)	Acc@1  85.77 ( 81.59)
The current update step is 7410
GPU_0_using curriculum 40 with window 40
Epoch: [247][20/30]	Time  1.493 ( 1.523)	Data  0.038 ( 0.037)	InnerLoop  0.633 ( 0.663)	Loss 4.6542e-01 (4.9683e-01)	Acc@1  83.67 ( 82.51)
The current update step is 7440
GPU_0_using curriculum 40 with window 40
Epoch: [248][20/30]	Time  1.495 ( 1.521)	Data  0.036 ( 0.049)	InnerLoop  0.633 ( 0.649)	Loss 5.5940e-01 (4.8068e-01)	Acc@1  80.81 ( 83.16)
The current update step is 7470
GPU_0_using curriculum 40 with window 40
Epoch: [249][20/30]	Time  1.498 ( 1.515)	Data  0.039 ( 0.060)	InnerLoop  0.637 ( 0.635)	Loss 6.3490e-01 (4.9464e-01)	Acc@1  79.17 ( 82.38)
The current update step is 7500
The current seed is 15697963398539314352
The current lr is: 0.0015
Testing Results:
 *   Acc@1 56.684
 *   Acc@1 56.389
 *   Acc@1 56.987
 *   Acc@1 56.763
 *   Acc@1 57.526
 *   Acc@1 57.222
 *   Acc@1 68.908
 *   Acc@1 68.810
 *   Acc@1 59.868
 *   Acc@1 59.852
 *   Acc@1 59.842
 *   Acc@1 60.403
 *   Acc@1 60.421
 *   Acc@1 60.917
 *   Acc@1 59.447
 *   Acc@1 59.907
 *   Acc@1 58.434
 *   Acc@1 58.799
 *   Acc@1 61.645
 *   Acc@1 62.403
 *   Acc@1 63.303
 *   Acc@1 63.606
 *   Acc@1 64.447
 *   Acc@1 64.377
Training for 300 epoch: 61.91447368421052
Training for 600 epoch: 59.901315789473685
Training for 1000 epoch: 60.0625
Training for 300 epoch: 62.12979166666667
Training for 600 epoch: 60.031875
Training for 1000 epoch: 60.20041666666667
[[61.91447368421052, 59.901315789473685, 60.0625], [62.12979166666667, 60.031875, 60.20041666666667]]
train loss 0.5202867684046427, epoch 249, best loss 0.2624552794933319, best_epoch 214
GPU_0_using curriculum 40 with window 40
Epoch: [250][20/30]	Time  1.486 ( 1.517)	Data  0.036 ( 0.049)	InnerLoop  0.629 ( 0.647)	Loss 4.7194e-01 (4.9183e-01)	Acc@1  83.01 ( 82.51)
The current update step is 7530
GPU_0_using curriculum 40 with window 40
Epoch: [251][20/30]	Time  1.488 ( 1.517)	Data  0.034 ( 0.060)	InnerLoop  0.629 ( 0.634)	Loss 4.8392e-01 (4.8592e-01)	Acc@1  83.06 ( 82.84)
The current update step is 7560
GPU_0_using curriculum 40 with window 40
Epoch: [252][20/30]	Time  1.497 ( 1.518)	Data  0.038 ( 0.049)	InnerLoop  0.632 ( 0.648)	Loss 4.8135e-01 (5.0417e-01)	Acc@1  83.25 ( 82.09)
The current update step is 7590
GPU_0_using curriculum 40 with window 40
Epoch: [253][20/30]	Time  1.495 ( 1.517)	Data  0.037 ( 0.066)	InnerLoop  0.633 ( 0.629)	Loss 5.2801e-01 (5.2553e-01)	Acc@1  80.64 ( 81.67)
The current update step is 7620
GPU_0_using curriculum 40 with window 40
Epoch: [254][20/30]	Time  1.498 ( 1.522)	Data  0.039 ( 0.067)	InnerLoop  0.629 ( 0.633)	Loss 4.4909e-01 (5.1509e-01)	Acc@1  84.47 ( 81.50)
The current update step is 7650
The current seed is 11487495956922470404
The current lr is: 0.0015
Testing Results:
 *   Acc@1 48.408
 *   Acc@1 48.897
 *   Acc@1 48.579
 *   Acc@1 48.813
 *   Acc@1 48.184
 *   Acc@1 48.599
 *   Acc@1 63.118
 *   Acc@1 63.484
 *   Acc@1 63.908
 *   Acc@1 64.061
 *   Acc@1 64.789
 *   Acc@1 64.725
 *   Acc@1 47.263
 *   Acc@1 47.444
 *   Acc@1 48.382
 *   Acc@1 48.688
 *   Acc@1 49.158
 *   Acc@1 49.458
 *   Acc@1 69.671
 *   Acc@1 70.442
 *   Acc@1 54.658
 *   Acc@1 54.993
 *   Acc@1 57.013
 *   Acc@1 56.985
Training for 300 epoch: 57.11513157894737
Training for 600 epoch: 53.88157894736842
Training for 1000 epoch: 54.786184210526315
Training for 300 epoch: 57.566874999999996
Training for 600 epoch: 54.13875
Training for 1000 epoch: 54.941874999999996
[[57.11513157894737, 53.88157894736842, 54.786184210526315], [57.566874999999996, 54.13875, 54.941874999999996]]
train loss 0.9351163798650106, epoch 254, best loss 0.2624552794933319, best_epoch 214
GPU_0_using curriculum 40 with window 40
Epoch: [255][20/30]	Time  1.507 ( 1.525)	Data  0.036 ( 0.061)	InnerLoop  0.636 ( 0.641)	Loss 6.0601e-01 (5.1399e-01)	Acc@1  79.57 ( 81.77)
The current update step is 7680
GPU_0_using curriculum 40 with window 40
Epoch: [256][20/30]	Time  1.487 ( 1.516)	Data  0.036 ( 0.067)	InnerLoop  0.626 ( 0.627)	Loss 5.9402e-01 (5.1373e-01)	Acc@1  79.66 ( 81.62)
The current update step is 7710
GPU_0_using curriculum 40 with window 40
Epoch: [257][20/30]	Time  1.496 ( 1.517)	Data  0.039 ( 0.061)	InnerLoop  0.630 ( 0.635)	Loss 4.8358e-01 (4.9831e-01)	Acc@1  83.18 ( 82.24)
The current update step is 7740
GPU_0_using curriculum 40 with window 40
Epoch: [258][20/30]	Time  1.490 ( 1.517)	Data  0.036 ( 0.061)	InnerLoop  0.625 ( 0.634)	Loss 4.5633e-01 (5.0094e-01)	Acc@1  83.89 ( 82.08)
The current update step is 7770
GPU_0_using curriculum 40 with window 40
Epoch: [259][20/30]	Time  1.490 ( 1.518)	Data  0.038 ( 0.055)	InnerLoop  0.631 ( 0.642)	Loss 4.9412e-01 (4.7982e-01)	Acc@1  82.23 ( 83.19)
The current update step is 7800
The current seed is 2483241636892197435
The current lr is: 0.0015
Testing Results:
 *   Acc@1 64.382
 *   Acc@1 64.697
 *   Acc@1 63.947
 *   Acc@1 64.531
 *   Acc@1 64.671
 *   Acc@1 64.648
 *   Acc@1 46.855
 *   Acc@1 46.548
 *   Acc@1 47.921
 *   Acc@1 47.685
 *   Acc@1 48.789
 *   Acc@1 48.124
 *   Acc@1 65.539
 *   Acc@1 64.620
 *   Acc@1 63.921
 *   Acc@1 62.868
 *   Acc@1 64.355
 *   Acc@1 62.841
 *   Acc@1 66.579
 *   Acc@1 66.498
 *   Acc@1 68.250
 *   Acc@1 67.674
 *   Acc@1 68.250
 *   Acc@1 67.791
Training for 300 epoch: 60.838815789473685
Training for 600 epoch: 61.00986842105263
Training for 1000 epoch: 61.516447368421055
Training for 300 epoch: 60.590625
Training for 600 epoch: 60.68958333333333
Training for 1000 epoch: 60.851041666666674
[[60.838815789473685, 61.00986842105263, 61.516447368421055], [60.590625, 60.68958333333333, 60.851041666666674]]
train loss 0.5415185623168945, epoch 259, best loss 0.2624552794933319, best_epoch 214
GPU_0_using curriculum 40 with window 40
Epoch: [260][20/30]	Time  1.611 ( 1.537)	Data  0.156 ( 0.068)	InnerLoop  0.626 ( 0.640)	Loss 4.8003e-01 (4.7925e-01)	Acc@1  83.72 ( 83.07)
The current update step is 7830
GPU_0_using curriculum 40 with window 40
Epoch: [261][20/30]	Time  1.614 ( 1.525)	Data  0.035 ( 0.056)	InnerLoop  0.754 ( 0.647)	Loss 4.7945e-01 (4.7116e-01)	Acc@1  83.33 ( 83.50)
The current update step is 7860
GPU_0_using curriculum 40 with window 40
Epoch: [262][20/30]	Time  1.494 ( 1.530)	Data  0.037 ( 0.051)	InnerLoop  0.633 ( 0.652)	Loss 5.0143e-01 (4.8828e-01)	Acc@1  81.69 ( 82.61)
The current update step is 7890
GPU_0_using curriculum 40 with window 40
Epoch: [263][20/30]	Time  1.489 ( 1.521)	Data  0.038 ( 0.055)	InnerLoop  0.628 ( 0.644)	Loss 4.8221e-01 (4.6514e-01)	Acc@1  82.37 ( 83.71)
The current update step is 7920
GPU_0_using curriculum 40 with window 40
Epoch: [264][20/30]	Time  1.495 ( 1.523)	Data  0.041 ( 0.044)	InnerLoop  0.635 ( 0.654)	Loss 4.5780e-01 (4.6558e-01)	Acc@1  84.08 ( 84.06)
The current update step is 7950
The current seed is 660502028452635215
The current lr is: 0.0015
Testing Results:
 *   Acc@1 72.618
 *   Acc@1 72.257
 *   Acc@1 72.526
 *   Acc@1 72.421
 *   Acc@1 72.645
 *   Acc@1 72.297
 *   Acc@1 74.197
 *   Acc@1 73.707
 *   Acc@1 75.105
 *   Acc@1 74.538
 *   Acc@1 75.079
 *   Acc@1 74.688
 *   Acc@1 54.224
 *   Acc@1 54.513
 *   Acc@1 54.724
 *   Acc@1 54.760
 *   Acc@1 54.526
 *   Acc@1 54.958
 *   Acc@1 61.316
 *   Acc@1 61.218
 *   Acc@1 58.974
 *   Acc@1 58.725
 *   Acc@1 58.158
 *   Acc@1 58.132
Training for 300 epoch: 65.58881578947368
Training for 600 epoch: 65.33223684210526
Training for 1000 epoch: 65.10197368421052
Training for 300 epoch: 65.42333333333332
Training for 600 epoch: 65.11104166666667
Training for 1000 epoch: 65.01895833333334
[[65.58881578947368, 65.33223684210526, 65.10197368421052], [65.42333333333332, 65.11104166666667, 65.01895833333334]]
train loss 0.6535636360486349, epoch 264, best loss 0.2624552794933319, best_epoch 214
GPU_0_using curriculum 40 with window 40
Epoch: [265][20/30]	Time  1.509 ( 1.526)	Data  0.041 ( 0.056)	InnerLoop  0.636 ( 0.644)	Loss 4.6610e-01 (4.8338e-01)	Acc@1  83.69 ( 82.87)
The current update step is 7980
GPU_0_using curriculum 40 with window 40
Epoch: [266][20/30]	Time  1.615 ( 1.528)	Data  0.155 ( 0.062)	InnerLoop  0.634 ( 0.642)	Loss 5.2106e-01 (5.0175e-01)	Acc@1  81.88 ( 82.52)
The current update step is 8010
GPU_0_using curriculum 40 with window 40
Epoch: [267][20/30]	Time  1.503 ( 1.519)	Data  0.040 ( 0.039)	InnerLoop  0.632 ( 0.659)	Loss 4.3977e-01 (4.8037e-01)	Acc@1  85.16 ( 83.09)
The current update step is 8040
GPU_0_using curriculum 40 with window 40
Epoch: [268][20/30]	Time  1.542 ( 1.524)	Data  0.043 ( 0.050)	InnerLoop  0.659 ( 0.649)	Loss 4.5591e-01 (4.6397e-01)	Acc@1  84.62 ( 83.84)
The current update step is 8070
GPU_0_using curriculum 40 with window 40
Epoch: [269][20/30]	Time  1.490 ( 1.520)	Data  0.038 ( 0.062)	InnerLoop  0.629 ( 0.636)	Loss 4.7079e-01 (5.1529e-01)	Acc@1  83.06 ( 81.52)
The current update step is 8100
The current seed is 4951146449814432258
The current lr is: 0.0015
Testing Results:
 *   Acc@1 56.566
 *   Acc@1 56.658
 *   Acc@1 56.868
 *   Acc@1 56.867
 *   Acc@1 57.500
 *   Acc@1 57.502
 *   Acc@1 65.618
 *   Acc@1 66.193
 *   Acc@1 66.171
 *   Acc@1 66.840
 *   Acc@1 66.237
 *   Acc@1 66.875
 *   Acc@1 40.895
 *   Acc@1 41.036
 *   Acc@1 42.263
 *   Acc@1 41.432
 *   Acc@1 41.803
 *   Acc@1 41.849
 *   Acc@1 58.697
 *   Acc@1 58.943
 *   Acc@1 64.803
 *   Acc@1 64.764
 *   Acc@1 70.000
 *   Acc@1 69.738
Training for 300 epoch: 55.44407894736842
Training for 600 epoch: 57.526315789473685
Training for 1000 epoch: 58.88486842105263
Training for 300 epoch: 55.70770833333333
Training for 600 epoch: 57.476041666666674
Training for 1000 epoch: 58.99104166666666
[[55.44407894736842, 57.526315789473685, 58.88486842105263], [55.70770833333333, 57.476041666666674, 58.99104166666666]]
train loss 0.4951187760194143, epoch 269, best loss 0.2624552794933319, best_epoch 214
GPU_0_using curriculum 40 with window 40
Epoch: [270][20/30]	Time  1.522 ( 1.520)	Data  0.040 ( 0.051)	InnerLoop  0.629 ( 0.646)	Loss 5.1730e-01 (4.8061e-01)	Acc@1  82.47 ( 83.14)
The current update step is 8130
GPU_0_using curriculum 40 with window 40
Epoch: [271][20/30]	Time  1.482 ( 1.518)	Data  0.034 ( 0.062)	InnerLoop  0.628 ( 0.634)	Loss 4.8699e-01 (5.1122e-01)	Acc@1  82.64 ( 82.21)
The current update step is 8160
GPU_0_using curriculum 40 with window 40
Epoch: [272][20/30]	Time  1.531 ( 1.538)	Data  0.042 ( 0.052)	InnerLoop  0.645 ( 0.656)	Loss 4.5451e-01 (5.0391e-01)	Acc@1  83.89 ( 82.05)
The current update step is 8190
GPU_0_using curriculum 40 with window 40
Epoch: [273][20/30]	Time  1.495 ( 1.538)	Data  0.041 ( 0.071)	InnerLoop  0.630 ( 0.637)	Loss 4.5717e-01 (5.0137e-01)	Acc@1  84.11 ( 82.69)
The current update step is 8220
GPU_0_using curriculum 40 with window 40
Epoch: [274][20/30]	Time  1.557 ( 1.558)	Data  0.043 ( 0.071)	InnerLoop  0.666 ( 0.648)	Loss 4.6842e-01 (5.1185e-01)	Acc@1  82.81 ( 82.42)
The current update step is 8250
The current seed is 10216963787334034855
The current lr is: 0.0015
Testing Results:
 *   Acc@1 62.711
 *   Acc@1 62.023
 *   Acc@1 71.539
 *   Acc@1 72.018
 *   Acc@1 71.421
 *   Acc@1 72.138
 *   Acc@1 65.368
 *   Acc@1 65.437
 *   Acc@1 62.539
 *   Acc@1 62.855
 *   Acc@1 61.934
 *   Acc@1 61.733
 *   Acc@1 64.618
 *   Acc@1 63.812
 *   Acc@1 72.342
 *   Acc@1 72.767
 *   Acc@1 72.658
 *   Acc@1 73.080
 *   Acc@1 49.526
 *   Acc@1 49.237
 *   Acc@1 70.066
 *   Acc@1 69.752
 *   Acc@1 70.605
 *   Acc@1 70.320
Training for 300 epoch: 60.555921052631575
Training for 600 epoch: 69.12171052631578
Training for 1000 epoch: 69.15460526315789
Training for 300 epoch: 60.127291666666665
Training for 600 epoch: 69.348125
Training for 1000 epoch: 69.31791666666666
[[60.555921052631575, 69.12171052631578, 69.15460526315789], [60.127291666666665, 69.348125, 69.31791666666666]]
train loss 0.6127742917378743, epoch 274, best loss 0.2624552794933319, best_epoch 274
GPU_0_using curriculum 40 with window 40
Epoch: [275][20/30]	Time  1.483 ( 1.522)	Data  0.037 ( 0.060)	InnerLoop  0.626 ( 0.639)	Loss 4.4084e-01 (5.0269e-01)	Acc@1  84.18 ( 82.32)
The current update step is 8280
GPU_0_using curriculum 40 with window 40
Epoch: [276][20/30]	Time  1.496 ( 1.517)	Data  0.038 ( 0.066)	InnerLoop  0.633 ( 0.629)	Loss 4.2972e-01 (5.0452e-01)	Acc@1  85.13 ( 82.37)
The current update step is 8310
GPU_0_using curriculum 40 with window 40
Epoch: [277][20/30]	Time  1.558 ( 1.568)	Data  0.041 ( 0.066)	InnerLoop  0.665 ( 0.658)	Loss 5.7610e-01 (4.7538e-01)	Acc@1  78.15 ( 83.06)
The current update step is 8340
GPU_0_using curriculum 40 with window 40
Epoch: [278][20/30]	Time  1.554 ( 1.581)	Data  0.047 ( 0.068)	InnerLoop  0.669 ( 0.666)	Loss 5.8344e-01 (5.0527e-01)	Acc@1  81.30 ( 82.26)
The current update step is 8370
GPU_0_using curriculum 40 with window 40
Epoch: [279][20/30]	Time  1.536 ( 1.566)	Data  0.042 ( 0.060)	InnerLoop  0.652 ( 0.661)	Loss 4.9408e-01 (4.9078e-01)	Acc@1  82.98 ( 82.45)
The current update step is 8400
The current seed is 124033362107520092
The current lr is: 0.0015
Testing Results:
 *   Acc@1 62.711
 *   Acc@1 62.472
 *   Acc@1 65.895
 *   Acc@1 65.379
 *   Acc@1 66.329
 *   Acc@1 66.250
 *   Acc@1 52.342
 *   Acc@1 52.693
 *   Acc@1 53.342
 *   Acc@1 53.616
 *   Acc@1 55.092
 *   Acc@1 54.754
 *   Acc@1 67.289
 *   Acc@1 68.144
 *   Acc@1 70.816
 *   Acc@1 70.422
 *   Acc@1 69.934
 *   Acc@1 70.190
 *   Acc@1 52.118
 *   Acc@1 52.062
 *   Acc@1 55.513
 *   Acc@1 55.142
 *   Acc@1 56.474
 *   Acc@1 56.814
Training for 300 epoch: 58.61513157894737
Training for 600 epoch: 61.39144736842105
Training for 1000 epoch: 61.95723684210526
Training for 300 epoch: 58.84291666666667
Training for 600 epoch: 61.139583333333334
Training for 1000 epoch: 62.00208333333333
[[58.61513157894737, 61.39144736842105, 61.95723684210526], [58.84291666666667, 61.139583333333334, 62.00208333333333]]
train loss 0.632107595984141, epoch 279, best loss 0.2624552794933319, best_epoch 274
GPU_0_using curriculum 40 with window 40
Epoch: [280][20/30]	Time  1.691 ( 1.569)	Data  0.167 ( 0.072)	InnerLoop  0.661 ( 0.655)	Loss 4.5573e-01 (4.9668e-01)	Acc@1  84.52 ( 82.57)
The current update step is 8430
GPU_0_using curriculum 40 with window 40
Epoch: [281][20/30]	Time  1.656 ( 1.577)	Data  0.041 ( 0.061)	InnerLoop  0.777 ( 0.675)	Loss 4.2320e-01 (4.8175e-01)	Acc@1  85.03 ( 82.84)
The current update step is 8460
GPU_0_using curriculum 40 with window 40
Epoch: [282][20/30]	Time  1.537 ( 1.566)	Data  0.041 ( 0.053)	InnerLoop  0.658 ( 0.672)	Loss 4.8313e-01 (4.7341e-01)	Acc@1  83.37 ( 83.71)
The current update step is 8490
GPU_0_using curriculum 40 with window 40
Epoch: [283][20/30]	Time  1.495 ( 1.532)	Data  0.037 ( 0.057)	InnerLoop  0.631 ( 0.650)	Loss 5.1267e-01 (4.8968e-01)	Acc@1  83.54 ( 82.72)
The current update step is 8520
GPU_0_using curriculum 40 with window 40
Epoch: [284][20/30]	Time  1.490 ( 1.520)	Data  0.038 ( 0.043)	InnerLoop  0.637 ( 0.656)	Loss 4.5404e-01 (4.8707e-01)	Acc@1  83.76 ( 83.06)
The current update step is 8550
The current seed is 5500246881864410702
The current lr is: 0.0015
Testing Results:
 *   Acc@1 74.921
 *   Acc@1 74.786
 *   Acc@1 74.763
 *   Acc@1 74.452
 *   Acc@1 74.382
 *   Acc@1 74.239
 *   Acc@1 56.658
 *   Acc@1 57.165
 *   Acc@1 57.197
 *   Acc@1 57.941
 *   Acc@1 57.395
 *   Acc@1 58.119
 *   Acc@1 75.553
 *   Acc@1 75.248
 *   Acc@1 76.342
 *   Acc@1 76.391
 *   Acc@1 76.579
 *   Acc@1 76.600
 *   Acc@1 52.684
 *   Acc@1 53.148
 *   Acc@1 53.303
 *   Acc@1 53.255
 *   Acc@1 52.934
 *   Acc@1 52.630
Training for 300 epoch: 64.95394736842105
Training for 600 epoch: 65.40131578947368
Training for 1000 epoch: 65.32236842105263
Training for 300 epoch: 65.08666666666666
Training for 600 epoch: 65.50958333333332
Training for 1000 epoch: 65.39708333333333
[[64.95394736842105, 65.40131578947368, 65.32236842105263], [65.08666666666666, 65.50958333333332, 65.39708333333333]]
train loss 0.7438150210380554, epoch 284, best loss 0.2624552794933319, best_epoch 274
GPU_0_using curriculum 40 with window 40
Epoch: [285][20/30]	Time  1.497 ( 1.520)	Data  0.038 ( 0.055)	InnerLoop  0.631 ( 0.644)	Loss 4.5068e-01 (4.8127e-01)	Acc@1  84.45 ( 83.30)
The current update step is 8580
GPU_0_using curriculum 40 with window 40
Epoch: [286][20/30]	Time  1.602 ( 1.524)	Data  0.157 ( 0.060)	InnerLoop  0.627 ( 0.643)	Loss 5.4170e-01 (4.8909e-01)	Acc@1  80.30 ( 82.89)
The current update step is 8610
GPU_0_using curriculum 40 with window 40
Epoch: [287][20/30]	Time  1.494 ( 1.516)	Data  0.036 ( 0.036)	InnerLoop  0.633 ( 0.659)	Loss 5.0050e-01 (4.8099e-01)	Acc@1  81.64 ( 83.06)
The current update step is 8640
GPU_0_using curriculum 40 with window 40
Epoch: [288][20/30]	Time  1.489 ( 1.519)	Data  0.036 ( 0.047)	InnerLoop  0.631 ( 0.650)	Loss 5.5626e-01 (5.0434e-01)	Acc@1  80.00 ( 82.05)
The current update step is 8670
GPU_0_using curriculum 40 with window 40
Epoch: [289][20/30]	Time  1.490 ( 1.519)	Data  0.037 ( 0.061)	InnerLoop  0.631 ( 0.636)	Loss 6.2646e-01 (4.9858e-01)	Acc@1  79.32 ( 82.79)
The current update step is 8700
The current seed is 12255894248134986015
The current lr is: 0.0015
Testing Results:
 *   Acc@1 68.421
 *   Acc@1 68.448
 *   Acc@1 69.092
 *   Acc@1 69.036
 *   Acc@1 69.553
 *   Acc@1 69.562
 *   Acc@1 77.776
 *   Acc@1 77.688
 *   Acc@1 69.289
 *   Acc@1 68.958
 *   Acc@1 68.842
 *   Acc@1 68.426
 *   Acc@1 65.289
 *   Acc@1 65.463
 *   Acc@1 57.737
 *   Acc@1 58.477
 *   Acc@1 58.882
 *   Acc@1 59.475
 *   Acc@1 54.171
 *   Acc@1 55.125
 *   Acc@1 60.053
 *   Acc@1 60.426
 *   Acc@1 60.250
 *   Acc@1 60.932
Training for 300 epoch: 66.41447368421052
Training for 600 epoch: 64.04276315789474
Training for 1000 epoch: 64.38157894736841
Training for 300 epoch: 66.68104166666666
Training for 600 epoch: 64.22416666666666
Training for 1000 epoch: 64.59875
[[66.41447368421052, 64.04276315789474, 64.38157894736841], [66.68104166666666, 64.22416666666666, 64.59875]]
train loss 0.5568063961982727, epoch 289, best loss 0.2624552794933319, best_epoch 274
GPU_0_using curriculum 40 with window 40
Epoch: [290][20/30]	Time  1.500 ( 1.525)	Data  0.039 ( 0.050)	InnerLoop  0.637 ( 0.652)	Loss 4.4917e-01 (4.8490e-01)	Acc@1  83.42 ( 82.85)
The current update step is 8730
GPU_0_using curriculum 40 with window 40
Epoch: [291][20/30]	Time  1.499 ( 1.517)	Data  0.036 ( 0.060)	InnerLoop  0.634 ( 0.635)	Loss 5.0977e-01 (4.8587e-01)	Acc@1  81.01 ( 83.13)
The current update step is 8760
GPU_0_using curriculum 40 with window 40
Epoch: [292][20/30]	Time  1.495 ( 1.519)	Data  0.037 ( 0.048)	InnerLoop  0.633 ( 0.651)	Loss 4.5569e-01 (4.8813e-01)	Acc@1  83.45 ( 82.96)
The current update step is 8790
GPU_0_using curriculum 40 with window 40
Epoch: [293][20/30]	Time  1.495 ( 1.520)	Data  0.038 ( 0.066)	InnerLoop  0.633 ( 0.632)	Loss 4.6657e-01 (4.7984e-01)	Acc@1  84.01 ( 83.18)
The current update step is 8820
GPU_0_using curriculum 40 with window 40
Epoch: [294][20/30]	Time  1.492 ( 1.527)	Data  0.037 ( 0.067)	InnerLoop  0.629 ( 0.637)	Loss 4.3780e-01 (4.8270e-01)	Acc@1  84.47 ( 82.63)
The current update step is 8850
The current seed is 13636917730958961742
The current lr is: 0.0015
Testing Results:
 *   Acc@1 82.684
 *   Acc@1 82.399
 *   Acc@1 82.474
 *   Acc@1 82.551
 *   Acc@1 82.395
 *   Acc@1 82.612
 *   Acc@1 69.447
 *   Acc@1 69.413
 *   Acc@1 71.605
 *   Acc@1 70.830
 *   Acc@1 71.697
 *   Acc@1 71.558
 *   Acc@1 42.224
 *   Acc@1 42.584
 *   Acc@1 42.158
 *   Acc@1 41.946
 *   Acc@1 42.039
 *   Acc@1 42.680
 *   Acc@1 35.250
 *   Acc@1 35.401
 *   Acc@1 37.987
 *   Acc@1 37.735
 *   Acc@1 35.237
 *   Acc@1 34.831
Training for 300 epoch: 57.401315789473685
Training for 600 epoch: 58.555921052631575
Training for 1000 epoch: 57.84210526315789
Training for 300 epoch: 57.449375
Training for 600 epoch: 58.26541666666667
Training for 1000 epoch: 57.92041666666667
[[57.401315789473685, 58.555921052631575, 57.84210526315789], [57.449375, 58.26541666666667, 57.92041666666667]]
train loss 1.1990366134643555, epoch 294, best loss 0.2624552794933319, best_epoch 274
GPU_0_using curriculum 40 with window 40
Epoch: [295][20/30]	Time  1.495 ( 1.527)	Data  0.037 ( 0.060)	InnerLoop  0.638 ( 0.645)	Loss 5.2161e-01 (4.9571e-01)	Acc@1  82.45 ( 82.70)
The current update step is 8880
GPU_0_using curriculum 40 with window 40
Epoch: [296][20/30]	Time  1.502 ( 1.522)	Data  0.036 ( 0.067)	InnerLoop  0.641 ( 0.634)	Loss 5.5304e-01 (4.9487e-01)	Acc@1  80.18 ( 82.69)
The current update step is 8910
GPU_0_using curriculum 40 with window 40
Epoch: [297][20/30]	Time  1.482 ( 1.515)	Data  0.034 ( 0.061)	InnerLoop  0.623 ( 0.633)	Loss 4.3310e-01 (4.8679e-01)	Acc@1  85.21 ( 82.45)
The current update step is 8940
GPU_0_using curriculum 40 with window 40
Epoch: [298][20/30]	Time  1.492 ( 1.520)	Data  0.038 ( 0.061)	InnerLoop  0.629 ( 0.636)	Loss 5.6189e-01 (4.8672e-01)	Acc@1  80.64 ( 82.96)
The current update step is 8970
GPU_0_using curriculum 40 with window 40
Epoch: [299][20/30]	Time  1.500 ( 1.515)	Data  0.036 ( 0.054)	InnerLoop  0.640 ( 0.641)	Loss 4.7027e-01 (4.7639e-01)	Acc@1  83.62 ( 83.35)
The current update step is 9000
The current seed is 3139230321540632217
The current lr is: 0.0015
Testing Results:
 *   Acc@1 71.053
 *   Acc@1 70.707
 *   Acc@1 71.618
 *   Acc@1 71.251
 *   Acc@1 71.855
 *   Acc@1 71.630
 *   Acc@1 67.697
 *   Acc@1 68.488
 *   Acc@1 67.868
 *   Acc@1 68.527
 *   Acc@1 67.855
 *   Acc@1 68.653
 *   Acc@1 60.408
 *   Acc@1 60.364
 *   Acc@1 60.553
 *   Acc@1 60.637
 *   Acc@1 60.645
 *   Acc@1 60.847
 *   Acc@1 71.461
 *   Acc@1 71.463
 *   Acc@1 72.434
 *   Acc@1 72.874
 *   Acc@1 72.684
 *   Acc@1 72.978
Training for 300 epoch: 67.65460526315789
Training for 600 epoch: 68.11842105263158
Training for 1000 epoch: 68.25986842105263
Training for 300 epoch: 67.75583333333333
Training for 600 epoch: 68.32208333333332
Training for 1000 epoch: 68.526875
[[67.65460526315789, 68.11842105263158, 68.25986842105263], [67.75583333333333, 68.32208333333332, 68.526875]]
train loss 0.393567244720459, epoch 299, best loss 0.2624552794933319, best_epoch 274
GPU_0_using curriculum 40 with window 40
Epoch: [300][20/30]	Time  1.605 ( 1.525)	Data  0.152 ( 0.067)	InnerLoop  0.628 ( 0.636)	Loss 4.5887e-01 (4.9189e-01)	Acc@1  84.47 ( 83.03)
The current update step is 9030
GPU_0_using curriculum 40 with window 40
Epoch: [301][20/30]	Time  1.605 ( 1.525)	Data  0.037 ( 0.055)	InnerLoop  0.748 ( 0.646)	Loss 5.8003e-01 (5.1713e-01)	Acc@1  76.73 ( 81.56)
The current update step is 9060
GPU_0_using curriculum 40 with window 40
Epoch: [302][20/30]	Time  1.481 ( 1.516)	Data  0.037 ( 0.049)	InnerLoop  0.625 ( 0.647)	Loss 4.4281e-01 (4.9517e-01)	Acc@1  84.52 ( 82.69)
The current update step is 9090
GPU_0_using curriculum 40 with window 40
Epoch: [303][20/30]	Time  1.492 ( 1.514)	Data  0.040 ( 0.055)	InnerLoop  0.627 ( 0.638)	Loss 4.4748e-01 (5.1177e-01)	Acc@1  84.33 ( 81.74)
The current update step is 9120
GPU_0_using curriculum 40 with window 40
Epoch: [304][20/30]	Time  1.491 ( 1.517)	Data  0.038 ( 0.043)	InnerLoop  0.629 ( 0.653)	Loss 5.0248e-01 (4.7678e-01)	Acc@1  81.62 ( 83.43)
The current update step is 9150
The current seed is 14995984689435769008
The current lr is: 0.0015
Testing Results:
 *   Acc@1 34.447
 *   Acc@1 34.877
 *   Acc@1 41.395
 *   Acc@1 42.042
 *   Acc@1 41.974
 *   Acc@1 42.305
 *   Acc@1 66.276
 *   Acc@1 66.042
 *   Acc@1 65.566
 *   Acc@1 65.349
 *   Acc@1 64.855
 *   Acc@1 64.920
 *   Acc@1 68.105
 *   Acc@1 67.963
 *   Acc@1 67.829
 *   Acc@1 67.894
 *   Acc@1 67.737
 *   Acc@1 67.799
 *   Acc@1 66.395
 *   Acc@1 66.463
 *   Acc@1 66.263
 *   Acc@1 66.425
 *   Acc@1 66.829
 *   Acc@1 66.634
Training for 300 epoch: 58.805921052631575
Training for 600 epoch: 60.263157894736835
Training for 1000 epoch: 60.348684210526315
Training for 300 epoch: 58.83583333333333
Training for 600 epoch: 60.42770833333333
Training for 1000 epoch: 60.414583333333326
[[58.805921052631575, 60.263157894736835, 60.348684210526315], [58.83583333333333, 60.42770833333333, 60.414583333333326]]
train loss 0.44313002529144285, epoch 304, best loss 0.2624552794933319, best_epoch 274
GPU_0_using curriculum 40 with window 40
Epoch: [305][20/30]	Time  1.493 ( 1.514)	Data  0.037 ( 0.054)	InnerLoop  0.632 ( 0.640)	Loss 5.0091e-01 (4.9268e-01)	Acc@1  82.08 ( 82.69)
The current update step is 9180
GPU_0_using curriculum 40 with window 40
Epoch: [306][20/30]	Time  1.607 ( 1.524)	Data  0.159 ( 0.060)	InnerLoop  0.626 ( 0.641)	Loss 5.4533e-01 (4.9073e-01)	Acc@1  80.86 ( 82.97)
The current update step is 9210
GPU_0_using curriculum 40 with window 40
Epoch: [307][20/30]	Time  1.493 ( 1.515)	Data  0.039 ( 0.037)	InnerLoop  0.631 ( 0.658)	Loss 4.9663e-01 (4.9386e-01)	Acc@1  82.47 ( 82.49)
The current update step is 9240
GPU_0_using curriculum 40 with window 40
Epoch: [308][20/30]	Time  1.494 ( 1.516)	Data  0.036 ( 0.048)	InnerLoop  0.635 ( 0.647)	Loss 4.5497e-01 (4.9883e-01)	Acc@1  83.76 ( 82.88)
The current update step is 9270
GPU_0_using curriculum 40 with window 40
Epoch: [309][20/30]	Time  1.495 ( 1.516)	Data  0.040 ( 0.060)	InnerLoop  0.630 ( 0.634)	Loss 4.9161e-01 (5.0184e-01)	Acc@1  82.59 ( 82.55)
The current update step is 9300
The current seed is 4898879098305625451
The current lr is: 0.0015
Testing Results:
 *   Acc@1 62.539
 *   Acc@1 61.841
 *   Acc@1 62.039
 *   Acc@1 61.587
 *   Acc@1 61.855
 *   Acc@1 61.726
 *   Acc@1 67.553
 *   Acc@1 67.647
 *   Acc@1 66.316
 *   Acc@1 66.613
 *   Acc@1 65.750
 *   Acc@1 66.145
 *   Acc@1 47.421
 *   Acc@1 48.257
 *   Acc@1 58.000
 *   Acc@1 57.509
 *   Acc@1 57.013
 *   Acc@1 57.248
 *   Acc@1 63.645
 *   Acc@1 62.661
 *   Acc@1 63.382
 *   Acc@1 62.668
 *   Acc@1 63.382
 *   Acc@1 62.782
Training for 300 epoch: 60.28947368421052
Training for 600 epoch: 62.43421052631579
Training for 1000 epoch: 62.0
Training for 300 epoch: 60.10145833333333
Training for 600 epoch: 62.094375
Training for 1000 epoch: 61.975208333333335
[[60.28947368421052, 62.43421052631579, 62.0], [60.10145833333333, 62.094375, 61.975208333333335]]
train loss 0.5153633126417796, epoch 309, best loss 0.2624552794933319, best_epoch 274
GPU_0_using curriculum 40 with window 40
Epoch: [310][20/30]	Time  1.491 ( 1.516)	Data  0.038 ( 0.049)	InnerLoop  0.630 ( 0.645)	Loss 4.8088e-01 (4.9234e-01)	Acc@1  82.93 ( 82.68)
The current update step is 9330
GPU_0_using curriculum 40 with window 40
Epoch: [311][20/30]	Time  1.485 ( 1.515)	Data  0.035 ( 0.060)	InnerLoop  0.627 ( 0.633)	Loss 4.9307e-01 (5.0011e-01)	Acc@1  82.89 ( 82.73)
The current update step is 9360
GPU_0_using curriculum 40 with window 40
Epoch: [312][20/30]	Time  1.485 ( 1.517)	Data  0.038 ( 0.049)	InnerLoop  0.620 ( 0.644)	Loss 4.1051e-01 (4.6721e-01)	Acc@1  85.50 ( 83.92)
The current update step is 9390
GPU_0_using curriculum 40 with window 40
Epoch: [313][20/30]	Time  1.488 ( 1.518)	Data  0.037 ( 0.067)	InnerLoop  0.625 ( 0.628)	Loss 6.3035e-01 (4.8673e-01)	Acc@1  78.34 ( 82.65)
The current update step is 9420
GPU_0_using curriculum 40 with window 40
Epoch: [314][20/30]	Time  1.485 ( 1.520)	Data  0.037 ( 0.067)	InnerLoop  0.623 ( 0.630)	Loss 4.8016e-01 (4.7700e-01)	Acc@1  83.40 ( 83.16)
The current update step is 9450
The current seed is 15175322827854810060
The current lr is: 0.0015
Testing Results:
 *   Acc@1 75.737
 *   Acc@1 75.796
 *   Acc@1 74.947
 *   Acc@1 74.922
 *   Acc@1 74.750
 *   Acc@1 75.002
 *   Acc@1 55.526
 *   Acc@1 56.112
 *   Acc@1 58.158
 *   Acc@1 58.537
 *   Acc@1 58.342
 *   Acc@1 58.999
 *   Acc@1 75.303
 *   Acc@1 74.840
 *   Acc@1 71.158
 *   Acc@1 71.506
 *   Acc@1 70.947
 *   Acc@1 71.055
 *   Acc@1 43.908
 *   Acc@1 43.793
 *   Acc@1 43.224
 *   Acc@1 43.119
 *   Acc@1 43.632
 *   Acc@1 43.247
Training for 300 epoch: 62.61842105263158
Training for 600 epoch: 61.871710526315795
Training for 1000 epoch: 61.91776315789473
Training for 300 epoch: 62.63541666666667
Training for 600 epoch: 62.020833333333336
Training for 1000 epoch: 62.075833333333335
[[62.61842105263158, 61.871710526315795, 61.91776315789473], [62.63541666666667, 62.020833333333336, 62.075833333333335]]
train loss 0.9735993273735046, epoch 314, best loss 0.2624552794933319, best_epoch 274
GPU_0_using curriculum 40 with window 40
Epoch: [315][20/30]	Time  1.494 ( 1.526)	Data  0.038 ( 0.061)	InnerLoop  0.630 ( 0.643)	Loss 4.9333e-01 (4.9637e-01)	Acc@1  82.32 ( 82.69)
The current update step is 9480
GPU_0_using curriculum 40 with window 40
Epoch: [316][20/30]	Time  1.492 ( 1.516)	Data  0.035 ( 0.067)	InnerLoop  0.631 ( 0.627)	Loss 4.6475e-01 (4.8510e-01)	Acc@1  83.81 ( 82.95)
The current update step is 9510
GPU_0_using curriculum 40 with window 40
Epoch: [317][20/30]	Time  1.493 ( 1.513)	Data  0.038 ( 0.061)	InnerLoop  0.633 ( 0.633)	Loss 4.7399e-01 (4.9884e-01)	Acc@1  83.11 ( 82.62)
The current update step is 9540
GPU_0_using curriculum 40 with window 40
Epoch: [318][20/30]	Time  1.486 ( 1.511)	Data  0.038 ( 0.061)	InnerLoop  0.622 ( 0.632)	Loss 5.2149e-01 (4.9847e-01)	Acc@1  81.10 ( 82.14)
The current update step is 9570
GPU_0_using curriculum 40 with window 40
Epoch: [319][20/30]	Time  1.491 ( 1.510)	Data  0.038 ( 0.055)	InnerLoop  0.632 ( 0.638)	Loss 4.1105e-01 (5.0387e-01)	Acc@1  86.01 ( 82.34)
The current update step is 9600
The current seed is 6375473541069029105
The current lr is: 0.0015
Testing Results:
 *   Acc@1 52.539
 *   Acc@1 52.502
 *   Acc@1 53.737
 *   Acc@1 52.744
 *   Acc@1 53.618
 *   Acc@1 53.093
 *   Acc@1 67.211
 *   Acc@1 67.503
 *   Acc@1 42.368
 *   Acc@1 43.258
 *   Acc@1 41.461
 *   Acc@1 42.067
 *   Acc@1 56.803
 *   Acc@1 56.865
 *   Acc@1 42.987
 *   Acc@1 43.059
 *   Acc@1 43.987
 *   Acc@1 44.162
 *   Acc@1 57.829
 *   Acc@1 57.833
 *   Acc@1 57.421
 *   Acc@1 57.683
 *   Acc@1 57.461
 *   Acc@1 57.562
Training for 300 epoch: 58.59539473684211
Training for 600 epoch: 49.128289473684205
Training for 1000 epoch: 49.131578947368425
Training for 300 epoch: 58.67583333333334
Training for 600 epoch: 49.18625
Training for 1000 epoch: 49.221041666666665
[[58.59539473684211, 49.128289473684205, 49.131578947368425], [58.67583333333334, 49.18625, 49.221041666666665]]
train loss 0.7216937625885009, epoch 319, best loss 0.2624552794933319, best_epoch 274
GPU_0_using curriculum 40 with window 40
Epoch: [320][20/30]	Time  1.594 ( 1.518)	Data  0.151 ( 0.066)	InnerLoop  0.622 ( 0.632)	Loss 5.2788e-01 (5.3057e-01)	Acc@1  81.86 ( 81.24)
The current update step is 9630
GPU_0_using curriculum 40 with window 40
Epoch: [321][20/30]	Time  1.608 ( 1.520)	Data  0.035 ( 0.054)	InnerLoop  0.748 ( 0.646)	Loss 5.5454e-01 (5.0821e-01)	Acc@1  80.35 ( 81.64)
The current update step is 9660
GPU_0_using curriculum 40 with window 40
Epoch: [322][20/30]	Time  1.490 ( 1.517)	Data  0.036 ( 0.049)	InnerLoop  0.630 ( 0.647)	Loss 4.9280e-01 (4.8190e-01)	Acc@1  82.86 ( 83.14)
The current update step is 9690
GPU_0_using curriculum 40 with window 40
Epoch: [323][20/30]	Time  1.502 ( 1.514)	Data  0.035 ( 0.054)	InnerLoop  0.629 ( 0.639)	Loss 4.8728e-01 (4.8599e-01)	Acc@1  84.06 ( 83.09)
The current update step is 9720
GPU_0_using curriculum 40 with window 40
Epoch: [324][20/30]	Time  1.482 ( 1.515)	Data  0.037 ( 0.043)	InnerLoop  0.627 ( 0.651)	Loss 4.8182e-01 (4.6374e-01)	Acc@1  83.18 ( 83.79)
The current update step is 9750
The current seed is 15912941843061912225
The current lr is: 0.0015
Testing Results:
 *   Acc@1 59.461
 *   Acc@1 59.195
 *   Acc@1 60.171
 *   Acc@1 59.648
 *   Acc@1 60.513
 *   Acc@1 60.413
 *   Acc@1 62.632
 *   Acc@1 63.021
 *   Acc@1 62.329
 *   Acc@1 62.678
 *   Acc@1 62.053
 *   Acc@1 62.080
 *   Acc@1 59.882
 *   Acc@1 59.821
 *   Acc@1 59.408
 *   Acc@1 59.582
 *   Acc@1 59.171
 *   Acc@1 58.794
 *   Acc@1 59.803
 *   Acc@1 59.889
 *   Acc@1 59.618
 *   Acc@1 59.105
 *   Acc@1 58.434
 *   Acc@1 58.395
Training for 300 epoch: 60.44407894736842
Training for 600 epoch: 60.381578947368425
Training for 1000 epoch: 60.04276315789474
Training for 300 epoch: 60.481458333333336
Training for 600 epoch: 60.25333333333333
Training for 1000 epoch: 59.920416666666675
[[60.44407894736842, 60.381578947368425, 60.04276315789474], [60.481458333333336, 60.25333333333333, 59.920416666666675]]
train loss 0.5532023025512696, epoch 324, best loss 0.2624552794933319, best_epoch 274
GPU_0_using curriculum 40 with window 40
Epoch: [325][20/30]	Time  1.490 ( 1.514)	Data  0.038 ( 0.054)	InnerLoop  0.633 ( 0.640)	Loss 4.8391e-01 (4.6191e-01)	Acc@1  82.54 ( 83.83)
The current update step is 9780
GPU_0_using curriculum 40 with window 40
Epoch: [326][20/30]	Time  1.612 ( 1.518)	Data  0.158 ( 0.060)	InnerLoop  0.627 ( 0.640)	Loss 4.8231e-01 (4.8314e-01)	Acc@1  83.94 ( 83.04)
The current update step is 9810
GPU_0_using curriculum 40 with window 40
Epoch: [327][20/30]	Time  1.494 ( 1.513)	Data  0.036 ( 0.036)	InnerLoop  0.633 ( 0.658)	Loss 4.7664e-01 (4.6223e-01)	Acc@1  83.59 ( 83.97)
The current update step is 9840
GPU_0_using curriculum 40 with window 40
Epoch: [328][20/30]	Time  1.488 ( 1.512)	Data  0.037 ( 0.049)	InnerLoop  0.627 ( 0.644)	Loss 4.4547e-01 (4.8714e-01)	Acc@1  84.59 ( 82.89)
The current update step is 9870
GPU_0_using curriculum 40 with window 40
Epoch: [329][20/30]	Time  1.493 ( 1.513)	Data  0.037 ( 0.060)	InnerLoop  0.636 ( 0.632)	Loss 4.5399e-01 (4.7944e-01)	Acc@1  84.18 ( 83.29)
The current update step is 9900
The current seed is 924040674832708356
The current lr is: 0.0015
Testing Results:
 *   Acc@1 61.289
 *   Acc@1 61.463
 *   Acc@1 55.395
 *   Acc@1 55.340
 *   Acc@1 56.039
 *   Acc@1 56.626
 *   Acc@1 74.803
 *   Acc@1 75.113
 *   Acc@1 72.776
 *   Acc@1 73.343
 *   Acc@1 71.211
 *   Acc@1 72.230
 *   Acc@1 55.987
 *   Acc@1 56.335
 *   Acc@1 58.013
 *   Acc@1 59.335
 *   Acc@1 58.895
 *   Acc@1 60.222
 *   Acc@1 76.368
 *   Acc@1 76.850
 *   Acc@1 76.789
 *   Acc@1 77.373
 *   Acc@1 76.842
 *   Acc@1 77.525
Training for 300 epoch: 67.11184210526315
Training for 600 epoch: 65.74342105263159
Training for 1000 epoch: 65.74671052631578
Training for 300 epoch: 67.44041666666666
Training for 600 epoch: 66.34791666666666
Training for 1000 epoch: 66.650625
[[67.11184210526315, 65.74342105263159, 65.74671052631578], [67.44041666666666, 66.34791666666666, 66.650625]]
train loss 0.2981523889064789, epoch 329, best loss 0.2624552794933319, best_epoch 274
GPU_0_using curriculum 40 with window 40
Epoch: [330][20/30]	Time  1.487 ( 1.514)	Data  0.038 ( 0.049)	InnerLoop  0.630 ( 0.645)	Loss 4.7152e-01 (4.7338e-01)	Acc@1  83.15 ( 83.47)
The current update step is 9930
GPU_0_using curriculum 40 with window 40
Epoch: [331][20/30]	Time  1.498 ( 1.514)	Data  0.036 ( 0.060)	InnerLoop  0.629 ( 0.633)	Loss 4.9550e-01 (4.7943e-01)	Acc@1  83.40 ( 83.24)
The current update step is 9960
GPU_0_using curriculum 40 with window 40
Epoch: [332][20/30]	Time  1.493 ( 1.515)	Data  0.042 ( 0.049)	InnerLoop  0.630 ( 0.645)	Loss 4.3604e-01 (4.8625e-01)	Acc@1  84.99 ( 82.95)
The current update step is 9990
GPU_0_using curriculum 40 with window 40
Epoch: [333][20/30]	Time  1.489 ( 1.514)	Data  0.038 ( 0.066)	InnerLoop  0.631 ( 0.628)	Loss 4.7269e-01 (5.0390e-01)	Acc@1  83.35 ( 82.14)
The current update step is 10020
GPU_0_using curriculum 40 with window 40
Epoch: [334][20/30]	Time  1.483 ( 1.521)	Data  0.037 ( 0.067)	InnerLoop  0.624 ( 0.634)	Loss 5.0556e-01 (4.9774e-01)	Acc@1  81.71 ( 82.28)
The current update step is 10050
The current seed is 11963387079928078860
The current lr is: 0.0015
Testing Results:
 *   Acc@1 54.013
 *   Acc@1 53.416
 *   Acc@1 52.461
 *   Acc@1 52.239
 *   Acc@1 51.303
 *   Acc@1 51.494
 *   Acc@1 71.434
 *   Acc@1 71.367
 *   Acc@1 71.132
 *   Acc@1 70.668
 *   Acc@1 70.947
 *   Acc@1 70.552
 *   Acc@1 65.961
 *   Acc@1 65.953
 *   Acc@1 67.421
 *   Acc@1 67.757
 *   Acc@1 67.579
 *   Acc@1 67.124
 *   Acc@1 64.513
 *   Acc@1 65.099
 *   Acc@1 65.329
 *   Acc@1 65.828
 *   Acc@1 64.921
 *   Acc@1 65.954
Training for 300 epoch: 63.98026315789474
Training for 600 epoch: 64.08552631578947
Training for 1000 epoch: 63.6875
Training for 300 epoch: 63.95854166666667
Training for 600 epoch: 64.123125
Training for 1000 epoch: 63.78125
[[63.98026315789474, 64.08552631578947, 63.6875], [63.95854166666667, 64.123125, 63.78125]]
train loss 0.47333437388738, epoch 334, best loss 0.2624552794933319, best_epoch 334
GPU_0_using curriculum 40 with window 40
Epoch: [335][20/30]	Time  1.488 ( 1.519)	Data  0.038 ( 0.061)	InnerLoop  0.626 ( 0.639)	Loss 5.4137e-01 (5.0285e-01)	Acc@1  80.69 ( 82.17)
The current update step is 10080
GPU_0_using curriculum 40 with window 40
Epoch: [336][20/30]	Time  1.498 ( 1.515)	Data  0.035 ( 0.066)	InnerLoop  0.633 ( 0.628)	Loss 5.5294e-01 (4.8288e-01)	Acc@1  80.93 ( 83.08)
The current update step is 10110
GPU_0_using curriculum 40 with window 40
Epoch: [337][20/30]	Time  1.490 ( 1.513)	Data  0.038 ( 0.060)	InnerLoop  0.633 ( 0.633)	Loss 5.2267e-01 (4.8381e-01)	Acc@1  82.64 ( 83.06)
The current update step is 10140
GPU_0_using curriculum 40 with window 40
Epoch: [338][20/30]	Time  1.481 ( 1.512)	Data  0.038 ( 0.060)	InnerLoop  0.624 ( 0.631)	Loss 4.8848e-01 (4.5741e-01)	Acc@1  82.03 ( 84.03)
The current update step is 10170
GPU_0_using curriculum 40 with window 40
Epoch: [339][20/30]	Time  1.485 ( 1.512)	Data  0.036 ( 0.055)	InnerLoop  0.628 ( 0.638)	Loss 4.6114e-01 (4.8263e-01)	Acc@1  84.42 ( 82.99)
The current update step is 10200
The current seed is 14005590682644036003
The current lr is: 0.0015
Testing Results:
 *   Acc@1 46.263
 *   Acc@1 46.209
 *   Acc@1 48.487
 *   Acc@1 48.327
 *   Acc@1 49.724
 *   Acc@1 49.435
 *   Acc@1 62.303
 *   Acc@1 62.260
 *   Acc@1 63.434
 *   Acc@1 63.783
 *   Acc@1 63.513
 *   Acc@1 63.718
 *   Acc@1 62.158
 *   Acc@1 62.033
 *   Acc@1 62.618
 *   Acc@1 62.805
 *   Acc@1 63.237
 *   Acc@1 62.863
 *   Acc@1 68.934
 *   Acc@1 68.862
 *   Acc@1 67.566
 *   Acc@1 68.608
 *   Acc@1 68.118
 *   Acc@1 69.431
Training for 300 epoch: 59.914473684210535
Training for 600 epoch: 60.526315789473685
Training for 1000 epoch: 61.148026315789465
Training for 300 epoch: 59.84125
Training for 600 epoch: 60.880624999999995
Training for 1000 epoch: 61.36166666666667
[[59.914473684210535, 60.526315789473685, 61.148026315789465], [59.84125, 60.880624999999995, 61.36166666666667]]
train loss 0.5271123105367025, epoch 339, best loss 0.2624552794933319, best_epoch 334
GPU_0_using curriculum 40 with window 40
Epoch: [340][20/30]	Time  1.579 ( 1.515)	Data  0.149 ( 0.066)	InnerLoop  0.616 ( 0.632)	Loss 4.4139e-01 (4.6280e-01)	Acc@1  84.11 ( 83.72)
The current update step is 10230
GPU_0_using curriculum 40 with window 40
Epoch: [341][20/30]	Time  1.590 ( 1.507)	Data  0.035 ( 0.054)	InnerLoop  0.741 ( 0.641)	Loss 4.6169e-01 (4.6020e-01)	Acc@1  83.76 ( 83.63)
The current update step is 10260
GPU_0_using curriculum 40 with window 40
Epoch: [342][20/30]	Time  1.478 ( 1.503)	Data  0.036 ( 0.047)	InnerLoop  0.626 ( 0.641)	Loss 4.6206e-01 (4.6186e-01)	Acc@1  84.18 ( 84.25)
The current update step is 10290
GPU_0_using curriculum 40 with window 40
Epoch: [343][20/30]	Time  1.512 ( 1.515)	Data  0.041 ( 0.054)	InnerLoop  0.641 ( 0.639)	Loss 4.8732e-01 (4.9592e-01)	Acc@1  82.67 ( 82.35)
The current update step is 10320
GPU_0_using curriculum 40 with window 40
Epoch: [344][20/30]	Time  1.472 ( 1.512)	Data  0.036 ( 0.043)	InnerLoop  0.622 ( 0.651)	Loss 4.2806e-01 (4.8917e-01)	Acc@1  85.21 ( 82.61)
The current update step is 10350
The current seed is 495158806171818799
The current lr is: 0.0015
Testing Results:
 *   Acc@1 67.197
 *   Acc@1 67.193
 *   Acc@1 65.842
 *   Acc@1 66.062
 *   Acc@1 58.658
 *   Acc@1 58.118
 *   Acc@1 64.618
 *   Acc@1 64.167
 *   Acc@1 59.737
 *   Acc@1 59.836
 *   Acc@1 59.276
 *   Acc@1 59.557
 *   Acc@1 69.211
 *   Acc@1 69.512
 *   Acc@1 62.882
 *   Acc@1 62.297
 *   Acc@1 63.079
 *   Acc@1 62.803
 *   Acc@1 55.750
 *   Acc@1 55.666
 *   Acc@1 56.487
 *   Acc@1 56.612
 *   Acc@1 56.474
 *   Acc@1 56.537
Training for 300 epoch: 64.19407894736842
Training for 600 epoch: 61.23684210526315
Training for 1000 epoch: 59.37171052631578
Training for 300 epoch: 64.134375
Training for 600 epoch: 61.20166666666667
Training for 1000 epoch: 59.25354166666666
[[64.19407894736842, 61.23684210526315, 59.37171052631578], [64.134375, 61.20166666666667, 59.25354166666666]]
train loss 0.697731353823344, epoch 344, best loss 0.2624552794933319, best_epoch 334
GPU_0_using curriculum 40 with window 40
Epoch: [345][20/30]	Time  1.483 ( 1.512)	Data  0.036 ( 0.054)	InnerLoop  0.628 ( 0.640)	Loss 4.8641e-01 (4.9374e-01)	Acc@1  82.89 ( 82.67)
The current update step is 10380
GPU_0_using curriculum 40 with window 40
Epoch: [346][20/30]	Time  1.593 ( 1.513)	Data  0.151 ( 0.059)	InnerLoop  0.626 ( 0.637)	Loss 4.3400e-01 (4.7420e-01)	Acc@1  84.06 ( 83.19)
The current update step is 10410
GPU_0_using curriculum 40 with window 40
Epoch: [347][20/30]	Time  1.480 ( 1.507)	Data  0.035 ( 0.036)	InnerLoop  0.627 ( 0.654)	Loss 4.7973e-01 (4.7919e-01)	Acc@1  83.84 ( 83.09)
The current update step is 10440
GPU_0_using curriculum 40 with window 40
Epoch: [348][20/30]	Time  1.478 ( 1.511)	Data  0.035 ( 0.048)	InnerLoop  0.624 ( 0.645)	Loss 4.8513e-01 (4.8548e-01)	Acc@1  82.71 ( 82.92)
The current update step is 10470
GPU_0_using curriculum 40 with window 40
Epoch: [349][20/30]	Time  1.484 ( 1.507)	Data  0.036 ( 0.059)	InnerLoop  0.629 ( 0.630)	Loss 5.1375e-01 (4.7857e-01)	Acc@1  81.93 ( 83.15)
The current update step is 10500
The current seed is 432867323146273376
The current lr is: 0.0015
Testing Results:
 *   Acc@1 57.829
 *   Acc@1 57.407
 *   Acc@1 56.447
 *   Acc@1 56.305
 *   Acc@1 56.408
 *   Acc@1 56.306
 *   Acc@1 66.132
 *   Acc@1 66.707
 *   Acc@1 66.303
 *   Acc@1 66.686
 *   Acc@1 66.645
 *   Acc@1 66.682
 *   Acc@1 68.750
 *   Acc@1 68.400
 *   Acc@1 70.066
 *   Acc@1 69.976
 *   Acc@1 70.539
 *   Acc@1 70.216
 *   Acc@1 72.395
 *   Acc@1 72.456
 *   Acc@1 72.697
 *   Acc@1 72.489
 *   Acc@1 72.961
 *   Acc@1 72.588
Training for 300 epoch: 66.27631578947368
Training for 600 epoch: 66.37828947368422
Training for 1000 epoch: 66.63815789473685
Training for 300 epoch: 66.24249999999999
Training for 600 epoch: 66.36395833333333
Training for 1000 epoch: 66.44791666666667
[[66.27631578947368, 66.37828947368422, 66.63815789473685], [66.24249999999999, 66.36395833333333, 66.44791666666667]]
train loss 0.4394438506603241, epoch 349, best loss 0.2624552794933319, best_epoch 334
GPU_0_using curriculum 40 with window 40
Epoch: [350][20/30]	Time  1.479 ( 1.507)	Data  0.037 ( 0.048)	InnerLoop  0.622 ( 0.642)	Loss 5.3522e-01 (5.0711e-01)	Acc@1  81.42 ( 81.93)
The current update step is 10530
GPU_0_using curriculum 40 with window 40
Epoch: [351][20/30]	Time  1.517 ( 1.522)	Data  0.038 ( 0.060)	InnerLoop  0.637 ( 0.637)	Loss 5.1190e-01 (4.8861e-01)	Acc@1  80.71 ( 82.74)
The current update step is 10560
GPU_0_using curriculum 40 with window 40
Epoch: [352][20/30]	Time  1.509 ( 1.541)	Data  0.037 ( 0.051)	InnerLoop  0.635 ( 0.657)	Loss 4.1169e-01 (4.8344e-01)	Acc@1  86.01 ( 82.92)
The current update step is 10590
GPU_0_using curriculum 40 with window 40
Epoch: [353][20/30]	Time  1.509 ( 1.520)	Data  0.038 ( 0.068)	InnerLoop  0.642 ( 0.629)	Loss 5.8469e-01 (4.7769e-01)	Acc@1  79.59 ( 83.15)
The current update step is 10620
GPU_0_using curriculum 40 with window 40
Epoch: [354][20/30]	Time  1.481 ( 1.532)	Data  0.036 ( 0.069)	InnerLoop  0.626 ( 0.639)	Loss 4.3529e-01 (4.6824e-01)	Acc@1  85.06 ( 83.74)
The current update step is 10650
The current seed is 14366940240507996357
The current lr is: 0.0015
Testing Results:
 *   Acc@1 63.500
 *   Acc@1 63.990
 *   Acc@1 63.987
 *   Acc@1 64.618
 *   Acc@1 63.974
 *   Acc@1 64.589
 *   Acc@1 75.039
 *   Acc@1 74.358
 *   Acc@1 74.934
 *   Acc@1 75.113
 *   Acc@1 74.987
 *   Acc@1 75.144
 *   Acc@1 56.737
 *   Acc@1 56.832
 *   Acc@1 55.250
 *   Acc@1 55.791
 *   Acc@1 55.171
 *   Acc@1 55.781
 *   Acc@1 75.132
 *   Acc@1 75.132
 *   Acc@1 74.474
 *   Acc@1 74.647
 *   Acc@1 74.684
 *   Acc@1 74.288
Training for 300 epoch: 67.60197368421052
Training for 600 epoch: 67.16118421052632
Training for 1000 epoch: 67.20394736842105
Training for 300 epoch: 67.57791666666667
Training for 600 epoch: 67.54229166666667
Training for 1000 epoch: 67.450625
[[67.60197368421052, 67.16118421052632, 67.20394736842105], [67.57791666666667, 67.54229166666667, 67.450625]]
train loss 0.4277449220021566, epoch 354, best loss 0.2624552794933319, best_epoch 334
GPU_0_using curriculum 40 with window 40
Epoch: [355][20/30]	Time  1.516 ( 1.525)	Data  0.038 ( 0.061)	InnerLoop  0.640 ( 0.640)	Loss 5.3054e-01 (4.7649e-01)	Acc@1  81.35 ( 83.50)
The current update step is 10680
GPU_0_using curriculum 40 with window 40
Epoch: [356][20/30]	Time  1.511 ( 1.526)	Data  0.039 ( 0.068)	InnerLoop  0.643 ( 0.631)	Loss 4.8610e-01 (4.7063e-01)	Acc@1  83.89 ( 83.84)
The current update step is 10710
GPU_0_using curriculum 40 with window 40
Epoch: [357][20/30]	Time  1.515 ( 1.525)	Data  0.047 ( 0.062)	InnerLoop  0.645 ( 0.636)	Loss 5.2809e-01 (4.7792e-01)	Acc@1  81.91 ( 83.40)
The current update step is 10740
GPU_0_using curriculum 40 with window 40
Epoch: [358][20/30]	Time  1.536 ( 1.577)	Data  0.041 ( 0.067)	InnerLoop  0.651 ( 0.661)	Loss 5.7619e-01 (4.7842e-01)	Acc@1  78.12 ( 83.11)
The current update step is 10770
GPU_0_using curriculum 40 with window 40
Epoch: [359][20/30]	Time  1.545 ( 1.569)	Data  0.039 ( 0.059)	InnerLoop  0.654 ( 0.665)	Loss 4.7584e-01 (4.8389e-01)	Acc@1  84.08 ( 83.07)
The current update step is 10800
The current seed is 15397437241901122578
The current lr is: 0.0015
Testing Results:
 *   Acc@1 50.342
 *   Acc@1 51.437
 *   Acc@1 62.039
 *   Acc@1 62.096
 *   Acc@1 61.461
 *   Acc@1 62.557
 *   Acc@1 69.671
 *   Acc@1 70.363
 *   Acc@1 69.763
 *   Acc@1 70.147
 *   Acc@1 69.671
 *   Acc@1 70.261
 *   Acc@1 67.553
 *   Acc@1 67.263
 *   Acc@1 67.842
 *   Acc@1 67.474
 *   Acc@1 68.118
 *   Acc@1 67.810
 *   Acc@1 38.500
 *   Acc@1 38.031
 *   Acc@1 38.737
 *   Acc@1 38.439
 *   Acc@1 39.579
 *   Acc@1 38.822
Training for 300 epoch: 56.516447368421055
Training for 600 epoch: 59.5953947368421
Training for 1000 epoch: 59.70723684210526
Training for 300 epoch: 56.77333333333333
Training for 600 epoch: 59.53916666666667
Training for 1000 epoch: 59.8625
[[56.516447368421055, 59.5953947368421, 59.70723684210526], [56.77333333333333, 59.53916666666667, 59.8625]]
train loss 1.1169047381718953, epoch 359, best loss 0.2624552794933319, best_epoch 334
GPU_0_using curriculum 40 with window 40
Epoch: [360][20/30]	Time  1.618 ( 1.528)	Data  0.156 ( 0.068)	InnerLoop  0.636 ( 0.638)	Loss 4.2954e-01 (4.5945e-01)	Acc@1  85.13 ( 84.11)
The current update step is 10830
GPU_0_using curriculum 40 with window 40
Epoch: [361][20/30]	Time  1.616 ( 1.522)	Data  0.039 ( 0.056)	InnerLoop  0.748 ( 0.644)	Loss 4.6357e-01 (4.6842e-01)	Acc@1  84.30 ( 83.63)
The current update step is 10860
GPU_0_using curriculum 40 with window 40
Epoch: [362][20/30]	Time  1.483 ( 1.517)	Data  0.039 ( 0.051)	InnerLoop  0.626 ( 0.646)	Loss 4.6887e-01 (4.6832e-01)	Acc@1  83.23 ( 83.79)
The current update step is 10890
GPU_0_using curriculum 40 with window 40
Epoch: [363][20/30]	Time  1.491 ( 1.518)	Data  0.040 ( 0.055)	InnerLoop  0.624 ( 0.639)	Loss 4.7547e-01 (4.9614e-01)	Acc@1  83.28 ( 82.49)
The current update step is 10920
GPU_0_using curriculum 40 with window 40
Epoch: [364][20/30]	Time  1.490 ( 1.530)	Data  0.041 ( 0.045)	InnerLoop  0.629 ( 0.656)	Loss 5.3122e-01 (5.0177e-01)	Acc@1  81.57 ( 82.34)
The current update step is 10950
The current seed is 16693654605465255024
The current lr is: 0.0015
Testing Results:
 *   Acc@1 51.105
 *   Acc@1 51.670
 *   Acc@1 50.513
 *   Acc@1 51.514
 *   Acc@1 51.105
 *   Acc@1 51.570
 *   Acc@1 64.987
 *   Acc@1 64.769
 *   Acc@1 65.605
 *   Acc@1 65.475
 *   Acc@1 66.368
 *   Acc@1 66.251
 *   Acc@1 42.605
 *   Acc@1 41.936
 *   Acc@1 58.171
 *   Acc@1 57.527
 *   Acc@1 57.882
 *   Acc@1 57.023
 *   Acc@1 63.500
 *   Acc@1 64.127
 *   Acc@1 61.566
 *   Acc@1 61.602
 *   Acc@1 61.763
 *   Acc@1 61.984
Training for 300 epoch: 55.549342105263165
Training for 600 epoch: 58.963815789473685
Training for 1000 epoch: 59.2796052631579
Training for 300 epoch: 55.625625
Training for 600 epoch: 59.029374999999995
Training for 1000 epoch: 59.206875
[[55.549342105263165, 58.963815789473685, 59.2796052631579], [55.625625, 59.029374999999995, 59.206875]]
train loss 0.6592988668441773, epoch 364, best loss 0.2624552794933319, best_epoch 334
GPU_0_using curriculum 40 with window 40
Epoch: [365][20/30]	Time  1.480 ( 1.512)	Data  0.037 ( 0.054)	InnerLoop  0.625 ( 0.638)	Loss 5.0687e-01 (4.7297e-01)	Acc@1  81.96 ( 83.55)
The current update step is 10980
GPU_0_using curriculum 40 with window 40
Epoch: [366][20/30]	Time  1.602 ( 1.520)	Data  0.155 ( 0.060)	InnerLoop  0.625 ( 0.638)	Loss 4.9708e-01 (4.6430e-01)	Acc@1  83.42 ( 83.70)
The current update step is 11010
GPU_0_using curriculum 40 with window 40
Epoch: [367][20/30]	Time  1.481 ( 1.512)	Data  0.036 ( 0.037)	InnerLoop  0.620 ( 0.653)	Loss 5.2353e-01 (4.8863e-01)	Acc@1  81.54 ( 82.84)
The current update step is 11040
GPU_0_using curriculum 40 with window 40
Epoch: [368][20/30]	Time  1.480 ( 1.511)	Data  0.036 ( 0.049)	InnerLoop  0.627 ( 0.642)	Loss 4.3993e-01 (4.9273e-01)	Acc@1  84.20 ( 82.78)
The current update step is 11070
GPU_0_using curriculum 40 with window 40
Epoch: [369][20/30]	Time  1.484 ( 1.515)	Data  0.036 ( 0.060)	InnerLoop  0.628 ( 0.633)	Loss 5.1963e-01 (4.6951e-01)	Acc@1  82.15 ( 83.39)
The current update step is 11100
The current seed is 7955579807746930011
The current lr is: 0.0015
Testing Results:
 *   Acc@1 75.408
 *   Acc@1 75.292
 *   Acc@1 65.382
 *   Acc@1 64.723
 *   Acc@1 66.013
 *   Acc@1 65.257
 *   Acc@1 72.224
 *   Acc@1 73.317
 *   Acc@1 73.368
 *   Acc@1 73.599
 *   Acc@1 73.632
 *   Acc@1 74.046
 *   Acc@1 65.579
 *   Acc@1 65.744
 *   Acc@1 59.474
 *   Acc@1 59.802
 *   Acc@1 44.158
 *   Acc@1 45.485
 *   Acc@1 74.671
 *   Acc@1 74.655
 *   Acc@1 76.776
 *   Acc@1 76.895
 *   Acc@1 76.368
 *   Acc@1 76.462
Training for 300 epoch: 71.97039473684211
Training for 600 epoch: 68.75
Training for 1000 epoch: 65.04276315789474
Training for 300 epoch: 72.25187500000001
Training for 600 epoch: 68.75479166666666
Training for 1000 epoch: 65.3125
[[71.97039473684211, 68.75, 65.04276315789474], [72.25187500000001, 68.75479166666666, 65.3125]]
train loss 0.4024007765293121, epoch 369, best loss 0.2624552794933319, best_epoch 334
GPU_0_using curriculum 40 with window 40
Epoch: [370][20/30]	Time  1.516 ( 1.566)	Data  0.039 ( 0.053)	InnerLoop  0.638 ( 0.669)	Loss 4.6011e-01 (4.8390e-01)	Acc@1  83.03 ( 83.04)
The current update step is 11130
GPU_0_using curriculum 40 with window 40
Epoch: [371][20/30]	Time  1.525 ( 1.549)	Data  0.040 ( 0.064)	InnerLoop  0.647 ( 0.648)	Loss 4.6110e-01 (4.8688e-01)	Acc@1  82.89 ( 82.87)
The current update step is 11160
GPU_0_using curriculum 40 with window 40
Epoch: [372][20/30]	Time  1.480 ( 1.517)	Data  0.037 ( 0.050)	InnerLoop  0.619 ( 0.644)	Loss 4.4303e-01 (4.7100e-01)	Acc@1  84.77 ( 83.44)
The current update step is 11190
GPU_0_using curriculum 40 with window 40
Epoch: [373][20/30]	Time  1.484 ( 1.512)	Data  0.036 ( 0.066)	InnerLoop  0.623 ( 0.625)	Loss 4.8541e-01 (4.6518e-01)	Acc@1  83.94 ( 83.62)
The current update step is 11220
GPU_0_using curriculum 40 with window 40
Epoch: [374][20/30]	Time  1.483 ( 1.515)	Data  0.036 ( 0.066)	InnerLoop  0.625 ( 0.629)	Loss 4.2182e-01 (4.5830e-01)	Acc@1  86.08 ( 84.04)
The current update step is 11250
The current seed is 17961708098556197071
The current lr is: 0.0015
Testing Results:
 *   Acc@1 47.026
 *   Acc@1 46.550
 *   Acc@1 51.211
 *   Acc@1 50.712
 *   Acc@1 51.645
 *   Acc@1 51.188
 *   Acc@1 66.750
 *   Acc@1 66.777
 *   Acc@1 67.947
 *   Acc@1 68.170
 *   Acc@1 69.118
 *   Acc@1 69.484
 *   Acc@1 63.526
 *   Acc@1 63.042
 *   Acc@1 62.842
 *   Acc@1 61.888
 *   Acc@1 62.553
 *   Acc@1 61.567
 *   Acc@1 63.276
 *   Acc@1 63.717
 *   Acc@1 63.816
 *   Acc@1 63.942
 *   Acc@1 63.158
 *   Acc@1 63.528
Training for 300 epoch: 60.14473684210526
Training for 600 epoch: 61.453947368421055
Training for 1000 epoch: 61.61842105263158
Training for 300 epoch: 60.021458333333335
Training for 600 epoch: 61.17791666666666
Training for 1000 epoch: 61.44166666666667
[[60.14473684210526, 61.453947368421055, 61.61842105263158], [60.021458333333335, 61.17791666666666, 61.44166666666667]]
train loss 0.5064754160086314, epoch 374, best loss 0.2624552794933319, best_epoch 334
GPU_0_using curriculum 40 with window 40
Epoch: [375][20/30]	Time  1.499 ( 1.518)	Data  0.036 ( 0.059)	InnerLoop  0.634 ( 0.637)	Loss 4.5528e-01 (5.0101e-01)	Acc@1  84.55 ( 82.65)
The current update step is 11280
GPU_0_using curriculum 40 with window 40
Epoch: [376][20/30]	Time  1.619 ( 1.565)	Data  0.047 ( 0.072)	InnerLoop  0.690 ( 0.650)	Loss 5.8099e-01 (5.0305e-01)	Acc@1  78.03 ( 82.77)
The current update step is 11310
GPU_0_using curriculum 40 with window 40
Epoch: [377][20/30]	Time  1.474 ( 1.505)	Data  0.035 ( 0.060)	InnerLoop  0.620 ( 0.628)	Loss 4.3849e-01 (4.9501e-01)	Acc@1  84.99 ( 82.42)
The current update step is 11340
GPU_0_using curriculum 40 with window 40
Epoch: [378][20/30]	Time  1.466 ( 1.503)	Data  0.035 ( 0.060)	InnerLoop  0.615 ( 0.627)	Loss 4.8715e-01 (4.7104e-01)	Acc@1  83.40 ( 83.53)
The current update step is 11370
GPU_0_using curriculum 40 with window 40
Epoch: [379][20/30]	Time  1.479 ( 1.503)	Data  0.037 ( 0.053)	InnerLoop  0.626 ( 0.634)	Loss 5.1476e-01 (4.8133e-01)	Acc@1  82.91 ( 83.29)
The current update step is 11400
The current seed is 6605453501877087
The current lr is: 0.0015
Testing Results:
 *   Acc@1 75.250
 *   Acc@1 75.492
 *   Acc@1 75.158
 *   Acc@1 75.270
 *   Acc@1 75.079
 *   Acc@1 75.187
 *   Acc@1 72.303
 *   Acc@1 72.312
 *   Acc@1 72.289
 *   Acc@1 72.508
 *   Acc@1 72.487
 *   Acc@1 72.493
 *   Acc@1 57.921
 *   Acc@1 58.386
 *   Acc@1 58.263
 *   Acc@1 58.760
 *   Acc@1 58.711
 *   Acc@1 59.067
 *   Acc@1 39.211
 *   Acc@1 38.767
 *   Acc@1 59.250
 *   Acc@1 58.974
 *   Acc@1 59.605
 *   Acc@1 59.330
Training for 300 epoch: 61.171052631578945
Training for 600 epoch: 66.24013157894737
Training for 1000 epoch: 66.47039473684211
Training for 300 epoch: 61.23916666666666
Training for 600 epoch: 66.378125
Training for 1000 epoch: 66.51916666666666
[[61.171052631578945, 66.24013157894737, 66.47039473684211], [61.23916666666666, 66.378125, 66.51916666666666]]
train loss 0.6688886242230733, epoch 379, best loss 0.2624552794933319, best_epoch 334
GPU_0_using curriculum 40 with window 40
Epoch: [380][20/30]	Time  1.621 ( 1.539)	Data  0.159 ( 0.068)	InnerLoop  0.632 ( 0.641)	Loss 5.8203e-01 (4.7887e-01)	Acc@1  77.73 ( 83.18)
The current update step is 11430
GPU_0_using curriculum 40 with window 40
Epoch: [381][20/30]	Time  1.594 ( 1.526)	Data  0.041 ( 0.056)	InnerLoop  0.737 ( 0.648)	Loss 4.5328e-01 (4.7747e-01)	Acc@1  84.06 ( 83.38)
The current update step is 11460
GPU_0_using curriculum 40 with window 40
Epoch: [382][20/30]	Time  1.510 ( 1.523)	Data  0.039 ( 0.049)	InnerLoop  0.645 ( 0.651)	Loss 5.0822e-01 (4.9319e-01)	Acc@1  83.08 ( 83.30)
The current update step is 11490
GPU_0_using curriculum 40 with window 40
Epoch: [383][20/30]	Time  1.479 ( 1.559)	Data  0.036 ( 0.058)	InnerLoop  0.624 ( 0.664)	Loss 4.5711e-01 (4.6832e-01)	Acc@1  84.67 ( 83.72)
The current update step is 11520
GPU_0_using curriculum 40 with window 40
Epoch: [384][20/30]	Time  1.479 ( 1.511)	Data  0.036 ( 0.042)	InnerLoop  0.628 ( 0.653)	Loss 5.0446e-01 (4.7093e-01)	Acc@1  81.88 ( 83.36)
The current update step is 11550
The current seed is 4908998552858148895
The current lr is: 0.0015
Testing Results:
 *   Acc@1 78.092
 *   Acc@1 78.052
 *   Acc@1 78.197
 *   Acc@1 78.272
 *   Acc@1 78.368
 *   Acc@1 78.109
 *   Acc@1 61.658
 *   Acc@1 61.705
 *   Acc@1 64.947
 *   Acc@1 65.020
 *   Acc@1 66.145
 *   Acc@1 65.677
 *   Acc@1 71.579
 *   Acc@1 71.929
 *   Acc@1 72.132
 *   Acc@1 73.162
 *   Acc@1 72.961
 *   Acc@1 73.156
 *   Acc@1 51.987
 *   Acc@1 52.132
 *   Acc@1 56.553
 *   Acc@1 56.171
 *   Acc@1 57.066
 *   Acc@1 56.552
Training for 300 epoch: 65.82894736842105
Training for 600 epoch: 67.95723684210526
Training for 1000 epoch: 68.63486842105263
Training for 300 epoch: 65.95458333333333
Training for 600 epoch: 68.15645833333333
Training for 1000 epoch: 68.37354166666667
[[65.82894736842105, 67.95723684210526, 68.63486842105263], [65.95458333333333, 68.15645833333333, 68.37354166666667]]
train loss 0.6610917579650879, epoch 384, best loss 0.2624552794933319, best_epoch 334
GPU_0_using curriculum 40 with window 40
Epoch: [385][20/30]	Time  1.477 ( 1.509)	Data  0.036 ( 0.053)	InnerLoop  0.626 ( 0.640)	Loss 4.8293e-01 (4.7074e-01)	Acc@1  83.33 ( 83.57)
The current update step is 11580
GPU_0_using curriculum 40 with window 40
Epoch: [386][20/30]	Time  1.625 ( 1.521)	Data  0.159 ( 0.061)	InnerLoop  0.632 ( 0.641)	Loss 4.4317e-01 (4.8766e-01)	Acc@1  83.94 ( 83.17)
The current update step is 11610
GPU_0_using curriculum 40 with window 40
Epoch: [387][20/30]	Time  1.479 ( 1.519)	Data  0.036 ( 0.037)	InnerLoop  0.630 ( 0.662)	Loss 4.5721e-01 (4.8271e-01)	Acc@1  84.40 ( 83.20)
The current update step is 11640
GPU_0_using curriculum 40 with window 40
Epoch: [388][20/30]	Time  1.488 ( 1.506)	Data  0.039 ( 0.047)	InnerLoop  0.630 ( 0.644)	Loss 4.5938e-01 (4.5606e-01)	Acc@1  84.03 ( 84.12)
The current update step is 11670
GPU_0_using curriculum 40 with window 40
Epoch: [389][20/30]	Time  1.484 ( 1.510)	Data  0.037 ( 0.060)	InnerLoop  0.625 ( 0.634)	Loss 5.1027e-01 (4.6963e-01)	Acc@1  80.49 ( 83.62)
The current update step is 11700
The current seed is 14707116072955649305
The current lr is: 0.0015
Testing Results:
 *   Acc@1 76.316
 *   Acc@1 76.112
 *   Acc@1 77.474
 *   Acc@1 77.369
 *   Acc@1 78.000
 *   Acc@1 77.665
 *   Acc@1 61.289
 *   Acc@1 60.966
 *   Acc@1 62.355
 *   Acc@1 62.233
 *   Acc@1 63.434
 *   Acc@1 62.995
 *   Acc@1 71.553
 *   Acc@1 71.918
 *   Acc@1 71.526
 *   Acc@1 71.679
 *   Acc@1 71.382
 *   Acc@1 71.463
 *   Acc@1 69.987
 *   Acc@1 70.530
 *   Acc@1 70.184
 *   Acc@1 70.502
 *   Acc@1 70.447
 *   Acc@1 70.765
Training for 300 epoch: 69.78618421052632
Training for 600 epoch: 70.38486842105263
Training for 1000 epoch: 70.81578947368422
Training for 300 epoch: 69.88125
Training for 600 epoch: 70.44583333333334
Training for 1000 epoch: 70.721875
[[69.78618421052632, 70.38486842105263, 70.81578947368422], [69.88125, 70.44583333333334, 70.721875]]
train loss 0.4922264384905497, epoch 389, best loss 0.2624552794933319, best_epoch 334
GPU_0_using curriculum 40 with window 40
Epoch: [390][20/30]	Time  1.489 ( 1.527)	Data  0.035 ( 0.050)	InnerLoop  0.631 ( 0.649)	Loss 4.2192e-01 (4.6241e-01)	Acc@1  85.23 ( 83.56)
The current update step is 11730
GPU_0_using curriculum 40 with window 40
Epoch: [391][20/30]	Time  1.526 ( 1.551)	Data  0.037 ( 0.064)	InnerLoop  0.647 ( 0.650)	Loss 4.3181e-01 (4.5917e-01)	Acc@1  85.77 ( 84.11)
The current update step is 11760
GPU_0_using curriculum 40 with window 40
Epoch: [392][20/30]	Time  1.499 ( 1.540)	Data  0.037 ( 0.050)	InnerLoop  0.630 ( 0.657)	Loss 4.4018e-01 (4.5264e-01)	Acc@1  83.96 ( 83.96)
The current update step is 11790
GPU_0_using curriculum 40 with window 40
Epoch: [393][20/30]	Time  1.504 ( 1.527)	Data  0.038 ( 0.068)	InnerLoop  0.635 ( 0.633)	Loss 4.6967e-01 (4.5629e-01)	Acc@1  84.01 ( 84.19)
The current update step is 11820
GPU_0_using curriculum 40 with window 40
Epoch: [394][20/30]	Time  1.514 ( 1.593)	Data  0.041 ( 0.073)	InnerLoop  0.646 ( 0.669)	Loss 4.2303e-01 (4.7137e-01)	Acc@1  85.67 ( 83.64)
The current update step is 11850
The current seed is 16410858860540218972
The current lr is: 0.0015
Testing Results:
 *   Acc@1 78.224
 *   Acc@1 78.723
 *   Acc@1 78.263
 *   Acc@1 78.785
 *   Acc@1 78.171
 *   Acc@1 78.668
 *   Acc@1 69.737
 *   Acc@1 70.168
 *   Acc@1 78.579
 *   Acc@1 78.740
 *   Acc@1 78.895
 *   Acc@1 78.916
 *   Acc@1 53.145
 *   Acc@1 52.778
 *   Acc@1 67.974
 *   Acc@1 67.888
 *   Acc@1 66.461
 *   Acc@1 66.481
 *   Acc@1 68.184
 *   Acc@1 69.061
 *   Acc@1 69.013
 *   Acc@1 69.089
 *   Acc@1 65.842
 *   Acc@1 65.612
Training for 300 epoch: 67.32236842105263
Training for 600 epoch: 73.45723684210526
Training for 1000 epoch: 72.34210526315789
Training for 300 epoch: 67.6825
Training for 600 epoch: 73.62562499999999
Training for 1000 epoch: 72.419375
[[67.32236842105263, 73.45723684210526, 72.34210526315789], [67.6825, 73.62562499999999, 72.419375]]
train loss 0.5330209443728129, epoch 394, best loss 0.2624552794933319, best_epoch 394
GPU_0_using curriculum 40 with window 40
Epoch: [395][20/30]	Time  1.486 ( 1.515)	Data  0.038 ( 0.059)	InnerLoop  0.629 ( 0.637)	Loss 4.9955e-01 (4.6944e-01)	Acc@1  82.35 ( 83.50)
The current update step is 11880
GPU_0_using curriculum 40 with window 40
Epoch: [396][20/30]	Time  1.481 ( 1.504)	Data  0.037 ( 0.064)	InnerLoop  0.624 ( 0.624)	Loss 5.9507e-01 (4.6842e-01)	Acc@1  76.39 ( 83.27)
The current update step is 11910
GPU_0_using curriculum 40 with window 40
Epoch: [397][20/30]	Time  1.474 ( 1.501)	Data  0.037 ( 0.059)	InnerLoop  0.622 ( 0.628)	Loss 4.5070e-01 (4.8959e-01)	Acc@1  84.01 ( 82.56)
The current update step is 11940
GPU_0_using curriculum 40 with window 40
Epoch: [398][20/30]	Time  1.469 ( 1.500)	Data  0.036 ( 0.059)	InnerLoop  0.619 ( 0.627)	Loss 4.2485e-01 (4.5847e-01)	Acc@1  86.04 ( 84.14)
The current update step is 11970
GPU_0_using curriculum 40 with window 40
Epoch: [399][20/30]	Time  1.486 ( 1.503)	Data  0.036 ( 0.053)	InnerLoop  0.629 ( 0.635)	Loss 4.4744e-01 (4.6918e-01)	Acc@1  84.20 ( 83.40)
The current update step is 12000
The current seed is 17931237143506502387
The current lr is: 0.0015
Testing Results:
 *   Acc@1 47.526
 *   Acc@1 47.071
 *   Acc@1 46.053
 *   Acc@1 46.509
 *   Acc@1 46.592
 *   Acc@1 47.054
 *   Acc@1 68.026
 *   Acc@1 67.574
 *   Acc@1 66.789
 *   Acc@1 66.695
 *   Acc@1 67.079
 *   Acc@1 66.677
 *   Acc@1 64.671
 *   Acc@1 64.637
 *   Acc@1 65.526
 *   Acc@1 65.687
 *   Acc@1 65.908
 *   Acc@1 66.032
 *   Acc@1 54.592
 *   Acc@1 54.535
 *   Acc@1 49.947
 *   Acc@1 50.027
 *   Acc@1 49.039
 *   Acc@1 49.112
Training for 300 epoch: 58.70394736842105
Training for 600 epoch: 57.07894736842105
Training for 1000 epoch: 57.1546052631579
Training for 300 epoch: 58.45416666666667
Training for 600 epoch: 57.229375
Training for 1000 epoch: 57.21875
[[58.70394736842105, 57.07894736842105, 57.1546052631579], [58.45416666666667, 57.229375, 57.21875]]
train loss 0.836534974193573, epoch 399, best loss 0.2624552794933319, best_epoch 394
GPU_0_using curriculum 40 with window 40
Epoch: [400][20/30]	Time  1.610 ( 1.518)	Data  0.154 ( 0.066)	InnerLoop  0.629 ( 0.632)	Loss 4.7135e-01 (4.9279e-01)	Acc@1  83.89 ( 82.42)
The current update step is 12030
GPU_0_using curriculum 40 with window 40
Epoch: [401][20/30]	Time  1.611 ( 1.528)	Data  0.036 ( 0.055)	InnerLoop  0.749 ( 0.650)	Loss 4.7229e-01 (4.6861e-01)	Acc@1  84.40 ( 83.59)
The current update step is 12060
GPU_0_using curriculum 40 with window 40
Epoch: [402][20/30]	Time  1.499 ( 1.522)	Data  0.039 ( 0.049)	InnerLoop  0.639 ( 0.651)	Loss 4.9890e-01 (4.8673e-01)	Acc@1  82.42 ( 82.68)
The current update step is 12090
GPU_0_using curriculum 40 with window 40
Epoch: [403][20/30]	Time  1.507 ( 1.523)	Data  0.040 ( 0.055)	InnerLoop  0.644 ( 0.644)	Loss 5.0858e-01 (4.6958e-01)	Acc@1  82.96 ( 83.46)
The current update step is 12120
GPU_0_using curriculum 40 with window 40
Epoch: [404][20/30]	Time  1.489 ( 1.522)	Data  0.036 ( 0.043)	InnerLoop  0.632 ( 0.655)	Loss 4.6679e-01 (4.9152e-01)	Acc@1  82.62 ( 82.82)
The current update step is 12150
The current seed is 10650043888504407282
The current lr is: 0.0015
Testing Results:
 *   Acc@1 70.842
 *   Acc@1 71.251
 *   Acc@1 70.539
 *   Acc@1 70.779
 *   Acc@1 70.711
 *   Acc@1 70.784
 *   Acc@1 76.618
 *   Acc@1 76.716
 *   Acc@1 76.947
 *   Acc@1 77.275
 *   Acc@1 76.947
 *   Acc@1 77.479
 *   Acc@1 74.658
 *   Acc@1 74.778
 *   Acc@1 73.763
 *   Acc@1 74.166
 *   Acc@1 73.684
 *   Acc@1 73.558
 *   Acc@1 72.368
 *   Acc@1 72.198
 *   Acc@1 69.000
 *   Acc@1 69.287
 *   Acc@1 68.974
 *   Acc@1 69.431
Training for 300 epoch: 73.6217105263158
Training for 600 epoch: 72.5625
Training for 1000 epoch: 72.57894736842105
Training for 300 epoch: 73.73541666666667
Training for 600 epoch: 72.87687500000001
Training for 1000 epoch: 72.813125
[[73.6217105263158, 72.5625, 72.57894736842105], [73.73541666666667, 72.87687500000001, 72.813125]]
train loss 0.4617602163473765, epoch 404, best loss 0.2624552794933319, best_epoch 394
GPU_0_using curriculum 40 with window 40
Epoch: [405][20/30]	Time  1.497 ( 1.523)	Data  0.037 ( 0.055)	InnerLoop  0.633 ( 0.645)	Loss 5.0492e-01 (4.7134e-01)	Acc@1  82.76 ( 83.45)
The current update step is 12180
GPU_0_using curriculum 40 with window 40
Epoch: [406][20/30]	Time  1.625 ( 1.525)	Data  0.157 ( 0.060)	InnerLoop  0.643 ( 0.643)	Loss 5.1977e-01 (4.8506e-01)	Acc@1  81.40 ( 82.93)
The current update step is 12210
GPU_0_using curriculum 40 with window 40
Epoch: [407][20/30]	Time  1.482 ( 1.523)	Data  0.036 ( 0.037)	InnerLoop  0.626 ( 0.663)	Loss 4.8055e-01 (4.6314e-01)	Acc@1  82.81 ( 83.64)
The current update step is 12240
GPU_0_using curriculum 40 with window 40
Epoch: [408][20/30]	Time  1.499 ( 1.522)	Data  0.036 ( 0.049)	InnerLoop  0.635 ( 0.651)	Loss 4.3240e-01 (4.8055e-01)	Acc@1  85.64 ( 82.92)
The current update step is 12270
GPU_0_using curriculum 40 with window 40
Epoch: [409][20/30]	Time  1.486 ( 1.517)	Data  0.037 ( 0.060)	InnerLoop  0.624 ( 0.636)	Loss 4.4614e-01 (4.7497e-01)	Acc@1  84.28 ( 83.37)
The current update step is 12300
The current seed is 833304611246538826
The current lr is: 0.0015
Testing Results:
 *   Acc@1 79.855
 *   Acc@1 79.237
 *   Acc@1 75.500
 *   Acc@1 75.492
 *   Acc@1 74.882
 *   Acc@1 74.824
 *   Acc@1 65.303
 *   Acc@1 65.168
 *   Acc@1 64.092
 *   Acc@1 64.864
 *   Acc@1 64.566
 *   Acc@1 64.598
 *   Acc@1 61.645
 *   Acc@1 62.273
 *   Acc@1 62.684
 *   Acc@1 63.431
 *   Acc@1 62.658
 *   Acc@1 63.637
 *   Acc@1 69.316
 *   Acc@1 69.704
 *   Acc@1 70.184
 *   Acc@1 70.384
 *   Acc@1 70.211
 *   Acc@1 70.560
Training for 300 epoch: 69.02960526315789
Training for 600 epoch: 68.11513157894737
Training for 1000 epoch: 68.07894736842105
Training for 300 epoch: 69.095625
Training for 600 epoch: 68.54270833333334
Training for 1000 epoch: 68.40479166666667
[[69.02960526315789, 68.11513157894737, 68.07894736842105], [69.095625, 68.54270833333334, 68.40479166666667]]
train loss 0.39696985230445864, epoch 409, best loss 0.2624552794933319, best_epoch 394
GPU_0_using curriculum 40 with window 40
Epoch: [410][20/30]	Time  1.496 ( 1.523)	Data  0.036 ( 0.049)	InnerLoop  0.630 ( 0.651)	Loss 4.7129e-01 (4.9331e-01)	Acc@1  83.69 ( 82.76)
The current update step is 12330
GPU_0_using curriculum 40 with window 40
Epoch: [411][20/30]	Time  1.484 ( 1.525)	Data  0.036 ( 0.062)	InnerLoop  0.629 ( 0.638)	Loss 4.3009e-01 (4.5015e-01)	Acc@1  85.30 ( 84.12)
The current update step is 12360
GPU_0_using curriculum 40 with window 40
Epoch: [412][20/30]	Time  1.492 ( 1.514)	Data  0.040 ( 0.048)	InnerLoop  0.626 ( 0.643)	Loss 4.9847e-01 (4.6802e-01)	Acc@1  83.15 ( 83.50)
The current update step is 12390
GPU_0_using curriculum 40 with window 40
Epoch: [413][20/30]	Time  1.484 ( 1.515)	Data  0.037 ( 0.066)	InnerLoop  0.621 ( 0.627)	Loss 4.8954e-01 (4.7594e-01)	Acc@1  83.47 ( 83.38)
The current update step is 12420
GPU_0_using curriculum 40 with window 40
Epoch: [414][20/30]	Time  1.497 ( 1.523)	Data  0.037 ( 0.066)	InnerLoop  0.635 ( 0.634)	Loss 4.2432e-01 (4.5718e-01)	Acc@1  84.89 ( 83.97)
The current update step is 12450
The current seed is 17706370044205640190
The current lr is: 0.0015
Testing Results:
 *   Acc@1 66.737
 *   Acc@1 66.954
 *   Acc@1 68.645
 *   Acc@1 69.230
 *   Acc@1 68.711
 *   Acc@1 68.727
 *   Acc@1 77.447
 *   Acc@1 77.956
 *   Acc@1 77.197
 *   Acc@1 77.835
 *   Acc@1 77.329
 *   Acc@1 77.924
 *   Acc@1 37.224
 *   Acc@1 37.638
 *   Acc@1 38.250
 *   Acc@1 39.187
 *   Acc@1 39.803
 *   Acc@1 40.157
 *   Acc@1 46.868
 *   Acc@1 47.303
 *   Acc@1 49.355
 *   Acc@1 49.638
 *   Acc@1 50.289
 *   Acc@1 49.967
Training for 300 epoch: 57.06907894736842
Training for 600 epoch: 58.36184210526316
Training for 1000 epoch: 59.0328947368421
Training for 300 epoch: 57.462500000000006
Training for 600 epoch: 58.9725
Training for 1000 epoch: 59.19354166666667
[[57.06907894736842, 58.36184210526316, 59.0328947368421], [57.462500000000006, 58.9725, 59.19354166666667]]
train loss 0.7575509074846903, epoch 414, best loss 0.2624552794933319, best_epoch 394
GPU_0_using curriculum 40 with window 40
Epoch: [415][20/30]	Time  1.503 ( 1.524)	Data  0.039 ( 0.061)	InnerLoop  0.632 ( 0.638)	Loss 5.0681e-01 (4.7909e-01)	Acc@1  81.93 ( 83.19)
The current update step is 12480
GPU_0_using curriculum 40 with window 40
Epoch: [416][20/30]	Time  1.487 ( 1.516)	Data  0.035 ( 0.066)	InnerLoop  0.625 ( 0.626)	Loss 4.8391e-01 (4.9642e-01)	Acc@1  83.52 ( 81.94)
The current update step is 12510
GPU_0_using curriculum 40 with window 40
Epoch: [417][20/30]	Time  1.499 ( 1.517)	Data  0.039 ( 0.060)	InnerLoop  0.633 ( 0.632)	Loss 4.9292e-01 (4.6837e-01)	Acc@1  83.20 ( 83.80)
The current update step is 12540
GPU_0_using curriculum 40 with window 40
Epoch: [418][20/30]	Time  1.490 ( 1.516)	Data  0.037 ( 0.060)	InnerLoop  0.619 ( 0.632)	Loss 4.4193e-01 (4.6485e-01)	Acc@1  84.33 ( 83.74)
The current update step is 12570
GPU_0_using curriculum 40 with window 40
Epoch: [419][20/30]	Time  1.494 ( 1.514)	Data  0.037 ( 0.055)	InnerLoop  0.627 ( 0.638)	Loss 4.1303e-01 (4.6549e-01)	Acc@1  85.38 ( 83.68)
The current update step is 12600
The current seed is 7065405699516131014
The current lr is: 0.0015
Testing Results:
 *   Acc@1 60.303
 *   Acc@1 60.307
 *   Acc@1 57.868
 *   Acc@1 57.744
 *   Acc@1 58.171
 *   Acc@1 58.102
 *   Acc@1 71.908
 *   Acc@1 71.605
 *   Acc@1 74.605
 *   Acc@1 74.220
 *   Acc@1 74.605
 *   Acc@1 74.297
 *   Acc@1 67.645
 *   Acc@1 67.826
 *   Acc@1 68.697
 *   Acc@1 68.977
 *   Acc@1 68.553
 *   Acc@1 68.767
 *   Acc@1 50.842
 *   Acc@1 51.300
 *   Acc@1 53.329
 *   Acc@1 53.482
 *   Acc@1 53.776
 *   Acc@1 54.191
Training for 300 epoch: 62.67434210526316
Training for 600 epoch: 63.625
Training for 1000 epoch: 63.776315789473685
Training for 300 epoch: 62.759375000000006
Training for 600 epoch: 63.605625
Training for 1000 epoch: 63.83916666666667
[[62.67434210526316, 63.625, 63.776315789473685], [62.759375000000006, 63.605625, 63.83916666666667]]
train loss 0.8285730206807455, epoch 419, best loss 0.2624552794933319, best_epoch 394
GPU_0_using curriculum 40 with window 40
Epoch: [420][20/30]	Time  1.609 ( 1.521)	Data  0.156 ( 0.066)	InnerLoop  0.623 ( 0.632)	Loss 4.3828e-01 (4.7069e-01)	Acc@1  84.40 ( 83.74)
The current update step is 12630
GPU_0_using curriculum 40 with window 40
Epoch: [421][20/30]	Time  1.592 ( 1.520)	Data  0.034 ( 0.055)	InnerLoop  0.740 ( 0.643)	Loss 4.6976e-01 (4.6292e-01)	Acc@1  83.76 ( 83.79)
The current update step is 12660
GPU_0_using curriculum 40 with window 40
Epoch: [422][20/30]	Time  1.510 ( 1.506)	Data  0.039 ( 0.048)	InnerLoop  0.638 ( 0.640)	Loss 4.6425e-01 (4.6047e-01)	Acc@1  84.11 ( 83.96)
The current update step is 12690
GPU_0_using curriculum 40 with window 40
Epoch: [423][20/30]	Time  1.473 ( 1.499)	Data  0.036 ( 0.053)	InnerLoop  0.620 ( 0.632)	Loss 5.0287e-01 (4.9230e-01)	Acc@1  83.11 ( 82.93)
The current update step is 12720
GPU_0_using curriculum 40 with window 40
Epoch: [424][20/30]	Time  1.480 ( 1.501)	Data  0.036 ( 0.042)	InnerLoop  0.625 ( 0.643)	Loss 4.6333e-01 (4.6070e-01)	Acc@1  84.40 ( 83.74)
The current update step is 12750
The current seed is 9913317811101127656
The current lr is: 0.0015
Testing Results:
 *   Acc@1 65.408
 *   Acc@1 66.373
 *   Acc@1 67.263
 *   Acc@1 68.245
 *   Acc@1 67.908
 *   Acc@1 69.064
 *   Acc@1 65.526
 *   Acc@1 66.377
 *   Acc@1 65.816
 *   Acc@1 66.305
 *   Acc@1 64.974
 *   Acc@1 66.338
 *   Acc@1 72.553
 *   Acc@1 72.937
 *   Acc@1 72.829
 *   Acc@1 73.173
 *   Acc@1 72.987
 *   Acc@1 73.429
 *   Acc@1 77.355
 *   Acc@1 77.950
 *   Acc@1 77.934
 *   Acc@1 78.051
 *   Acc@1 77.842
 *   Acc@1 78.224
Training for 300 epoch: 70.21052631578948
Training for 600 epoch: 70.96052631578947
Training for 1000 epoch: 70.92763157894737
Training for 300 epoch: 70.90916666666666
Training for 600 epoch: 71.44354166666668
Training for 1000 epoch: 71.76374999999999
[[70.21052631578948, 70.96052631578947, 70.92763157894737], [70.90916666666666, 71.44354166666668, 71.76374999999999]]
train loss 0.3201335209210714, epoch 424, best loss 0.2624552794933319, best_epoch 394
GPU_0_using curriculum 40 with window 40
Epoch: [425][20/30]	Time  1.477 ( 1.500)	Data  0.036 ( 0.053)	InnerLoop  0.615 ( 0.632)	Loss 4.3934e-01 (4.4451e-01)	Acc@1  84.72 ( 84.47)
The current update step is 12780
GPU_0_using curriculum 40 with window 40
Epoch: [426][20/30]	Time  1.586 ( 1.505)	Data  0.152 ( 0.058)	InnerLoop  0.622 ( 0.632)	Loss 4.5035e-01 (4.7051e-01)	Acc@1  84.30 ( 83.44)
The current update step is 12810
GPU_0_using curriculum 40 with window 40
Epoch: [427][20/30]	Time  1.478 ( 1.500)	Data  0.034 ( 0.036)	InnerLoop  0.623 ( 0.649)	Loss 4.4412e-01 (4.8664e-01)	Acc@1  84.40 ( 83.14)
The current update step is 12840
GPU_0_using curriculum 40 with window 40
Epoch: [428][20/30]	Time  1.482 ( 1.505)	Data  0.036 ( 0.047)	InnerLoop  0.628 ( 0.641)	Loss 4.6341e-01 (4.8799e-01)	Acc@1  83.62 ( 82.83)
The current update step is 12870
GPU_0_using curriculum 40 with window 40
Epoch: [429][20/30]	Time  1.520 ( 1.511)	Data  0.041 ( 0.060)	InnerLoop  0.645 ( 0.631)	Loss 6.0214e-01 (4.8822e-01)	Acc@1  76.88 ( 82.94)
The current update step is 12900
The current seed is 14425660652098127473
The current lr is: 0.0015
Testing Results:
 *   Acc@1 71.303
 *   Acc@1 71.424
 *   Acc@1 72.053
 *   Acc@1 72.282
 *   Acc@1 72.487
 *   Acc@1 72.161
 *   Acc@1 72.579
 *   Acc@1 72.895
 *   Acc@1 73.184
 *   Acc@1 73.440
 *   Acc@1 60.895
 *   Acc@1 60.925
 *   Acc@1 74.908
 *   Acc@1 74.969
 *   Acc@1 76.118
 *   Acc@1 76.068
 *   Acc@1 76.132
 *   Acc@1 76.365
 *   Acc@1 55.592
 *   Acc@1 56.060
 *   Acc@1 57.211
 *   Acc@1 57.727
 *   Acc@1 64.592
 *   Acc@1 65.234
Training for 300 epoch: 68.59539473684211
Training for 600 epoch: 69.64144736842105
Training for 1000 epoch: 68.5263157894737
Training for 300 epoch: 68.83708333333334
Training for 600 epoch: 69.879375
Training for 1000 epoch: 68.67125
[[68.59539473684211, 69.64144736842105, 68.5263157894737], [68.83708333333334, 69.879375, 68.67125]]
train loss 0.4315824774106344, epoch 429, best loss 0.2624552794933319, best_epoch 394
GPU_0_using curriculum 40 with window 40
Epoch: [430][20/30]	Time  1.480 ( 1.510)	Data  0.037 ( 0.050)	InnerLoop  0.622 ( 0.641)	Loss 5.0739e-01 (4.8332e-01)	Acc@1  82.01 ( 83.14)
The current update step is 12930
GPU_0_using curriculum 40 with window 40
Epoch: [431][20/30]	Time  1.487 ( 1.513)	Data  0.040 ( 0.061)	InnerLoop  0.624 ( 0.631)	Loss 4.1743e-01 (4.6616e-01)	Acc@1  85.38 ( 83.52)
The current update step is 12960
GPU_0_using curriculum 40 with window 40
Epoch: [432][20/30]	Time  1.544 ( 1.541)	Data  0.044 ( 0.052)	InnerLoop  0.655 ( 0.657)	Loss 4.7188e-01 (4.5455e-01)	Acc@1  83.69 ( 84.20)
The current update step is 12990
GPU_0_using curriculum 40 with window 40
Epoch: [433][20/30]	Time  1.508 ( 1.506)	Data  0.042 ( 0.067)	InnerLoop  0.631 ( 0.622)	Loss 4.1985e-01 (4.8429e-01)	Acc@1  85.50 ( 83.00)
The current update step is 13020
GPU_0_using curriculum 40 with window 40
Epoch: [434][20/30]	Time  1.487 ( 1.530)	Data  0.040 ( 0.069)	InnerLoop  0.624 ( 0.637)	Loss 4.7225e-01 (4.8679e-01)	Acc@1  82.06 ( 82.93)
The current update step is 13050
The current seed is 10932771233821306985
The current lr is: 0.0015
Testing Results:
 *   Acc@1 73.092
 *   Acc@1 73.142
 *   Acc@1 72.539
 *   Acc@1 72.653
 *   Acc@1 72.539
 *   Acc@1 72.662
 *   Acc@1 71.184
 *   Acc@1 71.762
 *   Acc@1 69.079
 *   Acc@1 69.812
 *   Acc@1 69.355
 *   Acc@1 69.596
 *   Acc@1 75.579
 *   Acc@1 75.907
 *   Acc@1 76.421
 *   Acc@1 76.483
 *   Acc@1 76.408
 *   Acc@1 76.908
 *   Acc@1 67.803
 *   Acc@1 68.010
 *   Acc@1 52.250
 *   Acc@1 52.604
 *   Acc@1 52.816
 *   Acc@1 52.949
Training for 300 epoch: 71.91447368421052
Training for 600 epoch: 67.57236842105263
Training for 1000 epoch: 67.77960526315789
Training for 300 epoch: 72.20541666666666
Training for 600 epoch: 67.888125
Training for 1000 epoch: 68.02895833333334
[[71.91447368421052, 67.57236842105263, 67.77960526315789], [72.20541666666666, 67.888125, 68.02895833333334]]
train loss 0.7592161277135213, epoch 434, best loss 0.2624552794933319, best_epoch 394
GPU_0_using curriculum 40 with window 40
Epoch: [435][20/30]	Time  1.499 ( 1.526)	Data  0.037 ( 0.062)	InnerLoop  0.630 ( 0.640)	Loss 4.2307e-01 (4.6948e-01)	Acc@1  84.79 ( 83.50)
The current update step is 13080
GPU_0_using curriculum 40 with window 40
Epoch: [436][20/30]	Time  1.511 ( 1.519)	Data  0.042 ( 0.068)	InnerLoop  0.630 ( 0.626)	Loss 5.3010e-01 (4.6708e-01)	Acc@1  80.76 ( 83.88)
The current update step is 13110
GPU_0_using curriculum 40 with window 40
Epoch: [437][20/30]	Time  1.506 ( 1.524)	Data  0.046 ( 0.063)	InnerLoop  0.633 ( 0.634)	Loss 4.9344e-01 (4.9654e-01)	Acc@1  82.69 ( 82.44)
The current update step is 13140
GPU_0_using curriculum 40 with window 40
Epoch: [438][20/30]	Time  1.473 ( 1.517)	Data  0.037 ( 0.063)	InnerLoop  0.619 ( 0.631)	Loss 4.2603e-01 (4.6046e-01)	Acc@1  84.79 ( 83.79)
The current update step is 13170
GPU_0_using curriculum 40 with window 40
Epoch: [439][20/30]	Time  1.584 ( 1.613)	Data  0.047 ( 0.063)	InnerLoop  0.676 ( 0.686)	Loss 4.3180e-01 (4.5062e-01)	Acc@1  84.64 ( 84.30)
The current update step is 13200
The current seed is 17561803766217823213
The current lr is: 0.0015
Testing Results:
 *   Acc@1 75.711
 *   Acc@1 76.034
 *   Acc@1 76.697
 *   Acc@1 77.100
 *   Acc@1 76.579
 *   Acc@1 77.323
 *   Acc@1 72.316
 *   Acc@1 72.791
 *   Acc@1 72.789
 *   Acc@1 72.731
 *   Acc@1 72.513
 *   Acc@1 72.533
 *   Acc@1 71.697
 *   Acc@1 71.521
 *   Acc@1 72.039
 *   Acc@1 72.029
 *   Acc@1 71.947
 *   Acc@1 71.931
 *   Acc@1 73.947
 *   Acc@1 74.394
 *   Acc@1 72.987
 *   Acc@1 73.197
 *   Acc@1 72.776
 *   Acc@1 73.360
Training for 300 epoch: 73.41776315789474
Training for 600 epoch: 73.6282894736842
Training for 1000 epoch: 73.45394736842105
Training for 300 epoch: 73.68499999999999
Training for 600 epoch: 73.76416666666667
Training for 1000 epoch: 73.78687500000001
[[73.41776315789474, 73.6282894736842, 73.45394736842105], [73.68499999999999, 73.76416666666667, 73.78687500000001]]
train loss 0.4045746143023173, epoch 439, best loss 0.2624552794933319, best_epoch 394
GPU_0_using curriculum 40 with window 40
Epoch: [440][20/30]	Time  1.698 ( 1.594)	Data  0.172 ( 0.074)	InnerLoop  0.665 ( 0.668)	Loss 4.9478e-01 (4.7340e-01)	Acc@1  82.59 ( 83.41)
The current update step is 13230
GPU_0_using curriculum 40 with window 40
Epoch: [441][20/30]	Time  1.697 ( 1.592)	Data  0.041 ( 0.061)	InnerLoop  0.794 ( 0.678)	Loss 4.2595e-01 (4.5492e-01)	Acc@1  85.11 ( 84.12)
The current update step is 13260
GPU_0_using curriculum 40 with window 40
Epoch: [442][20/30]	Time  1.576 ( 1.594)	Data  0.043 ( 0.055)	InnerLoop  0.667 ( 0.684)	Loss 4.6972e-01 (4.5424e-01)	Acc@1  83.50 ( 84.03)
The current update step is 13290
GPU_0_using curriculum 40 with window 40
Epoch: [443][20/30]	Time  1.566 ( 1.593)	Data  0.044 ( 0.062)	InnerLoop  0.661 ( 0.677)	Loss 4.4907e-01 (4.6842e-01)	Acc@1  84.84 ( 83.82)
The current update step is 13320
GPU_0_using curriculum 40 with window 40
Epoch: [444][20/30]	Time  1.592 ( 1.597)	Data  0.044 ( 0.050)	InnerLoop  0.676 ( 0.691)	Loss 4.2334e-01 (4.4593e-01)	Acc@1  85.64 ( 84.42)
The current update step is 13350
The current seed is 8051988624951434757
The current lr is: 0.0015
Testing Results:
 *   Acc@1 62.382
 *   Acc@1 62.399
 *   Acc@1 66.408
 *   Acc@1 66.157
 *   Acc@1 67.711
 *   Acc@1 67.679
 *   Acc@1 71.658
 *   Acc@1 72.592
 *   Acc@1 72.921
 *   Acc@1 73.417
 *   Acc@1 73.526
 *   Acc@1 73.640
 *   Acc@1 58.434
 *   Acc@1 58.578
 *   Acc@1 64.145
 *   Acc@1 64.403
 *   Acc@1 64.132
 *   Acc@1 64.647
 *   Acc@1 65.132
 *   Acc@1 65.282
 *   Acc@1 73.816
 *   Acc@1 74.198
 *   Acc@1 73.579
 *   Acc@1 73.871
Training for 300 epoch: 64.40131578947368
Training for 600 epoch: 69.32236842105263
Training for 1000 epoch: 69.73684210526316
Training for 300 epoch: 64.71270833333332
Training for 600 epoch: 69.54375
Training for 1000 epoch: 69.95916666666666
[[64.40131578947368, 69.32236842105263, 69.73684210526316], [64.71270833333332, 69.54375, 69.95916666666666]]
train loss 0.32820414611498516, epoch 444, best loss 0.2624552794933319, best_epoch 394
GPU_0_using curriculum 40 with window 40
Epoch: [445][20/30]	Time  1.569 ( 1.589)	Data  0.043 ( 0.062)	InnerLoop  0.667 ( 0.674)	Loss 4.8034e-01 (4.7798e-01)	Acc@1  83.40 ( 83.10)
The current update step is 13380
GPU_0_using curriculum 40 with window 40
Epoch: [446][20/30]	Time  1.700 ( 1.606)	Data  0.172 ( 0.068)	InnerLoop  0.667 ( 0.680)	Loss 4.5957e-01 (4.4920e-01)	Acc@1  84.11 ( 84.47)
The current update step is 13410
GPU_0_using curriculum 40 with window 40
Epoch: [447][20/30]	Time  1.553 ( 1.587)	Data  0.042 ( 0.042)	InnerLoop  0.661 ( 0.692)	Loss 4.1793e-01 (4.6859e-01)	Acc@1  85.62 ( 83.86)
The current update step is 13440
GPU_0_using curriculum 40 with window 40
Epoch: [448][20/30]	Time  1.555 ( 1.585)	Data  0.042 ( 0.055)	InnerLoop  0.661 ( 0.679)	Loss 4.6608e-01 (4.7287e-01)	Acc@1  82.42 ( 83.63)
The current update step is 13470
GPU_0_using curriculum 40 with window 40
Epoch: [449][20/30]	Time  1.573 ( 1.593)	Data  0.044 ( 0.068)	InnerLoop  0.669 ( 0.671)	Loss 4.8781e-01 (4.5632e-01)	Acc@1  82.45 ( 84.09)
The current update step is 13500
The current seed is 1212748446683866021
The current lr is: 0.0015
Testing Results:
 *   Acc@1 45.461
 *   Acc@1 46.337
 *   Acc@1 45.645
 *   Acc@1 46.163
 *   Acc@1 45.382
 *   Acc@1 45.662
 *   Acc@1 72.671
 *   Acc@1 72.993
 *   Acc@1 67.724
 *   Acc@1 67.519
 *   Acc@1 68.553
 *   Acc@1 67.679
 *   Acc@1 56.947
 *   Acc@1 57.111
 *   Acc@1 75.961
 *   Acc@1 76.318
 *   Acc@1 76.000
 *   Acc@1 76.018
 *   Acc@1 61.303
 *   Acc@1 61.205
 *   Acc@1 62.974
 *   Acc@1 62.759
 *   Acc@1 62.329
 *   Acc@1 62.695
Training for 300 epoch: 59.0953947368421
Training for 600 epoch: 63.075657894736835
Training for 1000 epoch: 63.065789473684205
Training for 300 epoch: 59.41145833333333
Training for 600 epoch: 63.19
Training for 1000 epoch: 63.01354166666667
[[59.0953947368421, 63.075657894736835, 63.065789473684205], [59.41145833333333, 63.19, 63.01354166666667]]
train loss 0.5142067038536072, epoch 449, best loss 0.2624552794933319, best_epoch 394
GPU_0_using curriculum 40 with window 40
Epoch: [450][20/30]	Time  1.571 ( 1.603)	Data  0.045 ( 0.057)	InnerLoop  0.666 ( 0.688)	Loss 5.2221e-01 (4.5368e-01)	Acc@1  81.91 ( 84.12)
The current update step is 13530
GPU_0_using curriculum 40 with window 40
Epoch: [451][20/30]	Time  1.600 ( 1.607)	Data  0.046 ( 0.069)	InnerLoop  0.686 ( 0.678)	Loss 4.6726e-01 (4.6849e-01)	Acc@1  83.42 ( 83.47)
The current update step is 13560
GPU_0_using curriculum 40 with window 40
Epoch: [452][20/30]	Time  1.569 ( 1.618)	Data  0.044 ( 0.057)	InnerLoop  0.669 ( 0.698)	Loss 4.9436e-01 (4.6263e-01)	Acc@1  82.98 ( 84.00)
The current update step is 13590
GPU_0_using curriculum 40 with window 40
Epoch: [453][20/30]	Time  1.578 ( 1.611)	Data  0.044 ( 0.076)	InnerLoop  0.672 ( 0.674)	Loss 4.4455e-01 (4.4475e-01)	Acc@1  84.06 ( 84.48)
The current update step is 13620
GPU_0_using curriculum 40 with window 40
Epoch: [454][20/30]	Time  1.489 ( 1.541)	Data  0.036 ( 0.070)	InnerLoop  0.624 ( 0.639)	Loss 4.7503e-01 (4.5915e-01)	Acc@1  83.54 ( 83.78)
The current update step is 13650
The current seed is 12262306179420083768
The current lr is: 0.0015
Testing Results:
 *   Acc@1 71.289
 *   Acc@1 72.130
 *   Acc@1 71.763
 *   Acc@1 72.763
 *   Acc@1 71.829
 *   Acc@1 72.704
 *   Acc@1 50.289
 *   Acc@1 50.612
 *   Acc@1 59.026
 *   Acc@1 59.425
 *   Acc@1 59.553
 *   Acc@1 60.217
 *   Acc@1 69.711
 *   Acc@1 70.265
 *   Acc@1 68.947
 *   Acc@1 69.621
 *   Acc@1 68.684
 *   Acc@1 68.885
 *   Acc@1 48.224
 *   Acc@1 48.002
 *   Acc@1 51.132
 *   Acc@1 50.417
 *   Acc@1 50.724
 *   Acc@1 50.837
Training for 300 epoch: 59.878289473684205
Training for 600 epoch: 62.71710526315789
Training for 1000 epoch: 62.69736842105263
Training for 300 epoch: 60.252291666666665
Training for 600 epoch: 63.056666666666665
Training for 1000 epoch: 63.160833333333336
[[59.878289473684205, 62.71710526315789, 62.69736842105263], [60.252291666666665, 63.056666666666665, 63.160833333333336]]
train loss 0.8017764802296956, epoch 454, best loss 0.2624552794933319, best_epoch 454
GPU_0_using curriculum 40 with window 40
Epoch: [455][20/30]	Time  1.504 ( 1.541)	Data  0.040 ( 0.063)	InnerLoop  0.630 ( 0.646)	Loss 4.6216e-01 (4.6678e-01)	Acc@1  83.45 ( 83.81)
The current update step is 13680
GPU_0_using curriculum 40 with window 40
Epoch: [456][20/30]	Time  1.527 ( 1.537)	Data  0.038 ( 0.071)	InnerLoop  0.639 ( 0.633)	Loss 4.3697e-01 (4.6328e-01)	Acc@1  85.30 ( 83.92)
The current update step is 13710
GPU_0_using curriculum 40 with window 40
Epoch: [457][20/30]	Time  1.502 ( 1.537)	Data  0.039 ( 0.064)	InnerLoop  0.628 ( 0.639)	Loss 4.7147e-01 (4.5219e-01)	Acc@1  83.64 ( 84.07)
The current update step is 13740
GPU_0_using curriculum 40 with window 40
Epoch: [458][20/30]	Time  1.553 ( 1.546)	Data  0.043 ( 0.065)	InnerLoop  0.657 ( 0.644)	Loss 4.7093e-01 (4.5446e-01)	Acc@1  83.52 ( 83.96)
The current update step is 13770
GPU_0_using curriculum 40 with window 40
Epoch: [459][20/30]	Time  1.534 ( 1.548)	Data  0.044 ( 0.059)	InnerLoop  0.647 ( 0.656)	Loss 4.2709e-01 (4.3991e-01)	Acc@1  85.33 ( 84.57)
The current update step is 13800
The current seed is 10611958119941791410
The current lr is: 0.0015
Testing Results:
 *   Acc@1 64.434
 *   Acc@1 64.610
 *   Acc@1 66.553
 *   Acc@1 66.522
 *   Acc@1 66.013
 *   Acc@1 66.087
 *   Acc@1 57.618
 *   Acc@1 57.446
 *   Acc@1 67.263
 *   Acc@1 67.864
 *   Acc@1 65.645
 *   Acc@1 66.913
 *   Acc@1 64.513
 *   Acc@1 65.313
 *   Acc@1 69.605
 *   Acc@1 70.414
 *   Acc@1 69.882
 *   Acc@1 70.804
 *   Acc@1 72.711
 *   Acc@1 72.523
 *   Acc@1 68.237
 *   Acc@1 68.876
 *   Acc@1 68.026
 *   Acc@1 68.609
Training for 300 epoch: 64.81907894736842
Training for 600 epoch: 67.91447368421053
Training for 1000 epoch: 67.39144736842105
Training for 300 epoch: 64.973125
Training for 600 epoch: 68.41916666666667
Training for 1000 epoch: 68.10333333333334
[[64.81907894736842, 67.91447368421053, 67.39144736842105], [64.973125, 68.41916666666667, 68.10333333333334]]
train loss 0.4595138530731201, epoch 459, best loss 0.2624552794933319, best_epoch 454
GPU_0_using curriculum 40 with window 40
Epoch: [460][20/30]	Time  1.609 ( 1.528)	Data  0.154 ( 0.068)	InnerLoop  0.626 ( 0.635)	Loss 4.8374e-01 (4.6465e-01)	Acc@1  82.67 ( 83.63)
The current update step is 13830
GPU_0_using curriculum 40 with window 40
Epoch: [461][20/30]	Time  1.622 ( 1.538)	Data  0.039 ( 0.057)	InnerLoop  0.752 ( 0.652)	Loss 4.3542e-01 (4.7131e-01)	Acc@1  85.06 ( 83.32)
The current update step is 13860
GPU_0_using curriculum 40 with window 40
Epoch: [462][20/30]	Time  1.478 ( 1.528)	Data  0.037 ( 0.050)	InnerLoop  0.620 ( 0.650)	Loss 5.0197e-01 (4.5880e-01)	Acc@1  80.59 ( 84.20)
The current update step is 13890
GPU_0_using curriculum 40 with window 40
Epoch: [463][20/30]	Time  1.559 ( 1.526)	Data  0.044 ( 0.056)	InnerLoop  0.656 ( 0.641)	Loss 4.4692e-01 (4.6969e-01)	Acc@1  84.91 ( 83.54)
The current update step is 13920
GPU_0_using curriculum 40 with window 40
Epoch: [464][20/30]	Time  1.487 ( 1.532)	Data  0.036 ( 0.044)	InnerLoop  0.627 ( 0.658)	Loss 4.6743e-01 (4.6534e-01)	Acc@1  84.30 ( 83.69)
The current update step is 13950
The current seed is 2082417281283137208
The current lr is: 0.0015
Testing Results:
 *   Acc@1 75.026
 *   Acc@1 74.869
 *   Acc@1 75.289
 *   Acc@1 76.168
 *   Acc@1 76.250
 *   Acc@1 76.465
 *   Acc@1 66.447
 *   Acc@1 66.436
 *   Acc@1 64.566
 *   Acc@1 64.844
 *   Acc@1 64.961
 *   Acc@1 65.145
 *   Acc@1 56.355
 *   Acc@1 56.242
 *   Acc@1 62.500
 *   Acc@1 63.032
 *   Acc@1 62.079
 *   Acc@1 62.431
 *   Acc@1 72.947
 *   Acc@1 73.289
 *   Acc@1 72.855
 *   Acc@1 72.866
 *   Acc@1 72.053
 *   Acc@1 72.353
Training for 300 epoch: 67.69407894736841
Training for 600 epoch: 68.80263157894737
Training for 1000 epoch: 68.83552631578948
Training for 300 epoch: 67.70916666666668
Training for 600 epoch: 69.22749999999999
Training for 1000 epoch: 69.09854166666668
[[67.69407894736841, 68.80263157894737, 68.83552631578948], [67.70916666666668, 69.22749999999999, 69.09854166666668]]
train loss 0.40934846742947895, epoch 464, best loss 0.2624552794933319, best_epoch 454
GPU_0_using curriculum 40 with window 40
Epoch: [465][20/30]	Time  1.476 ( 1.513)	Data  0.037 ( 0.054)	InnerLoop  0.620 ( 0.639)	Loss 4.7977e-01 (4.6182e-01)	Acc@1  83.01 ( 83.91)
The current update step is 13980
GPU_0_using curriculum 40 with window 40
Epoch: [466][20/30]	Time  1.606 ( 1.528)	Data  0.157 ( 0.060)	InnerLoop  0.622 ( 0.640)	Loss 4.6815e-01 (4.6181e-01)	Acc@1  84.35 ( 84.05)
The current update step is 14010
GPU_0_using curriculum 40 with window 40
Epoch: [467][20/30]	Time  1.475 ( 1.499)	Data  0.036 ( 0.035)	InnerLoop  0.623 ( 0.649)	Loss 4.1042e-01 (4.6478e-01)	Acc@1  85.79 ( 83.89)
The current update step is 14040
GPU_0_using curriculum 40 with window 40
Epoch: [468][20/30]	Time  1.485 ( 1.509)	Data  0.036 ( 0.048)	InnerLoop  0.621 ( 0.640)	Loss 5.1118e-01 (4.7490e-01)	Acc@1  81.93 ( 83.40)
The current update step is 14070
GPU_0_using curriculum 40 with window 40
Epoch: [469][20/30]	Time  1.531 ( 1.521)	Data  0.039 ( 0.061)	InnerLoop  0.643 ( 0.634)	Loss 4.3290e-01 (4.6397e-01)	Acc@1  84.99 ( 83.75)
The current update step is 14100
The current seed is 14025031025527830764
The current lr is: 0.0015
Testing Results:
 *   Acc@1 72.697
 *   Acc@1 73.114
 *   Acc@1 72.855
 *   Acc@1 73.205
 *   Acc@1 72.355
 *   Acc@1 72.833
 *   Acc@1 45.908
 *   Acc@1 46.580
 *   Acc@1 47.816
 *   Acc@1 48.307
 *   Acc@1 47.039
 *   Acc@1 48.271
 *   Acc@1 73.974
 *   Acc@1 74.315
 *   Acc@1 76.342
 *   Acc@1 76.232
 *   Acc@1 69.776
 *   Acc@1 70.550
 *   Acc@1 64.184
 *   Acc@1 63.972
 *   Acc@1 71.816
 *   Acc@1 71.838
 *   Acc@1 72.039
 *   Acc@1 71.577
Training for 300 epoch: 64.1907894736842
Training for 600 epoch: 67.20723684210526
Training for 1000 epoch: 65.30263157894737
Training for 300 epoch: 64.49520833333332
Training for 600 epoch: 67.39520833333333
Training for 1000 epoch: 65.80770833333332
[[64.1907894736842, 67.20723684210526, 65.30263157894737], [64.49520833333332, 67.39520833333333, 65.80770833333332]]
train loss 0.4253419921239217, epoch 469, best loss 0.2624552794933319, best_epoch 454
GPU_0_using curriculum 40 with window 40
Epoch: [470][20/30]	Time  1.497 ( 1.525)	Data  0.038 ( 0.050)	InnerLoop  0.632 ( 0.650)	Loss 4.3534e-01 (4.6295e-01)	Acc@1  85.57 ( 83.73)
The current update step is 14130
GPU_0_using curriculum 40 with window 40
Epoch: [471][20/30]	Time  1.489 ( 1.527)	Data  0.036 ( 0.062)	InnerLoop  0.627 ( 0.639)	Loss 4.9161e-01 (4.8553e-01)	Acc@1  83.47 ( 83.16)
The current update step is 14160
GPU_0_using curriculum 40 with window 40
Epoch: [472][20/30]	Time  1.482 ( 1.518)	Data  0.037 ( 0.049)	InnerLoop  0.623 ( 0.646)	Loss 4.8449e-01 (4.8171e-01)	Acc@1  83.35 ( 83.18)
The current update step is 14190
GPU_0_using curriculum 40 with window 40
Epoch: [473][20/30]	Time  1.488 ( 1.512)	Data  0.038 ( 0.066)	InnerLoop  0.631 ( 0.626)	Loss 4.4572e-01 (4.6615e-01)	Acc@1  83.57 ( 83.69)
The current update step is 14220
GPU_0_using curriculum 40 with window 40
Epoch: [474][20/30]	Time  1.481 ( 1.513)	Data  0.036 ( 0.065)	InnerLoop  0.628 ( 0.631)	Loss 5.5837e-01 (4.7446e-01)	Acc@1  81.62 ( 83.00)
The current update step is 14250
The current seed is 14715951069713872643
The current lr is: 0.0015
Testing Results:
 *   Acc@1 59.592
 *   Acc@1 59.649
 *   Acc@1 62.447
 *   Acc@1 62.661
 *   Acc@1 63.500
 *   Acc@1 63.843
 *   Acc@1 61.776
 *   Acc@1 61.942
 *   Acc@1 62.592
 *   Acc@1 62.416
 *   Acc@1 61.908
 *   Acc@1 61.685
 *   Acc@1 29.882
 *   Acc@1 30.138
 *   Acc@1 29.500
 *   Acc@1 29.358
 *   Acc@1 29.145
 *   Acc@1 29.240
 *   Acc@1 59.368
 *   Acc@1 60.128
 *   Acc@1 43.711
 *   Acc@1 44.111
 *   Acc@1 43.447
 *   Acc@1 43.581
Training for 300 epoch: 52.6546052631579
Training for 600 epoch: 49.5625
Training for 1000 epoch: 49.5
Training for 300 epoch: 52.964375
Training for 600 epoch: 49.636250000000004
Training for 1000 epoch: 49.58729166666667
[[52.6546052631579, 49.5625, 49.5], [52.964375, 49.636250000000004, 49.58729166666667]]
train loss 1.136118162091573, epoch 474, best loss 0.2624552794933319, best_epoch 454
GPU_0_using curriculum 40 with window 40
Epoch: [475][20/30]	Time  1.485 ( 1.511)	Data  0.037 ( 0.059)	InnerLoop  0.631 ( 0.636)	Loss 4.7992e-01 (4.9167e-01)	Acc@1  82.15 ( 82.55)
The current update step is 14280
GPU_0_using curriculum 40 with window 40
Epoch: [476][20/30]	Time  1.484 ( 1.508)	Data  0.034 ( 0.066)	InnerLoop  0.630 ( 0.624)	Loss 4.2113e-01 (4.6030e-01)	Acc@1  85.35 ( 83.78)
The current update step is 14310
GPU_0_using curriculum 40 with window 40
Epoch: [477][20/30]	Time  1.478 ( 1.504)	Data  0.035 ( 0.059)	InnerLoop  0.624 ( 0.628)	Loss 4.3302e-01 (4.7000e-01)	Acc@1  84.79 ( 83.91)
The current update step is 14340
GPU_0_using curriculum 40 with window 40
Epoch: [478][20/30]	Time  1.467 ( 1.505)	Data  0.037 ( 0.059)	InnerLoop  0.615 ( 0.629)	Loss 4.1858e-01 (4.5931e-01)	Acc@1  85.35 ( 84.04)
The current update step is 14370
GPU_0_using curriculum 40 with window 40
Epoch: [479][20/30]	Time  1.472 ( 1.505)	Data  0.035 ( 0.052)	InnerLoop  0.624 ( 0.636)	Loss 4.8337e-01 (4.7058e-01)	Acc@1  82.57 ( 83.61)
The current update step is 14400
The current seed is 3681858784983542964
The current lr is: 0.0015
Testing Results:
 *   Acc@1 71.513
 *   Acc@1 70.967
 *   Acc@1 72.474
 *   Acc@1 71.991
 *   Acc@1 73.053
 *   Acc@1 72.703
 *   Acc@1 57.592
 *   Acc@1 57.596
 *   Acc@1 62.171
 *   Acc@1 62.383
 *   Acc@1 62.500
 *   Acc@1 62.763
 *   Acc@1 57.605
 *   Acc@1 58.086
 *   Acc@1 58.066
 *   Acc@1 58.532
 *   Acc@1 58.974
 *   Acc@1 59.177
 *   Acc@1 73.237
 *   Acc@1 73.200
 *   Acc@1 72.158
 *   Acc@1 72.207
 *   Acc@1 72.237
 *   Acc@1 72.196
Training for 300 epoch: 64.98684210526316
Training for 600 epoch: 66.21710526315789
Training for 1000 epoch: 66.69078947368422
Training for 300 epoch: 64.96208333333334
Training for 600 epoch: 66.27791666666667
Training for 1000 epoch: 66.70958333333334
[[64.98684210526316, 66.21710526315789, 66.69078947368422], [64.96208333333334, 66.27791666666667, 66.70958333333334]]
train loss 0.5289019923528036, epoch 479, best loss 0.2624552794933319, best_epoch 454
GPU_0_using curriculum 40 with window 40
Epoch: [480][20/30]	Time  1.596 ( 1.510)	Data  0.152 ( 0.065)	InnerLoop  0.624 ( 0.627)	Loss 5.2361e-01 (4.8945e-01)	Acc@1  81.98 ( 83.12)
The current update step is 14430
GPU_0_using curriculum 40 with window 40
Epoch: [481][20/30]	Time  1.588 ( 1.510)	Data  0.037 ( 0.054)	InnerLoop  0.734 ( 0.640)	Loss 4.8532e-01 (4.6852e-01)	Acc@1  83.23 ( 83.54)
The current update step is 14460
GPU_0_using curriculum 40 with window 40
Epoch: [482][20/30]	Time  1.468 ( 1.499)	Data  0.038 ( 0.047)	InnerLoop  0.621 ( 0.638)	Loss 5.2642e-01 (4.9132e-01)	Acc@1  82.45 ( 82.57)
The current update step is 14490
GPU_0_using curriculum 40 with window 40
Epoch: [483][20/30]	Time  1.468 ( 1.501)	Data  0.035 ( 0.053)	InnerLoop  0.619 ( 0.632)	Loss 4.5411e-01 (4.6234e-01)	Acc@1  83.59 ( 83.62)
The current update step is 14520
GPU_0_using curriculum 40 with window 40
Epoch: [484][20/30]	Time  1.505 ( 1.514)	Data  0.036 ( 0.042)	InnerLoop  0.637 ( 0.650)	Loss 4.4592e-01 (4.7895e-01)	Acc@1  84.03 ( 83.23)
The current update step is 14550
The current seed is 13013299640364565030
The current lr is: 0.0015
Testing Results:
 *   Acc@1 53.316
 *   Acc@1 53.438
 *   Acc@1 52.697
 *   Acc@1 53.062
 *   Acc@1 52.697
 *   Acc@1 52.983
 *   Acc@1 69.092
 *   Acc@1 69.020
 *   Acc@1 69.487
 *   Acc@1 69.329
 *   Acc@1 69.789
 *   Acc@1 69.485
 *   Acc@1 63.447
 *   Acc@1 63.628
 *   Acc@1 57.184
 *   Acc@1 56.709
 *   Acc@1 57.316
 *   Acc@1 56.912
 *   Acc@1 66.526
 *   Acc@1 67.257
 *   Acc@1 67.908
 *   Acc@1 68.683
 *   Acc@1 67.868
 *   Acc@1 68.664
Training for 300 epoch: 63.09539473684211
Training for 600 epoch: 61.819078947368425
Training for 1000 epoch: 61.91776315789474
Training for 300 epoch: 63.33562499999999
Training for 600 epoch: 61.94583333333333
Training for 1000 epoch: 62.01104166666667
[[63.09539473684211, 61.819078947368425, 61.91776315789474], [63.33562499999999, 61.94583333333333, 62.01104166666667]]
train loss 0.5413921151479085, epoch 484, best loss 0.2624552794933319, best_epoch 454
GPU_0_using curriculum 40 with window 40
Epoch: [485][20/30]	Time  1.481 ( 1.521)	Data  0.037 ( 0.055)	InnerLoop  0.623 ( 0.640)	Loss 5.6538e-01 (4.7045e-01)	Acc@1  79.91 ( 83.65)
The current update step is 14580
GPU_0_using curriculum 40 with window 40
Epoch: [486][20/30]	Time  1.581 ( 1.520)	Data  0.150 ( 0.061)	InnerLoop  0.616 ( 0.637)	Loss 5.0675e-01 (4.7728e-01)	Acc@1  82.50 ( 83.33)
The current update step is 14610
GPU_0_using curriculum 40 with window 40
Epoch: [487][20/30]	Time  1.484 ( 1.514)	Data  0.036 ( 0.036)	InnerLoop  0.626 ( 0.655)	Loss 4.4713e-01 (4.6637e-01)	Acc@1  84.99 ( 83.87)
The current update step is 14640
GPU_0_using curriculum 40 with window 40
Epoch: [488][20/30]	Time  1.486 ( 1.508)	Data  0.036 ( 0.047)	InnerLoop  0.628 ( 0.641)	Loss 4.7151e-01 (4.6719e-01)	Acc@1  83.79 ( 83.47)
The current update step is 14670
GPU_0_using curriculum 40 with window 40
Epoch: [489][20/30]	Time  1.481 ( 1.520)	Data  0.035 ( 0.061)	InnerLoop  0.623 ( 0.635)	Loss 5.3854e-01 (4.7753e-01)	Acc@1  80.69 ( 83.32)
The current update step is 14700
The current seed is 2984295051468904273
The current lr is: 0.0015
Testing Results:
 *   Acc@1 70.105
 *   Acc@1 70.598
 *   Acc@1 70.368
 *   Acc@1 71.204
 *   Acc@1 70.026
 *   Acc@1 70.370
 *   Acc@1 70.539
 *   Acc@1 70.543
 *   Acc@1 69.750
 *   Acc@1 69.920
 *   Acc@1 68.882
 *   Acc@1 69.406
 *   Acc@1 65.711
 *   Acc@1 66.944
 *   Acc@1 66.553
 *   Acc@1 67.427
 *   Acc@1 67.316
 *   Acc@1 68.327
 *   Acc@1 67.553
 *   Acc@1 67.561
 *   Acc@1 48.329
 *   Acc@1 48.151
 *   Acc@1 48.211
 *   Acc@1 47.959
Training for 300 epoch: 68.47697368421052
Training for 600 epoch: 63.75
Training for 1000 epoch: 63.608552631578945
Training for 300 epoch: 68.91166666666666
Training for 600 epoch: 64.17541666666666
Training for 1000 epoch: 64.01541666666667
[[68.47697368421052, 63.75, 63.608552631578945], [68.91166666666666, 64.17541666666666, 64.01541666666667]]
train loss 0.781005655670166, epoch 489, best loss 0.2624552794933319, best_epoch 454
GPU_0_using curriculum 40 with window 40
Epoch: [490][20/30]	Time  1.570 ( 1.602)	Data  0.043 ( 0.056)	InnerLoop  0.672 ( 0.687)	Loss 4.3822e-01 (4.5880e-01)	Acc@1  84.81 ( 83.96)
The current update step is 14730
GPU_0_using curriculum 40 with window 40
Epoch: [491][20/30]	Time  1.592 ( 1.617)	Data  0.048 ( 0.070)	InnerLoop  0.679 ( 0.682)	Loss 4.2305e-01 (4.6626e-01)	Acc@1  84.86 ( 83.62)
The current update step is 14760
GPU_0_using curriculum 40 with window 40
Epoch: [492][20/30]	Time  1.510 ( 1.533)	Data  0.039 ( 0.051)	InnerLoop  0.641 ( 0.652)	Loss 6.2507e-01 (4.8757e-01)	Acc@1  78.34 ( 82.88)
The current update step is 14790
GPU_0_using curriculum 40 with window 40
Epoch: [493][20/30]	Time  1.504 ( 1.537)	Data  0.039 ( 0.069)	InnerLoop  0.641 ( 0.636)	Loss 4.9172e-01 (4.5296e-01)	Acc@1  82.10 ( 84.38)
The current update step is 14820
GPU_0_using curriculum 40 with window 40
Epoch: [494][20/30]	Time  1.532 ( 1.571)	Data  0.041 ( 0.073)	InnerLoop  0.652 ( 0.654)	Loss 4.4143e-01 (4.7743e-01)	Acc@1  83.81 ( 83.16)
The current update step is 14850
The current seed is 1817157966770389652
The current lr is: 0.0015
Testing Results:
 *   Acc@1 73.566
 *   Acc@1 73.712
 *   Acc@1 73.487
 *   Acc@1 74.097
 *   Acc@1 74.053
 *   Acc@1 74.229
 *   Acc@1 71.684
 *   Acc@1 72.833
 *   Acc@1 65.618
 *   Acc@1 65.636
 *   Acc@1 65.711
 *   Acc@1 66.028
 *   Acc@1 64.618
 *   Acc@1 64.487
 *   Acc@1 65.526
 *   Acc@1 65.847
 *   Acc@1 66.184
 *   Acc@1 66.451
 *   Acc@1 48.566
 *   Acc@1 49.296
 *   Acc@1 61.868
 *   Acc@1 62.278
 *   Acc@1 61.829
 *   Acc@1 62.572
Training for 300 epoch: 64.60855263157895
Training for 600 epoch: 66.625
Training for 1000 epoch: 66.94407894736842
Training for 300 epoch: 65.08187500000001
Training for 600 epoch: 66.96458333333334
Training for 1000 epoch: 67.32
[[64.60855263157895, 66.625, 66.94407894736842], [65.08187500000001, 66.96458333333334, 67.32]]
train loss 0.5093720101674398, epoch 494, best loss 0.2624552794933319, best_epoch 454
GPU_0_using curriculum 40 with window 40
Epoch: [495][20/30]	Time  1.555 ( 1.594)	Data  0.041 ( 0.067)	InnerLoop  0.667 ( 0.674)	Loss 4.7660e-01 (4.7478e-01)	Acc@1  83.42 ( 83.30)
The current update step is 14880
GPU_0_using curriculum 40 with window 40
Epoch: [496][20/30]	Time  1.547 ( 1.595)	Data  0.041 ( 0.075)	InnerLoop  0.659 ( 0.665)	Loss 4.7061e-01 (4.5812e-01)	Acc@1  84.59 ( 83.96)
The current update step is 14910
GPU_0_using curriculum 40 with window 40
Epoch: [497][20/30]	Time  1.536 ( 1.568)	Data  0.040 ( 0.067)	InnerLoop  0.651 ( 0.656)	Loss 4.4992e-01 (4.9642e-01)	Acc@1  83.91 ( 82.91)
The current update step is 14940
GPU_0_using curriculum 40 with window 40
Epoch: [498][20/30]	Time  1.590 ( 1.591)	Data  0.043 ( 0.068)	InnerLoop  0.676 ( 0.668)	Loss 4.7138e-01 (4.9818e-01)	Acc@1  82.23 ( 82.74)
The current update step is 14970
GPU_0_using curriculum 40 with window 40
Epoch: [499][20/30]	Time  1.612 ( 1.613)	Data  0.045 ( 0.063)	InnerLoop  0.689 ( 0.688)	Loss 4.6784e-01 (4.6490e-01)	Acc@1  83.98 ( 83.62)
The current update step is 15000
The current seed is 4420509124492525060
The current lr is: 0.0015
Testing Results:
 *   Acc@1 77.526
 *   Acc@1 77.624
 *   Acc@1 77.026
 *   Acc@1 77.177
 *   Acc@1 77.013
 *   Acc@1 77.325
 *   Acc@1 76.145
 *   Acc@1 76.163
 *   Acc@1 76.618
 *   Acc@1 76.457
 *   Acc@1 76.461
 *   Acc@1 76.562
 *   Acc@1 66.118
 *   Acc@1 66.001
 *   Acc@1 65.382
 *   Acc@1 65.125
 *   Acc@1 65.171
 *   Acc@1 64.993
 *   Acc@1 65.013
 *   Acc@1 64.929
 *   Acc@1 64.855
 *   Acc@1 65.058
 *   Acc@1 65.789
 *   Acc@1 65.339
Training for 300 epoch: 71.20065789473684
Training for 600 epoch: 70.97039473684211
Training for 1000 epoch: 71.10855263157895
Training for 300 epoch: 71.179375
Training for 600 epoch: 70.954375
Training for 1000 epoch: 71.05458333333334
[[71.20065789473684, 70.97039473684211, 71.10855263157895], [71.179375, 70.954375, 71.05458333333334]]
train loss 0.4628323424021403, epoch 499, best loss 0.2624552794933319, best_epoch 454
GPU_0_using curriculum 40 with window 40
Epoch: [500][20/30]	Time  1.647 ( 1.574)	Data  0.162 ( 0.072)	InnerLoop  0.648 ( 0.657)	Loss 4.7958e-01 (4.6141e-01)	Acc@1  82.89 ( 83.80)
The current update step is 15030
GPU_0_using curriculum 40 with window 40
Epoch: [501][20/30]	Time  1.674 ( 1.585)	Data  0.041 ( 0.061)	InnerLoop  0.785 ( 0.675)	Loss 5.2249e-01 (4.6571e-01)	Acc@1  81.45 ( 83.72)
The current update step is 15060
GPU_0_using curriculum 40 with window 40
Epoch: [502][20/30]	Time  1.555 ( 1.568)	Data  0.042 ( 0.054)	InnerLoop  0.661 ( 0.669)	Loss 4.2240e-01 (4.5304e-01)	Acc@1  84.42 ( 84.05)
The current update step is 15090
GPU_0_using curriculum 40 with window 40
Epoch: [503][20/30]	Time  1.539 ( 1.566)	Data  0.043 ( 0.060)	InnerLoop  0.648 ( 0.661)	Loss 4.4530e-01 (4.6041e-01)	Acc@1  84.06 ( 83.72)
The current update step is 15120
GPU_0_using curriculum 40 with window 40
Epoch: [504][20/30]	Time  1.548 ( 1.588)	Data  0.042 ( 0.048)	InnerLoop  0.653 ( 0.686)	Loss 4.5321e-01 (4.5040e-01)	Acc@1  83.57 ( 84.18)
The current update step is 15150
The current seed is 17713743954009367329
The current lr is: 0.0015
Testing Results:
 *   Acc@1 75.408
 *   Acc@1 75.198
 *   Acc@1 75.145
 *   Acc@1 74.823
 *   Acc@1 74.855
 *   Acc@1 74.823
 *   Acc@1 76.000
 *   Acc@1 76.789
 *   Acc@1 76.158
 *   Acc@1 76.837
 *   Acc@1 76.066
 *   Acc@1 76.698
 *   Acc@1 72.447
 *   Acc@1 72.546
 *   Acc@1 72.789
 *   Acc@1 73.289
 *   Acc@1 72.000
 *   Acc@1 72.960
 *   Acc@1 74.171
 *   Acc@1 74.158
 *   Acc@1 74.211
 *   Acc@1 74.386
 *   Acc@1 74.553
 *   Acc@1 74.508
Training for 300 epoch: 74.50657894736842
Training for 600 epoch: 74.57565789473685
Training for 1000 epoch: 74.36842105263159
Training for 300 epoch: 74.67291666666668
Training for 600 epoch: 74.83375000000001
Training for 1000 epoch: 74.74729166666667
[[74.50657894736842, 74.57565789473685, 74.36842105263159], [74.67291666666668, 74.83375000000001, 74.74729166666667]]
train loss 0.4159542199929555, epoch 504, best loss 0.2624552794933319, best_epoch 454
GPU_0_using curriculum 40 with window 40
Epoch: [505][20/30]	Time  1.609 ( 1.621)	Data  0.046 ( 0.063)	InnerLoop  0.694 ( 0.692)	Loss 4.9526e-01 (4.5504e-01)	Acc@1  83.30 ( 84.23)
The current update step is 15180
GPU_0_using curriculum 40 with window 40
Epoch: [506][20/30]	Time  1.719 ( 1.620)	Data  0.176 ( 0.069)	InnerLoop  0.674 ( 0.687)	Loss 4.2852e-01 (4.6285e-01)	Acc@1  86.45 ( 83.90)
The current update step is 15210
GPU_0_using curriculum 40 with window 40
Epoch: [507][20/30]	Time  1.591 ( 1.614)	Data  0.043 ( 0.042)	InnerLoop  0.681 ( 0.708)	Loss 4.0838e-01 (4.5707e-01)	Acc@1  86.11 ( 84.30)
The current update step is 15240
GPU_0_using curriculum 40 with window 40
Epoch: [508][20/30]	Time  1.537 ( 1.564)	Data  0.042 ( 0.053)	InnerLoop  0.648 ( 0.667)	Loss 4.8369e-01 (4.5425e-01)	Acc@1  83.74 ( 83.99)
The current update step is 15270
GPU_0_using curriculum 40 with window 40
Epoch: [509][20/30]	Time  1.521 ( 1.560)	Data  0.041 ( 0.065)	InnerLoop  0.639 ( 0.653)	Loss 4.7417e-01 (4.6185e-01)	Acc@1  83.37 ( 83.91)
The current update step is 15300
The current seed is 3465439249014485160
The current lr is: 0.0015
Testing Results:
 *   Acc@1 70.908
 *   Acc@1 71.163
 *   Acc@1 73.934
 *   Acc@1 73.906
 *   Acc@1 74.974
 *   Acc@1 74.859
 *   Acc@1 73.395
 *   Acc@1 73.692
 *   Acc@1 72.579
 *   Acc@1 72.542
 *   Acc@1 72.039
 *   Acc@1 72.069
 *   Acc@1 63.224
 *   Acc@1 64.151
 *   Acc@1 62.250
 *   Acc@1 63.626
 *   Acc@1 62.553
 *   Acc@1 63.482
 *   Acc@1 70.513
 *   Acc@1 71.031
 *   Acc@1 69.816
 *   Acc@1 70.478
 *   Acc@1 69.276
 *   Acc@1 70.223
Training for 300 epoch: 69.50986842105263
Training for 600 epoch: 69.64473684210526
Training for 1000 epoch: 69.71052631578947
Training for 300 epoch: 70.009375
Training for 600 epoch: 70.13791666666667
Training for 1000 epoch: 70.15833333333333
[[69.50986842105263, 69.64473684210526, 69.71052631578947], [70.009375, 70.13791666666667, 70.15833333333333]]
train loss 0.4348836701075236, epoch 509, best loss 0.2624552794933319, best_epoch 454
GPU_0_using curriculum 40 with window 40
Epoch: [510][20/30]	Time  1.550 ( 1.580)	Data  0.043 ( 0.054)	InnerLoop  0.654 ( 0.676)	Loss 4.0807e-01 (4.7843e-01)	Acc@1  85.74 ( 83.42)
The current update step is 15330
GPU_0_using curriculum 40 with window 40
Epoch: [511][20/30]	Time  1.599 ( 1.612)	Data  0.044 ( 0.069)	InnerLoop  0.682 ( 0.679)	Loss 4.4237e-01 (4.6783e-01)	Acc@1  84.47 ( 83.77)
The current update step is 15360
GPU_0_using curriculum 40 with window 40
Epoch: [512][20/30]	Time  1.573 ( 1.580)	Data  0.041 ( 0.054)	InnerLoop  0.672 ( 0.676)	Loss 4.8659e-01 (4.5427e-01)	Acc@1  83.20 ( 84.26)
The current update step is 15390
GPU_0_using curriculum 40 with window 40
Epoch: [513][20/30]	Time  1.563 ( 1.584)	Data  0.044 ( 0.075)	InnerLoop  0.660 ( 0.658)	Loss 4.4203e-01 (4.6488e-01)	Acc@1  84.16 ( 83.92)
The current update step is 15420
GPU_0_using curriculum 40 with window 40
Epoch: [514][20/30]	Time  1.567 ( 1.580)	Data  0.043 ( 0.073)	InnerLoop  0.662 ( 0.658)	Loss 4.0565e-01 (4.5809e-01)	Acc@1  85.62 ( 84.21)
The current update step is 15450
The current seed is 7756524075474857840
The current lr is: 0.0015
Testing Results:
 *   Acc@1 68.658
 *   Acc@1 68.971
 *   Acc@1 70.566
 *   Acc@1 70.582
 *   Acc@1 71.250
 *   Acc@1 71.332
 *   Acc@1 74.645
 *   Acc@1 74.491
 *   Acc@1 75.079
 *   Acc@1 75.170
 *   Acc@1 75.711
 *   Acc@1 75.757
 *   Acc@1 77.053
 *   Acc@1 76.777
 *   Acc@1 73.697
 *   Acc@1 74.122
 *   Acc@1 75.039
 *   Acc@1 75.045
 *   Acc@1 63.921
 *   Acc@1 63.551
 *   Acc@1 66.684
 *   Acc@1 66.526
 *   Acc@1 67.618
 *   Acc@1 67.484
Training for 300 epoch: 71.06907894736842
Training for 600 epoch: 71.50657894736842
Training for 1000 epoch: 72.40460526315789
Training for 300 epoch: 70.94729166666666
Training for 600 epoch: 71.6
Training for 1000 epoch: 72.40479166666667
[[71.06907894736842, 71.50657894736842, 72.40460526315789], [70.94729166666666, 71.6, 72.40479166666667]]
train loss 0.44135202522277833, epoch 514, best loss 0.2624552794933319, best_epoch 514
GPU_0_using curriculum 40 with window 40
Epoch: [515][20/30]	Time  1.581 ( 1.596)	Data  0.045 ( 0.067)	InnerLoop  0.670 ( 0.675)	Loss 4.9735e-01 (4.6099e-01)	Acc@1  83.62 ( 83.85)
The current update step is 15480
GPU_0_using curriculum 40 with window 40
Epoch: [516][20/30]	Time  1.554 ( 1.597)	Data  0.041 ( 0.074)	InnerLoop  0.654 ( 0.665)	Loss 4.3889e-01 (4.3933e-01)	Acc@1  84.57 ( 84.92)
The current update step is 15510
GPU_0_using curriculum 40 with window 40
Epoch: [517][20/30]	Time  1.570 ( 1.590)	Data  0.043 ( 0.069)	InnerLoop  0.662 ( 0.667)	Loss 4.3524e-01 (4.4331e-01)	Acc@1  85.30 ( 84.56)
The current update step is 15540
GPU_0_using curriculum 40 with window 40
Epoch: [518][20/30]	Time  1.563 ( 1.588)	Data  0.044 ( 0.069)	InnerLoop  0.666 ( 0.667)	Loss 4.3409e-01 (4.3605e-01)	Acc@1  85.03 ( 84.90)
The current update step is 15570
GPU_0_using curriculum 40 with window 40
Epoch: [519][20/30]	Time  1.563 ( 1.593)	Data  0.043 ( 0.062)	InnerLoop  0.662 ( 0.676)	Loss 5.2710e-01 (4.5207e-01)	Acc@1  83.40 ( 84.35)
The current update step is 15600
The current seed is 17357194774952571232
The current lr is: 0.0015
Testing Results:
 *   Acc@1 61.934
 *   Acc@1 62.650
 *   Acc@1 47.579
 *   Acc@1 47.940
 *   Acc@1 48.000
 *   Acc@1 48.508
 *   Acc@1 74.855
 *   Acc@1 75.246
 *   Acc@1 72.592
 *   Acc@1 73.161
 *   Acc@1 71.592
 *   Acc@1 72.190
 *   Acc@1 69.605
 *   Acc@1 70.296
 *   Acc@1 67.566
 *   Acc@1 67.675
 *   Acc@1 66.303
 *   Acc@1 66.743
 *   Acc@1 73.250
 *   Acc@1 73.358
 *   Acc@1 73.039
 *   Acc@1 73.067
 *   Acc@1 74.039
 *   Acc@1 74.004
Training for 300 epoch: 69.91118421052632
Training for 600 epoch: 65.19407894736841
Training for 1000 epoch: 64.98355263157895
Training for 300 epoch: 70.3875
Training for 600 epoch: 65.46083333333333
Training for 1000 epoch: 65.36145833333333
[[69.91118421052632, 65.19407894736841, 64.98355263157895], [70.3875, 65.46083333333333, 65.36145833333333]]
train loss 0.3869331825574239, epoch 519, best loss 0.2624552794933319, best_epoch 514
GPU_0_using curriculum 40 with window 40
Epoch: [520][20/30]	Time  1.662 ( 1.600)	Data  0.168 ( 0.075)	InnerLoop  0.646 ( 0.670)	Loss 4.1805e-01 (4.3462e-01)	Acc@1  85.25 ( 84.80)
The current update step is 15630
GPU_0_using curriculum 40 with window 40
Epoch: [521][20/30]	Time  1.674 ( 1.595)	Data  0.040 ( 0.062)	InnerLoop  0.786 ( 0.680)	Loss 4.4638e-01 (4.3772e-01)	Acc@1  85.13 ( 84.93)
The current update step is 15660
GPU_0_using curriculum 40 with window 40
Epoch: [522][20/30]	Time  1.541 ( 1.577)	Data  0.041 ( 0.055)	InnerLoop  0.650 ( 0.674)	Loss 4.4426e-01 (4.4429e-01)	Acc@1  84.30 ( 84.63)
The current update step is 15690
GPU_0_using curriculum 40 with window 40
Epoch: [523][20/30]	Time  1.581 ( 1.603)	Data  0.043 ( 0.063)	InnerLoop  0.669 ( 0.681)	Loss 4.9425e-01 (4.5474e-01)	Acc@1  82.67 ( 84.31)
The current update step is 15720
GPU_0_using curriculum 40 with window 40
Epoch: [524][20/30]	Time  1.580 ( 1.593)	Data  0.045 ( 0.049)	InnerLoop  0.677 ( 0.689)	Loss 4.3340e-01 (4.4992e-01)	Acc@1  85.18 ( 84.32)
The current update step is 15750
The current seed is 13164982086232889397
The current lr is: 0.0015
Testing Results:
 *   Acc@1 54.961
 *   Acc@1 55.369
 *   Acc@1 54.947
 *   Acc@1 55.900
 *   Acc@1 55.618
 *   Acc@1 56.133
 *   Acc@1 65.092
 *   Acc@1 65.588
 *   Acc@1 68.355
 *   Acc@1 67.596
 *   Acc@1 68.132
 *   Acc@1 67.162
 *   Acc@1 66.171
 *   Acc@1 66.162
 *   Acc@1 65.395
 *   Acc@1 65.749
 *   Acc@1 66.105
 *   Acc@1 66.274
 *   Acc@1 78.724
 *   Acc@1 78.695
 *   Acc@1 77.842
 *   Acc@1 77.977
 *   Acc@1 77.474
 *   Acc@1 77.772
Training for 300 epoch: 66.23684210526315
Training for 600 epoch: 66.63486842105263
Training for 1000 epoch: 66.83223684210526
Training for 300 epoch: 66.45375
Training for 600 epoch: 66.80541666666667
Training for 1000 epoch: 66.83520833333333
[[66.23684210526315, 66.63486842105263, 66.83223684210526], [66.45375, 66.80541666666667, 66.83520833333333]]
train loss 0.31673872429529826, epoch 524, best loss 0.2624552794933319, best_epoch 514
GPU_0_using curriculum 40 with window 40
Epoch: [525][20/30]	Time  1.564 ( 1.611)	Data  0.044 ( 0.063)	InnerLoop  0.666 ( 0.687)	Loss 4.1799e-01 (4.6057e-01)	Acc@1  85.91 ( 83.84)
The current update step is 15780
GPU_0_using curriculum 40 with window 40
Epoch: [526][20/30]	Time  1.670 ( 1.599)	Data  0.171 ( 0.068)	InnerLoop  0.652 ( 0.677)	Loss 4.4664e-01 (4.9435e-01)	Acc@1  83.84 ( 82.61)
The current update step is 15810
GPU_0_using curriculum 40 with window 40
Epoch: [527][20/30]	Time  1.608 ( 1.610)	Data  0.046 ( 0.044)	InnerLoop  0.679 ( 0.704)	Loss 5.1549e-01 (4.7190e-01)	Acc@1  82.91 ( 83.34)
The current update step is 15840
GPU_0_using curriculum 40 with window 40
Epoch: [528][20/30]	Time  1.565 ( 1.589)	Data  0.041 ( 0.054)	InnerLoop  0.668 ( 0.682)	Loss 5.1550e-01 (4.6081e-01)	Acc@1  81.40 ( 83.80)
The current update step is 15870
GPU_0_using curriculum 40 with window 40
Epoch: [529][20/30]	Time  1.580 ( 1.577)	Data  0.044 ( 0.068)	InnerLoop  0.678 ( 0.662)	Loss 4.2424e-01 (4.5688e-01)	Acc@1  85.69 ( 84.00)
The current update step is 15900
The current seed is 3997282998940887284
The current lr is: 0.0015
Testing Results:
 *   Acc@1 70.145
 *   Acc@1 70.605
 *   Acc@1 71.171
 *   Acc@1 71.628
 *   Acc@1 71.487
 *   Acc@1 72.049
 *   Acc@1 66.039
 *   Acc@1 66.247
 *   Acc@1 67.079
 *   Acc@1 67.472
 *   Acc@1 67.526
 *   Acc@1 67.932
 *   Acc@1 59.197
 *   Acc@1 58.682
 *   Acc@1 60.447
 *   Acc@1 60.050
 *   Acc@1 59.724
 *   Acc@1 59.794
 *   Acc@1 68.342
 *   Acc@1 68.667
 *   Acc@1 68.539
 *   Acc@1 68.991
 *   Acc@1 68.553
 *   Acc@1 68.915
Training for 300 epoch: 65.93092105263158
Training for 600 epoch: 66.80921052631578
Training for 1000 epoch: 66.82236842105263
Training for 300 epoch: 66.05000000000001
Training for 600 epoch: 67.03520833333333
Training for 1000 epoch: 67.17250000000001
[[65.93092105263158, 66.80921052631578, 66.82236842105263], [66.05000000000001, 67.03520833333333, 67.17250000000001]]
train loss 0.4231687651634216, epoch 529, best loss 0.2624552794933319, best_epoch 514
GPU_0_using curriculum 40 with window 40
Epoch: [530][20/30]	Time  1.574 ( 1.607)	Data  0.042 ( 0.056)	InnerLoop  0.667 ( 0.692)	Loss 4.7343e-01 (4.5422e-01)	Acc@1  83.94 ( 84.38)
The current update step is 15930
GPU_0_using curriculum 40 with window 40
Epoch: [531][20/30]	Time  1.567 ( 1.600)	Data  0.043 ( 0.068)	InnerLoop  0.673 ( 0.677)	Loss 4.1942e-01 (4.5370e-01)	Acc@1  85.18 ( 84.10)
The current update step is 15960
GPU_0_using curriculum 40 with window 40
Epoch: [532][20/30]	Time  1.563 ( 1.611)	Data  0.040 ( 0.056)	InnerLoop  0.665 ( 0.694)	Loss 4.4437e-01 (4.4647e-01)	Acc@1  84.20 ( 84.52)
The current update step is 15990
GPU_0_using curriculum 40 with window 40
Epoch: [533][20/30]	Time  1.525 ( 1.569)	Data  0.042 ( 0.073)	InnerLoop  0.651 ( 0.652)	Loss 4.5327e-01 (4.7014e-01)	Acc@1  84.40 ( 83.51)
The current update step is 16020
GPU_0_using curriculum 40 with window 40
Epoch: [534][20/30]	Time  1.563 ( 1.583)	Data  0.042 ( 0.074)	InnerLoop  0.666 ( 0.663)	Loss 5.3827e-01 (4.4335e-01)	Acc@1  81.01 ( 84.42)
The current update step is 16050
The current seed is 6099691444229020397
The current lr is: 0.0015
Testing Results:
 *   Acc@1 67.842
 *   Acc@1 67.975
 *   Acc@1 76.105
 *   Acc@1 75.987
 *   Acc@1 76.526
 *   Acc@1 76.572
 *   Acc@1 77.316
 *   Acc@1 77.450
 *   Acc@1 77.105
 *   Acc@1 77.420
 *   Acc@1 77.197
 *   Acc@1 77.490
 *   Acc@1 56.263
 *   Acc@1 56.615
 *   Acc@1 57.250
 *   Acc@1 57.528
 *   Acc@1 57.224
 *   Acc@1 57.662
 *   Acc@1 74.513
 *   Acc@1 74.330
 *   Acc@1 75.013
 *   Acc@1 74.580
 *   Acc@1 74.882
 *   Acc@1 74.755
Training for 300 epoch: 68.98355263157895
Training for 600 epoch: 71.36842105263158
Training for 1000 epoch: 71.45723684210526
Training for 300 epoch: 69.0925
Training for 600 epoch: 71.37895833333333
Training for 1000 epoch: 71.61958333333334
[[68.98355263157895, 71.36842105263158, 71.45723684210526], [69.0925, 71.37895833333333, 71.61958333333334]]
train loss 0.36845723288853965, epoch 534, best loss 0.2624552794933319, best_epoch 514
GPU_0_using curriculum 40 with window 40
Epoch: [535][20/30]	Time  1.588 ( 1.605)	Data  0.045 ( 0.068)	InnerLoop  0.686 ( 0.680)	Loss 4.5554e-01 (4.7135e-01)	Acc@1  84.01 ( 83.81)
The current update step is 16080
GPU_0_using curriculum 40 with window 40
Epoch: [536][20/30]	Time  1.555 ( 1.598)	Data  0.042 ( 0.076)	InnerLoop  0.663 ( 0.667)	Loss 4.3160e-01 (4.6410e-01)	Acc@1  84.64 ( 84.00)
The current update step is 16110
GPU_0_using curriculum 40 with window 40
Epoch: [537][20/30]	Time  1.586 ( 1.594)	Data  0.043 ( 0.069)	InnerLoop  0.677 ( 0.671)	Loss 4.4928e-01 (4.5899e-01)	Acc@1  84.20 ( 83.98)
The current update step is 16140
GPU_0_using curriculum 40 with window 40
Epoch: [538][20/30]	Time  1.537 ( 1.589)	Data  0.040 ( 0.067)	InnerLoop  0.650 ( 0.669)	Loss 4.0517e-01 (4.8142e-01)	Acc@1  85.55 ( 83.12)
The current update step is 16170
GPU_0_using curriculum 40 with window 40
Epoch: [539][20/30]	Time  1.578 ( 1.592)	Data  0.044 ( 0.061)	InnerLoop  0.677 ( 0.677)	Loss 5.2160e-01 (4.7027e-01)	Acc@1  80.62 ( 83.39)
The current update step is 16200
The current seed is 14395730104072037576
The current lr is: 0.0015
Testing Results:
 *   Acc@1 72.368
 *   Acc@1 72.416
 *   Acc@1 76.382
 *   Acc@1 76.882
 *   Acc@1 76.592
 *   Acc@1 77.211
 *   Acc@1 67.303
 *   Acc@1 67.865
 *   Acc@1 65.776
 *   Acc@1 65.459
 *   Acc@1 66.671
 *   Acc@1 66.598
 *   Acc@1 68.500
 *   Acc@1 68.787
 *   Acc@1 69.079
 *   Acc@1 69.374
 *   Acc@1 69.671
 *   Acc@1 70.190
 *   Acc@1 79.079
 *   Acc@1 79.915
 *   Acc@1 79.263
 *   Acc@1 80.429
 *   Acc@1 79.382
 *   Acc@1 80.004
Training for 300 epoch: 71.8125
Training for 600 epoch: 72.625
Training for 1000 epoch: 73.07894736842105
Training for 300 epoch: 72.24583333333334
Training for 600 epoch: 73.03625
Training for 1000 epoch: 73.50083333333333
[[71.8125, 72.625, 73.07894736842105], [72.24583333333334, 73.03625, 73.50083333333333]]
train loss 0.2433185348033905, epoch 539, best loss 0.2433185348033905, best_epoch 539
GPU_0_using curriculum 40 with window 40
Epoch: [540][20/30]	Time  1.692 ( 1.611)	Data  0.174 ( 0.075)	InnerLoop  0.654 ( 0.678)	Loss 4.0946e-01 (4.4344e-01)	Acc@1  85.91 ( 84.61)
The current update step is 16230
GPU_0_using curriculum 40 with window 40
Epoch: [541][20/30]	Time  1.710 ( 1.624)	Data  0.042 ( 0.063)	InnerLoop  0.799 ( 0.699)	Loss 4.9478e-01 (4.6521e-01)	Acc@1  82.47 ( 83.75)
The current update step is 16260
GPU_0_using curriculum 40 with window 40
Epoch: [542][20/30]	Time  1.547 ( 1.570)	Data  0.041 ( 0.054)	InnerLoop  0.657 ( 0.672)	Loss 4.4068e-01 (4.4723e-01)	Acc@1  84.74 ( 84.24)
The current update step is 16290
GPU_0_using curriculum 40 with window 40
Epoch: [543][20/30]	Time  1.545 ( 1.575)	Data  0.043 ( 0.060)	InnerLoop  0.657 ( 0.669)	Loss 3.9576e-01 (4.5571e-01)	Acc@1  86.55 ( 84.15)
The current update step is 16320
GPU_0_using curriculum 40 with window 40
Epoch: [544][20/30]	Time  1.571 ( 1.603)	Data  0.044 ( 0.050)	InnerLoop  0.670 ( 0.696)	Loss 5.0961e-01 (4.5400e-01)	Acc@1  82.62 ( 84.04)
The current update step is 16350
The current seed is 14453805164407763348
The current lr is: 0.0015
Testing Results:
 *   Acc@1 57.539
 *   Acc@1 57.454
 *   Acc@1 50.487
 *   Acc@1 50.173
 *   Acc@1 49.816
 *   Acc@1 49.685
 *   Acc@1 73.895
 *   Acc@1 74.367
 *   Acc@1 69.329
 *   Acc@1 69.418
 *   Acc@1 69.474
 *   Acc@1 69.848
 *   Acc@1 70.526
 *   Acc@1 70.623
 *   Acc@1 69.487
 *   Acc@1 70.114
 *   Acc@1 69.000
 *   Acc@1 69.543
 *   Acc@1 79.921
 *   Acc@1 80.321
 *   Acc@1 80.618
 *   Acc@1 80.663
 *   Acc@1 80.697
 *   Acc@1 80.770
Training for 300 epoch: 70.47039473684211
Training for 600 epoch: 67.48026315789474
Training for 1000 epoch: 67.24671052631578
Training for 300 epoch: 70.69104166666666
Training for 600 epoch: 67.59229166666665
Training for 1000 epoch: 67.46166666666666
[[70.47039473684211, 67.48026315789474, 67.24671052631578], [70.69104166666666, 67.59229166666665, 67.46166666666666]]
train loss 0.24042404685020446, epoch 544, best loss 0.24042404685020446, best_epoch 544
GPU_0_using curriculum 40 with window 40
Epoch: [545][20/30]	Time  1.548 ( 1.579)	Data  0.042 ( 0.061)	InnerLoop  0.656 ( 0.669)	Loss 4.0632e-01 (4.6605e-01)	Acc@1  85.62 ( 83.50)
The current update step is 16380
GPU_0_using curriculum 40 with window 40
Epoch: [546][20/30]	Time  1.704 ( 1.601)	Data  0.176 ( 0.068)	InnerLoop  0.665 ( 0.678)	Loss 5.0733e-01 (4.6047e-01)	Acc@1  82.06 ( 83.88)
The current update step is 16410
GPU_0_using curriculum 40 with window 40
Epoch: [547][20/30]	Time  1.542 ( 1.601)	Data  0.042 ( 0.043)	InnerLoop  0.650 ( 0.701)	Loss 4.0827e-01 (4.5046e-01)	Acc@1  85.50 ( 84.10)
The current update step is 16440
GPU_0_using curriculum 40 with window 40
Epoch: [548][20/30]	Time  1.573 ( 1.584)	Data  0.044 ( 0.054)	InnerLoop  0.663 ( 0.680)	Loss 5.4524e-01 (4.4353e-01)	Acc@1  80.57 ( 84.65)
The current update step is 16470
GPU_0_using curriculum 40 with window 40
Epoch: [549][20/30]	Time  1.548 ( 1.591)	Data  0.043 ( 0.068)	InnerLoop  0.653 ( 0.669)	Loss 6.3880e-01 (4.7099e-01)	Acc@1  76.93 ( 83.53)
The current update step is 16500
The current seed is 8677664106921965285
The current lr is: 0.0015
Testing Results:
 *   Acc@1 78.329
 *   Acc@1 78.615
 *   Acc@1 73.987
 *   Acc@1 74.800
 *   Acc@1 74.118
 *   Acc@1 74.672
 *   Acc@1 58.368
 *   Acc@1 58.108
 *   Acc@1 71.461
 *   Acc@1 71.670
 *   Acc@1 70.421
 *   Acc@1 70.290
 *   Acc@1 64.224
 *   Acc@1 64.778
 *   Acc@1 66.211
 *   Acc@1 66.633
 *   Acc@1 66.974
 *   Acc@1 67.390
 *   Acc@1 72.395
 *   Acc@1 72.264
 *   Acc@1 73.803
 *   Acc@1 73.682
 *   Acc@1 74.395
 *   Acc@1 74.196
Training for 300 epoch: 68.32894736842105
Training for 600 epoch: 71.36513157894737
Training for 1000 epoch: 71.47697368421052
Training for 300 epoch: 68.44104166666666
Training for 600 epoch: 71.69625
Training for 1000 epoch: 71.636875
[[68.32894736842105, 71.36513157894737, 71.47697368421052], [68.44104166666666, 71.69625, 71.636875]]
train loss 0.3908487553278605, epoch 549, best loss 0.24042404685020446, best_epoch 544
GPU_0_using curriculum 40 with window 40
Epoch: [550][20/30]	Time  1.580 ( 1.616)	Data  0.042 ( 0.056)	InnerLoop  0.682 ( 0.698)	Loss 4.0699e-01 (4.4703e-01)	Acc@1  85.84 ( 84.50)
The current update step is 16530
GPU_0_using curriculum 40 with window 40
Epoch: [551][20/30]	Time  1.583 ( 1.599)	Data  0.041 ( 0.068)	InnerLoop  0.677 ( 0.674)	Loss 4.3840e-01 (4.5125e-01)	Acc@1  85.08 ( 84.39)
The current update step is 16560
GPU_0_using curriculum 40 with window 40
Epoch: [552][20/30]	Time  1.540 ( 1.570)	Data  0.039 ( 0.054)	InnerLoop  0.656 ( 0.673)	Loss 4.8621e-01 (4.4703e-01)	Acc@1  84.67 ( 84.38)
The current update step is 16590
GPU_0_using curriculum 40 with window 40
Epoch: [553][20/30]	Time  1.581 ( 1.594)	Data  0.045 ( 0.075)	InnerLoop  0.676 ( 0.666)	Loss 5.1453e-01 (4.5354e-01)	Acc@1  81.88 ( 84.10)
The current update step is 16620
GPU_0_using curriculum 40 with window 40
Epoch: [554][20/30]	Time  1.573 ( 1.620)	Data  0.044 ( 0.076)	InnerLoop  0.669 ( 0.683)	Loss 4.7947e-01 (4.5939e-01)	Acc@1  82.79 ( 84.05)
The current update step is 16650
The current seed is 17056167875213126866
The current lr is: 0.0015
Testing Results:
 *   Acc@1 72.382
 *   Acc@1 72.659
 *   Acc@1 73.079
 *   Acc@1 73.233
 *   Acc@1 73.553
 *   Acc@1 73.620
 *   Acc@1 80.711
 *   Acc@1 81.276
 *   Acc@1 81.105
 *   Acc@1 81.323
 *   Acc@1 80.803
 *   Acc@1 80.994
 *   Acc@1 76.513
 *   Acc@1 76.346
 *   Acc@1 77.355
 *   Acc@1 77.045
 *   Acc@1 77.855
 *   Acc@1 77.431
 *   Acc@1 65.882
 *   Acc@1 66.463
 *   Acc@1 65.474
 *   Acc@1 65.976
 *   Acc@1 65.461
 *   Acc@1 65.880
Training for 300 epoch: 73.8717105263158
Training for 600 epoch: 74.2532894736842
Training for 1000 epoch: 74.41776315789474
Training for 300 epoch: 74.18583333333333
Training for 600 epoch: 74.394375
Training for 1000 epoch: 74.48125
[[73.8717105263158, 74.2532894736842, 74.41776315789474], [74.18583333333333, 74.394375, 74.48125]]
train loss 0.4494642974535624, epoch 554, best loss 0.24042404685020446, best_epoch 544
GPU_0_using curriculum 40 with window 40
Epoch: [555][20/30]	Time  1.570 ( 1.584)	Data  0.044 ( 0.067)	InnerLoop  0.666 ( 0.670)	Loss 5.3966e-01 (4.6784e-01)	Acc@1  80.59 ( 83.28)
The current update step is 16680
GPU_0_using curriculum 40 with window 40
Epoch: [556][20/30]	Time  1.576 ( 1.591)	Data  0.043 ( 0.075)	InnerLoop  0.670 ( 0.661)	Loss 4.2438e-01 (4.5055e-01)	Acc@1  85.13 ( 84.20)
The current update step is 16710
GPU_0_using curriculum 40 with window 40
Epoch: [557][20/30]	Time  1.559 ( 1.582)	Data  0.047 ( 0.067)	InnerLoop  0.661 ( 0.665)	Loss 4.5088e-01 (4.4642e-01)	Acc@1  83.91 ( 84.28)
The current update step is 16740
GPU_0_using curriculum 40 with window 40
Epoch: [558][20/30]	Time  1.551 ( 1.581)	Data  0.041 ( 0.067)	InnerLoop  0.651 ( 0.664)	Loss 5.1178e-01 (4.8302e-01)	Acc@1  82.32 ( 82.85)
The current update step is 16770
GPU_0_using curriculum 40 with window 40
Epoch: [559][20/30]	Time  1.556 ( 1.582)	Data  0.041 ( 0.061)	InnerLoop  0.660 ( 0.671)	Loss 4.5483e-01 (4.3922e-01)	Acc@1  84.18 ( 84.64)
The current update step is 16800
The current seed is 6254853948854526157
The current lr is: 0.0015
Testing Results:
 *   Acc@1 54.724
 *   Acc@1 55.031
 *   Acc@1 57.118
 *   Acc@1 57.593
 *   Acc@1 57.276
 *   Acc@1 57.741
 *   Acc@1 71.421
 *   Acc@1 72.176
 *   Acc@1 61.158
 *   Acc@1 61.789
 *   Acc@1 59.053
 *   Acc@1 60.342
 *   Acc@1 63.316
 *   Acc@1 63.873
 *   Acc@1 64.289
 *   Acc@1 64.729
 *   Acc@1 64.605
 *   Acc@1 65.038
 *   Acc@1 74.697
 *   Acc@1 75.355
 *   Acc@1 75.618
 *   Acc@1 76.167
 *   Acc@1 75.789
 *   Acc@1 76.213
Training for 300 epoch: 66.03947368421052
Training for 600 epoch: 64.54605263157895
Training for 1000 epoch: 64.18092105263158
Training for 300 epoch: 66.60875
Training for 600 epoch: 65.06937500000001
Training for 1000 epoch: 64.83354166666666
[[66.03947368421052, 64.54605263157895, 64.18092105263158], [66.60875, 65.06937500000001, 64.83354166666666]]
train loss 0.34270905510584515, epoch 559, best loss 0.24042404685020446, best_epoch 544
GPU_0_using curriculum 40 with window 40
Epoch: [560][20/30]	Time  1.624 ( 1.546)	Data  0.159 ( 0.069)	InnerLoop  0.631 ( 0.644)	Loss 4.2866e-01 (4.4632e-01)	Acc@1  85.03 ( 84.41)
The current update step is 16830
GPU_0_using curriculum 40 with window 40
Epoch: [561][20/30]	Time  1.606 ( 1.525)	Data  0.039 ( 0.056)	InnerLoop  0.743 ( 0.645)	Loss 4.3151e-01 (4.5677e-01)	Acc@1  85.16 ( 83.97)
The current update step is 16860
GPU_0_using curriculum 40 with window 40
Epoch: [562][20/30]	Time  1.467 ( 1.510)	Data  0.037 ( 0.049)	InnerLoop  0.616 ( 0.642)	Loss 5.0024e-01 (4.5814e-01)	Acc@1  82.35 ( 83.79)
The current update step is 16890
GPU_0_using curriculum 40 with window 40
Epoch: [563][20/30]	Time  1.480 ( 1.504)	Data  0.036 ( 0.054)	InnerLoop  0.621 ( 0.633)	Loss 4.6011e-01 (4.5909e-01)	Acc@1  84.33 ( 83.68)
The current update step is 16920
GPU_0_using curriculum 40 with window 40
Epoch: [564][20/30]	Time  1.481 ( 1.510)	Data  0.037 ( 0.042)	InnerLoop  0.621 ( 0.649)	Loss 4.1671e-01 (4.5842e-01)	Acc@1  85.52 ( 83.99)
The current update step is 16950
The current seed is 16542900214198438036
The current lr is: 0.0015
Testing Results:
 *   Acc@1 78.342
 *   Acc@1 78.460
 *   Acc@1 79.000
 *   Acc@1 78.727
 *   Acc@1 79.066
 *   Acc@1 78.649
 *   Acc@1 68.671
 *   Acc@1 69.216
 *   Acc@1 71.763
 *   Acc@1 72.547
 *   Acc@1 71.553
 *   Acc@1 71.878
 *   Acc@1 79.579
 *   Acc@1 79.632
 *   Acc@1 79.303
 *   Acc@1 79.414
 *   Acc@1 79.276
 *   Acc@1 79.296
 *   Acc@1 78.461
 *   Acc@1 79.121
 *   Acc@1 79.118
 *   Acc@1 79.384
 *   Acc@1 76.342
 *   Acc@1 76.612
Training for 300 epoch: 76.26315789473684
Training for 600 epoch: 77.29605263157895
Training for 1000 epoch: 76.55921052631578
Training for 300 epoch: 76.60708333333334
Training for 600 epoch: 77.518125
Training for 1000 epoch: 76.60895833333333
[[76.26315789473684, 77.29605263157895, 76.55921052631578], [76.60708333333334, 77.518125, 76.60895833333333]]
train loss 0.38696125777562457, epoch 564, best loss 0.24042404685020446, best_epoch 544
GPU_0_using curriculum 40 with window 40
Epoch: [565][20/30]	Time  1.475 ( 1.506)	Data  0.038 ( 0.053)	InnerLoop  0.625 ( 0.636)	Loss 4.0808e-01 (4.5555e-01)	Acc@1  85.72 ( 84.27)
The current update step is 16980
GPU_0_using curriculum 40 with window 40
Epoch: [566][20/30]	Time  1.592 ( 1.511)	Data  0.152 ( 0.059)	InnerLoop  0.622 ( 0.635)	Loss 4.3145e-01 (4.5216e-01)	Acc@1  85.47 ( 84.29)
The current update step is 17010
GPU_0_using curriculum 40 with window 40
Epoch: [567][20/30]	Time  1.480 ( 1.501)	Data  0.036 ( 0.035)	InnerLoop  0.622 ( 0.650)	Loss 5.5491e-01 (4.5906e-01)	Acc@1  81.18 ( 83.99)
The current update step is 17040
GPU_0_using curriculum 40 with window 40
Epoch: [568][20/30]	Time  1.483 ( 1.504)	Data  0.036 ( 0.047)	InnerLoop  0.624 ( 0.641)	Loss 4.1508e-01 (4.6436e-01)	Acc@1  85.16 ( 83.79)
The current update step is 17070
GPU_0_using curriculum 40 with window 40
Epoch: [569][20/30]	Time  1.488 ( 1.511)	Data  0.037 ( 0.059)	InnerLoop  0.630 ( 0.634)	Loss 4.8211e-01 (4.4745e-01)	Acc@1  83.59 ( 84.22)
The current update step is 17100
The current seed is 7673997729806445076
The current lr is: 0.0015
Testing Results:
 *   Acc@1 76.697
 *   Acc@1 76.293
 *   Acc@1 78.053
 *   Acc@1 77.982
 *   Acc@1 78.276
 *   Acc@1 77.967
 *   Acc@1 40.000
 *   Acc@1 40.809
 *   Acc@1 45.829
 *   Acc@1 46.913
 *   Acc@1 46.592
 *   Acc@1 47.601
 *   Acc@1 54.882
 *   Acc@1 55.222
 *   Acc@1 51.566
 *   Acc@1 52.238
 *   Acc@1 51.039
 *   Acc@1 51.447
 *   Acc@1 71.987
 *   Acc@1 72.650
 *   Acc@1 74.987
 *   Acc@1 75.798
 *   Acc@1 75.895
 *   Acc@1 75.962
Training for 300 epoch: 60.891447368421055
Training for 600 epoch: 62.608552631578945
Training for 1000 epoch: 62.95065789473684
Training for 300 epoch: 61.24375
Training for 600 epoch: 63.232708333333335
Training for 1000 epoch: 63.244166666666665
[[60.891447368421055, 62.608552631578945, 62.95065789473684], [61.24375, 63.232708333333335, 63.244166666666665]]
train loss 0.38574975883165996, epoch 569, best loss 0.24042404685020446, best_epoch 544
GPU_0_using curriculum 40 with window 40
Epoch: [570][20/30]	Time  1.492 ( 1.515)	Data  0.035 ( 0.048)	InnerLoop  0.629 ( 0.648)	Loss 4.4262e-01 (4.6395e-01)	Acc@1  85.18 ( 84.12)
The current update step is 17130
GPU_0_using curriculum 40 with window 40
Epoch: [571][20/30]	Time  1.497 ( 1.507)	Data  0.035 ( 0.059)	InnerLoop  0.625 ( 0.631)	Loss 4.7686e-01 (4.4119e-01)	Acc@1  84.25 ( 84.49)
The current update step is 17160
GPU_0_using curriculum 40 with window 40
Epoch: [572][20/30]	Time  1.482 ( 1.505)	Data  0.035 ( 0.048)	InnerLoop  0.630 ( 0.641)	Loss 4.2507e-01 (4.3926e-01)	Acc@1  85.52 ( 84.66)
The current update step is 17190
GPU_0_using curriculum 40 with window 40
Epoch: [573][20/30]	Time  1.480 ( 1.506)	Data  0.036 ( 0.065)	InnerLoop  0.628 ( 0.625)	Loss 4.5215e-01 (4.3614e-01)	Acc@1  84.01 ( 84.62)
The current update step is 17220
GPU_0_using curriculum 40 with window 40
Epoch: [574][20/30]	Time  1.493 ( 1.512)	Data  0.041 ( 0.065)	InnerLoop  0.630 ( 0.629)	Loss 4.4092e-01 (4.4023e-01)	Acc@1  85.28 ( 84.79)
The current update step is 17250
The current seed is 126398418566481453
The current lr is: 0.0015
Testing Results:
 *   Acc@1 76.250
 *   Acc@1 76.563
 *   Acc@1 73.697
 *   Acc@1 74.302
 *   Acc@1 73.750
 *   Acc@1 74.325
 *   Acc@1 71.934
 *   Acc@1 72.717
 *   Acc@1 74.461
 *   Acc@1 75.175
 *   Acc@1 74.500
 *   Acc@1 75.403
 *   Acc@1 77.105
 *   Acc@1 77.873
 *   Acc@1 78.368
 *   Acc@1 78.692
 *   Acc@1 78.408
 *   Acc@1 78.787
 *   Acc@1 77.118
 *   Acc@1 76.796
 *   Acc@1 77.987
 *   Acc@1 77.702
 *   Acc@1 77.882
 *   Acc@1 77.785
Training for 300 epoch: 75.60197368421052
Training for 600 epoch: 76.12828947368422
Training for 1000 epoch: 76.13486842105263
Training for 300 epoch: 75.98708333333333
Training for 600 epoch: 76.46791666666667
Training for 1000 epoch: 76.575
[[75.60197368421052, 76.12828947368422, 76.13486842105263], [75.98708333333333, 76.46791666666667, 76.575]]
train loss 0.326649262825648, epoch 574, best loss 0.24042404685020446, best_epoch 544
GPU_0_using curriculum 40 with window 40
Epoch: [575][20/30]	Time  1.496 ( 1.516)	Data  0.036 ( 0.060)	InnerLoop  0.636 ( 0.637)	Loss 4.1940e-01 (4.3564e-01)	Acc@1  85.72 ( 84.77)
The current update step is 17280
GPU_0_using curriculum 40 with window 40
Epoch: [576][20/30]	Time  1.484 ( 1.509)	Data  0.035 ( 0.066)	InnerLoop  0.628 ( 0.625)	Loss 4.6195e-01 (4.3595e-01)	Acc@1  82.93 ( 84.87)
The current update step is 17310
GPU_0_using curriculum 40 with window 40
Epoch: [577][20/30]	Time  1.498 ( 1.503)	Data  0.039 ( 0.060)	InnerLoop  0.629 ( 0.627)	Loss 4.4624e-01 (4.7242e-01)	Acc@1  85.11 ( 83.66)
The current update step is 17340
GPU_0_using curriculum 40 with window 40
Epoch: [578][20/30]	Time  1.475 ( 1.502)	Data  0.036 ( 0.059)	InnerLoop  0.620 ( 0.627)	Loss 4.9723e-01 (4.3233e-01)	Acc@1  82.30 ( 84.97)
The current update step is 17370
GPU_0_using curriculum 40 with window 40
Epoch: [579][20/30]	Time  1.476 ( 1.502)	Data  0.036 ( 0.053)	InnerLoop  0.625 ( 0.634)	Loss 6.1989e-01 (4.5590e-01)	Acc@1  78.15 ( 84.09)
The current update step is 17400
The current seed is 11243893539581664455
The current lr is: 0.0015
Testing Results:
 *   Acc@1 74.513
 *   Acc@1 75.212
 *   Acc@1 70.618
 *   Acc@1 70.618
 *   Acc@1 70.829
 *   Acc@1 71.172
 *   Acc@1 70.395
 *   Acc@1 71.470
 *   Acc@1 72.211
 *   Acc@1 72.951
 *   Acc@1 72.579
 *   Acc@1 73.464
 *   Acc@1 76.276
 *   Acc@1 76.584
 *   Acc@1 75.289
 *   Acc@1 75.992
 *   Acc@1 74.724
 *   Acc@1 75.414
 *   Acc@1 47.553
 *   Acc@1 47.823
 *   Acc@1 48.855
 *   Acc@1 48.789
 *   Acc@1 49.197
 *   Acc@1 49.763
Training for 300 epoch: 67.18421052631578
Training for 600 epoch: 66.74342105263158
Training for 1000 epoch: 66.83223684210526
Training for 300 epoch: 67.77229166666666
Training for 600 epoch: 67.08729166666667
Training for 1000 epoch: 67.45333333333333
[[67.18421052631578, 66.74342105263158, 66.83223684210526], [67.77229166666666, 67.08729166666667, 67.45333333333333]]
train loss 0.8285733357747396, epoch 579, best loss 0.24042404685020446, best_epoch 544
GPU_0_using curriculum 40 with window 40
Epoch: [580][20/30]	Time  1.601 ( 1.508)	Data  0.149 ( 0.065)	InnerLoop  0.622 ( 0.626)	Loss 4.3624e-01 (4.5828e-01)	Acc@1  84.35 ( 83.75)
The current update step is 17430
GPU_0_using curriculum 40 with window 40
Epoch: [581][20/30]	Time  1.592 ( 1.513)	Data  0.036 ( 0.054)	InnerLoop  0.737 ( 0.641)	Loss 4.3937e-01 (4.4932e-01)	Acc@1  84.89 ( 84.49)
The current update step is 17460
GPU_0_using curriculum 40 with window 40
Epoch: [582][20/30]	Time  1.501 ( 1.508)	Data  0.039 ( 0.048)	InnerLoop  0.634 ( 0.641)	Loss 4.6257e-01 (4.4746e-01)	Acc@1  83.52 ( 84.28)
The current update step is 17490
GPU_0_using curriculum 40 with window 40
Epoch: [583][20/30]	Time  1.484 ( 1.515)	Data  0.038 ( 0.055)	InnerLoop  0.629 ( 0.638)	Loss 4.3316e-01 (4.4641e-01)	Acc@1  84.74 ( 84.34)
The current update step is 17520
GPU_0_using curriculum 40 with window 40
Epoch: [584][20/30]	Time  1.495 ( 1.510)	Data  0.038 ( 0.043)	InnerLoop  0.627 ( 0.647)	Loss 4.3328e-01 (4.4990e-01)	Acc@1  84.81 ( 84.32)
The current update step is 17550
The current seed is 16289032775289554302
The current lr is: 0.0015
Testing Results:
 *   Acc@1 72.355
 *   Acc@1 72.212
 *   Acc@1 72.724
 *   Acc@1 73.297
 *   Acc@1 73.408
 *   Acc@1 74.080
 *   Acc@1 69.658
 *   Acc@1 70.127
 *   Acc@1 70.605
 *   Acc@1 70.998
 *   Acc@1 70.605
 *   Acc@1 71.053
 *   Acc@1 52.671
 *   Acc@1 53.038
 *   Acc@1 58.947
 *   Acc@1 58.710
 *   Acc@1 60.000
 *   Acc@1 59.741
 *   Acc@1 71.211
 *   Acc@1 71.883
 *   Acc@1 71.803
 *   Acc@1 72.427
 *   Acc@1 71.803
 *   Acc@1 72.584
Training for 300 epoch: 66.47368421052632
Training for 600 epoch: 68.51973684210526
Training for 1000 epoch: 68.95394736842105
Training for 300 epoch: 66.81520833333333
Training for 600 epoch: 68.858125
Training for 1000 epoch: 69.36458333333333
[[66.47368421052632, 68.51973684210526, 68.95394736842105], [66.81520833333333, 68.858125, 69.36458333333333]]
train loss 0.36780813468297324, epoch 584, best loss 0.24042404685020446, best_epoch 544
GPU_0_using curriculum 40 with window 40
Epoch: [585][20/30]	Time  1.478 ( 1.503)	Data  0.038 ( 0.053)	InnerLoop  0.622 ( 0.634)	Loss 4.8784e-01 (4.4407e-01)	Acc@1  82.81 ( 84.39)
The current update step is 17580
GPU_0_using curriculum 40 with window 40
Epoch: [586][20/30]	Time  1.588 ( 1.509)	Data  0.150 ( 0.059)	InnerLoop  0.620 ( 0.633)	Loss 4.4241e-01 (4.5233e-01)	Acc@1  85.16 ( 84.11)
The current update step is 17610
GPU_0_using curriculum 40 with window 40
Epoch: [587][20/30]	Time  1.494 ( 1.502)	Data  0.039 ( 0.036)	InnerLoop  0.628 ( 0.650)	Loss 4.3449e-01 (4.4871e-01)	Acc@1  85.40 ( 84.18)
The current update step is 17640
GPU_0_using curriculum 40 with window 40
Epoch: [588][20/30]	Time  1.473 ( 1.501)	Data  0.037 ( 0.048)	InnerLoop  0.622 ( 0.639)	Loss 4.4773e-01 (4.5704e-01)	Acc@1  83.81 ( 83.83)
The current update step is 17670
GPU_0_using curriculum 40 with window 40
Epoch: [589][20/30]	Time  1.479 ( 1.505)	Data  0.037 ( 0.059)	InnerLoop  0.624 ( 0.629)	Loss 4.5161e-01 (4.4909e-01)	Acc@1  84.28 ( 84.22)
The current update step is 17700
The current seed is 4271005385601639070
The current lr is: 0.0015
Testing Results:
 *   Acc@1 70.289
 *   Acc@1 70.440
 *   Acc@1 71.316
 *   Acc@1 71.797
 *   Acc@1 72.368
 *   Acc@1 72.862
 *   Acc@1 38.013
 *   Acc@1 38.364
 *   Acc@1 37.632
 *   Acc@1 38.057
 *   Acc@1 37.882
 *   Acc@1 38.294
 *   Acc@1 77.987
 *   Acc@1 77.833
 *   Acc@1 76.132
 *   Acc@1 76.877
 *   Acc@1 76.145
 *   Acc@1 76.834
 *   Acc@1 70.355
 *   Acc@1 70.913
 *   Acc@1 58.118
 *   Acc@1 58.608
 *   Acc@1 57.474
 *   Acc@1 58.127
Training for 300 epoch: 64.16118421052632
Training for 600 epoch: 60.79934210526316
Training for 1000 epoch: 60.96710526315789
Training for 300 epoch: 64.38770833333334
Training for 600 epoch: 61.334999999999994
Training for 1000 epoch: 61.529375
[[64.16118421052632, 60.79934210526316, 60.96710526315789], [64.38770833333334, 61.334999999999994, 61.529375]]
train loss 0.8662109600385031, epoch 589, best loss 0.24042404685020446, best_epoch 544
GPU_0_using curriculum 40 with window 40
Epoch: [590][20/30]	Time  1.494 ( 1.508)	Data  0.037 ( 0.047)	InnerLoop  0.626 ( 0.642)	Loss 4.2471e-01 (4.3719e-01)	Acc@1  85.45 ( 84.82)
The current update step is 17730
GPU_0_using curriculum 40 with window 40
Epoch: [591][20/30]	Time  1.476 ( 1.503)	Data  0.034 ( 0.059)	InnerLoop  0.623 ( 0.629)	Loss 4.3793e-01 (4.3909e-01)	Acc@1  84.89 ( 84.59)
The current update step is 17760
GPU_0_using curriculum 40 with window 40
Epoch: [592][20/30]	Time  1.474 ( 1.504)	Data  0.037 ( 0.048)	InnerLoop  0.622 ( 0.640)	Loss 4.5041e-01 (4.3856e-01)	Acc@1  83.94 ( 84.71)
The current update step is 17790
GPU_0_using curriculum 40 with window 40
Epoch: [593][20/30]	Time  1.477 ( 1.506)	Data  0.036 ( 0.065)	InnerLoop  0.622 ( 0.623)	Loss 4.9205e-01 (4.4405e-01)	Acc@1  84.06 ( 84.64)
The current update step is 17820
GPU_0_using curriculum 40 with window 40
Epoch: [594][20/30]	Time  1.493 ( 1.515)	Data  0.040 ( 0.065)	InnerLoop  0.628 ( 0.631)	Loss 4.1752e-01 (4.4226e-01)	Acc@1  84.99 ( 84.55)
The current update step is 17850
The current seed is 5596073909411672378
The current lr is: 0.0015
Testing Results:
 *   Acc@1 63.184
 *   Acc@1 64.499
 *   Acc@1 59.737
 *   Acc@1 59.531
 *   Acc@1 63.671
 *   Acc@1 63.953
 *   Acc@1 77.974
 *   Acc@1 78.571
 *   Acc@1 77.803
 *   Acc@1 78.388
 *   Acc@1 77.500
 *   Acc@1 78.358
 *   Acc@1 75.618
 *   Acc@1 75.519
 *   Acc@1 73.750
 *   Acc@1 74.016
 *   Acc@1 76.026
 *   Acc@1 76.125
 *   Acc@1 79.342
 *   Acc@1 79.819
 *   Acc@1 79.605
 *   Acc@1 79.930
 *   Acc@1 79.566
 *   Acc@1 79.826
Training for 300 epoch: 74.02960526315789
Training for 600 epoch: 72.72368421052632
Training for 1000 epoch: 74.19078947368422
Training for 300 epoch: 74.60208333333333
Training for 600 epoch: 72.96604166666667
Training for 1000 epoch: 74.56520833333333
[[74.02960526315789, 72.72368421052632, 74.19078947368422], [74.60208333333333, 72.96604166666667, 74.56520833333333]]
train loss 0.27853326930999756, epoch 594, best loss 0.24042404685020446, best_epoch 544
GPU_0_using curriculum 40 with window 40
Epoch: [595][20/30]	Time  1.482 ( 1.510)	Data  0.039 ( 0.060)	InnerLoop  0.628 ( 0.634)	Loss 4.1516e-01 (4.3568e-01)	Acc@1  84.94 ( 84.79)
The current update step is 17880
GPU_0_using curriculum 40 with window 40
Epoch: [596][20/30]	Time  1.472 ( 1.504)	Data  0.035 ( 0.065)	InnerLoop  0.619 ( 0.622)	Loss 4.4899e-01 (4.4009e-01)	Acc@1  84.16 ( 84.66)
The current update step is 17910
GPU_0_using curriculum 40 with window 40
Epoch: [597][20/30]	Time  1.503 ( 1.503)	Data  0.040 ( 0.060)	InnerLoop  0.632 ( 0.627)	Loss 4.5447e-01 (4.4010e-01)	Acc@1  83.59 ( 84.73)
The current update step is 17940
GPU_0_using curriculum 40 with window 40
Epoch: [598][20/30]	Time  1.473 ( 1.502)	Data  0.035 ( 0.059)	InnerLoop  0.623 ( 0.627)	Loss 4.4899e-01 (4.4860e-01)	Acc@1  84.74 ( 84.53)
The current update step is 17970
GPU_0_using curriculum 40 with window 40
Epoch: [599][20/30]	Time  1.468 ( 1.501)	Data  0.036 ( 0.053)	InnerLoop  0.616 ( 0.633)	Loss 4.5457e-01 (4.5118e-01)	Acc@1  83.69 ( 84.17)
The current update step is 18000
The current seed is 8293897821315100040
The current lr is: 0.0015
Testing Results:
 *   Acc@1 70.671
 *   Acc@1 70.867
 *   Acc@1 72.408
 *   Acc@1 72.859
 *   Acc@1 72.566
 *   Acc@1 73.083
 *   Acc@1 62.711
 *   Acc@1 63.665
 *   Acc@1 64.895
 *   Acc@1 65.428
 *   Acc@1 63.145
 *   Acc@1 63.526
 *   Acc@1 54.000
 *   Acc@1 54.305
 *   Acc@1 55.921
 *   Acc@1 56.067
 *   Acc@1 55.868
 *   Acc@1 55.890
 *   Acc@1 70.697
 *   Acc@1 71.412
 *   Acc@1 71.987
 *   Acc@1 72.982
 *   Acc@1 72.684
 *   Acc@1 73.785
Training for 300 epoch: 64.51973684210526
Training for 600 epoch: 66.30263157894737
Training for 1000 epoch: 66.06578947368422
Training for 300 epoch: 65.06208333333333
Training for 600 epoch: 66.83395833333333
Training for 1000 epoch: 66.57104166666667
[[64.51973684210526, 66.30263157894737, 66.06578947368422], [65.06208333333333, 66.83395833333333, 66.57104166666667]]
train loss 0.36271362767219545, epoch 599, best loss 0.24042404685020446, best_epoch 544
=== Final results:
{'acc': 77.29605263157895, 'test': [76.26315789473684, 77.29605263157895, 76.55921052631578], 'train': [76.26315789473684, 77.29605263157895, 76.55921052631578], 'ind': 1, 'epoch': 565, 'data': array([[-0.49768323,  0.05642358,  0.07464214, ...,  0.25349805,
        -0.1931045 ,  0.06439928],
       [-0.0037201 ,  0.04685206,  0.17992938, ...,  0.08454392,
        -0.04200172,  0.36532822],
       [-0.14734112, -0.14217886, -0.10593066, ...,  0.05353294,
         0.41489562,  0.12550887],
       ...,
       [ 0.11961501, -0.45228946,  0.2324492 , ..., -0.377351  ,
        -0.07703793, -0.24260855],
       [ 0.02562764,  0.30226645,  0.17645758, ...,  0.10857252,
        -0.07223282,  0.09350168],
       [ 0.24352995, -0.25213194, -0.1441275 , ..., -0.2283557 ,
         0.08224148, -0.23487835]], shape=(200, 768), dtype=float32)}
