Torch Seed Specified with rank: 0
Dataset: agnews_emb
Dataset Path: ./scripts
Namespace(seed=0, mp_distributed=False, world_size=1, rank=0, dist_url='tcp://224.66.41.62:23456', dist_backend='nccl', workers=0, gpu=None, root='./scripts', dataset='agnews_emb', arch='text_transformer', width=256, lr=0.001, inner_optim='Adam', outer_optim='Adam', inner_lr=0.001, label_lr_scale=1, num_per_class=5, batch_per_class=5, task_sampler_nc=4, window=40, minwindow=0, totwindow=40, num_train_eval=4, train_y=False, batch_size=4096, eps=1e-08, wd=0, test_freq=5, print_freq=20, start_epoch=0, epochs=200, ddtype='standard', cctype=0, zca=False, wandb=False, clip_coef=0.9, fname='out_tf_fullbptt_ipc05_s1', out_dir='./checkpoints', name='agnews_tf_fullbptt_s1', comp_aug=False, comp_aug_real=False, syn_strategy='none', real_strategy='none', ckptname='none', limit_train=False, load_ckpt=False, complete_random=False, boost_dd=False, boost_init_from='none', boost_beta=1.0, stage=1, distributed=False, data_root='./scripts/agnews_emb')
==> Preparing data..
None None
Dataset: number of classes: 4
Training set size: 120000
Image size: channel 1, height 768, width 1
Synthetic images, not_single False, keys []
==> Building model..
Initialized data with size, x: torch.Size([20, 768]), y:torch.Size([20])
TextTransformer(
  (input_proj): Linear(in_features=192, out_features=256, bias=True)
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=1024, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=1024, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (cls_head): Linear(in_features=256, out_features=4, bias=True)
)
use data parallel only
GPU_0_using curriculum 40 with window 40
Epoch: [0][20/30]	Time  1.584 ( 1.640)	Data  0.042 ( 0.055)	InnerLoop  0.651 ( 0.689)	Loss 1.4644e+00 (3.4112e+00)	Acc@1  43.77 ( 35.33)
The current update step is 30
GPU_0_using curriculum 40 with window 40
Epoch: [1][20/30]	Time  1.615 ( 1.622)	Data  0.045 ( 0.066)	InnerLoop  0.658 ( 0.659)	Loss 1.4419e+00 (1.6357e+00)	Acc@1  51.37 ( 48.06)
The current update step is 60
GPU_0_using curriculum 40 with window 40
Epoch: [2][20/30]	Time  1.750 ( 1.630)	Data  0.040 ( 0.073)	InnerLoop  0.783 ( 0.660)	Loss 1.2384e+00 (1.2896e+00)	Acc@1  55.69 ( 53.63)
The current update step is 90
GPU_0_using curriculum 40 with window 40
Epoch: [3][20/30]	Time  1.591 ( 1.616)	Data  0.042 ( 0.054)	InnerLoop  0.658 ( 0.670)	Loss 1.5231e+00 (1.2860e+00)	Acc@1  51.68 ( 56.00)
The current update step is 120
GPU_0_using curriculum 40 with window 40
Epoch: [4][20/30]	Time  1.567 ( 1.610)	Data  0.040 ( 0.060)	InnerLoop  0.647 ( 0.661)	Loss 9.2784e-01 (1.1331e+00)	Acc@1  63.99 ( 59.23)
The current update step is 150
The current seed is 12724502088562794180
The current lr is: 0.001
Testing Results:
 *   Acc@1 56.539
 *   Acc@1 56.572
 *   Acc@1 57.658
 *   Acc@1 57.782
 *   Acc@1 57.737
 *   Acc@1 57.861
 *   Acc@1 57.868
 *   Acc@1 57.948
 *   Acc@1 43.789
 *   Acc@1 43.598
 *   Acc@1 44.289
 *   Acc@1 43.764
 *   Acc@1 44.289
 *   Acc@1 43.932
 *   Acc@1 45.171
 *   Acc@1 44.928
 *   Acc@1 58.224
 *   Acc@1 58.002
 *   Acc@1 54.276
 *   Acc@1 54.095
 *   Acc@1 53.053
 *   Acc@1 52.897
 *   Acc@1 50.908
 *   Acc@1 50.565
 *   Acc@1 47.579
 *   Acc@1 47.938
 *   Acc@1 46.553
 *   Acc@1 46.848
 *   Acc@1 46.974
 *   Acc@1 47.458
 *   Acc@1 47.105
 *   Acc@1 47.434
Training for 300 epoch: 51.53289473684211
Training for 600 epoch: 50.69407894736842
Training for 1000 epoch: 50.513157894736835
Training for 3000 epoch: 50.26315789473684
Training for 300 epoch: 51.5275
Training for 600 epoch: 50.62229166666666
Training for 1000 epoch: 50.53666666666667
Training for 3000 epoch: 50.21875
[[51.53289473684211, 50.69407894736842, 50.513157894736835, 50.26315789473684], [51.5275, 50.62229166666666, 50.53666666666667, 50.21875]]
train loss 0.5039744882265726, epoch 4, best loss 0.5039744882265726, best_epoch 4
GPU_0_using curriculum 40 with window 40
Epoch: [5][20/30]	Time  1.551 ( 1.602)	Data  0.041 ( 0.064)	InnerLoop  0.639 ( 0.657)	Loss 1.0317e+00 (1.1737e+00)	Acc@1  61.74 ( 57.99)
The current update step is 180
GPU_0_using curriculum 40 with window 40
Epoch: [6][20/30]	Time  1.558 ( 1.592)	Data  0.040 ( 0.073)	InnerLoop  0.635 ( 0.640)	Loss 8.8593e-01 (1.0031e+00)	Acc@1  67.50 ( 62.44)
The current update step is 210
GPU_0_using curriculum 40 with window 40
Epoch: [7][20/30]	Time  1.569 ( 1.596)	Data  0.043 ( 0.066)	InnerLoop  0.647 ( 0.650)	Loss 7.7549e-01 (9.6388e-01)	Acc@1  71.31 ( 64.72)
The current update step is 240
GPU_0_using curriculum 40 with window 40
Epoch: [8][20/30]	Time  1.522 ( 1.549)	Data  0.043 ( 0.065)	InnerLoop  0.624 ( 0.631)	Loss 1.0806e+00 (1.0196e+00)	Acc@1  62.11 ( 63.13)
The current update step is 270
GPU_0_using curriculum 40 with window 40
Epoch: [9][20/30]	Time  1.518 ( 1.551)	Data  0.042 ( 0.059)	InnerLoop  0.625 ( 0.636)	Loss 1.0905e+00 (9.3146e-01)	Acc@1  58.94 ( 66.35)
The current update step is 300
The current seed is 1459784815192281272
The current lr is: 0.001
Testing Results:
 *   Acc@1 74.618
 *   Acc@1 74.756
 *   Acc@1 75.197
 *   Acc@1 75.412
 *   Acc@1 74.355
 *   Acc@1 74.943
 *   Acc@1 74.632
 *   Acc@1 74.395
 *   Acc@1 62.039
 *   Acc@1 62.133
 *   Acc@1 63.803
 *   Acc@1 64.105
 *   Acc@1 63.053
 *   Acc@1 64.175
 *   Acc@1 60.355
 *   Acc@1 60.385
 *   Acc@1 62.408
 *   Acc@1 62.372
 *   Acc@1 64.474
 *   Acc@1 64.861
 *   Acc@1 65.500
 *   Acc@1 65.634
 *   Acc@1 66.592
 *   Acc@1 66.882
 *   Acc@1 69.329
 *   Acc@1 69.367
 *   Acc@1 68.342
 *   Acc@1 67.641
 *   Acc@1 67.434
 *   Acc@1 67.206
 *   Acc@1 65.539
 *   Acc@1 65.148
Training for 300 epoch: 67.09868421052632
Training for 600 epoch: 67.95394736842104
Training for 1000 epoch: 67.58552631578948
Training for 3000 epoch: 66.77960526315789
Training for 300 epoch: 67.156875
Training for 600 epoch: 68.00458333333333
Training for 1000 epoch: 67.98958333333333
Training for 3000 epoch: 66.70270833333333
[[67.09868421052632, 67.95394736842104, 67.58552631578948, 66.77960526315789], [67.156875, 68.00458333333333, 67.98958333333333, 66.70270833333333]]
train loss 0.28689385396639505, epoch 9, best loss 0.28689385396639505, best_epoch 9
GPU_0_using curriculum 40 with window 40
Epoch: [10][20/30]	Time  1.479 ( 1.524)	Data  0.036 ( 0.062)	InnerLoop  0.613 ( 0.630)	Loss 8.1464e-01 (8.8889e-01)	Acc@1  69.56 ( 68.18)
The current update step is 330
GPU_0_using curriculum 40 with window 40
Epoch: [11][20/30]	Time  1.481 ( 1.513)	Data  0.037 ( 0.070)	InnerLoop  0.615 ( 0.614)	Loss 1.4490e+00 (9.2305e-01)	Acc@1  53.03 ( 66.65)
The current update step is 360
GPU_0_using curriculum 40 with window 40
Epoch: [12][20/30]	Time  1.507 ( 1.520)	Data  0.041 ( 0.064)	InnerLoop  0.636 ( 0.622)	Loss 8.6307e-01 (9.1563e-01)	Acc@1  64.01 ( 66.64)
The current update step is 390
GPU_0_using curriculum 40 with window 40
Epoch: [13][20/30]	Time  1.482 ( 1.520)	Data  0.039 ( 0.063)	InnerLoop  0.618 ( 0.623)	Loss 9.9905e-01 (8.8776e-01)	Acc@1  64.99 ( 67.68)
The current update step is 420
GPU_0_using curriculum 40 with window 40
Epoch: [14][20/30]	Time  1.489 ( 1.519)	Data  0.037 ( 0.057)	InnerLoop  0.611 ( 0.630)	Loss 8.8452e-01 (8.7358e-01)	Acc@1  63.31 ( 67.14)
The current update step is 450
The current seed is 1855524383600422744
The current lr is: 0.001
Testing Results:
 *   Acc@1 65.066
 *   Acc@1 65.118
 *   Acc@1 64.316
 *   Acc@1 64.334
 *   Acc@1 64.224
 *   Acc@1 64.177
 *   Acc@1 67.526
 *   Acc@1 67.921
 *   Acc@1 71.447
 *   Acc@1 71.653
 *   Acc@1 73.395
 *   Acc@1 73.058
 *   Acc@1 72.421
 *   Acc@1 72.786
 *   Acc@1 71.526
 *   Acc@1 71.473
 *   Acc@1 69.092
 *   Acc@1 69.393
 *   Acc@1 70.500
 *   Acc@1 70.109
 *   Acc@1 69.882
 *   Acc@1 70.046
 *   Acc@1 67.355
 *   Acc@1 67.316
 *   Acc@1 69.934
 *   Acc@1 69.978
 *   Acc@1 71.816
 *   Acc@1 72.338
 *   Acc@1 72.645
 *   Acc@1 72.742
 *   Acc@1 72.303
 *   Acc@1 72.737
Training for 300 epoch: 68.88486842105263
Training for 600 epoch: 70.00657894736842
Training for 1000 epoch: 69.79276315789474
Training for 3000 epoch: 69.67763157894737
Training for 300 epoch: 69.03562500000001
Training for 600 epoch: 69.95979166666666
Training for 1000 epoch: 69.9375
Training for 3000 epoch: 69.861875
[[68.88486842105263, 70.00657894736842, 69.79276315789474, 69.67763157894737], [69.03562500000001, 69.95979166666666, 69.9375, 69.861875]]
train loss 0.22610128786563874, epoch 14, best loss 0.22610128786563874, best_epoch 14
GPU_0_using curriculum 40 with window 40
Epoch: [15][20/30]	Time  1.502 ( 1.522)	Data  0.037 ( 0.060)	InnerLoop  0.611 ( 0.626)	Loss 7.2563e-01 (7.5793e-01)	Acc@1  71.34 ( 71.90)
The current update step is 480
GPU_0_using curriculum 40 with window 40
Epoch: [16][20/30]	Time  1.475 ( 1.517)	Data  0.037 ( 0.067)	InnerLoop  0.607 ( 0.614)	Loss 1.2996e+00 (9.7045e-01)	Acc@1  54.59 ( 67.22)
The current update step is 510
GPU_0_using curriculum 40 with window 40
Epoch: [17][20/30]	Time  1.476 ( 1.506)	Data  0.037 ( 0.061)	InnerLoop  0.608 ( 0.616)	Loss 1.0291e+00 (8.2998e-01)	Acc@1  56.35 ( 69.76)
The current update step is 540
GPU_0_using curriculum 40 with window 40
Epoch: [18][20/30]	Time  1.477 ( 1.506)	Data  0.037 ( 0.062)	InnerLoop  0.606 ( 0.616)	Loss 7.3175e-01 (8.3265e-01)	Acc@1  75.93 ( 69.55)
The current update step is 570
GPU_0_using curriculum 40 with window 40
Epoch: [19][20/30]	Time  1.490 ( 1.515)	Data  0.040 ( 0.055)	InnerLoop  0.616 ( 0.626)	Loss 6.8166e-01 (7.7341e-01)	Acc@1  75.51 ( 71.02)
The current update step is 600
The current seed is 13313721987166245376
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.342
 *   Acc@1 71.166
 *   Acc@1 71.105
 *   Acc@1 71.514
 *   Acc@1 71.684
 *   Acc@1 72.066
 *   Acc@1 71.737
 *   Acc@1 71.391
 *   Acc@1 70.487
 *   Acc@1 70.713
 *   Acc@1 71.053
 *   Acc@1 71.525
 *   Acc@1 72.329
 *   Acc@1 72.438
 *   Acc@1 72.329
 *   Acc@1 72.597
 *   Acc@1 71.974
 *   Acc@1 72.209
 *   Acc@1 73.092
 *   Acc@1 73.078
 *   Acc@1 72.592
 *   Acc@1 72.296
 *   Acc@1 71.724
 *   Acc@1 71.951
 *   Acc@1 58.487
 *   Acc@1 58.579
 *   Acc@1 60.000
 *   Acc@1 60.047
 *   Acc@1 62.211
 *   Acc@1 62.723
 *   Acc@1 64.513
 *   Acc@1 64.838
Training for 300 epoch: 67.82236842105263
Training for 600 epoch: 68.8125
Training for 1000 epoch: 69.70394736842105
Training for 3000 epoch: 70.07565789473684
Training for 300 epoch: 68.16666666666666
Training for 600 epoch: 69.04104166666667
Training for 1000 epoch: 69.88062500000001
Training for 3000 epoch: 70.19416666666666
[[67.82236842105263, 68.8125, 69.70394736842105, 70.07565789473684], [68.16666666666666, 69.04104166666667, 69.88062500000001, 70.19416666666666]]
train loss 0.23094435239632924, epoch 19, best loss 0.22610128786563874, best_epoch 14
GPU_0_using curriculum 40 with window 40
Epoch: [20][20/30]	Time  1.490 ( 1.518)	Data  0.040 ( 0.062)	InnerLoop  0.616 ( 0.626)	Loss 6.7913e-01 (8.2285e-01)	Acc@1  75.71 ( 69.44)
The current update step is 630
GPU_0_using curriculum 40 with window 40
Epoch: [21][20/30]	Time  1.487 ( 1.509)	Data  0.037 ( 0.068)	InnerLoop  0.610 ( 0.611)	Loss 1.2822e+00 (8.8632e-01)	Acc@1  52.83 ( 67.96)
The current update step is 660
GPU_0_using curriculum 40 with window 40
Epoch: [22][20/30]	Time  1.490 ( 1.513)	Data  0.040 ( 0.062)	InnerLoop  0.616 ( 0.620)	Loss 6.2020e-01 (7.7909e-01)	Acc@1  76.88 ( 71.44)
The current update step is 690
GPU_0_using curriculum 40 with window 40
Epoch: [23][20/30]	Time  1.477 ( 1.511)	Data  0.037 ( 0.062)	InnerLoop  0.613 ( 0.617)	Loss 6.8599e-01 (8.3202e-01)	Acc@1  73.95 ( 69.95)
The current update step is 720
GPU_0_using curriculum 40 with window 40
Epoch: [24][20/30]	Time  1.473 ( 1.513)	Data  0.037 ( 0.057)	InnerLoop  0.608 ( 0.626)	Loss 7.5038e-01 (7.5007e-01)	Acc@1  73.10 ( 72.22)
The current update step is 750
The current seed is 2372931194511494470
The current lr is: 0.001
Testing Results:
 *   Acc@1 60.368
 *   Acc@1 60.882
 *   Acc@1 59.921
 *   Acc@1 60.278
 *   Acc@1 59.908
 *   Acc@1 60.515
 *   Acc@1 61.461
 *   Acc@1 62.010
 *   Acc@1 72.789
 *   Acc@1 73.480
 *   Acc@1 69.750
 *   Acc@1 71.302
 *   Acc@1 69.526
 *   Acc@1 70.231
 *   Acc@1 67.145
 *   Acc@1 68.351
 *   Acc@1 71.461
 *   Acc@1 70.934
 *   Acc@1 71.605
 *   Acc@1 71.059
 *   Acc@1 70.776
 *   Acc@1 70.768
 *   Acc@1 69.737
 *   Acc@1 69.657
 *   Acc@1 72.105
 *   Acc@1 72.315
 *   Acc@1 74.105
 *   Acc@1 74.429
 *   Acc@1 73.842
 *   Acc@1 74.217
 *   Acc@1 72.211
 *   Acc@1 72.657
Training for 300 epoch: 69.18092105263159
Training for 600 epoch: 68.84539473684211
Training for 1000 epoch: 68.51315789473685
Training for 3000 epoch: 67.63815789473685
Training for 300 epoch: 69.40270833333334
Training for 600 epoch: 69.266875
Training for 1000 epoch: 68.93270833333332
Training for 3000 epoch: 68.16895833333334
[[69.18092105263159, 68.84539473684211, 68.51315789473685, 67.63815789473685], [69.40270833333334, 69.266875, 68.93270833333332, 68.16895833333334]]
train loss 0.1813782828648885, epoch 24, best loss 0.1813782828648885, best_epoch 24
GPU_0_using curriculum 40 with window 40
Epoch: [25][20/30]	Time  1.487 ( 1.517)	Data  0.042 ( 0.063)	InnerLoop  0.615 ( 0.625)	Loss 8.0852e-01 (7.6741e-01)	Acc@1  72.02 ( 72.09)
The current update step is 780
GPU_0_using curriculum 40 with window 40
Epoch: [26][20/30]	Time  1.476 ( 1.511)	Data  0.036 ( 0.068)	InnerLoop  0.610 ( 0.612)	Loss 8.5372e-01 (7.7525e-01)	Acc@1  70.56 ( 70.83)
The current update step is 810
GPU_0_using curriculum 40 with window 40
Epoch: [27][20/30]	Time  1.500 ( 1.511)	Data  0.041 ( 0.063)	InnerLoop  0.616 ( 0.617)	Loss 8.0310e-01 (7.7714e-01)	Acc@1  67.65 ( 71.60)
The current update step is 840
GPU_0_using curriculum 40 with window 40
Epoch: [28][20/30]	Time  1.480 ( 1.509)	Data  0.037 ( 0.062)	InnerLoop  0.614 ( 0.617)	Loss 1.0065e+00 (7.8322e-01)	Acc@1  62.35 ( 71.24)
The current update step is 870
GPU_0_using curriculum 40 with window 40
Epoch: [29][20/30]	Time  1.500 ( 1.516)	Data  0.038 ( 0.056)	InnerLoop  0.620 ( 0.629)	Loss 6.6318e-01 (7.9933e-01)	Acc@1  74.80 ( 70.32)
The current update step is 900
The current seed is 16288042169674144608
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.382
 *   Acc@1 71.816
 *   Acc@1 70.776
 *   Acc@1 71.305
 *   Acc@1 69.342
 *   Acc@1 70.401
 *   Acc@1 67.658
 *   Acc@1 68.248
 *   Acc@1 72.395
 *   Acc@1 73.383
 *   Acc@1 76.724
 *   Acc@1 77.074
 *   Acc@1 76.737
 *   Acc@1 76.927
 *   Acc@1 75.355
 *   Acc@1 75.681
 *   Acc@1 65.921
 *   Acc@1 65.914
 *   Acc@1 65.882
 *   Acc@1 65.773
 *   Acc@1 65.329
 *   Acc@1 65.613
 *   Acc@1 69.908
 *   Acc@1 69.680
 *   Acc@1 77.197
 *   Acc@1 77.181
 *   Acc@1 76.803
 *   Acc@1 77.117
 *   Acc@1 77.013
 *   Acc@1 77.532
 *   Acc@1 77.224
 *   Acc@1 77.611
Training for 300 epoch: 71.72368421052633
Training for 600 epoch: 72.54605263157896
Training for 1000 epoch: 72.10526315789473
Training for 3000 epoch: 72.53618421052632
Training for 300 epoch: 72.07354166666667
Training for 600 epoch: 72.81729166666666
Training for 1000 epoch: 72.61854166666666
Training for 3000 epoch: 72.80479166666667
[[71.72368421052633, 72.54605263157896, 72.10526315789473, 72.53618421052632], [72.07354166666667, 72.81729166666666, 72.61854166666666, 72.80479166666667]]
train loss 0.16217852989037831, epoch 29, best loss 0.16217852989037831, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [30][20/30]	Time  1.483 ( 1.516)	Data  0.039 ( 0.063)	InnerLoop  0.610 ( 0.627)	Loss 7.6582e-01 (7.3377e-01)	Acc@1  70.80 ( 73.48)
The current update step is 930
GPU_0_using curriculum 40 with window 40
Epoch: [31][20/30]	Time  1.485 ( 1.513)	Data  0.036 ( 0.067)	InnerLoop  0.620 ( 0.614)	Loss 5.8834e-01 (7.1680e-01)	Acc@1  77.76 ( 74.12)
The current update step is 960
GPU_0_using curriculum 40 with window 40
Epoch: [32][20/30]	Time  1.488 ( 1.511)	Data  0.042 ( 0.063)	InnerLoop  0.614 ( 0.618)	Loss 6.0071e-01 (7.2327e-01)	Acc@1  76.95 ( 73.09)
The current update step is 990
GPU_0_using curriculum 40 with window 40
Epoch: [33][20/30]	Time  1.483 ( 1.513)	Data  0.038 ( 0.063)	InnerLoop  0.615 ( 0.620)	Loss 6.7146e-01 (7.0428e-01)	Acc@1  75.93 ( 73.53)
The current update step is 1020
GPU_0_using curriculum 40 with window 40
Epoch: [34][20/30]	Time  1.489 ( 1.512)	Data  0.038 ( 0.055)	InnerLoop  0.614 ( 0.626)	Loss 1.1433e+00 (7.0792e-01)	Acc@1  64.16 ( 74.20)
The current update step is 1050
The current seed is 2023430723858577580
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.132
 *   Acc@1 77.030
 *   Acc@1 76.697
 *   Acc@1 76.642
 *   Acc@1 75.947
 *   Acc@1 75.642
 *   Acc@1 74.276
 *   Acc@1 74.169
 *   Acc@1 70.092
 *   Acc@1 69.961
 *   Acc@1 72.039
 *   Acc@1 71.830
 *   Acc@1 73.474
 *   Acc@1 73.427
 *   Acc@1 75.447
 *   Acc@1 75.070
 *   Acc@1 75.474
 *   Acc@1 75.671
 *   Acc@1 74.539
 *   Acc@1 75.041
 *   Acc@1 74.197
 *   Acc@1 74.975
 *   Acc@1 74.605
 *   Acc@1 74.683
 *   Acc@1 75.066
 *   Acc@1 74.912
 *   Acc@1 75.645
 *   Acc@1 75.554
 *   Acc@1 75.671
 *   Acc@1 75.427
 *   Acc@1 75.079
 *   Acc@1 75.427
Training for 300 epoch: 74.4407894736842
Training for 600 epoch: 74.73026315789474
Training for 1000 epoch: 74.82236842105263
Training for 3000 epoch: 74.85197368421052
Training for 300 epoch: 74.39333333333335
Training for 600 epoch: 74.766875
Training for 1000 epoch: 74.86770833333333
Training for 3000 epoch: 74.83708333333334
[[74.4407894736842, 74.73026315789474, 74.82236842105263, 74.85197368421052], [74.39333333333335, 74.766875, 74.86770833333333, 74.83708333333334]]
train loss 0.17980093961556753, epoch 34, best loss 0.16217852989037831, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [35][20/30]	Time  1.486 ( 1.525)	Data  0.038 ( 0.062)	InnerLoop  0.617 ( 0.630)	Loss 6.1690e-01 (7.1532e-01)	Acc@1  77.56 ( 74.21)
The current update step is 1080
GPU_0_using curriculum 40 with window 40
Epoch: [36][20/30]	Time  1.498 ( 1.515)	Data  0.047 ( 0.070)	InnerLoop  0.617 ( 0.614)	Loss 7.0130e-01 (6.9592e-01)	Acc@1  74.58 ( 74.95)
The current update step is 1110
GPU_0_using curriculum 40 with window 40
Epoch: [37][20/30]	Time  1.493 ( 1.516)	Data  0.041 ( 0.064)	InnerLoop  0.620 ( 0.620)	Loss 5.9432e-01 (7.1072e-01)	Acc@1  78.83 ( 73.60)
The current update step is 1140
GPU_0_using curriculum 40 with window 40
Epoch: [38][20/30]	Time  1.514 ( 1.518)	Data  0.042 ( 0.063)	InnerLoop  0.616 ( 0.622)	Loss 7.3720e-01 (7.4477e-01)	Acc@1  71.97 ( 73.45)
The current update step is 1170
GPU_0_using curriculum 40 with window 40
Epoch: [39][20/30]	Time  1.483 ( 1.518)	Data  0.040 ( 0.057)	InnerLoop  0.613 ( 0.628)	Loss 5.8318e-01 (7.0193e-01)	Acc@1  77.86 ( 73.92)
The current update step is 1200
The current seed is 1054921188875625860
The current lr is: 0.001
Testing Results:
 *   Acc@1 74.750
 *   Acc@1 75.149
 *   Acc@1 73.566
 *   Acc@1 73.475
 *   Acc@1 73.724
 *   Acc@1 73.555
 *   Acc@1 73.684
 *   Acc@1 73.712
 *   Acc@1 70.105
 *   Acc@1 70.321
 *   Acc@1 69.895
 *   Acc@1 70.588
 *   Acc@1 70.184
 *   Acc@1 70.887
 *   Acc@1 71.921
 *   Acc@1 72.614
 *   Acc@1 75.447
 *   Acc@1 75.323
 *   Acc@1 75.829
 *   Acc@1 75.669
 *   Acc@1 76.342
 *   Acc@1 76.249
 *   Acc@1 76.145
 *   Acc@1 75.892
 *   Acc@1 67.158
 *   Acc@1 66.920
 *   Acc@1 66.263
 *   Acc@1 66.159
 *   Acc@1 65.868
 *   Acc@1 65.918
 *   Acc@1 65.789
 *   Acc@1 65.718
Training for 300 epoch: 71.86513157894737
Training for 600 epoch: 71.38815789473684
Training for 1000 epoch: 71.52960526315789
Training for 3000 epoch: 71.88486842105263
Training for 300 epoch: 71.92833333333334
Training for 600 epoch: 71.47291666666666
Training for 1000 epoch: 71.65229166666667
Training for 3000 epoch: 71.98416666666665
[[71.86513157894737, 71.38815789473684, 71.52960526315789, 71.88486842105263], [71.92833333333334, 71.47291666666666, 71.65229166666667, 71.98416666666665]]
train loss 0.2632202752272288, epoch 39, best loss 0.16217852989037831, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [40][20/30]	Time  1.499 ( 1.530)	Data  0.039 ( 0.063)	InnerLoop  0.621 ( 0.630)	Loss 6.1160e-01 (7.1224e-01)	Acc@1  77.44 ( 73.22)
The current update step is 1230
GPU_0_using curriculum 40 with window 40
Epoch: [41][20/30]	Time  1.479 ( 1.516)	Data  0.037 ( 0.069)	InnerLoop  0.614 ( 0.613)	Loss 6.7144e-01 (7.4274e-01)	Acc@1  74.66 ( 72.52)
The current update step is 1260
GPU_0_using curriculum 40 with window 40
Epoch: [42][20/30]	Time  1.534 ( 1.522)	Data  0.042 ( 0.063)	InnerLoop  0.651 ( 0.624)	Loss 6.6543e-01 (7.1920e-01)	Acc@1  76.51 ( 73.75)
The current update step is 1290
GPU_0_using curriculum 40 with window 40
Epoch: [43][20/30]	Time  1.504 ( 1.518)	Data  0.037 ( 0.063)	InnerLoop  0.618 ( 0.621)	Loss 6.7375e-01 (7.9740e-01)	Acc@1  73.24 ( 71.06)
The current update step is 1320
GPU_0_using curriculum 40 with window 40
Epoch: [44][20/30]	Time  1.529 ( 1.517)	Data  0.040 ( 0.057)	InnerLoop  0.621 ( 0.627)	Loss 6.1456e-01 (7.3990e-01)	Acc@1  77.64 ( 72.58)
The current update step is 1350
The current seed is 2685664153478698020
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.224
 *   Acc@1 72.755
 *   Acc@1 72.263
 *   Acc@1 72.136
 *   Acc@1 73.105
 *   Acc@1 73.036
 *   Acc@1 74.145
 *   Acc@1 74.260
 *   Acc@1 68.987
 *   Acc@1 69.364
 *   Acc@1 66.250
 *   Acc@1 66.877
 *   Acc@1 67.526
 *   Acc@1 67.622
 *   Acc@1 68.408
 *   Acc@1 68.676
 *   Acc@1 69.842
 *   Acc@1 70.118
 *   Acc@1 69.882
 *   Acc@1 70.498
 *   Acc@1 69.368
 *   Acc@1 69.752
 *   Acc@1 69.276
 *   Acc@1 70.099
 *   Acc@1 68.408
 *   Acc@1 68.204
 *   Acc@1 67.803
 *   Acc@1 67.707
 *   Acc@1 69.276
 *   Acc@1 68.839
 *   Acc@1 70.289
 *   Acc@1 69.893
Training for 300 epoch: 70.11513157894737
Training for 600 epoch: 69.04934210526315
Training for 1000 epoch: 69.81907894736842
Training for 3000 epoch: 70.52960526315789
Training for 300 epoch: 70.11020833333333
Training for 600 epoch: 69.30479166666666
Training for 1000 epoch: 69.81229166666667
Training for 3000 epoch: 70.73208333333334
[[70.11513157894737, 69.04934210526315, 69.81907894736842, 70.52960526315789], [70.11020833333333, 69.30479166666666, 69.81229166666667, 70.73208333333334]]
train loss 0.21073530650933583, epoch 44, best loss 0.16217852989037831, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [45][20/30]	Time  1.493 ( 1.528)	Data  0.040 ( 0.063)	InnerLoop  0.610 ( 0.631)	Loss 8.0468e-01 (7.9779e-01)	Acc@1  72.61 ( 70.47)
The current update step is 1380
GPU_0_using curriculum 40 with window 40
Epoch: [46][20/30]	Time  1.482 ( 1.518)	Data  0.039 ( 0.069)	InnerLoop  0.615 ( 0.615)	Loss 8.3713e-01 (7.4319e-01)	Acc@1  65.67 ( 71.89)
The current update step is 1410
GPU_0_using curriculum 40 with window 40
Epoch: [47][20/30]	Time  1.490 ( 1.516)	Data  0.038 ( 0.064)	InnerLoop  0.616 ( 0.622)	Loss 5.8369e-01 (6.6943e-01)	Acc@1  77.98 ( 75.28)
The current update step is 1440
GPU_0_using curriculum 40 with window 40
Epoch: [48][20/30]	Time  1.482 ( 1.513)	Data  0.040 ( 0.063)	InnerLoop  0.615 ( 0.621)	Loss 5.5687e-01 (7.7257e-01)	Acc@1  78.59 ( 71.26)
The current update step is 1470
GPU_0_using curriculum 40 with window 40
Epoch: [49][20/30]	Time  1.495 ( 1.516)	Data  0.040 ( 0.056)	InnerLoop  0.624 ( 0.627)	Loss 5.8353e-01 (7.8042e-01)	Acc@1  77.61 ( 71.74)
The current update step is 1500
The current seed is 11115779111064958757
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.605
 *   Acc@1 69.436
 *   Acc@1 70.092
 *   Acc@1 70.243
 *   Acc@1 70.697
 *   Acc@1 71.162
 *   Acc@1 72.605
 *   Acc@1 72.737
 *   Acc@1 77.066
 *   Acc@1 77.724
 *   Acc@1 76.276
 *   Acc@1 77.252
 *   Acc@1 76.434
 *   Acc@1 76.342
 *   Acc@1 75.132
 *   Acc@1 74.908
 *   Acc@1 76.447
 *   Acc@1 76.617
 *   Acc@1 76.987
 *   Acc@1 77.205
 *   Acc@1 76.789
 *   Acc@1 77.195
 *   Acc@1 76.158
 *   Acc@1 76.616
 *   Acc@1 76.882
 *   Acc@1 77.358
 *   Acc@1 76.026
 *   Acc@1 75.895
 *   Acc@1 75.289
 *   Acc@1 75.481
 *   Acc@1 73.816
 *   Acc@1 74.168
Training for 300 epoch: 75.0
Training for 600 epoch: 74.84539473684211
Training for 1000 epoch: 74.80263157894737
Training for 3000 epoch: 74.42763157894737
Training for 300 epoch: 75.28354166666666
Training for 600 epoch: 75.14874999999999
Training for 1000 epoch: 75.045
Training for 3000 epoch: 74.60708333333334
[[75.0, 74.84539473684211, 74.80263157894737, 74.42763157894737], [75.28354166666666, 75.14874999999999, 75.045, 74.60708333333334]]
train loss 0.18126753718852998, epoch 49, best loss 0.16217852989037831, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [50][20/30]	Time  1.477 ( 1.516)	Data  0.037 ( 0.062)	InnerLoop  0.613 ( 0.627)	Loss 6.6345e-01 (8.1601e-01)	Acc@1  76.64 ( 70.46)
The current update step is 1530
GPU_0_using curriculum 40 with window 40
Epoch: [51][20/30]	Time  1.486 ( 1.513)	Data  0.038 ( 0.069)	InnerLoop  0.612 ( 0.613)	Loss 9.6197e-01 (7.6777e-01)	Acc@1  64.21 ( 71.30)
The current update step is 1560
GPU_0_using curriculum 40 with window 40
Epoch: [52][20/30]	Time  1.482 ( 1.511)	Data  0.039 ( 0.063)	InnerLoop  0.616 ( 0.620)	Loss 7.1285e-01 (7.2893e-01)	Acc@1  73.80 ( 73.05)
The current update step is 1590
GPU_0_using curriculum 40 with window 40
Epoch: [53][20/30]	Time  1.476 ( 1.514)	Data  0.036 ( 0.064)	InnerLoop  0.606 ( 0.620)	Loss 5.8746e-01 (7.2229e-01)	Acc@1  78.93 ( 72.94)
The current update step is 1620
GPU_0_using curriculum 40 with window 40
Epoch: [54][20/30]	Time  1.489 ( 1.511)	Data  0.039 ( 0.056)	InnerLoop  0.616 ( 0.624)	Loss 7.3907e-01 (8.2269e-01)	Acc@1  74.02 ( 70.39)
The current update step is 1650
The current seed is 1195681657397359251
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.079
 *   Acc@1 73.162
 *   Acc@1 71.882
 *   Acc@1 72.344
 *   Acc@1 72.592
 *   Acc@1 72.981
 *   Acc@1 74.724
 *   Acc@1 74.044
 *   Acc@1 73.487
 *   Acc@1 74.174
 *   Acc@1 73.671
 *   Acc@1 74.397
 *   Acc@1 73.066
 *   Acc@1 73.800
 *   Acc@1 70.987
 *   Acc@1 71.656
 *   Acc@1 73.803
 *   Acc@1 73.520
 *   Acc@1 72.539
 *   Acc@1 72.823
 *   Acc@1 71.566
 *   Acc@1 71.088
 *   Acc@1 70.276
 *   Acc@1 69.832
 *   Acc@1 77.684
 *   Acc@1 77.947
 *   Acc@1 77.053
 *   Acc@1 77.140
 *   Acc@1 76.053
 *   Acc@1 76.662
 *   Acc@1 75.829
 *   Acc@1 75.989
Training for 300 epoch: 74.51315789473685
Training for 600 epoch: 73.78618421052632
Training for 1000 epoch: 73.31907894736841
Training for 3000 epoch: 72.95394736842105
Training for 300 epoch: 74.70083333333332
Training for 600 epoch: 74.17583333333333
Training for 1000 epoch: 73.63270833333334
Training for 3000 epoch: 72.88020833333333
[[74.51315789473685, 73.78618421052632, 73.31907894736841, 72.95394736842105], [74.70083333333332, 74.17583333333333, 73.63270833333334, 72.88020833333333]]
train loss 0.16420993485450744, epoch 54, best loss 0.16217852989037831, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [55][20/30]	Time  1.483 ( 1.519)	Data  0.039 ( 0.061)	InnerLoop  0.611 ( 0.626)	Loss 8.8805e-01 (6.9698e-01)	Acc@1  66.24 ( 73.72)
The current update step is 1680
GPU_0_using curriculum 40 with window 40
Epoch: [56][20/30]	Time  1.498 ( 1.513)	Data  0.039 ( 0.068)	InnerLoop  0.613 ( 0.614)	Loss 6.0915e-01 (6.6834e-01)	Acc@1  76.37 ( 75.02)
The current update step is 1710
GPU_0_using curriculum 40 with window 40
Epoch: [57][20/30]	Time  1.514 ( 1.519)	Data  0.041 ( 0.064)	InnerLoop  0.634 ( 0.622)	Loss 6.1407e-01 (6.2675e-01)	Acc@1  77.03 ( 76.38)
The current update step is 1740
GPU_0_using curriculum 40 with window 40
Epoch: [58][20/30]	Time  1.482 ( 1.509)	Data  0.040 ( 0.062)	InnerLoop  0.610 ( 0.616)	Loss 7.8940e-01 (6.8662e-01)	Acc@1  67.85 ( 74.65)
The current update step is 1770
GPU_0_using curriculum 40 with window 40
Epoch: [59][20/30]	Time  1.494 ( 1.514)	Data  0.039 ( 0.056)	InnerLoop  0.618 ( 0.628)	Loss 1.0559e+00 (7.0581e-01)	Acc@1  65.55 ( 74.62)
The current update step is 1800
The current seed is 13019795309688738175
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.974
 *   Acc@1 71.593
 *   Acc@1 70.382
 *   Acc@1 70.324
 *   Acc@1 70.013
 *   Acc@1 69.625
 *   Acc@1 68.750
 *   Acc@1 69.048
 *   Acc@1 76.908
 *   Acc@1 77.108
 *   Acc@1 72.829
 *   Acc@1 73.170
 *   Acc@1 70.118
 *   Acc@1 70.817
 *   Acc@1 68.395
 *   Acc@1 68.774
 *   Acc@1 69.237
 *   Acc@1 69.317
 *   Acc@1 67.145
 *   Acc@1 67.578
 *   Acc@1 66.921
 *   Acc@1 67.411
 *   Acc@1 67.750
 *   Acc@1 67.927
 *   Acc@1 75.553
 *   Acc@1 75.100
 *   Acc@1 72.171
 *   Acc@1 72.027
 *   Acc@1 70.000
 *   Acc@1 69.453
 *   Acc@1 67.145
 *   Acc@1 66.874
Training for 300 epoch: 73.41776315789474
Training for 600 epoch: 70.63157894736842
Training for 1000 epoch: 69.26315789473684
Training for 3000 epoch: 68.00986842105263
Training for 300 epoch: 73.27958333333333
Training for 600 epoch: 70.77479166666666
Training for 1000 epoch: 69.32645833333333
Training for 3000 epoch: 68.15583333333333
[[73.41776315789474, 70.63157894736842, 69.26315789473684, 68.00986842105263], [73.27958333333333, 70.77479166666666, 69.32645833333333, 68.15583333333333]]
train loss 0.24428980859120686, epoch 59, best loss 0.16217852989037831, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [60][20/30]	Time  1.494 ( 1.515)	Data  0.038 ( 0.061)	InnerLoop  0.614 ( 0.623)	Loss 8.6903e-01 (6.8871e-01)	Acc@1  68.65 ( 74.93)
The current update step is 1830
GPU_0_using curriculum 40 with window 40
Epoch: [61][20/30]	Time  1.498 ( 1.513)	Data  0.039 ( 0.069)	InnerLoop  0.632 ( 0.612)	Loss 8.0713e-01 (7.4389e-01)	Acc@1  71.61 ( 72.44)
The current update step is 1860
GPU_0_using curriculum 40 with window 40
Epoch: [62][20/30]	Time  1.498 ( 1.518)	Data  0.040 ( 0.062)	InnerLoop  0.614 ( 0.621)	Loss 7.5287e-01 (6.7531e-01)	Acc@1  73.17 ( 74.71)
The current update step is 1890
GPU_0_using curriculum 40 with window 40
Epoch: [63][20/30]	Time  1.480 ( 1.517)	Data  0.038 ( 0.062)	InnerLoop  0.615 ( 0.620)	Loss 5.7508e-01 (6.8832e-01)	Acc@1  80.13 ( 74.57)
The current update step is 1920
GPU_0_using curriculum 40 with window 40
Epoch: [64][20/30]	Time  1.486 ( 1.509)	Data  0.037 ( 0.055)	InnerLoop  0.608 ( 0.624)	Loss 5.7475e-01 (6.6404e-01)	Acc@1  79.08 ( 75.18)
The current update step is 1950
The current seed is 15228861077985056636
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.513
 *   Acc@1 71.263
 *   Acc@1 68.263
 *   Acc@1 68.077
 *   Acc@1 67.908
 *   Acc@1 67.765
 *   Acc@1 68.645
 *   Acc@1 68.385
 *   Acc@1 78.618
 *   Acc@1 78.954
 *   Acc@1 78.500
 *   Acc@1 79.256
 *   Acc@1 78.855
 *   Acc@1 79.127
 *   Acc@1 77.947
 *   Acc@1 78.069
 *   Acc@1 74.632
 *   Acc@1 75.052
 *   Acc@1 73.316
 *   Acc@1 73.283
 *   Acc@1 72.118
 *   Acc@1 72.456
 *   Acc@1 72.237
 *   Acc@1 72.154
 *   Acc@1 76.105
 *   Acc@1 76.310
 *   Acc@1 75.566
 *   Acc@1 76.371
 *   Acc@1 74.158
 *   Acc@1 74.779
 *   Acc@1 73.474
 *   Acc@1 73.818
Training for 300 epoch: 75.21710526315789
Training for 600 epoch: 73.91118421052632
Training for 1000 epoch: 73.25986842105263
Training for 3000 epoch: 73.07565789473684
Training for 300 epoch: 75.39479166666666
Training for 600 epoch: 74.24666666666667
Training for 1000 epoch: 73.53187499999999
Training for 3000 epoch: 73.10666666666665
[[75.21710526315789, 73.91118421052632, 73.25986842105263, 73.07565789473684], [75.39479166666666, 74.24666666666667, 73.53187499999999, 73.10666666666665]]
train loss 0.18659736398061116, epoch 64, best loss 0.16217852989037831, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [65][20/30]	Time  1.467 ( 1.511)	Data  0.038 ( 0.061)	InnerLoop  0.606 ( 0.621)	Loss 7.9718e-01 (6.4939e-01)	Acc@1  66.72 ( 75.34)
The current update step is 1980
GPU_0_using curriculum 40 with window 40
Epoch: [66][20/30]	Time  1.475 ( 1.514)	Data  0.036 ( 0.067)	InnerLoop  0.612 ( 0.616)	Loss 5.5283e-01 (6.9615e-01)	Acc@1  79.61 ( 74.47)
The current update step is 2010
GPU_0_using curriculum 40 with window 40
Epoch: [67][20/30]	Time  1.481 ( 1.514)	Data  0.038 ( 0.063)	InnerLoop  0.611 ( 0.620)	Loss 5.2751e-01 (6.5287e-01)	Acc@1  81.08 ( 76.15)
The current update step is 2040
GPU_0_using curriculum 40 with window 40
Epoch: [68][20/30]	Time  1.493 ( 1.515)	Data  0.040 ( 0.062)	InnerLoop  0.626 ( 0.619)	Loss 5.6801e-01 (6.3227e-01)	Acc@1  79.98 ( 77.05)
The current update step is 2070
GPU_0_using curriculum 40 with window 40
Epoch: [69][20/30]	Time  1.476 ( 1.508)	Data  0.036 ( 0.056)	InnerLoop  0.605 ( 0.624)	Loss 7.6574e-01 (6.1236e-01)	Acc@1  70.75 ( 77.69)
The current update step is 2100
The current seed is 2676733229843431464
The current lr is: 0.001
Testing Results:
 *   Acc@1 74.961
 *   Acc@1 75.267
 *   Acc@1 74.303
 *   Acc@1 74.956
 *   Acc@1 74.000
 *   Acc@1 74.547
 *   Acc@1 72.750
 *   Acc@1 72.938
 *   Acc@1 78.382
 *   Acc@1 79.059
 *   Acc@1 78.184
 *   Acc@1 78.818
 *   Acc@1 78.197
 *   Acc@1 78.603
 *   Acc@1 77.908
 *   Acc@1 78.507
 *   Acc@1 74.171
 *   Acc@1 74.578
 *   Acc@1 74.224
 *   Acc@1 74.632
 *   Acc@1 75.645
 *   Acc@1 76.039
 *   Acc@1 77.447
 *   Acc@1 77.097
 *   Acc@1 74.382
 *   Acc@1 74.812
 *   Acc@1 72.066
 *   Acc@1 72.195
 *   Acc@1 69.079
 *   Acc@1 69.222
 *   Acc@1 66.053
 *   Acc@1 66.668
Training for 300 epoch: 75.47368421052633
Training for 600 epoch: 74.69407894736842
Training for 1000 epoch: 74.23026315789474
Training for 3000 epoch: 73.53947368421052
Training for 300 epoch: 75.92875
Training for 600 epoch: 75.15020833333332
Training for 1000 epoch: 74.60291666666666
Training for 3000 epoch: 73.80229166666666
[[75.47368421052633, 74.69407894736842, 74.23026315789474, 73.53947368421052], [75.92875, 75.15020833333332, 74.60291666666666, 73.80229166666666]]
train loss 0.23210348179340362, epoch 69, best loss 0.16217852989037831, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [70][20/30]	Time  1.484 ( 1.517)	Data  0.039 ( 0.061)	InnerLoop  0.616 ( 0.623)	Loss 5.4994e-01 (6.4692e-01)	Acc@1  78.15 ( 76.10)
The current update step is 2130
GPU_0_using curriculum 40 with window 40
Epoch: [71][20/30]	Time  1.487 ( 1.513)	Data  0.037 ( 0.068)	InnerLoop  0.618 ( 0.610)	Loss 7.0302e-01 (6.6256e-01)	Acc@1  73.75 ( 75.92)
The current update step is 2160
GPU_0_using curriculum 40 with window 40
Epoch: [72][20/30]	Time  1.508 ( 1.512)	Data  0.036 ( 0.062)	InnerLoop  0.625 ( 0.619)	Loss 5.9071e-01 (7.2237e-01)	Acc@1  77.44 ( 73.29)
The current update step is 2190
GPU_0_using curriculum 40 with window 40
Epoch: [73][20/30]	Time  1.470 ( 1.516)	Data  0.037 ( 0.062)	InnerLoop  0.606 ( 0.620)	Loss 6.1088e-01 (6.8241e-01)	Acc@1  75.22 ( 74.97)
The current update step is 2220
GPU_0_using curriculum 40 with window 40
Epoch: [74][20/30]	Time  1.473 ( 1.503)	Data  0.037 ( 0.055)	InnerLoop  0.613 ( 0.621)	Loss 7.8834e-01 (7.2612e-01)	Acc@1  68.68 ( 73.23)
The current update step is 2250
The current seed is 13856003165719091895
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.132
 *   Acc@1 73.781
 *   Acc@1 72.882
 *   Acc@1 73.265
 *   Acc@1 72.487
 *   Acc@1 73.145
 *   Acc@1 72.421
 *   Acc@1 72.800
 *   Acc@1 75.987
 *   Acc@1 76.612
 *   Acc@1 77.645
 *   Acc@1 78.628
 *   Acc@1 77.895
 *   Acc@1 78.858
 *   Acc@1 78.553
 *   Acc@1 79.156
 *   Acc@1 70.605
 *   Acc@1 71.093
 *   Acc@1 71.408
 *   Acc@1 71.720
 *   Acc@1 71.053
 *   Acc@1 71.298
 *   Acc@1 71.145
 *   Acc@1 71.301
 *   Acc@1 77.803
 *   Acc@1 77.894
 *   Acc@1 78.026
 *   Acc@1 78.424
 *   Acc@1 76.908
 *   Acc@1 76.820
 *   Acc@1 75.447
 *   Acc@1 75.097
Training for 300 epoch: 74.38157894736842
Training for 600 epoch: 74.99013157894737
Training for 1000 epoch: 74.58552631578948
Training for 3000 epoch: 74.39144736842104
Training for 300 epoch: 74.845
Training for 600 epoch: 75.50937499999999
Training for 1000 epoch: 75.03020833333333
Training for 3000 epoch: 74.58854166666666
[[74.38157894736842, 74.99013157894737, 74.58552631578948, 74.39144736842104], [74.845, 75.50937499999999, 75.03020833333333, 74.58854166666666]]
train loss 0.18163387464682262, epoch 74, best loss 0.16217852989037831, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [75][20/30]	Time  1.489 ( 1.519)	Data  0.036 ( 0.061)	InnerLoop  0.625 ( 0.626)	Loss 6.8412e-01 (6.7226e-01)	Acc@1  74.49 ( 74.95)
The current update step is 2280
GPU_0_using curriculum 40 with window 40
Epoch: [76][20/30]	Time  1.483 ( 1.509)	Data  0.038 ( 0.067)	InnerLoop  0.610 ( 0.610)	Loss 5.8927e-01 (6.9200e-01)	Acc@1  78.39 ( 74.73)
The current update step is 2310
GPU_0_using curriculum 40 with window 40
Epoch: [77][20/30]	Time  1.486 ( 1.501)	Data  0.037 ( 0.062)	InnerLoop  0.626 ( 0.614)	Loss 6.8035e-01 (6.4613e-01)	Acc@1  73.41 ( 75.93)
The current update step is 2340
GPU_0_using curriculum 40 with window 40
Epoch: [78][20/30]	Time  1.481 ( 1.508)	Data  0.040 ( 0.061)	InnerLoop  0.619 ( 0.614)	Loss 7.6588e-01 (6.4181e-01)	Acc@1  73.97 ( 76.39)
The current update step is 2370
GPU_0_using curriculum 40 with window 40
Epoch: [79][20/30]	Time  1.493 ( 1.516)	Data  0.037 ( 0.056)	InnerLoop  0.614 ( 0.626)	Loss 5.3476e-01 (6.3466e-01)	Acc@1  79.37 ( 76.73)
The current update step is 2400
The current seed is 8807844486217722494
The current lr is: 0.001
Testing Results:
 *   Acc@1 47.974
 *   Acc@1 49.325
 *   Acc@1 50.105
 *   Acc@1 51.211
 *   Acc@1 53.395
 *   Acc@1 54.475
 *   Acc@1 56.197
 *   Acc@1 57.091
 *   Acc@1 78.566
 *   Acc@1 79.042
 *   Acc@1 78.645
 *   Acc@1 78.838
 *   Acc@1 78.434
 *   Acc@1 79.047
 *   Acc@1 79.013
 *   Acc@1 79.283
 *   Acc@1 73.579
 *   Acc@1 74.311
 *   Acc@1 74.803
 *   Acc@1 75.392
 *   Acc@1 75.803
 *   Acc@1 76.528
 *   Acc@1 75.882
 *   Acc@1 76.314
 *   Acc@1 75.750
 *   Acc@1 75.882
 *   Acc@1 74.158
 *   Acc@1 74.087
 *   Acc@1 74.895
 *   Acc@1 75.052
 *   Acc@1 76.329
 *   Acc@1 76.408
Training for 300 epoch: 68.96710526315789
Training for 600 epoch: 69.42763157894737
Training for 1000 epoch: 70.63157894736841
Training for 3000 epoch: 71.85526315789474
Training for 300 epoch: 69.64
Training for 600 epoch: 69.88187500000001
Training for 1000 epoch: 71.27541666666667
Training for 3000 epoch: 72.27416666666667
[[68.96710526315789, 69.42763157894737, 70.63157894736841, 71.85526315789474], [69.64, 69.88187500000001, 71.27541666666667, 72.27416666666667]]
train loss 0.155606507786115, epoch 79, best loss 0.155606507786115, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [80][20/30]	Time  1.486 ( 1.514)	Data  0.038 ( 0.062)	InnerLoop  0.613 ( 0.621)	Loss 5.9165e-01 (7.2158e-01)	Acc@1  76.66 ( 74.24)
The current update step is 2430
GPU_0_using curriculum 40 with window 40
Epoch: [81][20/30]	Time  1.497 ( 1.504)	Data  0.039 ( 0.068)	InnerLoop  0.602 ( 0.607)	Loss 7.6667e-01 (6.4492e-01)	Acc@1  73.00 ( 76.40)
The current update step is 2460
GPU_0_using curriculum 40 with window 40
Epoch: [82][20/30]	Time  1.470 ( 1.518)	Data  0.036 ( 0.063)	InnerLoop  0.612 ( 0.621)	Loss 5.8189e-01 (5.8170e-01)	Acc@1  78.03 ( 78.61)
The current update step is 2490
GPU_0_using curriculum 40 with window 40
Epoch: [83][20/30]	Time  1.480 ( 1.506)	Data  0.037 ( 0.063)	InnerLoop  0.622 ( 0.615)	Loss 6.8280e-01 (6.3486e-01)	Acc@1  75.78 ( 77.06)
The current update step is 2520
GPU_0_using curriculum 40 with window 40
Epoch: [84][20/30]	Time  1.508 ( 1.514)	Data  0.038 ( 0.056)	InnerLoop  0.606 ( 0.624)	Loss 6.1603e-01 (7.4801e-01)	Acc@1  77.81 ( 72.26)
The current update step is 2550
The current seed is 5588702145577682842
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.013
 *   Acc@1 73.242
 *   Acc@1 70.737
 *   Acc@1 71.058
 *   Acc@1 69.487
 *   Acc@1 69.309
 *   Acc@1 69.145
 *   Acc@1 69.626
 *   Acc@1 80.224
 *   Acc@1 79.517
 *   Acc@1 78.763
 *   Acc@1 78.692
 *   Acc@1 77.132
 *   Acc@1 76.958
 *   Acc@1 74.579
 *   Acc@1 74.475
 *   Acc@1 62.105
 *   Acc@1 61.981
 *   Acc@1 62.895
 *   Acc@1 62.927
 *   Acc@1 64.039
 *   Acc@1 64.518
 *   Acc@1 65.224
 *   Acc@1 65.680
 *   Acc@1 71.329
 *   Acc@1 71.156
 *   Acc@1 72.171
 *   Acc@1 72.025
 *   Acc@1 73.882
 *   Acc@1 74.000
 *   Acc@1 75.539
 *   Acc@1 75.568
Training for 300 epoch: 71.66776315789474
Training for 600 epoch: 71.14144736842105
Training for 1000 epoch: 71.13486842105263
Training for 3000 epoch: 71.12171052631578
Training for 300 epoch: 71.47395833333334
Training for 600 epoch: 71.17541666666668
Training for 1000 epoch: 71.19645833333333
Training for 3000 epoch: 71.33729166666666
[[71.66776315789474, 71.14144736842105, 71.13486842105263, 71.12171052631578], [71.47395833333334, 71.17541666666668, 71.19645833333333, 71.33729166666666]]
train loss 0.17557584348519642, epoch 84, best loss 0.155606507786115, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [85][20/30]	Time  1.513 ( 1.521)	Data  0.039 ( 0.062)	InnerLoop  0.639 ( 0.628)	Loss 5.7836e-01 (6.5660e-01)	Acc@1  78.37 ( 75.71)
The current update step is 2580
GPU_0_using curriculum 40 with window 40
Epoch: [86][20/30]	Time  1.497 ( 1.518)	Data  0.039 ( 0.069)	InnerLoop  0.620 ( 0.617)	Loss 5.2817e-01 (6.9075e-01)	Acc@1  80.91 ( 75.47)
The current update step is 2610
GPU_0_using curriculum 40 with window 40
Epoch: [87][20/30]	Time  1.500 ( 1.517)	Data  0.041 ( 0.063)	InnerLoop  0.626 ( 0.621)	Loss 6.3304e-01 (7.2279e-01)	Acc@1  75.83 ( 74.56)
The current update step is 2640
GPU_0_using curriculum 40 with window 40
Epoch: [88][20/30]	Time  1.475 ( 1.512)	Data  0.036 ( 0.063)	InnerLoop  0.610 ( 0.617)	Loss 6.1676e-01 (6.7676e-01)	Acc@1  77.88 ( 74.67)
The current update step is 2670
GPU_0_using curriculum 40 with window 40
Epoch: [89][20/30]	Time  1.476 ( 1.514)	Data  0.036 ( 0.056)	InnerLoop  0.605 ( 0.625)	Loss 6.9762e-01 (6.8077e-01)	Acc@1  75.88 ( 74.83)
The current update step is 2700
The current seed is 6668685766707112352
The current lr is: 0.001
Testing Results:
 *   Acc@1 79.171
 *   Acc@1 79.409
 *   Acc@1 78.276
 *   Acc@1 78.227
 *   Acc@1 77.197
 *   Acc@1 77.685
 *   Acc@1 76.026
 *   Acc@1 76.460
 *   Acc@1 73.421
 *   Acc@1 73.281
 *   Acc@1 70.539
 *   Acc@1 70.471
 *   Acc@1 67.263
 *   Acc@1 67.191
 *   Acc@1 63.882
 *   Acc@1 64.222
 *   Acc@1 76.013
 *   Acc@1 76.474
 *   Acc@1 75.605
 *   Acc@1 75.857
 *   Acc@1 74.816
 *   Acc@1 75.191
 *   Acc@1 74.566
 *   Acc@1 74.481
 *   Acc@1 73.434
 *   Acc@1 73.832
 *   Acc@1 70.868
 *   Acc@1 71.172
 *   Acc@1 70.171
 *   Acc@1 70.197
 *   Acc@1 69.158
 *   Acc@1 69.320
Training for 300 epoch: 75.50986842105263
Training for 600 epoch: 73.82236842105263
Training for 1000 epoch: 72.36184210526316
Training for 3000 epoch: 70.90789473684211
Training for 300 epoch: 75.74916666666667
Training for 600 epoch: 73.93145833333334
Training for 1000 epoch: 72.56583333333333
Training for 3000 epoch: 71.12083333333334
[[75.50986842105263, 73.82236842105263, 72.36184210526316, 70.90789473684211], [75.74916666666667, 73.93145833333334, 72.56583333333333, 71.12083333333334]]
train loss 0.19721171466509502, epoch 89, best loss 0.155606507786115, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [90][20/30]	Time  1.492 ( 1.516)	Data  0.038 ( 0.061)	InnerLoop  0.608 ( 0.624)	Loss 6.2080e-01 (6.6318e-01)	Acc@1  77.03 ( 75.60)
The current update step is 2730
GPU_0_using curriculum 40 with window 40
Epoch: [91][20/30]	Time  1.479 ( 1.514)	Data  0.037 ( 0.068)	InnerLoop  0.614 ( 0.613)	Loss 8.8431e-01 (7.1727e-01)	Acc@1  68.36 ( 73.83)
The current update step is 2760
GPU_0_using curriculum 40 with window 40
Epoch: [92][20/30]	Time  1.481 ( 1.513)	Data  0.036 ( 0.062)	InnerLoop  0.614 ( 0.619)	Loss 7.9129e-01 (6.5595e-01)	Acc@1  69.07 ( 74.77)
The current update step is 2790
GPU_0_using curriculum 40 with window 40
Epoch: [93][20/30]	Time  1.502 ( 1.515)	Data  0.038 ( 0.063)	InnerLoop  0.629 ( 0.619)	Loss 9.1766e-01 (7.0405e-01)	Acc@1  65.99 ( 74.05)
The current update step is 2820
GPU_0_using curriculum 40 with window 40
Epoch: [94][20/30]	Time  1.498 ( 1.511)	Data  0.038 ( 0.057)	InnerLoop  0.614 ( 0.624)	Loss 8.2875e-01 (7.1153e-01)	Acc@1  70.19 ( 73.42)
The current update step is 2850
The current seed is 8865727968995062559
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.145
 *   Acc@1 70.202
 *   Acc@1 69.737
 *   Acc@1 69.513
 *   Acc@1 69.408
 *   Acc@1 69.499
 *   Acc@1 69.158
 *   Acc@1 69.731
 *   Acc@1 75.447
 *   Acc@1 75.377
 *   Acc@1 73.632
 *   Acc@1 74.062
 *   Acc@1 73.145
 *   Acc@1 73.335
 *   Acc@1 73.987
 *   Acc@1 74.007
 *   Acc@1 79.645
 *   Acc@1 80.046
 *   Acc@1 79.855
 *   Acc@1 79.987
 *   Acc@1 79.605
 *   Acc@1 79.332
 *   Acc@1 79.066
 *   Acc@1 78.616
 *   Acc@1 68.276
 *   Acc@1 68.373
 *   Acc@1 67.211
 *   Acc@1 67.077
 *   Acc@1 65.829
 *   Acc@1 65.918
 *   Acc@1 64.329
 *   Acc@1 64.815
Training for 300 epoch: 73.3782894736842
Training for 600 epoch: 72.60855263157896
Training for 1000 epoch: 71.9967105263158
Training for 3000 epoch: 71.63486842105263
Training for 300 epoch: 73.49916666666667
Training for 600 epoch: 72.65958333333333
Training for 1000 epoch: 72.02083333333333
Training for 3000 epoch: 71.79229166666667
[[73.3782894736842, 72.60855263157896, 71.9967105263158, 71.63486842105263], [73.49916666666667, 72.65958333333333, 72.02083333333333, 71.79229166666667]]
train loss 0.24678878961404166, epoch 94, best loss 0.155606507786115, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [95][20/30]	Time  1.484 ( 1.511)	Data  0.037 ( 0.061)	InnerLoop  0.612 ( 0.622)	Loss 5.2745e-01 (6.1062e-01)	Acc@1  80.96 ( 76.93)
The current update step is 2880
GPU_0_using curriculum 40 with window 40
Epoch: [96][20/30]	Time  1.499 ( 1.515)	Data  0.038 ( 0.068)	InnerLoop  0.621 ( 0.614)	Loss 6.0845e-01 (6.6231e-01)	Acc@1  76.44 ( 74.85)
The current update step is 2910
GPU_0_using curriculum 40 with window 40
Epoch: [97][20/30]	Time  1.522 ( 1.516)	Data  0.038 ( 0.063)	InnerLoop  0.616 ( 0.619)	Loss 6.5765e-01 (6.1727e-01)	Acc@1  76.05 ( 76.95)
The current update step is 2940
GPU_0_using curriculum 40 with window 40
Epoch: [98][20/30]	Time  1.509 ( 1.515)	Data  0.038 ( 0.062)	InnerLoop  0.618 ( 0.619)	Loss 5.2051e-01 (6.3464e-01)	Acc@1  81.25 ( 75.95)
The current update step is 2970
GPU_0_using curriculum 40 with window 40
Epoch: [99][20/30]	Time  1.483 ( 1.517)	Data  0.045 ( 0.056)	InnerLoop  0.609 ( 0.627)	Loss 7.9606e-01 (6.0363e-01)	Acc@1  70.21 ( 77.82)
The current update step is 3000
The current seed is 9836203564041330530
The current lr is: 0.001
Testing Results:
 *   Acc@1 61.447
 *   Acc@1 61.239
 *   Acc@1 60.447
 *   Acc@1 60.530
 *   Acc@1 60.145
 *   Acc@1 60.427
 *   Acc@1 59.263
 *   Acc@1 59.362
 *   Acc@1 78.395
 *   Acc@1 78.517
 *   Acc@1 77.329
 *   Acc@1 77.614
 *   Acc@1 76.197
 *   Acc@1 76.776
 *   Acc@1 71.842
 *   Acc@1 72.233
 *   Acc@1 69.895
 *   Acc@1 69.173
 *   Acc@1 70.645
 *   Acc@1 70.036
 *   Acc@1 71.750
 *   Acc@1 71.268
 *   Acc@1 72.408
 *   Acc@1 72.295
 *   Acc@1 63.145
 *   Acc@1 63.634
 *   Acc@1 62.105
 *   Acc@1 62.785
 *   Acc@1 64.539
 *   Acc@1 65.065
 *   Acc@1 66.105
 *   Acc@1 66.806
Training for 300 epoch: 68.22039473684211
Training for 600 epoch: 67.63157894736842
Training for 1000 epoch: 68.15789473684211
Training for 3000 epoch: 67.40460526315789
Training for 300 epoch: 68.14104166666667
Training for 600 epoch: 67.74125
Training for 1000 epoch: 68.38395833333334
Training for 3000 epoch: 67.67416666666666
[[68.22039473684211, 67.63157894736842, 68.15789473684211, 67.40460526315789], [68.14104166666667, 67.74125, 68.38395833333334, 67.67416666666666]]
train loss 0.24864404813448587, epoch 99, best loss 0.155606507786115, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [100][20/30]	Time  1.492 ( 1.516)	Data  0.036 ( 0.061)	InnerLoop  0.613 ( 0.624)	Loss 5.3454e-01 (7.0786e-01)	Acc@1  79.76 ( 74.06)
The current update step is 3030
GPU_0_using curriculum 40 with window 40
Epoch: [101][20/30]	Time  1.481 ( 1.509)	Data  0.036 ( 0.069)	InnerLoop  0.614 ( 0.610)	Loss 5.3051e-01 (6.6258e-01)	Acc@1  80.62 ( 75.32)
The current update step is 3060
GPU_0_using curriculum 40 with window 40
Epoch: [102][20/30]	Time  1.474 ( 1.510)	Data  0.037 ( 0.062)	InnerLoop  0.606 ( 0.618)	Loss 6.0482e-01 (6.4224e-01)	Acc@1  78.34 ( 76.26)
The current update step is 3090
GPU_0_using curriculum 40 with window 40
Epoch: [103][20/30]	Time  1.496 ( 1.511)	Data  0.039 ( 0.063)	InnerLoop  0.623 ( 0.618)	Loss 6.8594e-01 (6.1293e-01)	Acc@1  73.32 ( 77.32)
The current update step is 3120
GPU_0_using curriculum 40 with window 40
Epoch: [104][20/30]	Time  1.489 ( 1.511)	Data  0.042 ( 0.056)	InnerLoop  0.615 ( 0.625)	Loss 7.4437e-01 (6.5121e-01)	Acc@1  71.12 ( 75.84)
The current update step is 3150
The current seed is 10695339091503503752
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.355
 *   Acc@1 73.473
 *   Acc@1 72.053
 *   Acc@1 72.409
 *   Acc@1 71.145
 *   Acc@1 71.271
 *   Acc@1 70.684
 *   Acc@1 71.128
 *   Acc@1 73.947
 *   Acc@1 73.682
 *   Acc@1 71.184
 *   Acc@1 71.126
 *   Acc@1 70.803
 *   Acc@1 70.518
 *   Acc@1 70.395
 *   Acc@1 70.660
 *   Acc@1 76.132
 *   Acc@1 76.517
 *   Acc@1 76.237
 *   Acc@1 76.601
 *   Acc@1 76.684
 *   Acc@1 77.028
 *   Acc@1 76.645
 *   Acc@1 77.028
 *   Acc@1 79.487
 *   Acc@1 79.486
 *   Acc@1 79.079
 *   Acc@1 79.632
 *   Acc@1 79.500
 *   Acc@1 79.496
 *   Acc@1 78.539
 *   Acc@1 79.053
Training for 300 epoch: 75.73026315789474
Training for 600 epoch: 74.63815789473685
Training for 1000 epoch: 74.53289473684211
Training for 3000 epoch: 74.0657894736842
Training for 300 epoch: 75.78958333333334
Training for 600 epoch: 74.941875
Training for 1000 epoch: 74.578125
Training for 3000 epoch: 74.4675
[[75.73026315789474, 74.63815789473685, 74.53289473684211, 74.0657894736842], [75.78958333333334, 74.941875, 74.578125, 74.4675]]
train loss 0.1510807803074519, epoch 104, best loss 0.1510807803074519, best_epoch 104
GPU_0_using curriculum 40 with window 40
Epoch: [105][20/30]	Time  1.472 ( 1.517)	Data  0.042 ( 0.062)	InnerLoop  0.609 ( 0.625)	Loss 5.2009e-01 (6.1425e-01)	Acc@1  81.32 ( 77.36)
The current update step is 3180
GPU_0_using curriculum 40 with window 40
Epoch: [106][20/30]	Time  1.483 ( 1.509)	Data  0.040 ( 0.069)	InnerLoop  0.620 ( 0.610)	Loss 6.3811e-01 (5.7420e-01)	Acc@1  73.39 ( 78.19)
The current update step is 3210
GPU_0_using curriculum 40 with window 40
Epoch: [107][20/30]	Time  1.475 ( 1.509)	Data  0.041 ( 0.063)	InnerLoop  0.606 ( 0.617)	Loss 5.5416e-01 (6.3876e-01)	Acc@1  79.20 ( 76.79)
The current update step is 3240
GPU_0_using curriculum 40 with window 40
Epoch: [108][20/30]	Time  1.468 ( 1.510)	Data  0.038 ( 0.063)	InnerLoop  0.607 ( 0.619)	Loss 6.0919e-01 (6.4249e-01)	Acc@1  76.98 ( 76.29)
The current update step is 3270
GPU_0_using curriculum 40 with window 40
Epoch: [109][20/30]	Time  1.494 ( 1.506)	Data  0.037 ( 0.056)	InnerLoop  0.611 ( 0.621)	Loss 5.8467e-01 (6.2719e-01)	Acc@1  77.81 ( 76.36)
The current update step is 3300
The current seed is 6535661317513692434
The current lr is: 0.001
Testing Results:
 *   Acc@1 68.395
 *   Acc@1 68.528
 *   Acc@1 61.250
 *   Acc@1 61.348
 *   Acc@1 59.711
 *   Acc@1 59.534
 *   Acc@1 58.237
 *   Acc@1 58.688
 *   Acc@1 75.105
 *   Acc@1 75.406
 *   Acc@1 75.632
 *   Acc@1 75.931
 *   Acc@1 75.934
 *   Acc@1 76.199
 *   Acc@1 76.066
 *   Acc@1 76.327
 *   Acc@1 75.421
 *   Acc@1 75.496
 *   Acc@1 75.316
 *   Acc@1 75.241
 *   Acc@1 73.066
 *   Acc@1 73.148
 *   Acc@1 69.645
 *   Acc@1 69.927
 *   Acc@1 60.842
 *   Acc@1 60.873
 *   Acc@1 57.276
 *   Acc@1 57.762
 *   Acc@1 54.789
 *   Acc@1 55.235
 *   Acc@1 51.961
 *   Acc@1 52.568
Training for 300 epoch: 69.94078947368422
Training for 600 epoch: 67.36842105263159
Training for 1000 epoch: 65.875
Training for 3000 epoch: 63.97697368421053
Training for 300 epoch: 70.07541666666667
Training for 600 epoch: 67.57041666666666
Training for 1000 epoch: 66.02916666666667
Training for 3000 epoch: 64.37729166666666
[[69.94078947368422, 67.36842105263159, 65.875, 63.97697368421053], [70.07541666666667, 67.57041666666666, 66.02916666666667, 64.37729166666666]]
train loss 0.3772802531242371, epoch 109, best loss 0.1510807803074519, best_epoch 104
GPU_0_using curriculum 40 with window 40
Epoch: [110][20/30]	Time  1.477 ( 1.518)	Data  0.037 ( 0.061)	InnerLoop  0.613 ( 0.623)	Loss 5.9025e-01 (6.0023e-01)	Acc@1  78.00 ( 77.96)
The current update step is 3330
GPU_0_using curriculum 40 with window 40
Epoch: [111][20/30]	Time  1.477 ( 1.515)	Data  0.037 ( 0.068)	InnerLoop  0.611 ( 0.615)	Loss 5.7870e-01 (6.0508e-01)	Acc@1  80.13 ( 77.41)
The current update step is 3360
GPU_0_using curriculum 40 with window 40
Epoch: [112][20/30]	Time  1.472 ( 1.504)	Data  0.038 ( 0.062)	InnerLoop  0.613 ( 0.617)	Loss 5.5999e-01 (5.9852e-01)	Acc@1  78.61 ( 77.53)
The current update step is 3390
GPU_0_using curriculum 40 with window 40
Epoch: [113][20/30]	Time  1.482 ( 1.512)	Data  0.037 ( 0.061)	InnerLoop  0.617 ( 0.619)	Loss 5.8471e-01 (5.8822e-01)	Acc@1  78.05 ( 78.09)
The current update step is 3420
GPU_0_using curriculum 40 with window 40
Epoch: [114][20/30]	Time  1.487 ( 1.511)	Data  0.037 ( 0.055)	InnerLoop  0.614 ( 0.626)	Loss 5.2283e-01 (5.8821e-01)	Acc@1  81.52 ( 78.51)
The current update step is 3450
The current seed is 8675677429530827230
The current lr is: 0.001
Testing Results:
 *   Acc@1 74.908
 *   Acc@1 75.117
 *   Acc@1 72.934
 *   Acc@1 72.907
 *   Acc@1 73.026
 *   Acc@1 73.121
 *   Acc@1 72.434
 *   Acc@1 72.565
 *   Acc@1 73.895
 *   Acc@1 74.043
 *   Acc@1 76.355
 *   Acc@1 76.964
 *   Acc@1 78.329
 *   Acc@1 78.584
 *   Acc@1 78.184
 *   Acc@1 79.069
 *   Acc@1 78.763
 *   Acc@1 79.657
 *   Acc@1 78.855
 *   Acc@1 79.916
 *   Acc@1 78.737
 *   Acc@1 79.720
 *   Acc@1 77.566
 *   Acc@1 78.230
 *   Acc@1 72.408
 *   Acc@1 72.091
 *   Acc@1 72.539
 *   Acc@1 71.965
 *   Acc@1 72.171
 *   Acc@1 72.367
 *   Acc@1 72.382
 *   Acc@1 72.082
Training for 300 epoch: 74.99342105263159
Training for 600 epoch: 75.17105263157895
Training for 1000 epoch: 75.56578947368422
Training for 3000 epoch: 75.14144736842105
Training for 300 epoch: 75.226875
Training for 600 epoch: 75.43791666666667
Training for 1000 epoch: 75.94791666666666
Training for 3000 epoch: 75.48666666666666
[[74.99342105263159, 75.17105263157895, 75.56578947368422, 75.14144736842105], [75.226875, 75.43791666666667, 75.94791666666666, 75.48666666666666]]
train loss 0.1966468296766281, epoch 114, best loss 0.1510807803074519, best_epoch 104
GPU_0_using curriculum 40 with window 40
Epoch: [115][20/30]	Time  1.482 ( 1.518)	Data  0.037 ( 0.062)	InnerLoop  0.609 ( 0.625)	Loss 6.1743e-01 (5.6388e-01)	Acc@1  77.91 ( 79.32)
The current update step is 3480
GPU_0_using curriculum 40 with window 40
Epoch: [116][20/30]	Time  1.475 ( 1.505)	Data  0.039 ( 0.068)	InnerLoop  0.613 ( 0.611)	Loss 6.0812e-01 (6.0408e-01)	Acc@1  78.10 ( 77.76)
The current update step is 3510
GPU_0_using curriculum 40 with window 40
Epoch: [117][20/30]	Time  1.471 ( 1.505)	Data  0.037 ( 0.062)	InnerLoop  0.608 ( 0.614)	Loss 5.4870e-01 (5.9831e-01)	Acc@1  79.74 ( 77.94)
The current update step is 3540
GPU_0_using curriculum 40 with window 40
Epoch: [118][20/30]	Time  1.467 ( 1.507)	Data  0.036 ( 0.063)	InnerLoop  0.608 ( 0.618)	Loss 5.0623e-01 (6.0419e-01)	Acc@1  81.71 ( 77.76)
The current update step is 3570
GPU_0_using curriculum 40 with window 40
Epoch: [119][20/30]	Time  1.492 ( 1.510)	Data  0.038 ( 0.057)	InnerLoop  0.609 ( 0.624)	Loss 6.2290e-01 (5.8325e-01)	Acc@1  75.73 ( 78.85)
The current update step is 3600
The current seed is 10326030556623588317
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.026
 *   Acc@1 75.891
 *   Acc@1 74.053
 *   Acc@1 74.267
 *   Acc@1 72.842
 *   Acc@1 72.993
 *   Acc@1 73.000
 *   Acc@1 73.129
 *   Acc@1 76.132
 *   Acc@1 75.838
 *   Acc@1 73.803
 *   Acc@1 73.263
 *   Acc@1 71.605
 *   Acc@1 72.006
 *   Acc@1 70.750
 *   Acc@1 71.172
 *   Acc@1 75.487
 *   Acc@1 75.364
 *   Acc@1 75.947
 *   Acc@1 75.713
 *   Acc@1 76.461
 *   Acc@1 76.578
 *   Acc@1 77.132
 *   Acc@1 77.053
 *   Acc@1 77.224
 *   Acc@1 78.013
 *   Acc@1 76.513
 *   Acc@1 76.886
 *   Acc@1 75.645
 *   Acc@1 76.231
 *   Acc@1 74.342
 *   Acc@1 74.603
Training for 300 epoch: 76.21710526315789
Training for 600 epoch: 75.07894736842105
Training for 1000 epoch: 74.13815789473685
Training for 3000 epoch: 73.80592105263159
Training for 300 epoch: 76.27645833333334
Training for 600 epoch: 75.03229166666667
Training for 1000 epoch: 74.451875
Training for 3000 epoch: 73.98958333333334
[[76.21710526315789, 75.07894736842105, 74.13815789473685, 73.80592105263159], [76.27645833333334, 75.03229166666667, 74.451875, 73.98958333333334]]
train loss 0.17508836713631948, epoch 119, best loss 0.1510807803074519, best_epoch 104
GPU_0_using curriculum 40 with window 40
Epoch: [120][20/30]	Time  1.480 ( 1.516)	Data  0.040 ( 0.062)	InnerLoop  0.610 ( 0.623)	Loss 5.0511e-01 (6.1615e-01)	Acc@1  82.64 ( 77.71)
The current update step is 3630
GPU_0_using curriculum 40 with window 40
Epoch: [121][20/30]	Time  1.478 ( 1.510)	Data  0.039 ( 0.069)	InnerLoop  0.605 ( 0.612)	Loss 6.5763e-01 (6.2381e-01)	Acc@1  75.29 ( 76.82)
The current update step is 3660
GPU_0_using curriculum 40 with window 40
Epoch: [122][20/30]	Time  1.489 ( 1.514)	Data  0.038 ( 0.063)	InnerLoop  0.625 ( 0.619)	Loss 1.4423e+00 (6.6077e-01)	Acc@1  61.65 ( 76.27)
The current update step is 3690
GPU_0_using curriculum 40 with window 40
Epoch: [123][20/30]	Time  1.486 ( 1.512)	Data  0.037 ( 0.063)	InnerLoop  0.606 ( 0.618)	Loss 6.0591e-01 (6.2864e-01)	Acc@1  77.51 ( 77.48)
The current update step is 3720
GPU_0_using curriculum 40 with window 40
Epoch: [124][20/30]	Time  1.475 ( 1.511)	Data  0.036 ( 0.056)	InnerLoop  0.607 ( 0.623)	Loss 5.2864e-01 (5.7301e-01)	Acc@1  80.57 ( 78.92)
The current update step is 3750
The current seed is 2716186639403236107
The current lr is: 0.001
Testing Results:
 *   Acc@1 79.684
 *   Acc@1 79.322
 *   Acc@1 78.658
 *   Acc@1 78.694
 *   Acc@1 78.276
 *   Acc@1 77.993
 *   Acc@1 77.579
 *   Acc@1 78.118
 *   Acc@1 78.789
 *   Acc@1 79.547
 *   Acc@1 79.000
 *   Acc@1 79.311
 *   Acc@1 78.250
 *   Acc@1 79.325
 *   Acc@1 77.895
 *   Acc@1 78.461
 *   Acc@1 76.632
 *   Acc@1 77.439
 *   Acc@1 76.105
 *   Acc@1 76.482
 *   Acc@1 75.434
 *   Acc@1 75.917
 *   Acc@1 75.474
 *   Acc@1 75.973
 *   Acc@1 73.079
 *   Acc@1 72.812
 *   Acc@1 75.618
 *   Acc@1 75.495
 *   Acc@1 76.895
 *   Acc@1 76.957
 *   Acc@1 78.079
 *   Acc@1 78.278
Training for 300 epoch: 77.04605263157895
Training for 600 epoch: 77.34539473684211
Training for 1000 epoch: 77.21381578947368
Training for 3000 epoch: 77.25657894736841
Training for 300 epoch: 77.27979166666667
Training for 600 epoch: 77.49541666666667
Training for 1000 epoch: 77.548125
Training for 3000 epoch: 77.7075
[[77.04605263157895, 77.34539473684211, 77.21381578947368, 77.25657894736841], [77.27979166666667, 77.49541666666667, 77.548125, 77.7075]]
train loss 0.16411970704396567, epoch 124, best loss 0.1510807803074519, best_epoch 104
GPU_0_using curriculum 40 with window 40
Epoch: [125][20/30]	Time  1.495 ( 1.515)	Data  0.039 ( 0.061)	InnerLoop  0.627 ( 0.624)	Loss 5.1443e-01 (5.8074e-01)	Acc@1  81.45 ( 79.06)
The current update step is 3780
GPU_0_using curriculum 40 with window 40
Epoch: [126][20/30]	Time  1.490 ( 1.507)	Data  0.036 ( 0.068)	InnerLoop  0.611 ( 0.611)	Loss 5.5310e-01 (5.9368e-01)	Acc@1  78.93 ( 78.37)
The current update step is 3810
GPU_0_using curriculum 40 with window 40
Epoch: [127][20/30]	Time  1.480 ( 1.509)	Data  0.042 ( 0.063)	InnerLoop  0.612 ( 0.618)	Loss 5.2066e-01 (6.2330e-01)	Acc@1  81.47 ( 77.34)
The current update step is 3840
GPU_0_using curriculum 40 with window 40
Epoch: [128][20/30]	Time  1.464 ( 1.507)	Data  0.035 ( 0.062)	InnerLoop  0.606 ( 0.617)	Loss 5.2858e-01 (6.0622e-01)	Acc@1  79.96 ( 77.78)
The current update step is 3870
GPU_0_using curriculum 40 with window 40
Epoch: [129][20/30]	Time  1.481 ( 1.506)	Data  0.037 ( 0.056)	InnerLoop  0.611 ( 0.623)	Loss 7.1743e-01 (5.8937e-01)	Acc@1  76.54 ( 78.91)
The current update step is 3900
The current seed is 17805371460353717906
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.934
 *   Acc@1 78.735
 *   Acc@1 75.895
 *   Acc@1 76.351
 *   Acc@1 74.276
 *   Acc@1 74.954
 *   Acc@1 72.158
 *   Acc@1 72.534
 *   Acc@1 77.750
 *   Acc@1 77.715
 *   Acc@1 77.711
 *   Acc@1 77.939
 *   Acc@1 77.921
 *   Acc@1 78.317
 *   Acc@1 76.868
 *   Acc@1 77.032
 *   Acc@1 78.053
 *   Acc@1 77.755
 *   Acc@1 77.355
 *   Acc@1 77.345
 *   Acc@1 77.434
 *   Acc@1 77.049
 *   Acc@1 77.776
 *   Acc@1 77.292
 *   Acc@1 79.961
 *   Acc@1 80.562
 *   Acc@1 80.684
 *   Acc@1 81.112
 *   Acc@1 80.447
 *   Acc@1 80.602
 *   Acc@1 80.276
 *   Acc@1 80.166
Training for 300 epoch: 78.42434210526315
Training for 600 epoch: 77.91118421052632
Training for 1000 epoch: 77.51973684210526
Training for 3000 epoch: 76.76973684210527
Training for 300 epoch: 78.69166666666666
Training for 600 epoch: 78.18666666666667
Training for 1000 epoch: 77.730625
Training for 3000 epoch: 76.75583333333334
[[78.42434210526315, 77.91118421052632, 77.51973684210526, 76.76973684210527], [78.69166666666666, 78.18666666666667, 77.730625, 76.75583333333334]]
train loss 0.14260784270763396, epoch 129, best loss 0.14260784270763396, best_epoch 129
GPU_0_using curriculum 40 with window 40
Epoch: [130][20/30]	Time  1.477 ( 1.513)	Data  0.038 ( 0.062)	InnerLoop  0.612 ( 0.623)	Loss 5.0315e-01 (6.0813e-01)	Acc@1  81.32 ( 77.70)
The current update step is 3930
GPU_0_using curriculum 40 with window 40
Epoch: [131][20/30]	Time  1.508 ( 1.512)	Data  0.036 ( 0.067)	InnerLoop  0.606 ( 0.611)	Loss 6.1397e-01 (6.0563e-01)	Acc@1  77.69 ( 78.07)
The current update step is 3960
GPU_0_using curriculum 40 with window 40
Epoch: [132][20/30]	Time  1.493 ( 1.517)	Data  0.039 ( 0.062)	InnerLoop  0.618 ( 0.623)	Loss 6.0379e-01 (5.8917e-01)	Acc@1  77.93 ( 78.60)
The current update step is 3990
GPU_0_using curriculum 40 with window 40
Epoch: [133][20/30]	Time  1.468 ( 1.512)	Data  0.037 ( 0.064)	InnerLoop  0.609 ( 0.618)	Loss 4.8504e-01 (5.5706e-01)	Acc@1  83.18 ( 79.71)
The current update step is 4020
GPU_0_using curriculum 40 with window 40
Epoch: [134][20/30]	Time  1.519 ( 1.513)	Data  0.040 ( 0.056)	InnerLoop  0.620 ( 0.624)	Loss 5.3871e-01 (5.7618e-01)	Acc@1  79.86 ( 78.80)
The current update step is 4050
The current seed is 18366249383230667809
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.684
 *   Acc@1 76.733
 *   Acc@1 78.697
 *   Acc@1 78.726
 *   Acc@1 78.605
 *   Acc@1 78.251
 *   Acc@1 76.618
 *   Acc@1 76.317
 *   Acc@1 73.066
 *   Acc@1 73.448
 *   Acc@1 71.724
 *   Acc@1 71.717
 *   Acc@1 67.342
 *   Acc@1 67.599
 *   Acc@1 66.750
 *   Acc@1 66.718
 *   Acc@1 78.763
 *   Acc@1 78.823
 *   Acc@1 78.118
 *   Acc@1 78.334
 *   Acc@1 77.053
 *   Acc@1 77.523
 *   Acc@1 75.513
 *   Acc@1 75.895
 *   Acc@1 77.526
 *   Acc@1 77.611
 *   Acc@1 78.803
 *   Acc@1 78.495
 *   Acc@1 78.868
 *   Acc@1 78.703
 *   Acc@1 78.671
 *   Acc@1 78.677
Training for 300 epoch: 76.50986842105263
Training for 600 epoch: 76.83552631578948
Training for 1000 epoch: 75.46710526315789
Training for 3000 epoch: 74.38815789473684
Training for 300 epoch: 76.65354166666667
Training for 600 epoch: 76.81791666666666
Training for 1000 epoch: 75.51916666666666
Training for 3000 epoch: 74.401875
[[76.50986842105263, 76.83552631578948, 75.46710526315789, 74.38815789473684], [76.65354166666667, 76.81791666666666, 75.51916666666666, 74.401875]]
train loss 0.14765494186083475, epoch 134, best loss 0.14260784270763396, best_epoch 129
GPU_0_using curriculum 40 with window 40
Epoch: [135][20/30]	Time  1.508 ( 1.521)	Data  0.038 ( 0.062)	InnerLoop  0.621 ( 0.627)	Loss 7.7287e-01 (6.0603e-01)	Acc@1  71.19 ( 77.97)
The current update step is 4080
GPU_0_using curriculum 40 with window 40
Epoch: [136][20/30]	Time  1.473 ( 1.511)	Data  0.040 ( 0.069)	InnerLoop  0.611 ( 0.612)	Loss 5.5654e-01 (5.9382e-01)	Acc@1  80.47 ( 78.08)
The current update step is 4110
GPU_0_using curriculum 40 with window 40
Epoch: [137][20/30]	Time  1.481 ( 1.514)	Data  0.038 ( 0.063)	InnerLoop  0.618 ( 0.621)	Loss 4.6451e-01 (5.6661e-01)	Acc@1  82.89 ( 78.83)
The current update step is 4140
GPU_0_using curriculum 40 with window 40
Epoch: [138][20/30]	Time  1.489 ( 1.511)	Data  0.039 ( 0.063)	InnerLoop  0.630 ( 0.621)	Loss 5.4950e-01 (5.7371e-01)	Acc@1  80.49 ( 79.09)
The current update step is 4170
GPU_0_using curriculum 40 with window 40
Epoch: [139][20/30]	Time  1.507 ( 1.515)	Data  0.037 ( 0.056)	InnerLoop  0.634 ( 0.629)	Loss 5.8703e-01 (5.7549e-01)	Acc@1  79.05 ( 78.96)
The current update step is 4200
The current seed is 11186409205957427174
The current lr is: 0.001
Testing Results:
 *   Acc@1 80.447
 *   Acc@1 80.511
 *   Acc@1 79.053
 *   Acc@1 79.192
 *   Acc@1 77.500
 *   Acc@1 78.057
 *   Acc@1 76.000
 *   Acc@1 76.058
 *   Acc@1 77.118
 *   Acc@1 77.616
 *   Acc@1 78.303
 *   Acc@1 78.776
 *   Acc@1 76.882
 *   Acc@1 77.284
 *   Acc@1 74.039
 *   Acc@1 74.493
 *   Acc@1 77.961
 *   Acc@1 77.747
 *   Acc@1 78.803
 *   Acc@1 78.837
 *   Acc@1 79.224
 *   Acc@1 79.401
 *   Acc@1 80.237
 *   Acc@1 80.091
 *   Acc@1 72.763
 *   Acc@1 73.335
 *   Acc@1 72.026
 *   Acc@1 72.415
 *   Acc@1 71.724
 *   Acc@1 71.690
 *   Acc@1 72.987
 *   Acc@1 73.445
Training for 300 epoch: 77.07236842105263
Training for 600 epoch: 77.04605263157895
Training for 1000 epoch: 76.33223684210526
Training for 3000 epoch: 75.81578947368422
Training for 300 epoch: 77.30208333333333
Training for 600 epoch: 77.30479166666667
Training for 1000 epoch: 76.60791666666667
Training for 3000 epoch: 76.02166666666668
[[77.07236842105263, 77.04605263157895, 76.33223684210526, 75.81578947368422], [77.30208333333333, 77.30479166666667, 76.60791666666667, 76.02166666666668]]
train loss 0.19472492425441743, epoch 139, best loss 0.14260784270763396, best_epoch 129
GPU_0_using curriculum 40 with window 40
Epoch: [140][20/30]	Time  1.492 ( 1.522)	Data  0.038 ( 0.061)	InnerLoop  0.621 ( 0.632)	Loss 5.1053e-01 (5.5186e-01)	Acc@1  80.66 ( 79.90)
The current update step is 4230
GPU_0_using curriculum 40 with window 40
Epoch: [141][20/30]	Time  1.485 ( 1.526)	Data  0.037 ( 0.069)	InnerLoop  0.616 ( 0.619)	Loss 5.5280e-01 (5.7203e-01)	Acc@1  80.32 ( 78.86)
The current update step is 4260
GPU_0_using curriculum 40 with window 40
Epoch: [142][20/30]	Time  1.496 ( 1.511)	Data  0.037 ( 0.062)	InnerLoop  0.613 ( 0.621)	Loss 6.8281e-01 (5.9256e-01)	Acc@1  72.88 ( 78.09)
The current update step is 4290
GPU_0_using curriculum 40 with window 40
Epoch: [143][20/30]	Time  1.488 ( 1.512)	Data  0.041 ( 0.062)	InnerLoop  0.615 ( 0.621)	Loss 5.8192e-01 (6.1539e-01)	Acc@1  77.86 ( 77.57)
The current update step is 4320
GPU_0_using curriculum 40 with window 40
Epoch: [144][20/30]	Time  1.485 ( 1.515)	Data  0.045 ( 0.056)	InnerLoop  0.617 ( 0.629)	Loss 5.5900e-01 (6.0024e-01)	Acc@1  79.30 ( 78.58)
The current update step is 4350
The current seed is 3100656968838254308
The current lr is: 0.001
Testing Results:
 *   Acc@1 75.197
 *   Acc@1 75.470
 *   Acc@1 73.395
 *   Acc@1 74.033
 *   Acc@1 72.184
 *   Acc@1 72.679
 *   Acc@1 69.961
 *   Acc@1 70.389
 *   Acc@1 76.632
 *   Acc@1 76.154
 *   Acc@1 76.132
 *   Acc@1 76.043
 *   Acc@1 77.053
 *   Acc@1 76.843
 *   Acc@1 78.118
 *   Acc@1 77.626
 *   Acc@1 76.276
 *   Acc@1 76.178
 *   Acc@1 74.145
 *   Acc@1 74.142
 *   Acc@1 73.566
 *   Acc@1 73.582
 *   Acc@1 73.039
 *   Acc@1 72.668
 *   Acc@1 76.105
 *   Acc@1 76.296
 *   Acc@1 76.724
 *   Acc@1 77.149
 *   Acc@1 76.421
 *   Acc@1 77.242
 *   Acc@1 75.211
 *   Acc@1 75.635
Training for 300 epoch: 76.05263157894737
Training for 600 epoch: 75.09868421052632
Training for 1000 epoch: 74.80592105263159
Training for 3000 epoch: 74.08223684210526
Training for 300 epoch: 76.02458333333334
Training for 600 epoch: 75.34208333333333
Training for 1000 epoch: 75.08645833333333
Training for 3000 epoch: 74.07958333333333
[[76.05263157894737, 75.09868421052632, 74.80592105263159, 74.08223684210526], [76.02458333333334, 75.34208333333333, 75.08645833333333, 74.07958333333333]]
train loss 0.1916759729385376, epoch 144, best loss 0.14260784270763396, best_epoch 129
GPU_0_using curriculum 40 with window 40
Epoch: [145][20/30]	Time  1.474 ( 1.519)	Data  0.038 ( 0.062)	InnerLoop  0.613 ( 0.626)	Loss 5.0022e-01 (6.6633e-01)	Acc@1  82.18 ( 76.21)
The current update step is 4380
GPU_0_using curriculum 40 with window 40
Epoch: [146][20/30]	Time  1.491 ( 1.510)	Data  0.037 ( 0.068)	InnerLoop  0.619 ( 0.614)	Loss 5.5073e-01 (6.1135e-01)	Acc@1  80.49 ( 77.66)
The current update step is 4410
GPU_0_using curriculum 40 with window 40
Epoch: [147][20/30]	Time  1.475 ( 1.511)	Data  0.038 ( 0.062)	InnerLoop  0.610 ( 0.618)	Loss 5.7887e-01 (5.7395e-01)	Acc@1  78.39 ( 78.87)
The current update step is 4440
GPU_0_using curriculum 40 with window 40
Epoch: [148][20/30]	Time  1.476 ( 1.507)	Data  0.037 ( 0.063)	InnerLoop  0.611 ( 0.617)	Loss 4.9299e-01 (6.0397e-01)	Acc@1  81.76 ( 78.07)
The current update step is 4470
GPU_0_using curriculum 40 with window 40
Epoch: [149][20/30]	Time  1.481 ( 1.503)	Data  0.036 ( 0.056)	InnerLoop  0.616 ( 0.621)	Loss 4.7609e-01 (5.9409e-01)	Acc@1  82.06 ( 77.81)
The current update step is 4500
The current seed is 6382965745524841050
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.355
 *   Acc@1 77.218
 *   Acc@1 76.618
 *   Acc@1 76.888
 *   Acc@1 77.461
 *   Acc@1 77.286
 *   Acc@1 76.855
 *   Acc@1 77.009
 *   Acc@1 79.921
 *   Acc@1 80.196
 *   Acc@1 79.605
 *   Acc@1 79.725
 *   Acc@1 79.355
 *   Acc@1 79.541
 *   Acc@1 77.987
 *   Acc@1 78.566
 *   Acc@1 74.750
 *   Acc@1 75.372
 *   Acc@1 72.737
 *   Acc@1 72.671
 *   Acc@1 71.211
 *   Acc@1 71.395
 *   Acc@1 70.789
 *   Acc@1 70.847
 *   Acc@1 80.421
 *   Acc@1 80.945
 *   Acc@1 78.816
 *   Acc@1 79.448
 *   Acc@1 77.461
 *   Acc@1 77.877
 *   Acc@1 74.618
 *   Acc@1 74.843
Training for 300 epoch: 78.11184210526316
Training for 600 epoch: 76.94407894736842
Training for 1000 epoch: 76.3717105263158
Training for 3000 epoch: 75.0625
Training for 300 epoch: 78.43270833333334
Training for 600 epoch: 77.18291666666667
Training for 1000 epoch: 76.52458333333333
Training for 3000 epoch: 75.31625
[[78.11184210526316, 76.94407894736842, 76.3717105263158, 75.0625], [78.43270833333334, 77.18291666666667, 76.52458333333333, 75.31625]]
train loss 0.1698969800074895, epoch 149, best loss 0.14260784270763396, best_epoch 129
GPU_0_using curriculum 40 with window 40
Epoch: [150][20/30]	Time  1.479 ( 1.518)	Data  0.038 ( 0.062)	InnerLoop  0.605 ( 0.624)	Loss 4.8342e-01 (5.6947e-01)	Acc@1  82.23 ( 78.85)
The current update step is 4530
GPU_0_using curriculum 40 with window 40
Epoch: [151][20/30]	Time  1.465 ( 1.511)	Data  0.036 ( 0.068)	InnerLoop  0.607 ( 0.613)	Loss 7.2525e-01 (6.0639e-01)	Acc@1  73.75 ( 77.25)
The current update step is 4560
GPU_0_using curriculum 40 with window 40
Epoch: [152][20/30]	Time  1.478 ( 1.513)	Data  0.040 ( 0.062)	InnerLoop  0.612 ( 0.618)	Loss 6.0187e-01 (5.5764e-01)	Acc@1  77.76 ( 79.39)
The current update step is 4590
GPU_0_using curriculum 40 with window 40
Epoch: [153][20/30]	Time  1.492 ( 1.509)	Data  0.037 ( 0.061)	InnerLoop  0.615 ( 0.618)	Loss 7.2539e-01 (6.0615e-01)	Acc@1  73.24 ( 77.77)
The current update step is 4620
GPU_0_using curriculum 40 with window 40
Epoch: [154][20/30]	Time  1.485 ( 1.512)	Data  0.039 ( 0.057)	InnerLoop  0.617 ( 0.625)	Loss 4.9243e-01 (5.6941e-01)	Acc@1  82.37 ( 79.21)
The current update step is 4650
The current seed is 12134582856898759126
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.566
 *   Acc@1 77.868
 *   Acc@1 75.632
 *   Acc@1 75.997
 *   Acc@1 74.500
 *   Acc@1 75.103
 *   Acc@1 72.355
 *   Acc@1 73.223
 *   Acc@1 79.829
 *   Acc@1 80.069
 *   Acc@1 72.987
 *   Acc@1 73.272
 *   Acc@1 71.026
 *   Acc@1 71.236
 *   Acc@1 68.947
 *   Acc@1 69.067
 *   Acc@1 79.066
 *   Acc@1 79.822
 *   Acc@1 80.053
 *   Acc@1 80.498
 *   Acc@1 80.382
 *   Acc@1 80.088
 *   Acc@1 79.263
 *   Acc@1 79.097
 *   Acc@1 81.066
 *   Acc@1 81.517
 *   Acc@1 81.566
 *   Acc@1 82.069
 *   Acc@1 80.816
 *   Acc@1 81.016
 *   Acc@1 79.474
 *   Acc@1 79.701
Training for 300 epoch: 79.38157894736842
Training for 600 epoch: 77.5592105263158
Training for 1000 epoch: 76.68092105263159
Training for 3000 epoch: 75.00986842105263
Training for 300 epoch: 79.81895833333333
Training for 600 epoch: 77.95916666666666
Training for 1000 epoch: 76.86083333333333
Training for 3000 epoch: 75.27208333333333
[[79.38157894736842, 77.5592105263158, 76.68092105263159, 75.00986842105263], [79.81895833333333, 77.95916666666666, 76.86083333333333, 75.27208333333333]]
train loss 0.15784318803151448, epoch 154, best loss 0.14260784270763396, best_epoch 129
GPU_0_using curriculum 40 with window 40
Epoch: [155][20/30]	Time  1.472 ( 1.513)	Data  0.035 ( 0.061)	InnerLoop  0.612 ( 0.624)	Loss 5.4400e-01 (5.9398e-01)	Acc@1  80.93 ( 78.41)
The current update step is 4680
GPU_0_using curriculum 40 with window 40
Epoch: [156][20/30]	Time  1.468 ( 1.507)	Data  0.041 ( 0.068)	InnerLoop  0.604 ( 0.611)	Loss 5.6554e-01 (6.2390e-01)	Acc@1  79.64 ( 77.54)
The current update step is 4710
GPU_0_using curriculum 40 with window 40
Epoch: [157][20/30]	Time  1.475 ( 1.513)	Data  0.036 ( 0.062)	InnerLoop  0.610 ( 0.617)	Loss 7.2418e-01 (5.6294e-01)	Acc@1  72.49 ( 79.15)
The current update step is 4740
GPU_0_using curriculum 40 with window 40
Epoch: [158][20/30]	Time  1.472 ( 1.507)	Data  0.039 ( 0.062)	InnerLoop  0.607 ( 0.616)	Loss 5.6754e-01 (5.8471e-01)	Acc@1  77.93 ( 78.49)
The current update step is 4770
GPU_0_using curriculum 40 with window 40
Epoch: [159][20/30]	Time  1.469 ( 1.505)	Data  0.036 ( 0.056)	InnerLoop  0.608 ( 0.622)	Loss 5.1602e-01 (5.9281e-01)	Acc@1  81.57 ( 78.12)
The current update step is 4800
The current seed is 1734362099303717205
The current lr is: 0.001
Testing Results:
 *   Acc@1 81.684
 *   Acc@1 81.953
 *   Acc@1 81.026
 *   Acc@1 81.596
 *   Acc@1 80.461
 *   Acc@1 80.892
 *   Acc@1 77.816
 *   Acc@1 78.602
 *   Acc@1 76.447
 *   Acc@1 76.753
 *   Acc@1 78.961
 *   Acc@1 79.098
 *   Acc@1 78.039
 *   Acc@1 78.681
 *   Acc@1 77.026
 *   Acc@1 77.134
 *   Acc@1 78.303
 *   Acc@1 78.310
 *   Acc@1 74.329
 *   Acc@1 74.267
 *   Acc@1 71.289
 *   Acc@1 71.450
 *   Acc@1 66.697
 *   Acc@1 66.972
 *   Acc@1 65.882
 *   Acc@1 66.312
 *   Acc@1 68.224
 *   Acc@1 69.129
 *   Acc@1 70.526
 *   Acc@1 71.408
 *   Acc@1 71.092
 *   Acc@1 71.957
Training for 300 epoch: 75.57894736842105
Training for 600 epoch: 75.63486842105263
Training for 1000 epoch: 75.07894736842105
Training for 3000 epoch: 73.15789473684211
Training for 300 epoch: 75.83208333333333
Training for 600 epoch: 76.0225
Training for 1000 epoch: 75.60791666666665
Training for 3000 epoch: 73.66625
[[75.57894736842105, 75.63486842105263, 75.07894736842105, 73.15789473684211], [75.83208333333333, 76.0225, 75.60791666666665, 73.66625]]
train loss 0.20847547866503396, epoch 159, best loss 0.14260784270763396, best_epoch 129
GPU_0_using curriculum 40 with window 40
Epoch: [160][20/30]	Time  1.480 ( 1.514)	Data  0.039 ( 0.061)	InnerLoop  0.609 ( 0.626)	Loss 5.5345e-01 (5.5235e-01)	Acc@1  80.30 ( 79.45)
The current update step is 4830
GPU_0_using curriculum 40 with window 40
Epoch: [161][20/30]	Time  1.477 ( 1.510)	Data  0.037 ( 0.069)	InnerLoop  0.611 ( 0.611)	Loss 5.1871e-01 (5.9305e-01)	Acc@1  82.40 ( 77.95)
The current update step is 4860
GPU_0_using curriculum 40 with window 40
Epoch: [162][20/30]	Time  1.502 ( 1.509)	Data  0.039 ( 0.063)	InnerLoop  0.621 ( 0.614)	Loss 4.7937e-01 (5.8861e-01)	Acc@1  83.25 ( 78.09)
The current update step is 4890
GPU_0_using curriculum 40 with window 40
Epoch: [163][20/30]	Time  1.495 ( 1.516)	Data  0.039 ( 0.063)	InnerLoop  0.622 ( 0.622)	Loss 5.5549e-01 (6.0612e-01)	Acc@1  78.96 ( 77.91)
The current update step is 4920
GPU_0_using curriculum 40 with window 40
Epoch: [164][20/30]	Time  1.509 ( 1.517)	Data  0.042 ( 0.058)	InnerLoop  0.614 ( 0.628)	Loss 6.5246e-01 (5.7339e-01)	Acc@1  76.12 ( 78.82)
The current update step is 4950
The current seed is 13920250080695365566
The current lr is: 0.001
Testing Results:
 *   Acc@1 72.487
 *   Acc@1 73.026
 *   Acc@1 71.671
 *   Acc@1 72.172
 *   Acc@1 69.487
 *   Acc@1 70.160
 *   Acc@1 66.303
 *   Acc@1 66.540
 *   Acc@1 71.618
 *   Acc@1 71.653
 *   Acc@1 70.816
 *   Acc@1 70.667
 *   Acc@1 69.895
 *   Acc@1 70.097
 *   Acc@1 69.184
 *   Acc@1 69.518
 *   Acc@1 74.842
 *   Acc@1 75.006
 *   Acc@1 74.079
 *   Acc@1 74.001
 *   Acc@1 73.421
 *   Acc@1 73.214
 *   Acc@1 72.434
 *   Acc@1 72.340
 *   Acc@1 75.197
 *   Acc@1 75.343
 *   Acc@1 74.829
 *   Acc@1 74.522
 *   Acc@1 74.395
 *   Acc@1 74.123
 *   Acc@1 73.237
 *   Acc@1 72.959
Training for 300 epoch: 73.53618421052632
Training for 600 epoch: 72.84868421052632
Training for 1000 epoch: 71.79934210526316
Training for 3000 epoch: 70.28947368421053
Training for 300 epoch: 73.75666666666666
Training for 600 epoch: 72.84041666666667
Training for 1000 epoch: 71.89854166666666
Training for 3000 epoch: 70.339375
[[73.53618421052632, 72.84868421052632, 71.79934210526316, 70.28947368421053], [73.75666666666666, 72.84041666666667, 71.89854166666666, 70.339375]]
train loss 0.19389412919680277, epoch 164, best loss 0.14260784270763396, best_epoch 129
GPU_0_using curriculum 40 with window 40
Epoch: [165][20/30]	Time  1.470 ( 1.526)	Data  0.038 ( 0.063)	InnerLoop  0.612 ( 0.630)	Loss 5.9074e-01 (6.0539e-01)	Acc@1  77.93 ( 77.75)
The current update step is 4980
GPU_0_using curriculum 40 with window 40
Epoch: [166][20/30]	Time  1.484 ( 1.523)	Data  0.034 ( 0.068)	InnerLoop  0.627 ( 0.615)	Loss 5.9052e-01 (5.7137e-01)	Acc@1  76.83 ( 78.69)
The current update step is 5010
GPU_0_using curriculum 40 with window 40
Epoch: [167][20/30]	Time  1.489 ( 1.509)	Data  0.040 ( 0.063)	InnerLoop  0.615 ( 0.617)	Loss 5.3238e-01 (5.9256e-01)	Acc@1  80.88 ( 78.52)
The current update step is 5040
GPU_0_using curriculum 40 with window 40
Epoch: [168][20/30]	Time  1.498 ( 1.515)	Data  0.038 ( 0.062)	InnerLoop  0.629 ( 0.620)	Loss 7.7810e-01 (5.7103e-01)	Acc@1  73.34 ( 79.10)
The current update step is 5070
GPU_0_using curriculum 40 with window 40
Epoch: [169][20/30]	Time  1.480 ( 1.522)	Data  0.038 ( 0.056)	InnerLoop  0.608 ( 0.627)	Loss 5.8298e-01 (6.0077e-01)	Acc@1  79.10 ( 78.30)
The current update step is 5100
The current seed is 17373993907243820201
The current lr is: 0.001
Testing Results:
 *   Acc@1 64.000
 *   Acc@1 64.837
 *   Acc@1 69.184
 *   Acc@1 70.101
 *   Acc@1 72.395
 *   Acc@1 73.492
 *   Acc@1 73.961
 *   Acc@1 74.524
 *   Acc@1 77.079
 *   Acc@1 77.815
 *   Acc@1 78.316
 *   Acc@1 79.089
 *   Acc@1 78.803
 *   Acc@1 79.314
 *   Acc@1 77.895
 *   Acc@1 78.292
 *   Acc@1 72.289
 *   Acc@1 73.282
 *   Acc@1 73.039
 *   Acc@1 73.597
 *   Acc@1 72.671
 *   Acc@1 73.269
 *   Acc@1 72.566
 *   Acc@1 73.057
 *   Acc@1 72.974
 *   Acc@1 72.994
 *   Acc@1 67.671
 *   Acc@1 68.070
 *   Acc@1 66.303
 *   Acc@1 66.403
 *   Acc@1 65.000
 *   Acc@1 65.193
Training for 300 epoch: 71.58552631578947
Training for 600 epoch: 72.05263157894737
Training for 1000 epoch: 72.54276315789474
Training for 3000 epoch: 72.35526315789474
Training for 300 epoch: 72.23208333333334
Training for 600 epoch: 72.71437499999999
Training for 1000 epoch: 73.11958333333334
Training for 3000 epoch: 72.76645833333333
[[71.58552631578947, 72.05263157894737, 72.54276315789474, 72.35526315789474], [72.23208333333334, 72.71437499999999, 73.11958333333334, 72.76645833333333]]
train loss 0.21683646442890167, epoch 169, best loss 0.14260784270763396, best_epoch 129
GPU_0_using curriculum 40 with window 40
Epoch: [170][20/30]	Time  1.501 ( 1.521)	Data  0.037 ( 0.061)	InnerLoop  0.608 ( 0.627)	Loss 6.0253e-01 (5.7153e-01)	Acc@1  75.68 ( 79.08)
The current update step is 5130
GPU_0_using curriculum 40 with window 40
Epoch: [171][20/30]	Time  1.474 ( 1.508)	Data  0.038 ( 0.068)	InnerLoop  0.612 ( 0.613)	Loss 5.4467e-01 (5.9723e-01)	Acc@1  80.03 ( 77.92)
The current update step is 5160
GPU_0_using curriculum 40 with window 40
Epoch: [172][20/30]	Time  1.499 ( 1.523)	Data  0.038 ( 0.062)	InnerLoop  0.617 ( 0.626)	Loss 4.9640e-01 (5.8179e-01)	Acc@1  81.20 ( 77.96)
The current update step is 5190
GPU_0_using curriculum 40 with window 40
Epoch: [173][20/30]	Time  1.478 ( 1.508)	Data  0.038 ( 0.062)	InnerLoop  0.614 ( 0.620)	Loss 5.7951e-01 (5.8653e-01)	Acc@1  78.49 ( 78.51)
The current update step is 5220
GPU_0_using curriculum 40 with window 40
Epoch: [174][20/30]	Time  1.493 ( 1.516)	Data  0.048 ( 0.057)	InnerLoop  0.604 ( 0.629)	Loss 6.0019e-01 (5.9367e-01)	Acc@1  79.44 ( 78.23)
The current update step is 5250
The current seed is 7310259948576217828
The current lr is: 0.001
Testing Results:
 *   Acc@1 78.250
 *   Acc@1 78.983
 *   Acc@1 78.579
 *   Acc@1 79.542
 *   Acc@1 76.789
 *   Acc@1 77.866
 *   Acc@1 70.013
 *   Acc@1 71.169
 *   Acc@1 69.684
 *   Acc@1 69.992
 *   Acc@1 68.316
 *   Acc@1 68.759
 *   Acc@1 68.342
 *   Acc@1 68.599
 *   Acc@1 69.987
 *   Acc@1 70.241
 *   Acc@1 78.013
 *   Acc@1 78.383
 *   Acc@1 78.553
 *   Acc@1 78.795
 *   Acc@1 77.526
 *   Acc@1 77.623
 *   Acc@1 75.013
 *   Acc@1 75.436
 *   Acc@1 75.618
 *   Acc@1 75.597
 *   Acc@1 76.632
 *   Acc@1 76.727
 *   Acc@1 77.513
 *   Acc@1 78.052
 *   Acc@1 76.132
 *   Acc@1 76.247
Training for 300 epoch: 75.39144736842104
Training for 600 epoch: 75.51973684210526
Training for 1000 epoch: 75.04276315789473
Training for 3000 epoch: 72.78618421052632
Training for 300 epoch: 75.73854166666666
Training for 600 epoch: 75.95562500000001
Training for 1000 epoch: 75.53479166666666
Training for 3000 epoch: 73.273125
[[75.39144736842104, 75.51973684210526, 75.04276315789473, 72.78618421052632], [75.73854166666666, 75.95562500000001, 75.53479166666666, 73.273125]]
train loss 0.15443362441857655, epoch 174, best loss 0.14260784270763396, best_epoch 129
GPU_0_using curriculum 40 with window 40
Epoch: [175][20/30]	Time  1.505 ( 1.517)	Data  0.037 ( 0.061)	InnerLoop  0.610 ( 0.627)	Loss 6.8260e-01 (6.3279e-01)	Acc@1  74.34 ( 76.56)
The current update step is 5280
GPU_0_using curriculum 40 with window 40
Epoch: [176][20/30]	Time  1.472 ( 1.514)	Data  0.037 ( 0.068)	InnerLoop  0.606 ( 0.613)	Loss 4.6920e-01 (5.5810e-01)	Acc@1  82.42 ( 79.57)
The current update step is 5310
GPU_0_using curriculum 40 with window 40
Epoch: [177][20/30]	Time  1.472 ( 1.516)	Data  0.037 ( 0.062)	InnerLoop  0.613 ( 0.624)	Loss 4.9847e-01 (5.6900e-01)	Acc@1  82.40 ( 78.81)
The current update step is 5340
GPU_0_using curriculum 40 with window 40
Epoch: [178][20/30]	Time  1.481 ( 1.518)	Data  0.036 ( 0.062)	InnerLoop  0.611 ( 0.621)	Loss 7.2510e-01 (6.0469e-01)	Acc@1  74.12 ( 78.17)
The current update step is 5370
GPU_0_using curriculum 40 with window 40
Epoch: [179][20/30]	Time  1.512 ( 1.509)	Data  0.037 ( 0.055)	InnerLoop  0.642 ( 0.625)	Loss 5.8069e-01 (5.7115e-01)	Acc@1  78.49 ( 79.19)
The current update step is 5400
The current seed is 12316904349392602956
The current lr is: 0.001
Testing Results:
 *   Acc@1 60.250
 *   Acc@1 61.303
 *   Acc@1 57.658
 *   Acc@1 58.292
 *   Acc@1 57.039
 *   Acc@1 57.202
 *   Acc@1 59.053
 *   Acc@1 59.794
 *   Acc@1 77.250
 *   Acc@1 76.991
 *   Acc@1 76.408
 *   Acc@1 76.472
 *   Acc@1 75.342
 *   Acc@1 75.222
 *   Acc@1 73.500
 *   Acc@1 73.080
 *   Acc@1 77.118
 *   Acc@1 77.130
 *   Acc@1 75.474
 *   Acc@1 75.436
 *   Acc@1 74.158
 *   Acc@1 73.916
 *   Acc@1 72.276
 *   Acc@1 71.919
 *   Acc@1 76.250
 *   Acc@1 76.577
 *   Acc@1 75.539
 *   Acc@1 75.508
 *   Acc@1 75.039
 *   Acc@1 74.909
 *   Acc@1 73.789
 *   Acc@1 73.910
Training for 300 epoch: 72.71710526315789
Training for 600 epoch: 71.26973684210526
Training for 1000 epoch: 70.39473684210526
Training for 3000 epoch: 69.65460526315789
Training for 300 epoch: 73.00020833333333
Training for 600 epoch: 71.42708333333333
Training for 1000 epoch: 70.31229166666668
Training for 3000 epoch: 69.67583333333334
[[72.71710526315789, 71.26973684210526, 70.39473684210526, 69.65460526315789], [73.00020833333333, 71.42708333333333, 70.31229166666668, 69.67583333333334]]
train loss 0.19916841468016305, epoch 179, best loss 0.14260784270763396, best_epoch 129
GPU_0_using curriculum 40 with window 40
Epoch: [180][20/30]	Time  1.487 ( 1.524)	Data  0.039 ( 0.063)	InnerLoop  0.612 ( 0.627)	Loss 5.0869e-01 (5.6843e-01)	Acc@1  82.57 ( 79.56)
The current update step is 5430
GPU_0_using curriculum 40 with window 40
Epoch: [181][20/30]	Time  1.515 ( 1.515)	Data  0.042 ( 0.069)	InnerLoop  0.614 ( 0.611)	Loss 5.8903e-01 (5.7033e-01)	Acc@1  76.81 ( 78.95)
The current update step is 5460
GPU_0_using curriculum 40 with window 40
Epoch: [182][20/30]	Time  1.483 ( 1.510)	Data  0.042 ( 0.062)	InnerLoop  0.611 ( 0.616)	Loss 5.1640e-01 (5.4666e-01)	Acc@1  81.42 ( 80.00)
The current update step is 5490
GPU_0_using curriculum 40 with window 40
Epoch: [183][20/30]	Time  1.489 ( 1.514)	Data  0.046 ( 0.063)	InnerLoop  0.609 ( 0.618)	Loss 5.2782e-01 (5.9901e-01)	Acc@1  81.23 ( 78.03)
The current update step is 5520
GPU_0_using curriculum 40 with window 40
Epoch: [184][20/30]	Time  1.475 ( 1.517)	Data  0.037 ( 0.056)	InnerLoop  0.610 ( 0.628)	Loss 5.5487e-01 (5.8926e-01)	Acc@1  79.81 ( 78.46)
The current update step is 5550
The current seed is 4771927089030305261
The current lr is: 0.001
Testing Results:
 *   Acc@1 79.447
 *   Acc@1 79.328
 *   Acc@1 77.500
 *   Acc@1 77.493
 *   Acc@1 76.250
 *   Acc@1 76.226
 *   Acc@1 74.855
 *   Acc@1 74.748
 *   Acc@1 72.224
 *   Acc@1 72.838
 *   Acc@1 68.658
 *   Acc@1 68.850
 *   Acc@1 66.947
 *   Acc@1 67.613
 *   Acc@1 66.395
 *   Acc@1 66.965
 *   Acc@1 73.842
 *   Acc@1 74.581
 *   Acc@1 71.395
 *   Acc@1 71.680
 *   Acc@1 69.842
 *   Acc@1 70.329
 *   Acc@1 67.711
 *   Acc@1 67.709
 *   Acc@1 70.974
 *   Acc@1 71.917
 *   Acc@1 72.763
 *   Acc@1 73.259
 *   Acc@1 72.382
 *   Acc@1 73.031
 *   Acc@1 70.013
 *   Acc@1 70.543
Training for 300 epoch: 74.1217105263158
Training for 600 epoch: 72.57894736842105
Training for 1000 epoch: 71.35526315789474
Training for 3000 epoch: 69.74342105263158
Training for 300 epoch: 74.66583333333334
Training for 600 epoch: 72.820625
Training for 1000 epoch: 71.79979166666666
Training for 3000 epoch: 69.99125000000001
[[74.1217105263158, 72.57894736842105, 71.35526315789474, 69.74342105263158], [74.66583333333334, 72.820625, 71.79979166666666, 69.99125000000001]]
train loss 0.2226902704556783, epoch 184, best loss 0.14260784270763396, best_epoch 129
GPU_0_using curriculum 40 with window 40
Epoch: [185][20/30]	Time  1.478 ( 1.512)	Data  0.037 ( 0.060)	InnerLoop  0.611 ( 0.621)	Loss 5.4385e-01 (5.6217e-01)	Acc@1  79.61 ( 79.29)
The current update step is 5580
GPU_0_using curriculum 40 with window 40
Epoch: [186][20/30]	Time  1.506 ( 1.516)	Data  0.039 ( 0.068)	InnerLoop  0.611 ( 0.609)	Loss 5.9427e-01 (5.6509e-01)	Acc@1  79.71 ( 79.44)
The current update step is 5610
GPU_0_using curriculum 40 with window 40
Epoch: [187][20/30]	Time  1.476 ( 1.507)	Data  0.040 ( 0.063)	InnerLoop  0.608 ( 0.616)	Loss 5.2450e-01 (5.9383e-01)	Acc@1  81.54 ( 78.33)
The current update step is 5640
GPU_0_using curriculum 40 with window 40
Epoch: [188][20/30]	Time  1.508 ( 1.509)	Data  0.041 ( 0.062)	InnerLoop  0.628 ( 0.616)	Loss 5.3141e-01 (5.7324e-01)	Acc@1  80.15 ( 78.81)
The current update step is 5670
GPU_0_using curriculum 40 with window 40
Epoch: [189][20/30]	Time  1.472 ( 1.508)	Data  0.037 ( 0.055)	InnerLoop  0.611 ( 0.622)	Loss 6.4324e-01 (5.8163e-01)	Acc@1  76.93 ( 78.69)
The current update step is 5700
The current seed is 7618131788115606988
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.882
 *   Acc@1 73.868
 *   Acc@1 71.553
 *   Acc@1 71.405
 *   Acc@1 71.368
 *   Acc@1 71.682
 *   Acc@1 71.368
 *   Acc@1 71.785
 *   Acc@1 79.618
 *   Acc@1 79.947
 *   Acc@1 79.487
 *   Acc@1 79.573
 *   Acc@1 79.447
 *   Acc@1 79.448
 *   Acc@1 78.237
 *   Acc@1 78.842
 *   Acc@1 74.750
 *   Acc@1 75.384
 *   Acc@1 74.368
 *   Acc@1 74.809
 *   Acc@1 73.882
 *   Acc@1 73.870
 *   Acc@1 72.526
 *   Acc@1 73.069
 *   Acc@1 65.579
 *   Acc@1 65.750
 *   Acc@1 66.632
 *   Acc@1 67.573
 *   Acc@1 68.487
 *   Acc@1 69.354
 *   Acc@1 68.184
 *   Acc@1 68.927
Training for 300 epoch: 73.45723684210526
Training for 600 epoch: 73.00986842105263
Training for 1000 epoch: 73.29605263157896
Training for 3000 epoch: 72.57894736842105
Training for 300 epoch: 73.73729166666666
Training for 600 epoch: 73.34
Training for 1000 epoch: 73.58833333333334
Training for 3000 epoch: 73.155625
[[73.45723684210526, 73.00986842105263, 73.29605263157896, 72.57894736842105], [73.73729166666666, 73.34, 73.58833333333334, 73.155625]]
train loss 0.23204091262817383, epoch 189, best loss 0.14260784270763396, best_epoch 189
GPU_0_using curriculum 40 with window 40
Epoch: [190][20/30]	Time  1.510 ( 1.521)	Data  0.037 ( 0.062)	InnerLoop  0.631 ( 0.627)	Loss 6.1669e-01 (5.7938e-01)	Acc@1  77.25 ( 79.09)
The current update step is 5730
GPU_0_using curriculum 40 with window 40
Epoch: [191][20/30]	Time  1.458 ( 1.509)	Data  0.036 ( 0.067)	InnerLoop  0.601 ( 0.613)	Loss 5.2571e-01 (5.6363e-01)	Acc@1  80.47 ( 79.62)
The current update step is 5760
GPU_0_using curriculum 40 with window 40
Epoch: [192][20/30]	Time  1.490 ( 1.516)	Data  0.037 ( 0.063)	InnerLoop  0.622 ( 0.620)	Loss 5.0937e-01 (5.6344e-01)	Acc@1  82.20 ( 79.56)
The current update step is 5790
GPU_0_using curriculum 40 with window 40
Epoch: [193][20/30]	Time  1.480 ( 1.515)	Data  0.039 ( 0.062)	InnerLoop  0.610 ( 0.618)	Loss 5.4244e-01 (5.5553e-01)	Acc@1  81.18 ( 79.81)
The current update step is 5820
GPU_0_using curriculum 40 with window 40
Epoch: [194][20/30]	Time  1.478 ( 1.510)	Data  0.037 ( 0.056)	InnerLoop  0.611 ( 0.622)	Loss 5.2345e-01 (5.6098e-01)	Acc@1  80.91 ( 79.81)
The current update step is 5850
The current seed is 9472439949387075086
The current lr is: 0.001
Testing Results:
 *   Acc@1 63.500
 *   Acc@1 64.054
 *   Acc@1 60.197
 *   Acc@1 60.868
 *   Acc@1 58.776
 *   Acc@1 59.645
 *   Acc@1 58.026
 *   Acc@1 58.394
 *   Acc@1 77.079
 *   Acc@1 77.800
 *   Acc@1 74.158
 *   Acc@1 74.422
 *   Acc@1 72.474
 *   Acc@1 73.062
 *   Acc@1 70.289
 *   Acc@1 70.907
 *   Acc@1 75.526
 *   Acc@1 76.239
 *   Acc@1 74.684
 *   Acc@1 75.684
 *   Acc@1 74.316
 *   Acc@1 75.523
 *   Acc@1 73.592
 *   Acc@1 74.317
 *   Acc@1 74.184
 *   Acc@1 74.424
 *   Acc@1 73.395
 *   Acc@1 73.634
 *   Acc@1 71.724
 *   Acc@1 72.188
 *   Acc@1 67.092
 *   Acc@1 67.482
Training for 300 epoch: 72.57236842105263
Training for 600 epoch: 70.60855263157895
Training for 1000 epoch: 69.32236842105263
Training for 3000 epoch: 67.25
Training for 300 epoch: 73.129375
Training for 600 epoch: 71.15208333333334
Training for 1000 epoch: 70.10458333333334
Training for 3000 epoch: 67.77520833333334
[[72.57236842105263, 70.60855263157895, 69.32236842105263, 67.25], [73.129375, 71.15208333333334, 70.10458333333334, 67.77520833333334]]
train loss 0.21138171541690826, epoch 194, best loss 0.14260784270763396, best_epoch 189
GPU_0_using curriculum 40 with window 40
Epoch: [195][20/30]	Time  1.484 ( 1.522)	Data  0.038 ( 0.062)	InnerLoop  0.609 ( 0.625)	Loss 5.6360e-01 (5.7279e-01)	Acc@1  79.83 ( 79.15)
The current update step is 5880
GPU_0_using curriculum 40 with window 40
Epoch: [196][20/30]	Time  1.475 ( 1.510)	Data  0.037 ( 0.069)	InnerLoop  0.606 ( 0.610)	Loss 4.6738e-01 (6.2121e-01)	Acc@1  83.33 ( 77.34)
The current update step is 5910
GPU_0_using curriculum 40 with window 40
Epoch: [197][20/30]	Time  1.473 ( 1.510)	Data  0.037 ( 0.063)	InnerLoop  0.605 ( 0.616)	Loss 6.1735e-01 (5.8748e-01)	Acc@1  74.90 ( 78.18)
The current update step is 5940
GPU_0_using curriculum 40 with window 40
Epoch: [198][20/30]	Time  1.483 ( 1.510)	Data  0.038 ( 0.062)	InnerLoop  0.616 ( 0.616)	Loss 5.5596e-01 (5.4409e-01)	Acc@1  79.42 ( 80.20)
The current update step is 5970
GPU_0_using curriculum 40 with window 40
Epoch: [199][20/30]	Time  1.472 ( 1.513)	Data  0.037 ( 0.057)	InnerLoop  0.610 ( 0.624)	Loss 5.2264e-01 (5.6330e-01)	Acc@1  81.13 ( 79.32)
The current update step is 6000
The current seed is 3953188194152949762
The current lr is: 0.001
Testing Results:
 *   Acc@1 81.474
 *   Acc@1 82.017
 *   Acc@1 80.447
 *   Acc@1 81.085
 *   Acc@1 80.276
 *   Acc@1 80.388
 *   Acc@1 78.855
 *   Acc@1 79.474
 *   Acc@1 79.553
 *   Acc@1 79.934
 *   Acc@1 79.829
 *   Acc@1 80.296
 *   Acc@1 79.447
 *   Acc@1 80.140
 *   Acc@1 78.724
 *   Acc@1 79.143
 *   Acc@1 66.289
 *   Acc@1 66.662
 *   Acc@1 67.737
 *   Acc@1 68.229
 *   Acc@1 68.263
 *   Acc@1 68.768
 *   Acc@1 67.553
 *   Acc@1 68.283
 *   Acc@1 79.789
 *   Acc@1 80.242
 *   Acc@1 80.053
 *   Acc@1 81.036
 *   Acc@1 80.316
 *   Acc@1 80.786
 *   Acc@1 79.079
 *   Acc@1 80.116
Training for 300 epoch: 76.77631578947368
Training for 600 epoch: 77.01644736842107
Training for 1000 epoch: 77.07565789473684
Training for 3000 epoch: 76.05263157894737
Training for 300 epoch: 77.21354166666666
Training for 600 epoch: 77.66145833333334
Training for 1000 epoch: 77.52041666666668
Training for 3000 epoch: 76.75416666666666
[[76.77631578947368, 77.01644736842107, 77.07565789473684, 76.05263157894737], [77.21354166666666, 77.66145833333334, 77.52041666666668, 76.75416666666666]]
train loss 0.14974743412335714, epoch 199, best loss 0.14260784270763396, best_epoch 189
=== Final results:
{'acc': 79.38157894736842, 'test': [79.38157894736842, 77.5592105263158, 76.68092105263159, 75.00986842105263], 'train': [79.38157894736842, 77.5592105263158, 76.68092105263159, 75.00986842105263], 'ind': 0, 'epoch': 155, 'data': array([[-0.11618079, -0.05567449, -0.02028736, ...,  0.09871145,
         0.02824996,  0.01526752],
       [-0.01409055, -0.00486025, -0.00614427, ..., -0.01837691,
         0.08724123,  0.06049389],
       [-0.06963534,  0.03324476, -0.14220509, ...,  0.03302351,
         0.04416189, -0.02118294],
       ...,
       [-0.03218676,  0.02696915,  0.01435014, ..., -0.04715585,
        -0.04384137,  0.01699112],
       [-0.02113034,  0.08553479,  0.04457424, ...,  0.05872165,
        -0.07406872,  0.04861473],
       [ 0.02925369,  0.13621306, -0.00239134, ...,  0.02557496,
        -0.01788331, -0.08413732]], shape=(20, 768), dtype=float32)}
