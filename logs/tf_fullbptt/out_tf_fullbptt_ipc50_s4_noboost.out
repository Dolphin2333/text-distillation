Torch Seed Specified with rank: 0
Dataset: agnews_emb
Dataset Path: ./scripts
Namespace(seed=0, mp_distributed=False, world_size=1, rank=0, dist_url='tcp://224.66.41.62:23456', dist_backend='nccl', workers=0, gpu=None, root='./scripts', dataset='agnews_emb', arch='text_transformer', width=256, lr=0.002, inner_optim='Adam', outer_optim='Adam', inner_lr=0.0015, label_lr_scale=1, num_per_class=50, batch_per_class=20, task_sampler_nc=6, window=40, minwindow=0, totwindow=40, num_train_eval=2, train_y=False, batch_size=4096, eps=1e-08, wd=0, test_freq=5, print_freq=20, start_epoch=0, epochs=600, ddtype='standard', cctype=0, zca=False, wandb=False, clip_coef=0.9, fname='out_tf_fullbptt_ipc50_s4_noboost', out_dir='./checkpoints', name='agnews_tf_fullbptt_s4_noboost', comp_aug=False, comp_aug_real=False, syn_strategy='none', real_strategy='none', ckptname='none', limit_train=False, load_ckpt=False, complete_random=False, boost_dd=False, boost_init_from='none', boost_beta=1.0, stage=4, distributed=False, data_root='./scripts/agnews_emb')
==> Preparing data..
None None
Dataset: number of classes: 4
Training set size: 120000
Image size: channel 1, height 768, width 1
Synthetic images, not_single False, keys []
==> Building model..
Initialized data with size, x: torch.Size([200, 768]), y:torch.Size([200])
TextTransformer(
  (input_proj): Linear(in_features=192, out_features=256, bias=True)
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=1024, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=1024, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (cls_head): Linear(in_features=256, out_features=4, bias=True)
)
use data parallel only
GPU_0_using curriculum 40 with window 40
Epoch: [0][20/30]	Time  1.623 ( 1.742)	Data  0.039 ( 0.056)	InnerLoop  0.673 ( 0.759)	Loss 4.4290e+00 (3.1515e+00)	Acc@1  25.24 ( 26.44)
The current update step is 30
GPU_0_using curriculum 40 with window 40
Epoch: [1][20/30]	Time  1.666 ( 1.656)	Data  0.040 ( 0.063)	InnerLoop  0.684 ( 0.692)	Loss 1.4675e+00 (1.8923e+00)	Acc@1  43.36 ( 35.72)
The current update step is 60
GPU_0_using curriculum 40 with window 40
Epoch: [2][20/30]	Time  1.718 ( 1.662)	Data  0.042 ( 0.073)	InnerLoop  0.786 ( 0.690)	Loss 1.1673e+00 (1.4134e+00)	Acc@1  53.44 ( 47.39)
The current update step is 90
GPU_0_using curriculum 40 with window 40
Epoch: [3][20/30]	Time  1.607 ( 1.628)	Data  0.040 ( 0.053)	InnerLoop  0.687 ( 0.689)	Loss 1.3695e+00 (1.3246e+00)	Acc@1  40.67 ( 43.74)
The current update step is 120
GPU_0_using curriculum 40 with window 40
Epoch: [4][20/30]	Time  1.605 ( 1.628)	Data  0.040 ( 0.059)	InnerLoop  0.668 ( 0.684)	Loss 1.3055e+00 (1.2538e+00)	Acc@1  40.97 ( 49.57)
The current update step is 150
The current seed is 11088316954711910092
The current lr is: 0.0015
Testing Results:
 *   Acc@1 54.250
 *   Acc@1 54.517
 *   Acc@1 54.645
 *   Acc@1 55.130
 *   Acc@1 55.487
 *   Acc@1 55.217
 *   Acc@1 23.737
 *   Acc@1 23.589
 *   Acc@1 23.329
 *   Acc@1 23.633
 *   Acc@1 23.895
 *   Acc@1 23.785
Training for 300 epoch: 38.993421052631575
Training for 600 epoch: 38.98684210526316
Training for 1000 epoch: 39.69078947368421
Training for 300 epoch: 39.05291666666667
Training for 600 epoch: 39.38166666666667
Training for 1000 epoch: 39.50083333333333
[[38.993421052631575, 38.98684210526316, 39.69078947368421], [39.05291666666667, 39.38166666666667, 39.50083333333333]]
train loss 3.034797275543213, epoch 4, best loss 3.034797275543213, best_epoch 4
GPU_0_using curriculum 40 with window 40
Epoch: [5][20/30]	Time  1.701 ( 1.622)	Data  0.156 ( 0.068)	InnerLoop  0.671 ( 0.675)	Loss 1.4154e+00 (1.2036e+00)	Acc@1  39.23 ( 50.42)
The current update step is 180
GPU_0_using curriculum 40 with window 40
Epoch: [6][20/30]	Time  1.719 ( 1.626)	Data  0.041 ( 0.059)	InnerLoop  0.772 ( 0.686)	Loss 9.2881e-01 (1.1834e+00)	Acc@1  63.13 ( 52.58)
The current update step is 210
GPU_0_using curriculum 40 with window 40
Epoch: [7][20/30]	Time  1.572 ( 1.613)	Data  0.038 ( 0.052)	InnerLoop  0.667 ( 0.683)	Loss 1.0189e+00 (1.1625e+00)	Acc@1  58.64 ( 54.04)
The current update step is 240
GPU_0_using curriculum 40 with window 40
Epoch: [8][20/30]	Time  1.540 ( 1.571)	Data  0.039 ( 0.056)	InnerLoop  0.653 ( 0.661)	Loss 8.9459e-01 (1.0745e+00)	Acc@1  62.01 ( 57.68)
The current update step is 270
GPU_0_using curriculum 40 with window 40
Epoch: [9][20/30]	Time  1.546 ( 1.579)	Data  0.038 ( 0.045)	InnerLoop  0.658 ( 0.678)	Loss 8.3160e-01 (1.0033e+00)	Acc@1  67.38 ( 62.38)
The current update step is 300
The current seed is 17880009935684753568
The current lr is: 0.0015
Testing Results:
 *   Acc@1 50.539
 *   Acc@1 50.674
 *   Acc@1 51.066
 *   Acc@1 51.261
 *   Acc@1 50.447
 *   Acc@1 50.596
 *   Acc@1 61.500
 *   Acc@1 61.618
 *   Acc@1 61.368
 *   Acc@1 61.564
 *   Acc@1 61.487
 *   Acc@1 61.767
Training for 300 epoch: 56.01973684210526
Training for 600 epoch: 56.2171052631579
Training for 1000 epoch: 55.96710526315789
Training for 300 epoch: 56.146249999999995
Training for 600 epoch: 56.412499999999994
Training for 1000 epoch: 56.18125
[[56.01973684210526, 56.2171052631579, 55.96710526315789], [56.146249999999995, 56.412499999999994, 56.18125]]
train loss 1.2433456912994385, epoch 9, best loss 1.2433456912994385, best_epoch 9
GPU_0_using curriculum 40 with window 40
Epoch: [10][20/30]	Time  1.630 ( 1.567)	Data  0.156 ( 0.068)	InnerLoop  0.636 ( 0.651)	Loss 8.9558e-01 (9.8376e-01)	Acc@1  63.96 ( 61.23)
The current update step is 330
GPU_0_using curriculum 40 with window 40
Epoch: [11][20/30]	Time  1.648 ( 1.552)	Data  0.037 ( 0.055)	InnerLoop  0.765 ( 0.658)	Loss 1.0459e+00 (9.9537e-01)	Acc@1  53.61 ( 61.60)
The current update step is 360
GPU_0_using curriculum 40 with window 40
Epoch: [12][20/30]	Time  1.525 ( 1.551)	Data  0.035 ( 0.050)	InnerLoop  0.638 ( 0.659)	Loss 1.0069e+00 (9.4901e-01)	Acc@1  65.38 ( 63.23)
The current update step is 390
GPU_0_using curriculum 40 with window 40
Epoch: [13][20/30]	Time  1.523 ( 1.555)	Data  0.038 ( 0.056)	InnerLoop  0.641 ( 0.660)	Loss 1.2076e+00 (9.8222e-01)	Acc@1  51.17 ( 62.25)
The current update step is 420
GPU_0_using curriculum 40 with window 40
Epoch: [14][20/30]	Time  1.523 ( 1.554)	Data  0.037 ( 0.044)	InnerLoop  0.648 ( 0.666)	Loss 8.1327e-01 (1.1678e+00)	Acc@1  71.61 ( 59.21)
The current update step is 450
The current seed is 13146990241563112333
The current lr is: 0.0015
Testing Results:
 *   Acc@1 56.408
 *   Acc@1 56.815
 *   Acc@1 56.395
 *   Acc@1 57.095
 *   Acc@1 57.526
 *   Acc@1 57.729
 *   Acc@1 54.632
 *   Acc@1 54.512
 *   Acc@1 55.237
 *   Acc@1 55.127
 *   Acc@1 55.737
 *   Acc@1 55.521
Training for 300 epoch: 55.51973684210526
Training for 600 epoch: 55.815789473684205
Training for 1000 epoch: 56.631578947368425
Training for 300 epoch: 55.66333333333333
Training for 600 epoch: 56.11125
Training for 1000 epoch: 56.625
[[55.51973684210526, 55.815789473684205, 56.631578947368425], [55.66333333333333, 56.11125, 56.625]]
train loss 1.0154701438903808, epoch 14, best loss 1.0154701438903808, best_epoch 14
GPU_0_using curriculum 40 with window 40
Epoch: [15][20/30]	Time  1.645 ( 1.555)	Data  0.160 ( 0.067)	InnerLoop  0.645 ( 0.651)	Loss 8.6036e-01 (9.4149e-01)	Acc@1  65.70 ( 63.24)
The current update step is 480
GPU_0_using curriculum 40 with window 40
Epoch: [16][20/30]	Time  1.685 ( 1.566)	Data  0.040 ( 0.055)	InnerLoop  0.771 ( 0.663)	Loss 1.1508e+00 (8.8755e-01)	Acc@1  57.79 ( 66.28)
The current update step is 510
GPU_0_using curriculum 40 with window 40
Epoch: [17][20/30]	Time  1.542 ( 1.559)	Data  0.036 ( 0.050)	InnerLoop  0.657 ( 0.664)	Loss 1.1513e+00 (9.4452e-01)	Acc@1  60.79 ( 63.59)
The current update step is 540
GPU_0_using curriculum 40 with window 40
Epoch: [18][20/30]	Time  1.566 ( 1.570)	Data  0.041 ( 0.058)	InnerLoop  0.653 ( 0.664)	Loss 8.1457e-01 (9.5230e-01)	Acc@1  70.58 ( 66.05)
The current update step is 570
GPU_0_using curriculum 40 with window 40
Epoch: [19][20/30]	Time  1.627 ( 1.599)	Data  0.048 ( 0.047)	InnerLoop  0.692 ( 0.688)	Loss 8.6469e-01 (9.0877e-01)	Acc@1  66.24 ( 65.42)
The current update step is 600
The current seed is 11576319569044580147
The current lr is: 0.0015
Testing Results:
 *   Acc@1 69.987
 *   Acc@1 69.927
 *   Acc@1 70.868
 *   Acc@1 70.472
 *   Acc@1 70.961
 *   Acc@1 70.966
 *   Acc@1 73.526
 *   Acc@1 73.926
 *   Acc@1 72.987
 *   Acc@1 73.988
 *   Acc@1 73.645
 *   Acc@1 74.354
Training for 300 epoch: 71.75657894736842
Training for 600 epoch: 71.92763157894737
Training for 1000 epoch: 72.30263157894737
Training for 300 epoch: 71.92666666666666
Training for 600 epoch: 72.22999999999999
Training for 1000 epoch: 72.66
[[71.75657894736842, 71.92763157894737, 72.30263157894737], [71.92666666666666, 72.22999999999999, 72.66]]
train loss 0.6865545042991639, epoch 19, best loss 0.6865545042991639, best_epoch 19
GPU_0_using curriculum 40 with window 40
Epoch: [20][20/30]	Time  1.780 ( 1.699)	Data  0.184 ( 0.081)	InnerLoop  0.703 ( 0.723)	Loss 7.7011e-01 (8.7473e-01)	Acc@1  68.55 ( 68.48)
The current update step is 630
GPU_0_using curriculum 40 with window 40
Epoch: [21][20/30]	Time  1.803 ( 1.700)	Data  0.047 ( 0.067)	InnerLoop  0.865 ( 0.738)	Loss 1.1719e+00 (9.6949e-01)	Acc@1  57.89 ( 64.72)
The current update step is 660
GPU_0_using curriculum 40 with window 40
Epoch: [22][20/30]	Time  1.671 ( 1.666)	Data  0.048 ( 0.058)	InnerLoop  0.726 ( 0.723)	Loss 7.4280e-01 (9.9166e-01)	Acc@1  70.92 ( 60.95)
The current update step is 690
GPU_0_using curriculum 40 with window 40
Epoch: [23][20/30]	Time  1.659 ( 1.684)	Data  0.046 ( 0.067)	InnerLoop  0.717 ( 0.725)	Loss 6.9712e-01 (7.8668e-01)	Acc@1  74.76 ( 69.95)
The current update step is 720
GPU_0_using curriculum 40 with window 40
Epoch: [24][20/30]	Time  1.625 ( 1.670)	Data  0.045 ( 0.053)	InnerLoop  0.703 ( 0.733)	Loss 8.9633e-01 (8.1010e-01)	Acc@1  69.14 ( 70.04)
The current update step is 750
The current seed is 657705887826454674
The current lr is: 0.0015
Testing Results:
 *   Acc@1 58.987
 *   Acc@1 58.973
 *   Acc@1 58.697
 *   Acc@1 58.732
 *   Acc@1 57.579
 *   Acc@1 57.795
 *   Acc@1 73.697
 *   Acc@1 74.162
 *   Acc@1 74.539
 *   Acc@1 74.654
 *   Acc@1 74.671
 *   Acc@1 74.668
Training for 300 epoch: 66.34210526315789
Training for 600 epoch: 66.61842105263158
Training for 1000 epoch: 66.125
Training for 300 epoch: 66.5675
Training for 600 epoch: 66.69291666666666
Training for 1000 epoch: 66.23166666666667
[[66.34210526315789, 66.61842105263158, 66.125], [66.5675, 66.69291666666666, 66.23166666666667]]
train loss 0.6198632555643717, epoch 24, best loss 0.6198632555643717, best_epoch 24
GPU_0_using curriculum 40 with window 40
Epoch: [25][20/30]	Time  1.784 ( 1.652)	Data  0.181 ( 0.078)	InnerLoop  0.697 ( 0.700)	Loss 8.2427e-01 (1.0018e+00)	Acc@1  69.38 ( 66.57)
The current update step is 780
GPU_0_using curriculum 40 with window 40
Epoch: [26][20/30]	Time  1.743 ( 1.678)	Data  0.043 ( 0.066)	InnerLoop  0.830 ( 0.729)	Loss 6.9141e-01 (8.7695e-01)	Acc@1  74.24 ( 67.85)
The current update step is 810
GPU_0_using curriculum 40 with window 40
Epoch: [27][20/30]	Time  1.646 ( 1.675)	Data  0.046 ( 0.059)	InnerLoop  0.713 ( 0.731)	Loss 1.2119e+00 (8.8943e-01)	Acc@1  55.71 ( 67.21)
The current update step is 840
GPU_0_using curriculum 40 with window 40
Epoch: [28][20/30]	Time  1.600 ( 1.656)	Data  0.044 ( 0.066)	InnerLoop  0.688 ( 0.713)	Loss 6.4267e-01 (8.0663e-01)	Acc@1  75.71 ( 69.99)
The current update step is 870
GPU_0_using curriculum 40 with window 40
Epoch: [29][20/30]	Time  1.503 ( 1.557)	Data  0.037 ( 0.046)	InnerLoop  0.638 ( 0.674)	Loss 7.6653e-01 (7.8224e-01)	Acc@1  68.87 ( 70.87)
The current update step is 900
The current seed is 16648862041683981231
The current lr is: 0.0015
Testing Results:
 *   Acc@1 60.579
 *   Acc@1 61.171
 *   Acc@1 60.158
 *   Acc@1 60.647
 *   Acc@1 60.211
 *   Acc@1 60.841
 *   Acc@1 47.566
 *   Acc@1 47.564
 *   Acc@1 48.211
 *   Acc@1 47.940
 *   Acc@1 47.789
 *   Acc@1 48.248
Training for 300 epoch: 54.07236842105263
Training for 600 epoch: 54.18421052631579
Training for 1000 epoch: 54.0
Training for 300 epoch: 54.3675
Training for 600 epoch: 54.29333333333334
Training for 1000 epoch: 54.54416666666667
[[54.07236842105263, 54.18421052631579, 54.0], [54.3675, 54.29333333333334, 54.54416666666667]]
train loss 1.2564837834676106, epoch 29, best loss 0.6198632555643717, best_epoch 24
GPU_0_using curriculum 40 with window 40
Epoch: [30][20/30]	Time  1.614 ( 1.559)	Data  0.154 ( 0.068)	InnerLoop  0.629 ( 0.651)	Loss 7.2518e-01 (8.7137e-01)	Acc@1  71.39 ( 67.77)
The current update step is 930
GPU_0_using curriculum 40 with window 40
Epoch: [31][20/30]	Time  1.686 ( 1.583)	Data  0.042 ( 0.059)	InnerLoop  0.791 ( 0.677)	Loss 6.7816e-01 (8.0866e-01)	Acc@1  76.49 ( 70.48)
The current update step is 960
GPU_0_using curriculum 40 with window 40
Epoch: [32][20/30]	Time  1.547 ( 1.566)	Data  0.039 ( 0.051)	InnerLoop  0.656 ( 0.668)	Loss 6.5775e-01 (7.7947e-01)	Acc@1  77.22 ( 71.10)
The current update step is 990
GPU_0_using curriculum 40 with window 40
Epoch: [33][20/30]	Time  1.531 ( 1.598)	Data  0.040 ( 0.061)	InnerLoop  0.650 ( 0.679)	Loss 6.3633e-01 (8.1989e-01)	Acc@1  76.29 ( 70.55)
The current update step is 1020
GPU_0_using curriculum 40 with window 40
Epoch: [34][20/30]	Time  1.628 ( 1.634)	Data  0.047 ( 0.050)	InnerLoop  0.702 ( 0.710)	Loss 7.0829e-01 (8.0573e-01)	Acc@1  74.07 ( 71.65)
The current update step is 1050
The current seed is 10342193876395275401
The current lr is: 0.0015
Testing Results:
 *   Acc@1 72.092
 *   Acc@1 72.250
 *   Acc@1 71.303
 *   Acc@1 72.000
 *   Acc@1 71.539
 *   Acc@1 71.767
 *   Acc@1 71.579
 *   Acc@1 71.477
 *   Acc@1 71.553
 *   Acc@1 71.882
 *   Acc@1 71.579
 *   Acc@1 71.923
Training for 300 epoch: 71.83552631578948
Training for 600 epoch: 71.42763157894737
Training for 1000 epoch: 71.55921052631578
Training for 300 epoch: 71.86333333333334
Training for 600 epoch: 71.94125
Training for 1000 epoch: 71.845
[[71.83552631578948, 71.42763157894737, 71.55921052631578], [71.86333333333334, 71.94125, 71.845]]
train loss 0.6074704151471456, epoch 34, best loss 0.6074704151471456, best_epoch 34
GPU_0_using curriculum 40 with window 40
Epoch: [35][20/30]	Time  1.740 ( 1.656)	Data  0.177 ( 0.077)	InnerLoop  0.690 ( 0.700)	Loss 7.0938e-01 (7.4001e-01)	Acc@1  73.54 ( 73.56)
The current update step is 1080
GPU_0_using curriculum 40 with window 40
Epoch: [36][20/30]	Time  1.784 ( 1.657)	Data  0.046 ( 0.065)	InnerLoop  0.854 ( 0.716)	Loss 5.9859e-01 (8.0158e-01)	Acc@1  78.03 ( 70.82)
The current update step is 1110
GPU_0_using curriculum 40 with window 40
Epoch: [37][20/30]	Time  1.649 ( 1.623)	Data  0.047 ( 0.056)	InnerLoop  0.707 ( 0.700)	Loss 8.2867e-01 (8.4451e-01)	Acc@1  71.51 ( 69.57)
The current update step is 1140
GPU_0_using curriculum 40 with window 40
Epoch: [38][20/30]	Time  1.562 ( 1.630)	Data  0.041 ( 0.064)	InnerLoop  0.657 ( 0.698)	Loss 7.3871e-01 (8.1715e-01)	Acc@1  74.27 ( 71.45)
The current update step is 1170
GPU_0_using curriculum 40 with window 40
Epoch: [39][20/30]	Time  1.606 ( 1.645)	Data  0.046 ( 0.050)	InnerLoop  0.691 ( 0.720)	Loss 7.1366e-01 (7.6796e-01)	Acc@1  70.83 ( 71.14)
The current update step is 1200
The current seed is 2904804431692200876
The current lr is: 0.0015
Testing Results:
 *   Acc@1 66.013
 *   Acc@1 66.015
 *   Acc@1 66.066
 *   Acc@1 65.869
 *   Acc@1 66.039
 *   Acc@1 65.802
 *   Acc@1 53.763
 *   Acc@1 53.857
 *   Acc@1 53.868
 *   Acc@1 53.981
 *   Acc@1 53.934
 *   Acc@1 53.786
Training for 300 epoch: 59.888157894736835
Training for 600 epoch: 59.96710526315789
Training for 1000 epoch: 59.98684210526315
Training for 300 epoch: 59.935833333333335
Training for 600 epoch: 59.925000000000004
Training for 1000 epoch: 59.79416666666667
[[59.888157894736835, 59.96710526315789, 59.98684210526315], [59.935833333333335, 59.925000000000004, 59.79416666666667]]
train loss 1.7005077349980673, epoch 39, best loss 0.6074704151471456, best_epoch 34
GPU_0_using curriculum 40 with window 40
Epoch: [40][20/30]	Time  1.696 ( 1.644)	Data  0.176 ( 0.077)	InnerLoop  0.668 ( 0.697)	Loss 6.4654e-01 (6.7890e-01)	Acc@1  78.30 ( 75.65)
The current update step is 1230
GPU_0_using curriculum 40 with window 40
Epoch: [41][20/30]	Time  1.742 ( 1.654)	Data  0.046 ( 0.065)	InnerLoop  0.821 ( 0.713)	Loss 7.6378e-01 (7.2092e-01)	Acc@1  71.95 ( 74.73)
The current update step is 1260
GPU_0_using curriculum 40 with window 40
Epoch: [42][20/30]	Time  1.603 ( 1.620)	Data  0.046 ( 0.057)	InnerLoop  0.687 ( 0.696)	Loss 5.8620e-01 (7.3679e-01)	Acc@1  79.08 ( 73.58)
The current update step is 1290
GPU_0_using curriculum 40 with window 40
Epoch: [43][20/30]	Time  1.554 ( 1.627)	Data  0.041 ( 0.064)	InnerLoop  0.663 ( 0.696)	Loss 6.7889e-01 (7.8427e-01)	Acc@1  75.29 ( 71.98)
The current update step is 1320
GPU_0_using curriculum 40 with window 40
Epoch: [44][20/30]	Time  1.602 ( 1.646)	Data  0.046 ( 0.052)	InnerLoop  0.691 ( 0.719)	Loss 1.0914e+00 (7.1527e-01)	Acc@1  62.77 ( 74.44)
The current update step is 1350
The current seed is 10445878352166354526
The current lr is: 0.0015
Testing Results:
 *   Acc@1 68.118
 *   Acc@1 68.644
 *   Acc@1 68.145
 *   Acc@1 68.448
 *   Acc@1 67.566
 *   Acc@1 67.970
 *   Acc@1 68.684
 *   Acc@1 69.232
 *   Acc@1 69.947
 *   Acc@1 69.841
 *   Acc@1 70.592
 *   Acc@1 70.218
Training for 300 epoch: 68.40131578947368
Training for 600 epoch: 69.04605263157895
Training for 1000 epoch: 69.07894736842104
Training for 300 epoch: 68.93791666666667
Training for 600 epoch: 69.14458333333334
Training for 1000 epoch: 69.09416666666667
[[68.40131578947368, 69.04605263157895, 69.07894736842104], [68.93791666666667, 69.14458333333334, 69.09416666666667]]
train loss 0.6357869963328043, epoch 44, best loss 0.6074704151471456, best_epoch 34
GPU_0_using curriculum 40 with window 40
Epoch: [45][20/30]	Time  1.767 ( 1.652)	Data  0.181 ( 0.078)	InnerLoop  0.690 ( 0.697)	Loss 7.1154e-01 (7.0090e-01)	Acc@1  75.61 ( 75.34)
The current update step is 1380
GPU_0_using curriculum 40 with window 40
Epoch: [46][20/30]	Time  1.671 ( 1.637)	Data  0.038 ( 0.064)	InnerLoop  0.784 ( 0.704)	Loss 6.4282e-01 (6.9343e-01)	Acc@1  80.35 ( 75.59)
The current update step is 1410
GPU_0_using curriculum 40 with window 40
Epoch: [47][20/30]	Time  1.646 ( 1.650)	Data  0.050 ( 0.058)	InnerLoop  0.705 ( 0.712)	Loss 6.9520e-01 (7.1651e-01)	Acc@1  77.08 ( 74.65)
The current update step is 1440
GPU_0_using curriculum 40 with window 40
Epoch: [48][20/30]	Time  1.655 ( 1.698)	Data  0.045 ( 0.066)	InnerLoop  0.703 ( 0.720)	Loss 6.8785e-01 (7.6961e-01)	Acc@1  75.46 ( 73.09)
The current update step is 1470
GPU_0_using curriculum 40 with window 40
Epoch: [49][20/30]	Time  1.625 ( 1.674)	Data  0.051 ( 0.054)	InnerLoop  0.693 ( 0.734)	Loss 7.7634e-01 (6.7105e-01)	Acc@1  70.92 ( 76.24)
The current update step is 1500
The current seed is 5217256308477103579
The current lr is: 0.0015
Testing Results:
 *   Acc@1 75.276
 *   Acc@1 75.947
 *   Acc@1 75.026
 *   Acc@1 76.035
 *   Acc@1 75.118
 *   Acc@1 76.076
 *   Acc@1 74.974
 *   Acc@1 75.253
 *   Acc@1 75.053
 *   Acc@1 75.088
 *   Acc@1 74.474
 *   Acc@1 74.929
Training for 300 epoch: 75.125
Training for 600 epoch: 75.03947368421052
Training for 1000 epoch: 74.79605263157895
Training for 300 epoch: 75.6
Training for 600 epoch: 75.56125
Training for 1000 epoch: 75.5025
[[75.125, 75.03947368421052, 74.79605263157895], [75.6, 75.56125, 75.5025]]
train loss 0.5923313861211141, epoch 49, best loss 0.5923313861211141, best_epoch 49
GPU_0_using curriculum 40 with window 40
Epoch: [50][20/30]	Time  1.767 ( 1.672)	Data  0.180 ( 0.079)	InnerLoop  0.693 ( 0.707)	Loss 5.5648e-01 (6.3589e-01)	Acc@1  81.25 ( 77.83)
The current update step is 1530
GPU_0_using curriculum 40 with window 40
Epoch: [51][20/30]	Time  1.644 ( 1.667)	Data  0.047 ( 0.065)	InnerLoop  0.704 ( 0.716)	Loss 8.4650e-01 (6.9074e-01)	Acc@1  71.44 ( 76.13)
The current update step is 1560
GPU_0_using curriculum 40 with window 40
Epoch: [52][20/30]	Time  1.640 ( 1.650)	Data  0.046 ( 0.079)	InnerLoop  0.699 ( 0.693)	Loss 1.0114e+00 (7.0669e-01)	Acc@1  66.21 ( 75.62)
The current update step is 1590
GPU_0_using curriculum 40 with window 40
Epoch: [53][20/30]	Time  1.497 ( 1.548)	Data  0.039 ( 0.058)	InnerLoop  0.631 ( 0.655)	Loss 6.9913e-01 (6.8969e-01)	Acc@1  73.05 ( 76.44)
The current update step is 1620
GPU_0_using curriculum 40 with window 40
Epoch: [54][20/30]	Time  1.667 ( 1.576)	Data  0.167 ( 0.072)	InnerLoop  0.647 ( 0.658)	Loss 5.3449e-01 (6.9632e-01)	Acc@1  80.81 ( 75.46)
The current update step is 1650
The current seed is 13845139729385407563
The current lr is: 0.0015
Testing Results:
 *   Acc@1 56.697
 *   Acc@1 58.123
 *   Acc@1 56.908
 *   Acc@1 57.966
 *   Acc@1 56.855
 *   Acc@1 57.991
 *   Acc@1 70.684
 *   Acc@1 70.999
 *   Acc@1 70.342
 *   Acc@1 71.129
 *   Acc@1 70.697
 *   Acc@1 71.202
Training for 300 epoch: 63.69078947368421
Training for 600 epoch: 63.625
Training for 1000 epoch: 63.776315789473685
Training for 300 epoch: 64.56083333333333
Training for 600 epoch: 64.5475
Training for 1000 epoch: 64.59625
[[63.69078947368421, 63.625, 63.776315789473685], [64.56083333333333, 64.5475, 64.59625]]
train loss 0.8457856717427572, epoch 54, best loss 0.5923313861211141, best_epoch 49
GPU_0_using curriculum 40 with window 40
Epoch: [55][20/30]	Time  1.533 ( 1.573)	Data  0.041 ( 0.052)	InnerLoop  0.657 ( 0.674)	Loss 5.6690e-01 (6.6989e-01)	Acc@1  79.86 ( 75.89)
The current update step is 1680
GPU_0_using curriculum 40 with window 40
Epoch: [56][20/30]	Time  1.662 ( 1.572)	Data  0.164 ( 0.070)	InnerLoop  0.646 ( 0.656)	Loss 7.2247e-01 (7.0845e-01)	Acc@1  75.34 ( 75.86)
The current update step is 1710
GPU_0_using curriculum 40 with window 40
Epoch: [57][20/30]	Time  1.531 ( 1.542)	Data  0.042 ( 0.056)	InnerLoop  0.642 ( 0.649)	Loss 6.3631e-01 (7.1586e-01)	Acc@1  76.10 ( 74.68)
The current update step is 1740
GPU_0_using curriculum 40 with window 40
Epoch: [58][20/30]	Time  1.490 ( 1.568)	Data  0.038 ( 0.047)	InnerLoop  0.625 ( 0.677)	Loss 5.9620e-01 (7.2848e-01)	Acc@1  78.56 ( 73.65)
The current update step is 1770
GPU_0_using curriculum 40 with window 40
Epoch: [59][20/30]	Time  1.547 ( 1.570)	Data  0.040 ( 0.070)	InnerLoop  0.656 ( 0.651)	Loss 6.0772e-01 (6.8840e-01)	Acc@1  78.71 ( 75.22)
The current update step is 1800
The current seed is 3765678004914951304
The current lr is: 0.0015
Testing Results:
 *   Acc@1 74.276
 *   Acc@1 75.418
 *   Acc@1 73.447
 *   Acc@1 74.448
 *   Acc@1 73.592
 *   Acc@1 74.491
 *   Acc@1 61.987
 *   Acc@1 63.153
 *   Acc@1 62.553
 *   Acc@1 62.864
 *   Acc@1 61.724
 *   Acc@1 62.350
Training for 300 epoch: 68.13157894736842
Training for 600 epoch: 68.0
Training for 1000 epoch: 67.65789473684211
Training for 300 epoch: 69.28541666666666
Training for 600 epoch: 68.65625
Training for 1000 epoch: 68.42041666666667
[[68.13157894736842, 68.0, 67.65789473684211], [69.28541666666666, 68.65625, 68.42041666666667]]
train loss 1.0329310033162435, epoch 59, best loss 0.5923313861211141, best_epoch 49
GPU_0_using curriculum 40 with window 40
Epoch: [60][20/30]	Time  1.676 ( 1.577)	Data  0.170 ( 0.071)	InnerLoop  0.650 ( 0.660)	Loss 6.0819e-01 (6.9705e-01)	Acc@1  80.10 ( 75.19)
The current update step is 1830
GPU_0_using curriculum 40 with window 40
Epoch: [61][20/30]	Time  1.548 ( 1.549)	Data  0.041 ( 0.057)	InnerLoop  0.652 ( 0.655)	Loss 5.8468e-01 (6.9737e-01)	Acc@1  79.57 ( 75.26)
The current update step is 1860
GPU_0_using curriculum 40 with window 40
Epoch: [62][20/30]	Time  1.497 ( 1.550)	Data  0.038 ( 0.069)	InnerLoop  0.632 ( 0.643)	Loss 6.1574e-01 (6.9815e-01)	Acc@1  79.61 ( 75.69)
The current update step is 1890
GPU_0_using curriculum 40 with window 40
Epoch: [63][20/30]	Time  1.537 ( 1.573)	Data  0.041 ( 0.059)	InnerLoop  0.649 ( 0.666)	Loss 5.8003e-01 (6.9700e-01)	Acc@1  79.30 ( 74.35)
The current update step is 1920
GPU_0_using curriculum 40 with window 40
Epoch: [64][20/30]	Time  1.671 ( 1.554)	Data  0.168 ( 0.069)	InnerLoop  0.652 ( 0.645)	Loss 1.1333e+00 (6.8616e-01)	Acc@1  63.92 ( 75.84)
The current update step is 1950
The current seed is 6979702855820852217
The current lr is: 0.0015
Testing Results:
 *   Acc@1 69.579
 *   Acc@1 69.569
 *   Acc@1 69.737
 *   Acc@1 69.790
 *   Acc@1 69.882
 *   Acc@1 69.913
 *   Acc@1 59.961
 *   Acc@1 59.382
 *   Acc@1 59.553
 *   Acc@1 59.508
 *   Acc@1 59.171
 *   Acc@1 58.930
Training for 300 epoch: 64.76973684210526
Training for 600 epoch: 64.64473684210526
Training for 1000 epoch: 64.52631578947368
Training for 300 epoch: 64.47541666666666
Training for 600 epoch: 64.64916666666667
Training for 1000 epoch: 64.42166666666667
[[64.76973684210526, 64.64473684210526, 64.52631578947368], [64.47541666666666, 64.64916666666667, 64.42166666666667]]
train loss 1.2655827946980793, epoch 64, best loss 0.5923313861211141, best_epoch 49
GPU_0_using curriculum 40 with window 40
Epoch: [65][20/30]	Time  1.534 ( 1.555)	Data  0.037 ( 0.052)	InnerLoop  0.654 ( 0.657)	Loss 5.5803e-01 (6.8932e-01)	Acc@1  79.57 ( 75.35)
The current update step is 1980
GPU_0_using curriculum 40 with window 40
Epoch: [66][20/30]	Time  1.653 ( 1.558)	Data  0.157 ( 0.070)	InnerLoop  0.626 ( 0.647)	Loss 6.8500e-01 (7.1283e-01)	Acc@1  74.49 ( 72.53)
The current update step is 2010
GPU_0_using curriculum 40 with window 40
Epoch: [67][20/30]	Time  1.568 ( 1.580)	Data  0.042 ( 0.059)	InnerLoop  0.673 ( 0.665)	Loss 6.8791e-01 (6.7280e-01)	Acc@1  74.76 ( 75.60)
The current update step is 2040
GPU_0_using curriculum 40 with window 40
Epoch: [68][20/30]	Time  1.554 ( 1.569)	Data  0.037 ( 0.045)	InnerLoop  0.651 ( 0.667)	Loss 6.6975e-01 (6.7777e-01)	Acc@1  75.76 ( 75.51)
The current update step is 2070
GPU_0_using curriculum 40 with window 40
Epoch: [69][20/30]	Time  1.534 ( 1.555)	Data  0.041 ( 0.069)	InnerLoop  0.646 ( 0.641)	Loss 6.5426e-01 (6.7010e-01)	Acc@1  77.10 ( 76.53)
The current update step is 2100
The current seed is 3135899544102862428
The current lr is: 0.0015
Testing Results:
 *   Acc@1 45.526
 *   Acc@1 45.432
 *   Acc@1 47.816
 *   Acc@1 47.292
 *   Acc@1 48.158
 *   Acc@1 48.243
 *   Acc@1 67.132
 *   Acc@1 67.129
 *   Acc@1 66.079
 *   Acc@1 66.406
 *   Acc@1 66.197
 *   Acc@1 66.275
Training for 300 epoch: 56.328947368421055
Training for 600 epoch: 56.94736842105263
Training for 1000 epoch: 57.17763157894737
Training for 300 epoch: 56.280833333333334
Training for 600 epoch: 56.848749999999995
Training for 1000 epoch: 57.25916666666667
[[56.328947368421055, 56.94736842105263, 57.17763157894737], [56.280833333333334, 56.848749999999995, 57.25916666666667]]
train loss 0.8316774588902791, epoch 69, best loss 0.5923313861211141, best_epoch 49
GPU_0_using curriculum 40 with window 40
Epoch: [70][20/30]	Time  1.674 ( 1.566)	Data  0.166 ( 0.072)	InnerLoop  0.647 ( 0.652)	Loss 5.9420e-01 (6.9759e-01)	Acc@1  79.20 ( 74.95)
The current update step is 2130
GPU_0_using curriculum 40 with window 40
Epoch: [71][20/30]	Time  1.492 ( 1.564)	Data  0.034 ( 0.059)	InnerLoop  0.625 ( 0.660)	Loss 8.1634e-01 (6.7548e-01)	Acc@1  71.34 ( 75.66)
The current update step is 2160
GPU_0_using curriculum 40 with window 40
Epoch: [72][20/30]	Time  1.576 ( 1.571)	Data  0.042 ( 0.073)	InnerLoop  0.652 ( 0.651)	Loss 7.7415e-01 (7.4866e-01)	Acc@1  71.95 ( 73.43)
The current update step is 2190
GPU_0_using curriculum 40 with window 40
Epoch: [73][20/30]	Time  1.542 ( 1.564)	Data  0.041 ( 0.059)	InnerLoop  0.649 ( 0.659)	Loss 5.8630e-01 (6.3656e-01)	Acc@1  80.71 ( 77.56)
The current update step is 2220
GPU_0_using curriculum 40 with window 40
Epoch: [74][20/30]	Time  1.671 ( 1.560)	Data  0.164 ( 0.070)	InnerLoop  0.648 ( 0.648)	Loss 6.2677e-01 (7.3515e-01)	Acc@1  78.39 ( 74.01)
The current update step is 2250
The current seed is 9087862629955566884
The current lr is: 0.0015
Testing Results:
 *   Acc@1 74.382
 *   Acc@1 74.211
 *   Acc@1 73.711
 *   Acc@1 73.657
 *   Acc@1 73.671
 *   Acc@1 73.603
 *   Acc@1 71.539
 *   Acc@1 71.467
 *   Acc@1 70.276
 *   Acc@1 70.542
 *   Acc@1 69.711
 *   Acc@1 69.926
Training for 300 epoch: 72.96052631578948
Training for 600 epoch: 71.99342105263159
Training for 1000 epoch: 71.69078947368422
Training for 300 epoch: 72.83875
Training for 600 epoch: 72.09958333333333
Training for 1000 epoch: 71.76458333333333
[[72.96052631578948, 71.99342105263159, 71.69078947368422], [72.83875, 72.09958333333333, 71.76458333333333]]
train loss 0.5973546017646789, epoch 74, best loss 0.5923313861211141, best_epoch 49
GPU_0_using curriculum 40 with window 40
Epoch: [75][20/30]	Time  1.533 ( 1.541)	Data  0.044 ( 0.051)	InnerLoop  0.647 ( 0.656)	Loss 7.5393e-01 (6.7646e-01)	Acc@1  79.79 ( 75.65)
The current update step is 2280
GPU_0_using curriculum 40 with window 40
Epoch: [76][20/30]	Time  1.620 ( 1.567)	Data  0.152 ( 0.071)	InnerLoop  0.636 ( 0.654)	Loss 5.8541e-01 (6.4783e-01)	Acc@1  79.66 ( 77.48)
The current update step is 2310
GPU_0_using curriculum 40 with window 40
Epoch: [77][20/30]	Time  1.555 ( 1.571)	Data  0.044 ( 0.060)	InnerLoop  0.657 ( 0.663)	Loss 5.7805e-01 (6.7142e-01)	Acc@1  80.86 ( 76.02)
The current update step is 2340
GPU_0_using curriculum 40 with window 40
Epoch: [78][20/30]	Time  1.556 ( 1.544)	Data  0.040 ( 0.045)	InnerLoop  0.657 ( 0.663)	Loss 5.6755e-01 (6.2176e-01)	Acc@1  80.86 ( 78.18)
The current update step is 2370
GPU_0_using curriculum 40 with window 40
Epoch: [79][20/30]	Time  1.496 ( 1.554)	Data  0.036 ( 0.071)	InnerLoop  0.633 ( 0.646)	Loss 7.1802e-01 (6.9843e-01)	Acc@1  76.81 ( 75.40)
The current update step is 2400
The current seed is 11912433260588089685
The current lr is: 0.0015
Testing Results:
 *   Acc@1 76.395
 *   Acc@1 77.013
 *   Acc@1 75.987
 *   Acc@1 76.642
 *   Acc@1 76.303
 *   Acc@1 76.839
 *   Acc@1 75.079
 *   Acc@1 74.838
 *   Acc@1 74.276
 *   Acc@1 73.919
 *   Acc@1 73.961
 *   Acc@1 73.790
Training for 300 epoch: 75.73684210526315
Training for 600 epoch: 75.13157894736842
Training for 1000 epoch: 75.13157894736842
Training for 300 epoch: 75.92500000000001
Training for 600 epoch: 75.28041666666667
Training for 1000 epoch: 75.31458333333333
[[75.73684210526315, 75.13157894736842, 75.13157894736842], [75.92500000000001, 75.28041666666667, 75.31458333333333]]
train loss 0.5472409844557444, epoch 79, best loss 0.5472409844557444, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [80][20/30]	Time  1.626 ( 1.549)	Data  0.155 ( 0.069)	InnerLoop  0.632 ( 0.644)	Loss 6.7876e-01 (6.4860e-01)	Acc@1  75.95 ( 76.76)
The current update step is 2430
GPU_0_using curriculum 40 with window 40
Epoch: [81][20/30]	Time  1.555 ( 1.570)	Data  0.040 ( 0.059)	InnerLoop  0.659 ( 0.666)	Loss 6.7341e-01 (6.8094e-01)	Acc@1  76.17 ( 76.17)
The current update step is 2460
GPU_0_using curriculum 40 with window 40
Epoch: [82][20/30]	Time  1.562 ( 1.566)	Data  0.044 ( 0.072)	InnerLoop  0.667 ( 0.652)	Loss 5.5502e-01 (6.8043e-01)	Acc@1  79.57 ( 75.92)
The current update step is 2490
GPU_0_using curriculum 40 with window 40
Epoch: [83][20/30]	Time  1.535 ( 1.551)	Data  0.042 ( 0.057)	InnerLoop  0.645 ( 0.653)	Loss 7.2969e-01 (6.6360e-01)	Acc@1  74.12 ( 75.98)
The current update step is 2520
GPU_0_using curriculum 40 with window 40
Epoch: [84][20/30]	Time  1.608 ( 1.566)	Data  0.150 ( 0.070)	InnerLoop  0.634 ( 0.655)	Loss 5.8017e-01 (6.1640e-01)	Acc@1  80.47 ( 78.30)
The current update step is 2550
The current seed is 5427006493172159873
The current lr is: 0.0015
Testing Results:
 *   Acc@1 74.211
 *   Acc@1 74.368
 *   Acc@1 73.618
 *   Acc@1 73.877
 *   Acc@1 73.447
 *   Acc@1 73.627
 *   Acc@1 72.947
 *   Acc@1 73.411
 *   Acc@1 72.250
 *   Acc@1 72.826
 *   Acc@1 72.158
 *   Acc@1 72.543
Training for 300 epoch: 73.57894736842105
Training for 600 epoch: 72.93421052631578
Training for 1000 epoch: 72.80263157894737
Training for 300 epoch: 73.88958333333333
Training for 600 epoch: 73.35125
Training for 1000 epoch: 73.08541666666667
[[73.57894736842105, 72.93421052631578, 72.80263157894737], [73.88958333333333, 73.35125, 73.08541666666667]]
train loss 0.6318011664390564, epoch 84, best loss 0.5472409844557444, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [85][20/30]	Time  1.500 ( 1.552)	Data  0.035 ( 0.051)	InnerLoop  0.636 ( 0.661)	Loss 6.4896e-01 (6.6357e-01)	Acc@1  76.07 ( 76.26)
The current update step is 2580
GPU_0_using curriculum 40 with window 40
Epoch: [86][20/30]	Time  1.661 ( 1.578)	Data  0.164 ( 0.071)	InnerLoop  0.649 ( 0.660)	Loss 1.0631e+00 (7.4527e-01)	Acc@1  62.40 ( 74.32)
The current update step is 2610
GPU_0_using curriculum 40 with window 40
Epoch: [87][20/30]	Time  1.533 ( 1.560)	Data  0.041 ( 0.058)	InnerLoop  0.643 ( 0.658)	Loss 6.2376e-01 (6.8461e-01)	Acc@1  77.78 ( 75.27)
The current update step is 2640
GPU_0_using curriculum 40 with window 40
Epoch: [88][20/30]	Time  1.544 ( 1.550)	Data  0.041 ( 0.044)	InnerLoop  0.662 ( 0.667)	Loss 7.4446e-01 (6.8415e-01)	Acc@1  69.58 ( 74.95)
The current update step is 2670
GPU_0_using curriculum 40 with window 40
Epoch: [89][20/30]	Time  1.490 ( 1.564)	Data  0.036 ( 0.070)	InnerLoop  0.625 ( 0.648)	Loss 6.6210e-01 (6.5515e-01)	Acc@1  76.61 ( 77.60)
The current update step is 2700
The current seed is 15988499265344756644
The current lr is: 0.0015
Testing Results:
 *   Acc@1 55.855
 *   Acc@1 55.633
 *   Acc@1 55.618
 *   Acc@1 55.450
 *   Acc@1 54.934
 *   Acc@1 55.331
 *   Acc@1 64.671
 *   Acc@1 64.424
 *   Acc@1 62.671
 *   Acc@1 62.740
 *   Acc@1 61.276
 *   Acc@1 61.364
Training for 300 epoch: 60.26315789473684
Training for 600 epoch: 59.14473684210526
Training for 1000 epoch: 58.10526315789474
Training for 300 epoch: 60.02875
Training for 600 epoch: 59.095
Training for 1000 epoch: 58.3475
[[60.26315789473684, 59.14473684210526, 58.10526315789474], [60.02875, 59.095, 58.3475]]
train loss 1.0037028768539429, epoch 89, best loss 0.5472409844557444, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [90][20/30]	Time  1.616 ( 1.563)	Data  0.156 ( 0.070)	InnerLoop  0.629 ( 0.652)	Loss 8.4890e-01 (7.1883e-01)	Acc@1  71.75 ( 73.99)
The current update step is 2730
GPU_0_using curriculum 40 with window 40
Epoch: [91][20/30]	Time  1.529 ( 1.568)	Data  0.043 ( 0.059)	InnerLoop  0.643 ( 0.662)	Loss 7.7997e-01 (7.2548e-01)	Acc@1  71.14 ( 74.62)
The current update step is 2760
GPU_0_using curriculum 40 with window 40
Epoch: [92][20/30]	Time  1.542 ( 1.555)	Data  0.038 ( 0.071)	InnerLoop  0.652 ( 0.646)	Loss 1.0059e+00 (6.8924e-01)	Acc@1  64.43 ( 74.92)
The current update step is 2790
GPU_0_using curriculum 40 with window 40
Epoch: [93][20/30]	Time  1.504 ( 1.548)	Data  0.038 ( 0.057)	InnerLoop  0.633 ( 0.653)	Loss 7.2231e-01 (7.9557e-01)	Acc@1  72.83 ( 71.29)
The current update step is 2820
GPU_0_using curriculum 40 with window 40
Epoch: [94][20/30]	Time  1.658 ( 1.577)	Data  0.167 ( 0.072)	InnerLoop  0.648 ( 0.660)	Loss 7.3434e-01 (7.0784e-01)	Acc@1  71.95 ( 74.73)
The current update step is 2850
The current seed is 7823097346685657949
The current lr is: 0.0015
Testing Results:
 *   Acc@1 71.382
 *   Acc@1 71.672
 *   Acc@1 70.961
 *   Acc@1 71.491
 *   Acc@1 71.829
 *   Acc@1 71.693
 *   Acc@1 67.882
 *   Acc@1 68.793
 *   Acc@1 67.211
 *   Acc@1 67.818
 *   Acc@1 67.474
 *   Acc@1 67.920
Training for 300 epoch: 69.63157894736842
Training for 600 epoch: 69.08552631578948
Training for 1000 epoch: 69.65131578947368
Training for 300 epoch: 70.23291666666667
Training for 600 epoch: 69.65458333333333
Training for 1000 epoch: 69.80666666666667
[[69.63157894736842, 69.08552631578948, 69.65131578947368], [70.23291666666667, 69.65458333333333, 69.80666666666667]]
train loss 0.7631074372927348, epoch 94, best loss 0.5472409844557444, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [95][20/30]	Time  1.529 ( 1.574)	Data  0.042 ( 0.054)	InnerLoop  0.640 ( 0.674)	Loss 7.4104e-01 (6.5875e-01)	Acc@1  70.17 ( 76.77)
The current update step is 2880
GPU_0_using curriculum 40 with window 40
Epoch: [96][20/30]	Time  1.650 ( 1.563)	Data  0.161 ( 0.070)	InnerLoop  0.652 ( 0.649)	Loss 7.9097e-01 (6.6444e-01)	Acc@1  71.04 ( 75.59)
The current update step is 2910
GPU_0_using curriculum 40 with window 40
Epoch: [97][20/30]	Time  1.566 ( 1.549)	Data  0.038 ( 0.057)	InnerLoop  0.662 ( 0.651)	Loss 7.6554e-01 (6.3047e-01)	Acc@1  73.32 ( 77.74)
The current update step is 2940
GPU_0_using curriculum 40 with window 40
Epoch: [98][20/30]	Time  1.499 ( 1.556)	Data  0.039 ( 0.046)	InnerLoop  0.630 ( 0.671)	Loss 5.6650e-01 (6.3611e-01)	Acc@1  80.54 ( 77.68)
The current update step is 2970
GPU_0_using curriculum 40 with window 40
Epoch: [99][20/30]	Time  1.527 ( 1.566)	Data  0.038 ( 0.070)	InnerLoop  0.642 ( 0.650)	Loss 6.4723e-01 (6.0593e-01)	Acc@1  77.12 ( 78.93)
The current update step is 3000
The current seed is 3202513293110632356
The current lr is: 0.0015
Testing Results:
 *   Acc@1 72.803
 *   Acc@1 72.610
 *   Acc@1 72.645
 *   Acc@1 72.552
 *   Acc@1 72.750
 *   Acc@1 72.372
 *   Acc@1 72.566
 *   Acc@1 72.562
 *   Acc@1 72.276
 *   Acc@1 72.321
 *   Acc@1 71.987
 *   Acc@1 71.820
Training for 300 epoch: 72.68421052631578
Training for 600 epoch: 72.46052631578948
Training for 1000 epoch: 72.36842105263159
Training for 300 epoch: 72.58625
Training for 600 epoch: 72.43666666666667
Training for 1000 epoch: 72.09583333333333
[[72.68421052631578, 72.46052631578948, 72.36842105263159], [72.58625, 72.43666666666667, 72.09583333333333]]
train loss 0.8454540649731954, epoch 99, best loss 0.5472409844557444, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [100][20/30]	Time  1.658 ( 1.574)	Data  0.162 ( 0.070)	InnerLoop  0.657 ( 0.656)	Loss 4.7068e-01 (5.9105e-01)	Acc@1  83.84 ( 78.95)
The current update step is 3030
GPU_0_using curriculum 40 with window 40
Epoch: [101][20/30]	Time  1.560 ( 1.560)	Data  0.040 ( 0.056)	InnerLoop  0.670 ( 0.661)	Loss 6.2682e-01 (6.6747e-01)	Acc@1  76.27 ( 76.69)
The current update step is 3060
GPU_0_using curriculum 40 with window 40
Epoch: [102][20/30]	Time  1.503 ( 1.540)	Data  0.037 ( 0.067)	InnerLoop  0.639 ( 0.641)	Loss 5.9169e-01 (6.6209e-01)	Acc@1  77.83 ( 75.78)
The current update step is 3090
GPU_0_using curriculum 40 with window 40
Epoch: [103][20/30]	Time  1.554 ( 1.569)	Data  0.041 ( 0.059)	InnerLoop  0.671 ( 0.665)	Loss 6.5823e-01 (6.4268e-01)	Acc@1  77.76 ( 77.49)
The current update step is 3120
GPU_0_using curriculum 40 with window 40
Epoch: [104][20/30]	Time  1.663 ( 1.567)	Data  0.169 ( 0.070)	InnerLoop  0.655 ( 0.655)	Loss 9.0610e-01 (7.0274e-01)	Acc@1  68.99 ( 75.28)
The current update step is 3150
The current seed is 8518096520963481463
The current lr is: 0.0015
Testing Results:
 *   Acc@1 74.908
 *   Acc@1 75.265
 *   Acc@1 73.855
 *   Acc@1 74.072
 *   Acc@1 72.684
 *   Acc@1 73.095
 *   Acc@1 59.671
 *   Acc@1 60.191
 *   Acc@1 59.671
 *   Acc@1 60.201
 *   Acc@1 59.803
 *   Acc@1 60.339
Training for 300 epoch: 67.28947368421052
Training for 600 epoch: 66.76315789473685
Training for 1000 epoch: 66.24342105263159
Training for 300 epoch: 67.72791666666666
Training for 600 epoch: 67.13625
Training for 1000 epoch: 66.71708333333333
[[67.28947368421052, 66.76315789473685, 66.24342105263159], [67.72791666666666, 67.13625, 66.71708333333333]]
train loss 1.1481686691284179, epoch 104, best loss 0.5472409844557444, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [105][20/30]	Time  1.570 ( 1.569)	Data  0.041 ( 0.052)	InnerLoop  0.662 ( 0.672)	Loss 1.0407e+00 (7.9636e-01)	Acc@1  62.99 ( 72.19)
The current update step is 3180
GPU_0_using curriculum 40 with window 40
Epoch: [106][20/30]	Time  1.646 ( 1.561)	Data  0.160 ( 0.069)	InnerLoop  0.640 ( 0.646)	Loss 6.5891e-01 (6.8003e-01)	Acc@1  76.66 ( 75.52)
The current update step is 3210
GPU_0_using curriculum 40 with window 40
Epoch: [107][20/30]	Time  1.490 ( 1.568)	Data  0.039 ( 0.057)	InnerLoop  0.628 ( 0.658)	Loss 5.7042e-01 (6.4161e-01)	Acc@1  81.35 ( 77.10)
The current update step is 3240
GPU_0_using curriculum 40 with window 40
Epoch: [108][20/30]	Time  1.560 ( 1.594)	Data  0.039 ( 0.047)	InnerLoop  0.663 ( 0.691)	Loss 5.6469e-01 (6.3622e-01)	Acc@1  80.15 ( 78.31)
The current update step is 3270
GPU_0_using curriculum 40 with window 40
Epoch: [109][20/30]	Time  1.552 ( 1.578)	Data  0.041 ( 0.071)	InnerLoop  0.659 ( 0.658)	Loss 5.8996e-01 (5.9362e-01)	Acc@1  79.76 ( 79.19)
The current update step is 3300
The current seed is 11435249387003436963
The current lr is: 0.0015
Testing Results:
 *   Acc@1 59.882
 *   Acc@1 60.068
 *   Acc@1 60.645
 *   Acc@1 60.588
 *   Acc@1 61.013
 *   Acc@1 60.786
 *   Acc@1 75.947
 *   Acc@1 76.145
 *   Acc@1 76.053
 *   Acc@1 76.113
 *   Acc@1 75.553
 *   Acc@1 75.630
Training for 300 epoch: 67.91447368421052
Training for 600 epoch: 68.34868421052632
Training for 1000 epoch: 68.28289473684211
Training for 300 epoch: 68.10666666666667
Training for 600 epoch: 68.35083333333333
Training for 1000 epoch: 68.20791666666666
[[67.91447368421052, 68.34868421052632, 68.28289473684211], [68.10666666666667, 68.35083333333333, 68.20791666666666]]
train loss 0.5810897158622742, epoch 109, best loss 0.5472409844557444, best_epoch 79
GPU_0_using curriculum 40 with window 40
Epoch: [110][20/30]	Time  1.668 ( 1.582)	Data  0.164 ( 0.073)	InnerLoop  0.653 ( 0.660)	Loss 4.8571e-01 (6.0594e-01)	Acc@1  83.01 ( 78.14)
The current update step is 3330
GPU_0_using curriculum 40 with window 40
Epoch: [111][20/30]	Time  1.564 ( 1.549)	Data  0.043 ( 0.056)	InnerLoop  0.648 ( 0.651)	Loss 6.0340e-01 (6.2971e-01)	Acc@1  80.00 ( 78.08)
The current update step is 3360
GPU_0_using curriculum 40 with window 40
Epoch: [112][20/30]	Time  1.494 ( 1.563)	Data  0.036 ( 0.070)	InnerLoop  0.632 ( 0.646)	Loss 7.7032e-01 (6.2929e-01)	Acc@1  70.04 ( 77.78)
The current update step is 3390
GPU_0_using curriculum 40 with window 40
Epoch: [113][20/30]	Time  1.550 ( 1.573)	Data  0.043 ( 0.059)	InnerLoop  0.659 ( 0.667)	Loss 5.6591e-01 (6.1890e-01)	Acc@1  82.32 ( 78.13)
The current update step is 3420
GPU_0_using curriculum 40 with window 40
Epoch: [114][20/30]	Time  1.668 ( 1.567)	Data  0.162 ( 0.070)	InnerLoop  0.658 ( 0.654)	Loss 5.1747e-01 (6.1772e-01)	Acc@1  81.76 ( 78.73)
The current update step is 3450
The current seed is 9234514586796589302
The current lr is: 0.0015
Testing Results:
 *   Acc@1 77.658
 *   Acc@1 77.699
 *   Acc@1 77.750
 *   Acc@1 77.959
 *   Acc@1 77.763
 *   Acc@1 77.811
 *   Acc@1 79.132
 *   Acc@1 79.418
 *   Acc@1 79.605
 *   Acc@1 80.013
 *   Acc@1 79.816
 *   Acc@1 80.388
Training for 300 epoch: 78.39473684210526
Training for 600 epoch: 78.67763157894737
Training for 1000 epoch: 78.78947368421052
Training for 300 epoch: 78.55833333333334
Training for 600 epoch: 78.98583333333333
Training for 1000 epoch: 79.09958333333333
[[78.39473684210526, 78.67763157894737, 78.78947368421052], [78.55833333333334, 78.98583333333333, 79.09958333333333]]
train loss 0.4521389428456624, epoch 114, best loss 0.4521389428456624, best_epoch 114
GPU_0_using curriculum 40 with window 40
Epoch: [115][20/30]	Time  1.566 ( 1.567)	Data  0.039 ( 0.052)	InnerLoop  0.671 ( 0.671)	Loss 5.9776e-01 (7.2863e-01)	Acc@1  77.69 ( 74.61)
The current update step is 3480
GPU_0_using curriculum 40 with window 40
Epoch: [116][20/30]	Time  1.660 ( 1.552)	Data  0.162 ( 0.069)	InnerLoop  0.648 ( 0.644)	Loss 7.4757e-01 (6.7173e-01)	Acc@1  75.39 ( 76.38)
The current update step is 3510
GPU_0_using curriculum 40 with window 40
Epoch: [117][20/30]	Time  1.502 ( 1.558)	Data  0.039 ( 0.058)	InnerLoop  0.635 ( 0.656)	Loss 5.8510e-01 (6.5976e-01)	Acc@1  80.37 ( 76.69)
The current update step is 3540
GPU_0_using curriculum 40 with window 40
Epoch: [118][20/30]	Time  1.539 ( 1.570)	Data  0.040 ( 0.046)	InnerLoop  0.652 ( 0.676)	Loss 9.7155e-01 (6.8308e-01)	Acc@1  74.46 ( 76.67)
The current update step is 3570
GPU_0_using curriculum 40 with window 40
Epoch: [119][20/30]	Time  1.602 ( 1.564)	Data  0.042 ( 0.071)	InnerLoop  0.651 ( 0.648)	Loss 8.7681e-01 (6.9074e-01)	Acc@1  72.80 ( 74.68)
The current update step is 3600
The current seed is 15431296595456134009
The current lr is: 0.0015
Testing Results:
 *   Acc@1 71.711
 *   Acc@1 71.266
 *   Acc@1 71.368
 *   Acc@1 70.707
 *   Acc@1 70.355
 *   Acc@1 70.068
 *   Acc@1 64.118
 *   Acc@1 63.317
 *   Acc@1 64.961
 *   Acc@1 64.259
 *   Acc@1 65.368
 *   Acc@1 64.613
Training for 300 epoch: 67.91447368421052
Training for 600 epoch: 68.16447368421052
Training for 1000 epoch: 67.86184210526315
Training for 300 epoch: 67.29125
Training for 600 epoch: 67.48333333333333
Training for 1000 epoch: 67.34083333333334
[[67.91447368421052, 68.16447368421052, 67.86184210526315], [67.29125, 67.48333333333333, 67.34083333333334]]
train loss 0.8237993299166362, epoch 119, best loss 0.4521389428456624, best_epoch 114
GPU_0_using curriculum 40 with window 40
Epoch: [120][20/30]	Time  1.663 ( 1.576)	Data  0.042 ( 0.072)	InnerLoop  0.771 ( 0.657)	Loss 8.9333e-01 (6.9396e-01)	Acc@1  67.90 ( 75.88)
The current update step is 3630
GPU_0_using curriculum 40 with window 40
Epoch: [121][20/30]	Time  1.536 ( 1.555)	Data  0.040 ( 0.057)	InnerLoop  0.649 ( 0.653)	Loss 7.9622e-01 (6.2481e-01)	Acc@1  68.19 ( 77.77)
The current update step is 3660
GPU_0_using curriculum 40 with window 40
Epoch: [122][20/30]	Time  1.513 ( 1.552)	Data  0.037 ( 0.044)	InnerLoop  0.634 ( 0.666)	Loss 8.3904e-01 (5.9544e-01)	Acc@1  70.80 ( 79.00)
The current update step is 3690
GPU_0_using curriculum 40 with window 40
Epoch: [123][20/30]	Time  1.546 ( 1.571)	Data  0.038 ( 0.053)	InnerLoop  0.650 ( 0.670)	Loss 5.7343e-01 (6.1321e-01)	Acc@1  78.69 ( 78.46)
The current update step is 3720
GPU_0_using curriculum 40 with window 40
Epoch: [124][20/30]	Time  1.675 ( 1.562)	Data  0.167 ( 0.070)	InnerLoop  0.658 ( 0.647)	Loss 5.9262e-01 (6.2923e-01)	Acc@1  78.27 ( 77.77)
The current update step is 3750
The current seed is 10204214593058535657
The current lr is: 0.0015
Testing Results:
 *   Acc@1 76.079
 *   Acc@1 76.478
 *   Acc@1 76.158
 *   Acc@1 76.448
 *   Acc@1 75.487
 *   Acc@1 75.752
 *   Acc@1 58.408
 *   Acc@1 58.258
 *   Acc@1 59.816
 *   Acc@1 59.352
 *   Acc@1 60.618
 *   Acc@1 60.457
Training for 300 epoch: 67.24342105263158
Training for 600 epoch: 67.98684210526316
Training for 1000 epoch: 68.05263157894737
Training for 300 epoch: 67.3675
Training for 600 epoch: 67.9
Training for 1000 epoch: 68.10458333333332
[[67.24342105263158, 67.98684210526316, 68.05263157894737], [67.3675, 67.9, 68.10458333333332]]
train loss 1.1016809361775717, epoch 124, best loss 0.4521389428456624, best_epoch 114
GPU_0_using curriculum 40 with window 40
Epoch: [125][20/30]	Time  1.564 ( 1.572)	Data  0.038 ( 0.053)	InnerLoop  0.644 ( 0.669)	Loss 5.7197e-01 (6.2520e-01)	Acc@1  79.49 ( 77.94)
The current update step is 3780
GPU_0_using curriculum 40 with window 40
Epoch: [126][20/30]	Time  1.642 ( 1.552)	Data  0.161 ( 0.070)	InnerLoop  0.638 ( 0.644)	Loss 6.5086e-01 (6.4836e-01)	Acc@1  74.95 ( 77.03)
The current update step is 3810
GPU_0_using curriculum 40 with window 40
Epoch: [127][20/30]	Time  1.512 ( 1.560)	Data  0.037 ( 0.058)	InnerLoop  0.638 ( 0.657)	Loss 6.8194e-01 (6.0739e-01)	Acc@1  77.98 ( 78.31)
The current update step is 3840
GPU_0_using curriculum 40 with window 40
Epoch: [128][20/30]	Time  1.532 ( 1.568)	Data  0.040 ( 0.046)	InnerLoop  0.645 ( 0.676)	Loss 7.4494e-01 (6.2476e-01)	Acc@1  73.07 ( 78.20)
The current update step is 3870
GPU_0_using curriculum 40 with window 40
Epoch: [129][20/30]	Time  1.540 ( 1.560)	Data  0.043 ( 0.072)	InnerLoop  0.646 ( 0.643)	Loss 9.2667e-01 (6.5245e-01)	Acc@1  69.48 ( 76.80)
The current update step is 3900
The current seed is 1400451576936908063
The current lr is: 0.0015
Testing Results:
 *   Acc@1 78.526
 *   Acc@1 78.463
 *   Acc@1 78.842
 *   Acc@1 78.417
 *   Acc@1 78.632
 *   Acc@1 78.383
 *   Acc@1 65.658
 *   Acc@1 65.677
 *   Acc@1 65.934
 *   Acc@1 66.093
 *   Acc@1 66.276
 *   Acc@1 66.293
Training for 300 epoch: 72.09210526315789
Training for 600 epoch: 72.38815789473685
Training for 1000 epoch: 72.45394736842105
Training for 300 epoch: 72.07
Training for 600 epoch: 72.25458333333333
Training for 1000 epoch: 72.33791666666667
[[72.09210526315789, 72.38815789473685, 72.45394736842105], [72.07, 72.25458333333333, 72.33791666666667]]
train loss 1.004447307840983, epoch 129, best loss 0.4521389428456624, best_epoch 114
GPU_0_using curriculum 40 with window 40
Epoch: [130][20/30]	Time  1.672 ( 1.571)	Data  0.042 ( 0.070)	InnerLoop  0.783 ( 0.654)	Loss 6.3153e-01 (5.9845e-01)	Acc@1  76.42 ( 78.39)
The current update step is 3930
GPU_0_using curriculum 40 with window 40
Epoch: [131][20/30]	Time  1.530 ( 1.556)	Data  0.041 ( 0.058)	InnerLoop  0.642 ( 0.656)	Loss 9.3038e-01 (6.1489e-01)	Acc@1  68.09 ( 78.51)
The current update step is 3960
GPU_0_using curriculum 40 with window 40
Epoch: [132][20/30]	Time  1.524 ( 1.557)	Data  0.051 ( 0.045)	InnerLoop  0.643 ( 0.671)	Loss 5.7212e-01 (6.0013e-01)	Acc@1  77.91 ( 78.42)
The current update step is 3990
GPU_0_using curriculum 40 with window 40
Epoch: [133][20/30]	Time  1.525 ( 1.569)	Data  0.039 ( 0.052)	InnerLoop  0.643 ( 0.670)	Loss 6.3642e-01 (6.4985e-01)	Acc@1  77.83 ( 76.81)
The current update step is 4020
GPU_0_using curriculum 40 with window 40
Epoch: [134][20/30]	Time  1.646 ( 1.568)	Data  0.162 ( 0.071)	InnerLoop  0.643 ( 0.653)	Loss 6.1897e-01 (6.1030e-01)	Acc@1  77.71 ( 78.30)
The current update step is 4050
The current seed is 11614621640476159006
The current lr is: 0.0015
Testing Results:
 *   Acc@1 76.592
 *   Acc@1 76.297
 *   Acc@1 76.250
 *   Acc@1 76.277
 *   Acc@1 76.487
 *   Acc@1 75.978
 *   Acc@1 71.671
 *   Acc@1 72.301
 *   Acc@1 71.895
 *   Acc@1 72.659
 *   Acc@1 72.184
 *   Acc@1 72.938
Training for 300 epoch: 74.13157894736841
Training for 600 epoch: 74.07236842105263
Training for 1000 epoch: 74.33552631578948
Training for 300 epoch: 74.29916666666666
Training for 600 epoch: 74.46791666666667
Training for 1000 epoch: 74.45750000000001
[[74.13157894736841, 74.07236842105263, 74.33552631578948], [74.29916666666666, 74.46791666666667, 74.45750000000001]]
train loss 0.9385258705774943, epoch 134, best loss 0.4521389428456624, best_epoch 114
GPU_0_using curriculum 40 with window 40
Epoch: [135][20/30]	Time  1.545 ( 1.576)	Data  0.040 ( 0.053)	InnerLoop  0.660 ( 0.675)	Loss 6.1057e-01 (6.0729e-01)	Acc@1  78.98 ( 78.68)
The current update step is 4080
GPU_0_using curriculum 40 with window 40
Epoch: [136][20/30]	Time  1.661 ( 1.552)	Data  0.159 ( 0.070)	InnerLoop  0.648 ( 0.645)	Loss 5.2415e-01 (5.8341e-01)	Acc@1  81.49 ( 79.36)
The current update step is 4110
GPU_0_using curriculum 40 with window 40
Epoch: [137][20/30]	Time  1.500 ( 1.548)	Data  0.038 ( 0.057)	InnerLoop  0.632 ( 0.654)	Loss 5.0550e-01 (6.0703e-01)	Acc@1  82.08 ( 78.97)
The current update step is 4140
GPU_0_using curriculum 40 with window 40
Epoch: [138][20/30]	Time  1.524 ( 1.567)	Data  0.040 ( 0.047)	InnerLoop  0.642 ( 0.674)	Loss 5.1604e-01 (6.0128e-01)	Acc@1  83.52 ( 79.03)
The current update step is 4170
GPU_0_using curriculum 40 with window 40
Epoch: [139][20/30]	Time  1.521 ( 1.557)	Data  0.039 ( 0.071)	InnerLoop  0.641 ( 0.644)	Loss 5.9903e-01 (6.3058e-01)	Acc@1  76.32 ( 78.18)
The current update step is 4200
The current seed is 6363831969538180523
The current lr is: 0.0015
Testing Results:
 *   Acc@1 72.434
 *   Acc@1 72.786
 *   Acc@1 67.105
 *   Acc@1 67.223
 *   Acc@1 67.329
 *   Acc@1 67.524
 *   Acc@1 76.171
 *   Acc@1 76.917
 *   Acc@1 76.711
 *   Acc@1 77.128
 *   Acc@1 76.855
 *   Acc@1 77.340
Training for 300 epoch: 74.30263157894737
Training for 600 epoch: 71.90789473684211
Training for 1000 epoch: 72.09210526315789
Training for 300 epoch: 74.85125
Training for 600 epoch: 72.17583333333333
Training for 1000 epoch: 72.43208333333334
[[74.30263157894737, 71.90789473684211, 72.09210526315789], [74.85125, 72.17583333333333, 72.43208333333334]]
train loss 0.5052167934258779, epoch 139, best loss 0.4521389428456624, best_epoch 114
GPU_0_using curriculum 40 with window 40
Epoch: [140][20/30]	Time  1.687 ( 1.575)	Data  0.042 ( 0.072)	InnerLoop  0.793 ( 0.656)	Loss 5.8835e-01 (5.9893e-01)	Acc@1  78.42 ( 79.32)
The current update step is 4230
GPU_0_using curriculum 40 with window 40
Epoch: [141][20/30]	Time  1.546 ( 1.552)	Data  0.043 ( 0.058)	InnerLoop  0.651 ( 0.656)	Loss 5.1545e-01 (5.7444e-01)	Acc@1  81.54 ( 80.09)
The current update step is 4260
GPU_0_using curriculum 40 with window 40
Epoch: [142][20/30]	Time  1.478 ( 1.550)	Data  0.037 ( 0.046)	InnerLoop  0.625 ( 0.667)	Loss 5.3491e-01 (6.1943e-01)	Acc@1  81.54 ( 78.56)
The current update step is 4290
GPU_0_using curriculum 40 with window 40
Epoch: [143][20/30]	Time  1.561 ( 1.569)	Data  0.041 ( 0.054)	InnerLoop  0.671 ( 0.669)	Loss 1.2719e+00 (6.3889e-01)	Acc@1  59.06 ( 77.61)
The current update step is 4320
GPU_0_using curriculum 40 with window 40
Epoch: [144][20/30]	Time  1.656 ( 1.573)	Data  0.161 ( 0.072)	InnerLoop  0.650 ( 0.656)	Loss 5.4200e-01 (5.9335e-01)	Acc@1  82.08 ( 79.39)
The current update step is 4350
The current seed is 4844950519306405551
The current lr is: 0.0015
Testing Results:
 *   Acc@1 73.092
 *   Acc@1 73.282
 *   Acc@1 73.763
 *   Acc@1 73.910
 *   Acc@1 73.842
 *   Acc@1 74.026
 *   Acc@1 54.368
 *   Acc@1 54.362
 *   Acc@1 53.316
 *   Acc@1 53.046
 *   Acc@1 52.724
 *   Acc@1 52.676
Training for 300 epoch: 63.73026315789474
Training for 600 epoch: 63.53947368421052
Training for 1000 epoch: 63.2828947368421
Training for 300 epoch: 63.8225
Training for 600 epoch: 63.477916666666665
Training for 1000 epoch: 63.35083333333334
[[63.73026315789474, 63.53947368421052, 63.2828947368421], [63.8225, 63.477916666666665, 63.35083333333334]]
train loss 1.5416797684987387, epoch 144, best loss 0.4521389428456624, best_epoch 114
GPU_0_using curriculum 40 with window 40
Epoch: [145][20/30]	Time  1.537 ( 1.569)	Data  0.042 ( 0.053)	InnerLoop  0.653 ( 0.669)	Loss 5.7509e-01 (5.5198e-01)	Acc@1  81.03 ( 80.61)
The current update step is 4380
GPU_0_using curriculum 40 with window 40
Epoch: [146][20/30]	Time  1.682 ( 1.558)	Data  0.169 ( 0.070)	InnerLoop  0.648 ( 0.647)	Loss 5.7476e-01 (5.7287e-01)	Acc@1  78.08 ( 79.53)
The current update step is 4410
GPU_0_using curriculum 40 with window 40
Epoch: [147][20/30]	Time  1.498 ( 1.552)	Data  0.040 ( 0.058)	InnerLoop  0.626 ( 0.652)	Loss 7.0789e-01 (6.0589e-01)	Acc@1  73.88 ( 78.91)
The current update step is 4440
GPU_0_using curriculum 40 with window 40
Epoch: [148][20/30]	Time  1.553 ( 1.572)	Data  0.038 ( 0.047)	InnerLoop  0.667 ( 0.679)	Loss 5.2640e-01 (5.9237e-01)	Acc@1  81.49 ( 79.43)
The current update step is 4470
GPU_0_using curriculum 40 with window 40
Epoch: [149][20/30]	Time  1.537 ( 1.576)	Data  0.042 ( 0.073)	InnerLoop  0.650 ( 0.654)	Loss 8.2722e-01 (5.9135e-01)	Acc@1  67.24 ( 79.24)
The current update step is 4500
The current seed is 7913030720984690933
The current lr is: 0.0015
Testing Results:
 *   Acc@1 75.079
 *   Acc@1 74.843
 *   Acc@1 73.408
 *   Acc@1 73.323
 *   Acc@1 72.395
 *   Acc@1 72.138
 *   Acc@1 74.500
 *   Acc@1 74.930
 *   Acc@1 74.092
 *   Acc@1 74.367
 *   Acc@1 74.000
 *   Acc@1 74.302
Training for 300 epoch: 74.78947368421052
Training for 600 epoch: 73.75
Training for 1000 epoch: 73.19736842105263
Training for 300 epoch: 74.88666666666667
Training for 600 epoch: 73.845
Training for 1000 epoch: 73.22
[[74.78947368421052, 73.75, 73.19736842105263], [74.88666666666667, 73.845, 73.22]]
train loss 0.7086279785792032, epoch 149, best loss 0.4521389428456624, best_epoch 114
GPU_0_using curriculum 40 with window 40
Epoch: [150][20/30]	Time  1.658 ( 1.580)	Data  0.039 ( 0.073)	InnerLoop  0.776 ( 0.657)	Loss 5.3736e-01 (5.7532e-01)	Acc@1  80.40 ( 80.17)
The current update step is 4530
GPU_0_using curriculum 40 with window 40
Epoch: [151][20/30]	Time  1.536 ( 1.574)	Data  0.041 ( 0.058)	InnerLoop  0.652 ( 0.658)	Loss 6.6166e-01 (5.7376e-01)	Acc@1  78.86 ( 80.03)
The current update step is 4560
GPU_0_using curriculum 40 with window 40
Epoch: [152][20/30]	Time  1.594 ( 1.555)	Data  0.040 ( 0.045)	InnerLoop  0.655 ( 0.669)	Loss 5.6277e-01 (5.9051e-01)	Acc@1  81.25 ( 80.07)
The current update step is 4590
GPU_0_using curriculum 40 with window 40
Epoch: [153][20/30]	Time  1.530 ( 1.572)	Data  0.048 ( 0.052)	InnerLoop  0.640 ( 0.669)	Loss 5.2125e-01 (5.7561e-01)	Acc@1  81.42 ( 80.07)
The current update step is 4620
GPU_0_using curriculum 40 with window 40
Epoch: [154][20/30]	Time  1.672 ( 1.594)	Data  0.164 ( 0.072)	InnerLoop  0.663 ( 0.663)	Loss 7.5048e-01 (6.5254e-01)	Acc@1  76.54 ( 77.24)
The current update step is 4650
The current seed is 7732835215442087939
The current lr is: 0.0015
Testing Results:
 *   Acc@1 63.145
 *   Acc@1 63.773
 *   Acc@1 63.776
 *   Acc@1 64.032
 *   Acc@1 64.276
 *   Acc@1 64.673
 *   Acc@1 71.671
 *   Acc@1 71.358
 *   Acc@1 71.289
 *   Acc@1 71.138
 *   Acc@1 71.803
 *   Acc@1 71.412
Training for 300 epoch: 67.40789473684211
Training for 600 epoch: 67.53289473684211
Training for 1000 epoch: 68.03947368421052
Training for 300 epoch: 67.56541666666666
Training for 600 epoch: 67.58458333333334
Training for 1000 epoch: 68.04249999999999
[[67.40789473684211, 67.53289473684211, 68.03947368421052], [67.56541666666666, 67.58458333333334, 68.04249999999999]]
train loss 0.5919132830937703, epoch 154, best loss 0.4521389428456624, best_epoch 114
GPU_0_using curriculum 40 with window 40
Epoch: [155][20/30]	Time  1.533 ( 1.582)	Data  0.040 ( 0.053)	InnerLoop  0.648 ( 0.674)	Loss 4.7719e-01 (5.5892e-01)	Acc@1  83.62 ( 80.50)
The current update step is 4680
GPU_0_using curriculum 40 with window 40
Epoch: [156][20/30]	Time  1.680 ( 1.561)	Data  0.170 ( 0.070)	InnerLoop  0.656 ( 0.649)	Loss 5.2158e-01 (5.6278e-01)	Acc@1  81.25 ( 80.31)
The current update step is 4710
GPU_0_using curriculum 40 with window 40
Epoch: [157][20/30]	Time  1.521 ( 1.552)	Data  0.037 ( 0.057)	InnerLoop  0.633 ( 0.657)	Loss 4.5645e-01 (5.9637e-01)	Acc@1  84.28 ( 79.47)
The current update step is 4740
GPU_0_using curriculum 40 with window 40
Epoch: [158][20/30]	Time  1.574 ( 1.589)	Data  0.041 ( 0.048)	InnerLoop  0.667 ( 0.686)	Loss 5.4591e-01 (5.4004e-01)	Acc@1  81.37 ( 81.20)
The current update step is 4770
GPU_0_using curriculum 40 with window 40
Epoch: [159][20/30]	Time  1.563 ( 1.579)	Data  0.042 ( 0.073)	InnerLoop  0.661 ( 0.654)	Loss 5.0750e-01 (5.9280e-01)	Acc@1  82.93 ( 79.60)
The current update step is 4800
The current seed is 6806251971555535649
The current lr is: 0.0015
Testing Results:
 *   Acc@1 69.184
 *   Acc@1 68.495
 *   Acc@1 69.000
 *   Acc@1 68.463
 *   Acc@1 68.263
 *   Acc@1 67.669
 *   Acc@1 55.579
 *   Acc@1 55.659
 *   Acc@1 56.316
 *   Acc@1 56.424
 *   Acc@1 56.829
 *   Acc@1 56.831
Training for 300 epoch: 62.381578947368425
Training for 600 epoch: 62.65789473684211
Training for 1000 epoch: 62.546052631578945
Training for 300 epoch: 62.077083333333334
Training for 600 epoch: 62.443333333333335
Training for 1000 epoch: 62.25
[[62.381578947368425, 62.65789473684211, 62.546052631578945], [62.077083333333334, 62.443333333333335, 62.25]]
train loss 1.2223499589284261, epoch 159, best loss 0.4521389428456624, best_epoch 114
GPU_0_using curriculum 40 with window 40
Epoch: [160][20/30]	Time  1.686 ( 1.597)	Data  0.044 ( 0.075)	InnerLoop  0.781 ( 0.667)	Loss 4.9087e-01 (5.5398e-01)	Acc@1  82.91 ( 80.79)
The current update step is 4830
GPU_0_using curriculum 40 with window 40
Epoch: [161][20/30]	Time  1.589 ( 1.571)	Data  0.046 ( 0.060)	InnerLoop  0.673 ( 0.665)	Loss 6.7859e-01 (5.4639e-01)	Acc@1  79.20 ( 81.01)
The current update step is 4860
GPU_0_using curriculum 40 with window 40
Epoch: [162][20/30]	Time  1.553 ( 1.567)	Data  0.039 ( 0.047)	InnerLoop  0.639 ( 0.674)	Loss 5.7252e-01 (5.5828e-01)	Acc@1  80.20 ( 80.41)
The current update step is 4890
GPU_0_using curriculum 40 with window 40
Epoch: [163][20/30]	Time  1.567 ( 1.590)	Data  0.041 ( 0.055)	InnerLoop  0.674 ( 0.682)	Loss 5.0312e-01 (5.6091e-01)	Acc@1  82.76 ( 80.36)
The current update step is 4920
GPU_0_using curriculum 40 with window 40
Epoch: [164][20/30]	Time  1.712 ( 1.602)	Data  0.171 ( 0.075)	InnerLoop  0.665 ( 0.670)	Loss 5.7296e-01 (5.6570e-01)	Acc@1  79.83 ( 80.37)
The current update step is 4950
The current seed is 18047659466242167519
The current lr is: 0.0015
Testing Results:
 *   Acc@1 50.855
 *   Acc@1 50.536
 *   Acc@1 50.658
 *   Acc@1 50.055
 *   Acc@1 50.434
 *   Acc@1 49.632
 *   Acc@1 73.289
 *   Acc@1 73.639
 *   Acc@1 73.092
 *   Acc@1 72.790
 *   Acc@1 72.105
 *   Acc@1 72.306
Training for 300 epoch: 62.07236842105263
Training for 600 epoch: 61.875
Training for 1000 epoch: 61.26973684210526
Training for 300 epoch: 62.087500000000006
Training for 600 epoch: 61.4225
Training for 1000 epoch: 60.96875
[[62.07236842105263, 61.875, 61.26973684210526], [62.087500000000006, 61.4225, 60.96875]]
train loss 0.6068174449920655, epoch 164, best loss 0.4521389428456624, best_epoch 114
GPU_0_using curriculum 40 with window 40
Epoch: [165][20/30]	Time  1.553 ( 1.590)	Data  0.040 ( 0.054)	InnerLoop  0.660 ( 0.682)	Loss 6.3444e-01 (5.5679e-01)	Acc@1  78.27 ( 80.74)
The current update step is 4980
GPU_0_using curriculum 40 with window 40
Epoch: [166][20/30]	Time  1.692 ( 1.593)	Data  0.169 ( 0.074)	InnerLoop  0.668 ( 0.667)	Loss 6.6588e-01 (5.8272e-01)	Acc@1  75.49 ( 79.38)
The current update step is 5010
GPU_0_using curriculum 40 with window 40
Epoch: [167][20/30]	Time  1.577 ( 1.576)	Data  0.044 ( 0.060)	InnerLoop  0.678 ( 0.672)	Loss 6.1685e-01 (5.5688e-01)	Acc@1  78.66 ( 80.27)
The current update step is 5040
GPU_0_using curriculum 40 with window 40
Epoch: [168][20/30]	Time  1.542 ( 1.587)	Data  0.044 ( 0.048)	InnerLoop  0.645 ( 0.689)	Loss 6.8470e-01 (5.5507e-01)	Acc@1  72.22 ( 80.78)
The current update step is 5070
GPU_0_using curriculum 40 with window 40
Epoch: [169][20/30]	Time  1.556 ( 1.598)	Data  0.042 ( 0.075)	InnerLoop  0.665 ( 0.670)	Loss 6.1323e-01 (5.7705e-01)	Acc@1  79.05 ( 79.61)
The current update step is 5100
The current seed is 13050485342990292823
The current lr is: 0.0015
Testing Results:
 *   Acc@1 71.671
 *   Acc@1 71.936
 *   Acc@1 72.566
 *   Acc@1 72.511
 *   Acc@1 72.539
 *   Acc@1 72.517
 *   Acc@1 67.961
 *   Acc@1 68.416
 *   Acc@1 70.645
 *   Acc@1 71.290
 *   Acc@1 70.408
 *   Acc@1 71.392
Training for 300 epoch: 69.81578947368422
Training for 600 epoch: 71.60526315789474
Training for 1000 epoch: 71.47368421052632
Training for 300 epoch: 70.17583333333334
Training for 600 epoch: 71.90041666666667
Training for 1000 epoch: 71.95416666666667
[[69.81578947368422, 71.60526315789474, 71.47368421052632], [70.17583333333334, 71.90041666666667, 71.95416666666667]]
train loss 0.9285899039268494, epoch 169, best loss 0.4521389428456624, best_epoch 114
GPU_0_using curriculum 40 with window 40
Epoch: [170][20/30]	Time  1.657 ( 1.585)	Data  0.042 ( 0.073)	InnerLoop  0.778 ( 0.666)	Loss 4.7316e-01 (5.5904e-01)	Acc@1  83.94 ( 80.46)
The current update step is 5130
GPU_0_using curriculum 40 with window 40
Epoch: [171][20/30]	Time  1.551 ( 1.577)	Data  0.041 ( 0.060)	InnerLoop  0.657 ( 0.671)	Loss 5.9838e-01 (5.6028e-01)	Acc@1  79.44 ( 80.72)
The current update step is 5160
GPU_0_using curriculum 40 with window 40
Epoch: [172][20/30]	Time  1.543 ( 1.564)	Data  0.045 ( 0.047)	InnerLoop  0.658 ( 0.677)	Loss 6.4197e-01 (5.5053e-01)	Acc@1  76.15 ( 80.55)
The current update step is 5190
GPU_0_using curriculum 40 with window 40
Epoch: [173][20/30]	Time  1.537 ( 1.561)	Data  0.038 ( 0.051)	InnerLoop  0.643 ( 0.671)	Loss 4.6717e-01 (5.6357e-01)	Acc@1  84.55 ( 80.48)
The current update step is 5220
GPU_0_using curriculum 40 with window 40
Epoch: [174][20/30]	Time  1.659 ( 1.585)	Data  0.160 ( 0.071)	InnerLoop  0.652 ( 0.665)	Loss 5.1446e-01 (5.7199e-01)	Acc@1  82.06 ( 80.13)
The current update step is 5250
The current seed is 3821466551044972335
The current lr is: 0.0015
Testing Results:
 *   Acc@1 41.316
 *   Acc@1 41.048
 *   Acc@1 43.447
 *   Acc@1 42.955
 *   Acc@1 43.303
 *   Acc@1 43.692
 *   Acc@1 64.039
 *   Acc@1 64.555
 *   Acc@1 64.184
 *   Acc@1 65.073
 *   Acc@1 64.763
 *   Acc@1 65.169
Training for 300 epoch: 52.67763157894737
Training for 600 epoch: 53.81578947368421
Training for 1000 epoch: 54.0328947368421
Training for 300 epoch: 52.80166666666667
Training for 600 epoch: 54.01375
Training for 1000 epoch: 54.43041666666667
[[52.67763157894737, 53.81578947368421, 54.0328947368421], [52.80166666666667, 54.01375, 54.43041666666667]]
train loss 0.9117617797851563, epoch 174, best loss 0.4521389428456624, best_epoch 174
GPU_0_using curriculum 40 with window 40
Epoch: [175][20/30]	Time  1.503 ( 1.570)	Data  0.036 ( 0.052)	InnerLoop  0.639 ( 0.675)	Loss 6.0819e-01 (5.5958e-01)	Acc@1  76.34 ( 80.48)
The current update step is 5280
GPU_0_using curriculum 40 with window 40
Epoch: [176][20/30]	Time  1.662 ( 1.583)	Data  0.164 ( 0.072)	InnerLoop  0.654 ( 0.665)	Loss 5.1090e-01 (5.5659e-01)	Acc@1  83.11 ( 80.61)
The current update step is 5310
GPU_0_using curriculum 40 with window 40
Epoch: [177][20/30]	Time  1.532 ( 1.563)	Data  0.040 ( 0.059)	InnerLoop  0.655 ( 0.666)	Loss 6.7160e-01 (5.6594e-01)	Acc@1  75.07 ( 80.04)
The current update step is 5340
GPU_0_using curriculum 40 with window 40
Epoch: [178][20/30]	Time  1.554 ( 1.563)	Data  0.042 ( 0.045)	InnerLoop  0.658 ( 0.678)	Loss 8.3795e-01 (5.6403e-01)	Acc@1  71.97 ( 80.33)
The current update step is 5370
GPU_0_using curriculum 40 with window 40
Epoch: [179][20/30]	Time  1.513 ( 1.572)	Data  0.037 ( 0.072)	InnerLoop  0.642 ( 0.659)	Loss 4.9691e-01 (5.4239e-01)	Acc@1  83.03 ( 81.15)
The current update step is 5400
The current seed is 17906098709547346274
The current lr is: 0.0015
Testing Results:
 *   Acc@1 61.237
 *   Acc@1 61.900
 *   Acc@1 61.026
 *   Acc@1 61.608
 *   Acc@1 60.934
 *   Acc@1 61.643
 *   Acc@1 75.105
 *   Acc@1 75.709
 *   Acc@1 75.237
 *   Acc@1 75.983
 *   Acc@1 74.987
 *   Acc@1 75.367
Training for 300 epoch: 68.17105263157895
Training for 600 epoch: 68.13157894736842
Training for 1000 epoch: 67.96052631578948
Training for 300 epoch: 68.80458333333333
Training for 600 epoch: 68.79541666666667
Training for 1000 epoch: 68.505
[[68.17105263157895, 68.13157894736842, 67.96052631578948], [68.80458333333333, 68.79541666666667, 68.505]]
train loss 0.7206545093218486, epoch 179, best loss 0.4521389428456624, best_epoch 174
GPU_0_using curriculum 40 with window 40
Epoch: [180][20/30]	Time  1.639 ( 1.578)	Data  0.042 ( 0.073)	InnerLoop  0.762 ( 0.662)	Loss 5.5654e-01 (5.8430e-01)	Acc@1  79.49 ( 79.30)
The current update step is 5430
GPU_0_using curriculum 40 with window 40
Epoch: [181][20/30]	Time  1.565 ( 1.579)	Data  0.040 ( 0.059)	InnerLoop  0.673 ( 0.676)	Loss 5.4167e-01 (5.7661e-01)	Acc@1  81.01 ( 80.30)
The current update step is 5460
GPU_0_using curriculum 40 with window 40
Epoch: [182][20/30]	Time  1.554 ( 1.564)	Data  0.043 ( 0.045)	InnerLoop  0.661 ( 0.678)	Loss 5.6284e-01 (6.0232e-01)	Acc@1  79.35 ( 78.77)
The current update step is 5490
GPU_0_using curriculum 40 with window 40
Epoch: [183][20/30]	Time  1.555 ( 1.562)	Data  0.039 ( 0.051)	InnerLoop  0.664 ( 0.669)	Loss 5.5303e-01 (6.0468e-01)	Acc@1  80.86 ( 79.02)
The current update step is 5520
GPU_0_using curriculum 40 with window 40
Epoch: [184][20/30]	Time  1.632 ( 1.584)	Data  0.165 ( 0.073)	InnerLoop  0.645 ( 0.666)	Loss 5.9630e-01 (5.6731e-01)	Acc@1  79.47 ( 79.98)
The current update step is 5550
The current seed is 8921423519308757007
The current lr is: 0.0015
Testing Results:
 *   Acc@1 54.263
 *   Acc@1 54.996
 *   Acc@1 49.500
 *   Acc@1 50.433
 *   Acc@1 50.684
 *   Acc@1 51.354
 *   Acc@1 62.171
 *   Acc@1 62.578
 *   Acc@1 62.974
 *   Acc@1 62.955
 *   Acc@1 62.789
 *   Acc@1 62.937
Training for 300 epoch: 58.21710526315789
Training for 600 epoch: 56.23684210526316
Training for 1000 epoch: 56.73684210526316
Training for 300 epoch: 58.78666666666666
Training for 600 epoch: 56.69416666666666
Training for 1000 epoch: 57.14541666666666
[[58.21710526315789, 56.23684210526316, 56.73684210526316], [58.78666666666666, 56.69416666666666, 57.14541666666666]]
train loss 0.9762934852600098, epoch 184, best loss 0.4521389428456624, best_epoch 174
GPU_0_using curriculum 40 with window 40
Epoch: [185][20/30]	Time  1.501 ( 1.568)	Data  0.037 ( 0.052)	InnerLoop  0.637 ( 0.674)	Loss 6.3009e-01 (5.9116e-01)	Acc@1  79.79 ( 79.23)
The current update step is 5580
GPU_0_using curriculum 40 with window 40
Epoch: [186][20/30]	Time  1.680 ( 1.584)	Data  0.167 ( 0.073)	InnerLoop  0.658 ( 0.666)	Loss 5.7448e-01 (5.8063e-01)	Acc@1  80.37 ( 79.48)
The current update step is 5610
GPU_0_using curriculum 40 with window 40
Epoch: [187][20/30]	Time  1.552 ( 1.564)	Data  0.043 ( 0.057)	InnerLoop  0.662 ( 0.665)	Loss 5.5846e-01 (5.7546e-01)	Acc@1  80.76 ( 80.05)
The current update step is 5640
GPU_0_using curriculum 40 with window 40
Epoch: [188][20/30]	Time  1.546 ( 1.553)	Data  0.037 ( 0.045)	InnerLoop  0.661 ( 0.672)	Loss 6.6363e-01 (6.2206e-01)	Acc@1  74.85 ( 78.53)
The current update step is 5670
GPU_0_using curriculum 40 with window 40
Epoch: [189][20/30]	Time  1.506 ( 1.572)	Data  0.040 ( 0.073)	InnerLoop  0.641 ( 0.656)	Loss 5.6840e-01 (6.2096e-01)	Acc@1  79.66 ( 78.20)
The current update step is 5700
The current seed is 96326550302475821
The current lr is: 0.0015
Testing Results:
 *   Acc@1 55.513
 *   Acc@1 56.065
 *   Acc@1 55.632
 *   Acc@1 56.014
 *   Acc@1 56.342
 *   Acc@1 56.316
 *   Acc@1 73.158
 *   Acc@1 74.423
 *   Acc@1 73.724
 *   Acc@1 75.295
 *   Acc@1 74.158
 *   Acc@1 75.638
Training for 300 epoch: 64.33552631578948
Training for 600 epoch: 64.67763157894737
Training for 1000 epoch: 65.25
Training for 300 epoch: 65.24416666666667
Training for 600 epoch: 65.65458333333333
Training for 1000 epoch: 65.97666666666666
[[64.33552631578948, 64.67763157894737, 65.25], [65.24416666666667, 65.65458333333333, 65.97666666666666]]
train loss 0.5447960154215494, epoch 189, best loss 0.4521389428456624, best_epoch 174
GPU_0_using curriculum 40 with window 40
Epoch: [190][20/30]	Time  1.622 ( 1.575)	Data  0.038 ( 0.072)	InnerLoop  0.758 ( 0.662)	Loss 4.7437e-01 (5.4935e-01)	Acc@1  83.52 ( 81.22)
The current update step is 5730
GPU_0_using curriculum 40 with window 40
Epoch: [191][20/30]	Time  1.541 ( 1.576)	Data  0.040 ( 0.060)	InnerLoop  0.655 ( 0.673)	Loss 8.4397e-01 (5.9161e-01)	Acc@1  73.88 ( 78.91)
The current update step is 5760
GPU_0_using curriculum 40 with window 40
Epoch: [192][20/30]	Time  1.550 ( 1.556)	Data  0.039 ( 0.047)	InnerLoop  0.659 ( 0.671)	Loss 5.5037e-01 (5.4784e-01)	Acc@1  80.74 ( 81.08)
The current update step is 5790
GPU_0_using curriculum 40 with window 40
Epoch: [193][20/30]	Time  1.505 ( 1.555)	Data  0.041 ( 0.051)	InnerLoop  0.638 ( 0.668)	Loss 5.4254e-01 (5.8262e-01)	Acc@1  81.25 ( 79.61)
The current update step is 5820
GPU_0_using curriculum 40 with window 40
Epoch: [194][20/30]	Time  1.673 ( 1.583)	Data  0.162 ( 0.073)	InnerLoop  0.665 ( 0.666)	Loss 4.7059e-01 (5.5788e-01)	Acc@1  83.50 ( 80.48)
The current update step is 5850
The current seed is 18322048637673447440
The current lr is: 0.0015
Testing Results:
 *   Acc@1 76.447
 *   Acc@1 77.118
 *   Acc@1 70.066
 *   Acc@1 70.388
 *   Acc@1 50.158
 *   Acc@1 50.935
 *   Acc@1 56.079
 *   Acc@1 55.183
 *   Acc@1 56.763
 *   Acc@1 56.112
 *   Acc@1 57.184
 *   Acc@1 56.969
Training for 300 epoch: 66.26315789473685
Training for 600 epoch: 63.41447368421052
Training for 1000 epoch: 53.671052631578945
Training for 300 epoch: 66.15083333333334
Training for 600 epoch: 63.25
Training for 1000 epoch: 53.952083333333334
[[66.26315789473685, 63.41447368421052, 53.671052631578945], [66.15083333333334, 63.25, 53.952083333333334]]
train loss 1.6704541630427043, epoch 194, best loss 0.4521389428456624, best_epoch 174
GPU_0_using curriculum 40 with window 40
Epoch: [195][20/30]	Time  1.512 ( 1.575)	Data  0.039 ( 0.053)	InnerLoop  0.642 ( 0.675)	Loss 5.7111e-01 (5.5033e-01)	Acc@1  78.56 ( 81.18)
The current update step is 5880
GPU_0_using curriculum 40 with window 40
Epoch: [196][20/30]	Time  1.662 ( 1.577)	Data  0.162 ( 0.071)	InnerLoop  0.651 ( 0.659)	Loss 7.2208e-01 (5.4277e-01)	Acc@1  73.61 ( 80.93)
The current update step is 5910
GPU_0_using curriculum 40 with window 40
Epoch: [197][20/30]	Time  1.549 ( 1.565)	Data  0.039 ( 0.057)	InnerLoop  0.660 ( 0.667)	Loss 4.6879e-01 (5.5071e-01)	Acc@1  84.03 ( 80.67)
The current update step is 5940
GPU_0_using curriculum 40 with window 40
Epoch: [198][20/30]	Time  1.506 ( 1.559)	Data  0.036 ( 0.045)	InnerLoop  0.635 ( 0.676)	Loss 6.0522e-01 (5.3963e-01)	Acc@1  80.13 ( 81.22)
The current update step is 5970
GPU_0_using curriculum 40 with window 40
Epoch: [199][20/30]	Time  1.576 ( 1.574)	Data  0.043 ( 0.072)	InnerLoop  0.675 ( 0.659)	Loss 5.2420e-01 (5.8894e-01)	Acc@1  81.69 ( 79.70)
The current update step is 6000
The current seed is 6197451469463137997
The current lr is: 0.0015
Testing Results:
 *   Acc@1 65.342
 *   Acc@1 65.797
 *   Acc@1 65.461
 *   Acc@1 65.942
 *   Acc@1 66.079
 *   Acc@1 66.095
 *   Acc@1 64.618
 *   Acc@1 64.461
 *   Acc@1 64.355
 *   Acc@1 64.618
 *   Acc@1 64.579
 *   Acc@1 64.431
Training for 300 epoch: 64.98026315789474
Training for 600 epoch: 64.90789473684211
Training for 1000 epoch: 65.32894736842105
Training for 300 epoch: 65.12916666666666
Training for 600 epoch: 65.28041666666667
Training for 1000 epoch: 65.26291666666667
[[64.98026315789474, 64.90789473684211, 65.32894736842105], [65.12916666666666, 65.28041666666667, 65.26291666666667]]
train loss 1.2274865564982096, epoch 199, best loss 0.4521389428456624, best_epoch 174
GPU_0_using curriculum 40 with window 40
Epoch: [200][20/30]	Time  1.643 ( 1.588)	Data  0.043 ( 0.073)	InnerLoop  0.761 ( 0.668)	Loss 6.0021e-01 (5.6620e-01)	Acc@1  76.59 ( 80.13)
The current update step is 6030
GPU_0_using curriculum 40 with window 40
Epoch: [201][20/30]	Time  1.556 ( 1.580)	Data  0.040 ( 0.060)	InnerLoop  0.668 ( 0.674)	Loss 5.0394e-01 (5.3740e-01)	Acc@1  83.15 ( 81.10)
The current update step is 6060
GPU_0_using curriculum 40 with window 40
Epoch: [202][20/30]	Time  1.565 ( 1.569)	Data  0.043 ( 0.046)	InnerLoop  0.672 ( 0.680)	Loss 5.5824e-01 (5.5618e-01)	Acc@1  79.22 ( 81.06)
The current update step is 6090
GPU_0_using curriculum 40 with window 40
Epoch: [203][20/30]	Time  1.552 ( 1.558)	Data  0.040 ( 0.051)	InnerLoop  0.655 ( 0.670)	Loss 5.4195e-01 (5.2558e-01)	Acc@1  81.27 ( 81.78)
The current update step is 6120
GPU_0_using curriculum 40 with window 40
Epoch: [204][20/30]	Time  1.664 ( 1.580)	Data  0.161 ( 0.071)	InnerLoop  0.670 ( 0.664)	Loss 5.8150e-01 (5.6266e-01)	Acc@1  80.30 ( 80.33)
The current update step is 6150
The current seed is 1455047035789172687
The current lr is: 0.0015
Testing Results:
 *   Acc@1 76.447
 *   Acc@1 76.932
 *   Acc@1 76.513
 *   Acc@1 77.046
 *   Acc@1 76.342
 *   Acc@1 76.615
 *   Acc@1 77.039
 *   Acc@1 77.859
 *   Acc@1 77.513
 *   Acc@1 78.519
 *   Acc@1 77.684
 *   Acc@1 78.657
Training for 300 epoch: 76.74342105263158
Training for 600 epoch: 77.01315789473684
Training for 1000 epoch: 77.01315789473685
Training for 300 epoch: 77.39541666666668
Training for 600 epoch: 77.7825
Training for 1000 epoch: 77.63624999999999
[[76.74342105263158, 77.01315789473684, 77.01315789473685], [77.39541666666668, 77.7825, 77.63624999999999]]
train loss 0.49316361088752747, epoch 204, best loss 0.4521389428456624, best_epoch 174
GPU_0_using curriculum 40 with window 40
Epoch: [205][20/30]	Time  1.509 ( 1.557)	Data  0.043 ( 0.052)	InnerLoop  0.638 ( 0.665)	Loss 5.0720e-01 (5.3103e-01)	Acc@1  82.47 ( 81.43)
The current update step is 6180
GPU_0_using curriculum 40 with window 40
Epoch: [206][20/30]	Time  1.664 ( 1.580)	Data  0.171 ( 0.072)	InnerLoop  0.648 ( 0.660)	Loss 5.1851e-01 (5.3999e-01)	Acc@1  81.62 ( 81.47)
The current update step is 6210
GPU_0_using curriculum 40 with window 40
Epoch: [207][20/30]	Time  1.567 ( 1.570)	Data  0.038 ( 0.058)	InnerLoop  0.648 ( 0.661)	Loss 6.3061e-01 (5.5692e-01)	Acc@1  78.74 ( 80.44)
The current update step is 6240
GPU_0_using curriculum 40 with window 40
Epoch: [208][20/30]	Time  1.522 ( 1.550)	Data  0.038 ( 0.045)	InnerLoop  0.634 ( 0.664)	Loss 7.5442e-01 (5.6545e-01)	Acc@1  75.29 ( 80.76)
The current update step is 6270
GPU_0_using curriculum 40 with window 40
Epoch: [209][20/30]	Time  1.520 ( 1.542)	Data  0.040 ( 0.068)	InnerLoop  0.640 ( 0.635)	Loss 5.3950e-01 (5.9487e-01)	Acc@1  82.15 ( 79.42)
The current update step is 6300
The current seed is 8031728310674878624
The current lr is: 0.0015
Testing Results:
 *   Acc@1 72.026
 *   Acc@1 72.516
 *   Acc@1 71.961
 *   Acc@1 72.522
 *   Acc@1 71.079
 *   Acc@1 72.262
 *   Acc@1 70.355
 *   Acc@1 70.674
 *   Acc@1 58.658
 *   Acc@1 58.371
 *   Acc@1 66.855
 *   Acc@1 66.959
Training for 300 epoch: 71.19078947368422
Training for 600 epoch: 65.3092105263158
Training for 1000 epoch: 68.96710526315789
Training for 300 epoch: 71.595
Training for 600 epoch: 65.44624999999999
Training for 1000 epoch: 69.61041666666667
[[71.19078947368422, 65.3092105263158, 68.96710526315789], [71.595, 65.44624999999999, 69.61041666666667]]
train loss 1.3926546769460042, epoch 209, best loss 0.4521389428456624, best_epoch 174
GPU_0_using curriculum 40 with window 40
Epoch: [210][20/30]	Time  1.608 ( 1.537)	Data  0.038 ( 0.068)	InnerLoop  0.738 ( 0.636)	Loss 5.1301e-01 (5.4785e-01)	Acc@1  81.96 ( 81.01)
The current update step is 6330
GPU_0_using curriculum 40 with window 40
Epoch: [211][20/30]	Time  1.562 ( 1.545)	Data  0.045 ( 0.058)	InnerLoop  0.656 ( 0.649)	Loss 5.1859e-01 (5.4127e-01)	Acc@1  81.08 ( 81.04)
The current update step is 6360
GPU_0_using curriculum 40 with window 40
Epoch: [212][20/30]	Time  1.527 ( 1.570)	Data  0.046 ( 0.048)	InnerLoop  0.642 ( 0.675)	Loss 5.1366e-01 (5.6745e-01)	Acc@1  82.15 ( 80.60)
The current update step is 6390
GPU_0_using curriculum 40 with window 40
Epoch: [213][20/30]	Time  1.514 ( 1.566)	Data  0.042 ( 0.052)	InnerLoop  0.642 ( 0.664)	Loss 4.9987e-01 (5.1727e-01)	Acc@1  82.20 ( 82.13)
The current update step is 6420
GPU_0_using curriculum 40 with window 40
Epoch: [214][20/30]	Time  1.667 ( 1.580)	Data  0.160 ( 0.070)	InnerLoop  0.646 ( 0.659)	Loss 5.8444e-01 (5.6431e-01)	Acc@1  78.25 ( 80.20)
The current update step is 6450
The current seed is 13734740005247095623
The current lr is: 0.0015
Testing Results:
 *   Acc@1 70.118
 *   Acc@1 70.373
 *   Acc@1 69.711
 *   Acc@1 69.953
 *   Acc@1 69.447
 *   Acc@1 69.854
 *   Acc@1 65.526
 *   Acc@1 65.989
 *   Acc@1 65.697
 *   Acc@1 66.021
 *   Acc@1 65.737
 *   Acc@1 66.286
Training for 300 epoch: 67.82236842105263
Training for 600 epoch: 67.70394736842105
Training for 1000 epoch: 67.59210526315789
Training for 300 epoch: 68.18125
Training for 600 epoch: 67.98708333333333
Training for 1000 epoch: 68.07
[[67.82236842105263, 67.70394736842105, 67.59210526315789], [68.18125, 67.98708333333333, 68.07]]
train loss 1.0204782515843709, epoch 214, best loss 0.4521389428456624, best_epoch 174
GPU_0_using curriculum 40 with window 40
Epoch: [215][20/30]	Time  1.534 ( 1.573)	Data  0.043 ( 0.052)	InnerLoop  0.654 ( 0.671)	Loss 5.3990e-01 (5.5272e-01)	Acc@1  82.98 ( 81.52)
The current update step is 6480
GPU_0_using curriculum 40 with window 40
Epoch: [216][20/30]	Time  1.663 ( 1.583)	Data  0.160 ( 0.071)	InnerLoop  0.652 ( 0.663)	Loss 6.0266e-01 (5.5628e-01)	Acc@1  79.39 ( 80.77)
The current update step is 6510
GPU_0_using curriculum 40 with window 40
Epoch: [217][20/30]	Time  1.544 ( 1.564)	Data  0.038 ( 0.058)	InnerLoop  0.644 ( 0.658)	Loss 5.3163e-01 (5.8718e-01)	Acc@1  81.03 ( 79.48)
The current update step is 6540
GPU_0_using curriculum 40 with window 40
Epoch: [218][20/30]	Time  1.565 ( 1.570)	Data  0.042 ( 0.046)	InnerLoop  0.663 ( 0.675)	Loss 5.7167e-01 (5.7269e-01)	Acc@1  79.76 ( 80.25)
The current update step is 6570
GPU_0_using curriculum 40 with window 40
Epoch: [219][20/30]	Time  1.576 ( 1.571)	Data  0.038 ( 0.071)	InnerLoop  0.668 ( 0.650)	Loss 7.9167e-01 (5.8836e-01)	Acc@1  69.78 ( 79.45)
The current update step is 6600
The current seed is 18344976500798731095
The current lr is: 0.0015
Testing Results:
 *   Acc@1 73.079
 *   Acc@1 73.123
 *   Acc@1 72.145
 *   Acc@1 72.442
 *   Acc@1 72.000
 *   Acc@1 72.019
 *   Acc@1 74.382
 *   Acc@1 74.740
 *   Acc@1 75.474
 *   Acc@1 75.358
 *   Acc@1 75.645
 *   Acc@1 75.673
Training for 300 epoch: 73.73026315789474
Training for 600 epoch: 73.80921052631578
Training for 1000 epoch: 73.82236842105263
Training for 300 epoch: 73.93125
Training for 600 epoch: 73.90041666666667
Training for 1000 epoch: 73.84625
[[73.73026315789474, 73.80921052631578, 73.82236842105263], [73.93125, 73.90041666666667, 73.84625]]
train loss 0.6007506639480591, epoch 219, best loss 0.4521389428456624, best_epoch 174
GPU_0_using curriculum 40 with window 40
Epoch: [220][20/30]	Time  1.701 ( 1.570)	Data  0.044 ( 0.071)	InnerLoop  0.795 ( 0.652)	Loss 5.0478e-01 (5.7025e-01)	Acc@1  82.93 ( 79.80)
The current update step is 6630
GPU_0_using curriculum 40 with window 40
Epoch: [221][20/30]	Time  1.524 ( 1.565)	Data  0.036 ( 0.058)	InnerLoop  0.637 ( 0.661)	Loss 6.4027e-01 (5.8082e-01)	Acc@1  81.54 ( 80.09)
The current update step is 6660
GPU_0_using curriculum 40 with window 40
Epoch: [222][20/30]	Time  1.515 ( 1.565)	Data  0.041 ( 0.045)	InnerLoop  0.632 ( 0.673)	Loss 5.1406e-01 (5.5345e-01)	Acc@1  82.40 ( 80.83)
The current update step is 6690
GPU_0_using curriculum 40 with window 40
Epoch: [223][20/30]	Time  1.560 ( 1.571)	Data  0.042 ( 0.051)	InnerLoop  0.651 ( 0.668)	Loss 5.7038e-01 (5.4407e-01)	Acc@1  80.27 ( 81.18)
The current update step is 6720
GPU_0_using curriculum 40 with window 40
Epoch: [224][20/30]	Time  1.679 ( 1.576)	Data  0.169 ( 0.072)	InnerLoop  0.650 ( 0.652)	Loss 5.9848e-01 (5.3298e-01)	Acc@1  80.08 ( 81.56)
The current update step is 6750
The current seed is 4599000543186385132
The current lr is: 0.0015
Testing Results:
 *   Acc@1 64.118
 *   Acc@1 64.168
 *   Acc@1 67.303
 *   Acc@1 67.433
 *   Acc@1 69.987
 *   Acc@1 69.742
 *   Acc@1 65.776
 *   Acc@1 65.267
 *   Acc@1 54.513
 *   Acc@1 54.542
 *   Acc@1 54.145
 *   Acc@1 54.477
Training for 300 epoch: 64.94736842105263
Training for 600 epoch: 60.90789473684211
Training for 1000 epoch: 62.06578947368421
Training for 300 epoch: 64.71791666666667
Training for 600 epoch: 60.98708333333333
Training for 1000 epoch: 62.10958333333333
[[64.94736842105263, 60.90789473684211, 62.06578947368421], [64.71791666666667, 60.98708333333333, 62.10958333333333]]
train loss 1.4270985125859579, epoch 224, best loss 0.4521389428456624, best_epoch 174
GPU_0_using curriculum 40 with window 40
Epoch: [225][20/30]	Time  1.544 ( 1.574)	Data  0.043 ( 0.053)	InnerLoop  0.661 ( 0.674)	Loss 5.6734e-01 (5.3634e-01)	Acc@1  81.57 ( 81.42)
The current update step is 6780
GPU_0_using curriculum 40 with window 40
Epoch: [226][20/30]	Time  1.642 ( 1.572)	Data  0.157 ( 0.071)	InnerLoop  0.648 ( 0.656)	Loss 6.5307e-01 (5.6460e-01)	Acc@1  76.10 ( 80.43)
The current update step is 6810
GPU_0_using curriculum 40 with window 40
Epoch: [227][20/30]	Time  1.543 ( 1.570)	Data  0.043 ( 0.059)	InnerLoop  0.632 ( 0.660)	Loss 7.2746e-01 (5.9153e-01)	Acc@1  73.78 ( 79.46)
The current update step is 6840
GPU_0_using curriculum 40 with window 40
Epoch: [228][20/30]	Time  1.527 ( 1.560)	Data  0.043 ( 0.046)	InnerLoop  0.642 ( 0.669)	Loss 6.8656e-01 (5.7334e-01)	Acc@1  73.90 ( 79.91)
The current update step is 6870
GPU_0_using curriculum 40 with window 40
Epoch: [229][20/30]	Time  1.583 ( 1.570)	Data  0.043 ( 0.071)	InnerLoop  0.684 ( 0.649)	Loss 4.9972e-01 (5.4839e-01)	Acc@1  83.18 ( 81.27)
The current update step is 6900
The current seed is 366759911492924750
The current lr is: 0.0015
Testing Results:
 *   Acc@1 74.750
 *   Acc@1 75.100
 *   Acc@1 75.224
 *   Acc@1 75.709
 *   Acc@1 75.355
 *   Acc@1 75.823
 *   Acc@1 73.987
 *   Acc@1 74.700
 *   Acc@1 45.092
 *   Acc@1 45.532
 *   Acc@1 43.776
 *   Acc@1 44.453
Training for 300 epoch: 74.36842105263159
Training for 600 epoch: 60.15789473684211
Training for 1000 epoch: 59.56578947368421
Training for 300 epoch: 74.9
Training for 600 epoch: 60.620416666666664
Training for 1000 epoch: 60.138333333333335
[[74.36842105263159, 60.15789473684211, 59.56578947368421], [74.9, 60.620416666666664, 60.138333333333335]]
train loss 2.0090944286346435, epoch 229, best loss 0.4521389428456624, best_epoch 174
GPU_0_using curriculum 40 with window 40
Epoch: [230][20/30]	Time  1.653 ( 1.573)	Data  0.038 ( 0.072)	InnerLoop  0.772 ( 0.653)	Loss 5.2864e-01 (5.6818e-01)	Acc@1  81.25 ( 80.47)
The current update step is 6930
GPU_0_using curriculum 40 with window 40
Epoch: [231][20/30]	Time  1.521 ( 1.569)	Data  0.042 ( 0.059)	InnerLoop  0.642 ( 0.661)	Loss 5.7773e-01 (5.8442e-01)	Acc@1  81.08 ( 80.56)
The current update step is 6960
GPU_0_using curriculum 40 with window 40
Epoch: [232][20/30]	Time  1.529 ( 1.571)	Data  0.040 ( 0.047)	InnerLoop  0.631 ( 0.677)	Loss 6.3194e-01 (5.5566e-01)	Acc@1  76.54 ( 80.35)
The current update step is 6990
GPU_0_using curriculum 40 with window 40
Epoch: [233][20/30]	Time  1.523 ( 1.572)	Data  0.040 ( 0.052)	InnerLoop  0.640 ( 0.671)	Loss 5.9748e-01 (5.6586e-01)	Acc@1  79.49 ( 80.68)
The current update step is 7020
GPU_0_using curriculum 40 with window 40
Epoch: [234][20/30]	Time  1.684 ( 1.575)	Data  0.168 ( 0.071)	InnerLoop  0.661 ( 0.655)	Loss 5.1927e-01 (5.4753e-01)	Acc@1  82.15 ( 81.19)
The current update step is 7050
The current seed is 7760072544480237121
The current lr is: 0.0015
Testing Results:
 *   Acc@1 76.066
 *   Acc@1 76.703
 *   Acc@1 76.092
 *   Acc@1 76.931
 *   Acc@1 76.197
 *   Acc@1 76.978
 *   Acc@1 73.579
 *   Acc@1 73.897
 *   Acc@1 73.447
 *   Acc@1 73.855
 *   Acc@1 73.250
 *   Acc@1 73.825
Training for 300 epoch: 74.82236842105263
Training for 600 epoch: 74.76973684210526
Training for 1000 epoch: 74.72368421052632
Training for 300 epoch: 75.29958333333333
Training for 600 epoch: 75.39291666666668
Training for 1000 epoch: 75.40125
[[74.82236842105263, 74.76973684210526, 74.72368421052632], [75.29958333333333, 75.39291666666668, 75.40125]]
train loss 0.6505110067685446, epoch 234, best loss 0.4521389428456624, best_epoch 234
GPU_0_using curriculum 40 with window 40
Epoch: [235][20/30]	Time  1.544 ( 1.571)	Data  0.049 ( 0.053)	InnerLoop  0.642 ( 0.668)	Loss 5.3755e-01 (5.3851e-01)	Acc@1  80.64 ( 81.25)
The current update step is 7080
GPU_0_using curriculum 40 with window 40
Epoch: [236][20/30]	Time  1.680 ( 1.582)	Data  0.165 ( 0.072)	InnerLoop  0.670 ( 0.655)	Loss 4.8788e-01 (5.6313e-01)	Acc@1  83.28 ( 80.51)
The current update step is 7110
GPU_0_using curriculum 40 with window 40
Epoch: [237][20/30]	Time  1.537 ( 1.576)	Data  0.044 ( 0.060)	InnerLoop  0.651 ( 0.663)	Loss 6.1163e-01 (5.2927e-01)	Acc@1  78.78 ( 81.48)
The current update step is 7140
GPU_0_using curriculum 40 with window 40
Epoch: [238][20/30]	Time  1.586 ( 1.577)	Data  0.044 ( 0.047)	InnerLoop  0.674 ( 0.677)	Loss 4.5461e-01 (5.3375e-01)	Acc@1  84.13 ( 81.70)
The current update step is 7170
GPU_0_using curriculum 40 with window 40
Epoch: [239][20/30]	Time  1.576 ( 1.581)	Data  0.041 ( 0.073)	InnerLoop  0.665 ( 0.654)	Loss 5.5449e-01 (5.8083e-01)	Acc@1  81.25 ( 79.20)
The current update step is 7200
The current seed is 7261401923130757637
The current lr is: 0.0015
Testing Results:
 *   Acc@1 68.171
 *   Acc@1 68.311
 *   Acc@1 68.395
 *   Acc@1 68.582
 *   Acc@1 68.289
 *   Acc@1 68.653
 *   Acc@1 57.395
 *   Acc@1 58.277
 *   Acc@1 59.895
 *   Acc@1 60.108
 *   Acc@1 68.079
 *   Acc@1 68.524
Training for 300 epoch: 62.7828947368421
Training for 600 epoch: 64.14473684210526
Training for 1000 epoch: 68.18421052631578
Training for 300 epoch: 63.29375
Training for 600 epoch: 64.34458333333333
Training for 1000 epoch: 68.58833333333334
[[62.7828947368421, 64.14473684210526, 68.18421052631578], [63.29375, 64.34458333333333, 68.58833333333334]]
train loss 0.7900604458808899, epoch 239, best loss 0.4521389428456624, best_epoch 234
GPU_0_using curriculum 40 with window 40
Epoch: [240][20/30]	Time  1.695 ( 1.575)	Data  0.046 ( 0.072)	InnerLoop  0.784 ( 0.655)	Loss 4.8554e-01 (5.2785e-01)	Acc@1  83.47 ( 81.88)
The current update step is 7230
GPU_0_using curriculum 40 with window 40
Epoch: [241][20/30]	Time  1.511 ( 1.574)	Data  0.037 ( 0.060)	InnerLoop  0.636 ( 0.666)	Loss 4.5956e-01 (5.2768e-01)	Acc@1  84.08 ( 82.03)
The current update step is 7260
GPU_0_using curriculum 40 with window 40
Epoch: [242][20/30]	Time  1.531 ( 1.577)	Data  0.041 ( 0.048)	InnerLoop  0.649 ( 0.684)	Loss 4.5953e-01 (5.4627e-01)	Acc@1  84.40 ( 81.23)
The current update step is 7290
GPU_0_using curriculum 40 with window 40
Epoch: [243][20/30]	Time  1.582 ( 1.582)	Data  0.044 ( 0.053)	InnerLoop  0.677 ( 0.681)	Loss 5.4065e-01 (5.5068e-01)	Acc@1  80.13 ( 80.79)
The current update step is 7320
GPU_0_using curriculum 40 with window 40
Epoch: [244][20/30]	Time  1.659 ( 1.576)	Data  0.160 ( 0.071)	InnerLoop  0.655 ( 0.663)	Loss 6.3796e-01 (5.6634e-01)	Acc@1  76.03 ( 80.48)
The current update step is 7350
The current seed is 8670142929553025592
The current lr is: 0.0015
Testing Results:
 *   Acc@1 73.118
 *   Acc@1 73.157
 *   Acc@1 72.645
 *   Acc@1 72.805
 *   Acc@1 72.474
 *   Acc@1 72.784
 *   Acc@1 75.526
 *   Acc@1 75.870
 *   Acc@1 76.289
 *   Acc@1 76.784
 *   Acc@1 76.408
 *   Acc@1 77.081
Training for 300 epoch: 74.32236842105263
Training for 600 epoch: 74.46710526315789
Training for 1000 epoch: 74.44078947368422
Training for 300 epoch: 74.51333333333334
Training for 600 epoch: 74.79458333333334
Training for 1000 epoch: 74.9325
[[74.32236842105263, 74.46710526315789, 74.44078947368422], [74.51333333333334, 74.79458333333334, 74.9325]]
train loss 0.5674184317906698, epoch 244, best loss 0.4521389428456624, best_epoch 234
GPU_0_using curriculum 40 with window 40
Epoch: [245][20/30]	Time  1.521 ( 1.546)	Data  0.040 ( 0.051)	InnerLoop  0.638 ( 0.663)	Loss 5.3874e-01 (5.6323e-01)	Acc@1  81.08 ( 80.23)
The current update step is 7380
GPU_0_using curriculum 40 with window 40
Epoch: [246][20/30]	Time  1.633 ( 1.551)	Data  0.161 ( 0.068)	InnerLoop  0.642 ( 0.650)	Loss 5.2247e-01 (5.9251e-01)	Acc@1  81.49 ( 79.06)
The current update step is 7410
GPU_0_using curriculum 40 with window 40
Epoch: [247][20/30]	Time  1.506 ( 1.547)	Data  0.038 ( 0.057)	InnerLoop  0.638 ( 0.658)	Loss 6.8458e-01 (5.9233e-01)	Acc@1  75.95 ( 78.92)
The current update step is 7440
GPU_0_using curriculum 40 with window 40
Epoch: [248][20/30]	Time  1.505 ( 1.544)	Data  0.037 ( 0.044)	InnerLoop  0.634 ( 0.667)	Loss 7.8025e-01 (5.6315e-01)	Acc@1  71.36 ( 80.48)
The current update step is 7470
GPU_0_using curriculum 40 with window 40
Epoch: [249][20/30]	Time  1.510 ( 1.540)	Data  0.041 ( 0.069)	InnerLoop  0.642 ( 0.642)	Loss 4.9392e-01 (5.6610e-01)	Acc@1  82.84 ( 80.70)
The current update step is 7500
The current seed is 5617653697592273578
The current lr is: 0.0015
Testing Results:
 *   Acc@1 73.605
 *   Acc@1 73.698
 *   Acc@1 74.039
 *   Acc@1 74.343
 *   Acc@1 74.461
 *   Acc@1 74.837
 *   Acc@1 73.500
 *   Acc@1 74.632
 *   Acc@1 71.776
 *   Acc@1 72.618
 *   Acc@1 71.276
 *   Acc@1 71.737
Training for 300 epoch: 73.55263157894737
Training for 600 epoch: 72.90789473684211
Training for 1000 epoch: 72.86842105263159
Training for 300 epoch: 74.16541666666666
Training for 600 epoch: 73.48083333333334
Training for 1000 epoch: 73.28666666666666
[[73.55263157894737, 72.90789473684211, 72.86842105263159], [74.16541666666666, 73.48083333333334, 73.28666666666666]]
train loss 0.6271531676292419, epoch 249, best loss 0.4521389428456624, best_epoch 234
GPU_0_using curriculum 40 with window 40
Epoch: [250][20/30]	Time  1.623 ( 1.551)	Data  0.037 ( 0.068)	InnerLoop  0.760 ( 0.652)	Loss 5.0188e-01 (5.2019e-01)	Acc@1  81.27 ( 81.95)
The current update step is 7530
GPU_0_using curriculum 40 with window 40
Epoch: [251][20/30]	Time  1.502 ( 1.537)	Data  0.037 ( 0.057)	InnerLoop  0.637 ( 0.651)	Loss 4.7328e-01 (5.4359e-01)	Acc@1  84.16 ( 81.20)
The current update step is 7560
GPU_0_using curriculum 40 with window 40
Epoch: [252][20/30]	Time  1.560 ( 1.568)	Data  0.039 ( 0.044)	InnerLoop  0.633 ( 0.672)	Loss 5.9384e-01 (5.3994e-01)	Acc@1  79.69 ( 81.35)
The current update step is 7590
GPU_0_using curriculum 40 with window 40
Epoch: [253][20/30]	Time  1.508 ( 1.552)	Data  0.040 ( 0.050)	InnerLoop  0.641 ( 0.664)	Loss 5.2594e-01 (5.3054e-01)	Acc@1  81.18 ( 81.75)
The current update step is 7620
GPU_0_using curriculum 40 with window 40
Epoch: [254][20/30]	Time  1.628 ( 1.564)	Data  0.157 ( 0.068)	InnerLoop  0.628 ( 0.645)	Loss 5.1445e-01 (5.1685e-01)	Acc@1  82.01 ( 82.28)
The current update step is 7650
The current seed is 8388609953953494927
The current lr is: 0.0015
Testing Results:
 *   Acc@1 77.263
 *   Acc@1 78.114
 *   Acc@1 76.566
 *   Acc@1 77.200
 *   Acc@1 76.013
 *   Acc@1 76.971
 *   Acc@1 68.461
 *   Acc@1 68.697
 *   Acc@1 68.605
 *   Acc@1 69.203
 *   Acc@1 68.671
 *   Acc@1 69.647
Training for 300 epoch: 72.86184210526315
Training for 600 epoch: 72.58552631578948
Training for 1000 epoch: 72.34210526315789
Training for 300 epoch: 73.40541666666667
Training for 600 epoch: 73.20166666666667
Training for 1000 epoch: 73.30916666666667
[[72.86184210526315, 72.58552631578948, 72.34210526315789], [73.40541666666667, 73.20166666666667, 73.30916666666667]]
train loss 0.7655043327013652, epoch 254, best loss 0.4521389428456624, best_epoch 234
GPU_0_using curriculum 40 with window 40
Epoch: [255][20/30]	Time  1.505 ( 1.540)	Data  0.040 ( 0.050)	InnerLoop  0.633 ( 0.655)	Loss 5.1731e-01 (5.6263e-01)	Acc@1  82.01 ( 80.22)
The current update step is 7680
GPU_0_using curriculum 40 with window 40
Epoch: [256][20/30]	Time  1.667 ( 1.537)	Data  0.153 ( 0.067)	InnerLoop  0.653 ( 0.638)	Loss 5.4338e-01 (5.5159e-01)	Acc@1  81.45 ( 80.96)
The current update step is 7710
GPU_0_using curriculum 40 with window 40
Epoch: [257][20/30]	Time  1.531 ( 1.542)	Data  0.038 ( 0.056)	InnerLoop  0.647 ( 0.650)	Loss 5.7600e-01 (5.5041e-01)	Acc@1  78.78 ( 80.82)
The current update step is 7740
GPU_0_using curriculum 40 with window 40
Epoch: [258][20/30]	Time  1.547 ( 1.548)	Data  0.042 ( 0.044)	InnerLoop  0.639 ( 0.665)	Loss 4.5395e-01 (5.7737e-01)	Acc@1  83.94 ( 79.64)
The current update step is 7770
GPU_0_using curriculum 40 with window 40
Epoch: [259][20/30]	Time  1.511 ( 1.541)	Data  0.038 ( 0.068)	InnerLoop  0.634 ( 0.637)	Loss 4.8044e-01 (5.6146e-01)	Acc@1  83.62 ( 80.62)
The current update step is 7800
The current seed is 11024666527612241207
The current lr is: 0.0015
Testing Results:
 *   Acc@1 67.237
 *   Acc@1 68.273
 *   Acc@1 67.658
 *   Acc@1 68.651
 *   Acc@1 68.053
 *   Acc@1 68.938
 *   Acc@1 77.039
 *   Acc@1 77.688
 *   Acc@1 77.079
 *   Acc@1 77.644
 *   Acc@1 77.145
 *   Acc@1 77.867
Training for 300 epoch: 72.13815789473685
Training for 600 epoch: 72.36842105263159
Training for 1000 epoch: 72.59868421052632
Training for 300 epoch: 72.98083333333332
Training for 600 epoch: 73.14750000000001
Training for 1000 epoch: 73.4025
[[72.13815789473685, 72.36842105263159, 72.59868421052632], [72.98083333333332, 73.14750000000001, 73.4025]]
train loss 0.5868892869313558, epoch 259, best loss 0.4521389428456624, best_epoch 234
GPU_0_using curriculum 40 with window 40
Epoch: [260][20/30]	Time  1.639 ( 1.544)	Data  0.039 ( 0.068)	InnerLoop  0.751 ( 0.642)	Loss 5.1249e-01 (5.4396e-01)	Acc@1  82.08 ( 81.62)
The current update step is 7830
GPU_0_using curriculum 40 with window 40
Epoch: [261][20/30]	Time  1.509 ( 1.535)	Data  0.039 ( 0.056)	InnerLoop  0.638 ( 0.646)	Loss 5.4414e-01 (5.4061e-01)	Acc@1  81.67 ( 81.41)
The current update step is 7860
GPU_0_using curriculum 40 with window 40
Epoch: [262][20/30]	Time  1.508 ( 1.534)	Data  0.041 ( 0.044)	InnerLoop  0.630 ( 0.658)	Loss 4.7647e-01 (5.6983e-01)	Acc@1  82.76 ( 80.24)
The current update step is 7890
GPU_0_using curriculum 40 with window 40
Epoch: [263][20/30]	Time  1.503 ( 1.536)	Data  0.038 ( 0.051)	InnerLoop  0.637 ( 0.652)	Loss 4.4907e-01 (5.3739e-01)	Acc@1  85.11 ( 81.51)
The current update step is 7920
GPU_0_using curriculum 40 with window 40
Epoch: [264][20/30]	Time  1.637 ( 1.540)	Data  0.158 ( 0.067)	InnerLoop  0.637 ( 0.639)	Loss 5.7878e-01 (5.6088e-01)	Acc@1  79.08 ( 80.49)
The current update step is 7950
The current seed is 15095636731866154156
The current lr is: 0.0015
Testing Results:
 *   Acc@1 75.039
 *   Acc@1 75.714
 *   Acc@1 68.303
 *   Acc@1 68.926
 *   Acc@1 68.500
 *   Acc@1 68.940
 *   Acc@1 57.803
 *   Acc@1 57.307
 *   Acc@1 60.263
 *   Acc@1 60.282
 *   Acc@1 60.934
 *   Acc@1 60.862
Training for 300 epoch: 66.42105263157895
Training for 600 epoch: 64.28289473684211
Training for 1000 epoch: 64.71710526315789
Training for 300 epoch: 66.51041666666667
Training for 600 epoch: 64.60416666666666
Training for 1000 epoch: 64.90083333333334
[[66.42105263157895, 64.28289473684211, 64.71710526315789], [66.51041666666667, 64.60416666666666, 64.90083333333334]]
train loss 1.1240980854670206, epoch 264, best loss 0.4521389428456624, best_epoch 234
GPU_0_using curriculum 40 with window 40
Epoch: [265][20/30]	Time  1.517 ( 1.540)	Data  0.040 ( 0.050)	InnerLoop  0.643 ( 0.656)	Loss 5.9071e-01 (5.3725e-01)	Acc@1  77.00 ( 81.08)
The current update step is 7980
GPU_0_using curriculum 40 with window 40
Epoch: [266][20/30]	Time  1.621 ( 1.537)	Data  0.154 ( 0.068)	InnerLoop  0.628 ( 0.638)	Loss 6.1064e-01 (5.5674e-01)	Acc@1  78.37 ( 80.86)
The current update step is 8010
GPU_0_using curriculum 40 with window 40
Epoch: [267][20/30]	Time  1.497 ( 1.548)	Data  0.039 ( 0.056)	InnerLoop  0.628 ( 0.651)	Loss 5.4732e-01 (5.7870e-01)	Acc@1  79.66 ( 79.81)
The current update step is 8040
GPU_0_using curriculum 40 with window 40
Epoch: [268][20/30]	Time  1.538 ( 1.547)	Data  0.040 ( 0.044)	InnerLoop  0.657 ( 0.664)	Loss 8.2296e-01 (5.8879e-01)	Acc@1  66.85 ( 79.22)
The current update step is 8070
GPU_0_using curriculum 40 with window 40
Epoch: [269][20/30]	Time  1.521 ( 1.557)	Data  0.038 ( 0.070)	InnerLoop  0.643 ( 0.644)	Loss 4.9869e-01 (5.8074e-01)	Acc@1  82.40 ( 79.28)
The current update step is 8100
The current seed is 7952597808164925114
The current lr is: 0.0015
Testing Results:
 *   Acc@1 61.316
 *   Acc@1 61.800
 *   Acc@1 62.434
 *   Acc@1 62.946
 *   Acc@1 62.671
 *   Acc@1 63.197
 *   Acc@1 72.197
 *   Acc@1 73.079
 *   Acc@1 72.066
 *   Acc@1 72.625
 *   Acc@1 72.105
 *   Acc@1 72.593
Training for 300 epoch: 66.75657894736842
Training for 600 epoch: 67.25
Training for 1000 epoch: 67.38815789473685
Training for 300 epoch: 67.43958333333333
Training for 600 epoch: 67.78541666666666
Training for 1000 epoch: 67.895
[[66.75657894736842, 67.25, 67.38815789473685], [67.43958333333333, 67.78541666666666, 67.895]]
train loss 0.732539129670461, epoch 269, best loss 0.4521389428456624, best_epoch 234
GPU_0_using curriculum 40 with window 40
Epoch: [270][20/30]	Time  1.624 ( 1.534)	Data  0.039 ( 0.067)	InnerLoop  0.753 ( 0.638)	Loss 5.2106e-01 (5.5393e-01)	Acc@1  82.20 ( 80.63)
The current update step is 8130
GPU_0_using curriculum 40 with window 40
Epoch: [271][20/30]	Time  1.503 ( 1.530)	Data  0.037 ( 0.056)	InnerLoop  0.641 ( 0.644)	Loss 5.2695e-01 (5.5387e-01)	Acc@1  81.15 ( 80.92)
The current update step is 8160
GPU_0_using curriculum 40 with window 40
Epoch: [272][20/30]	Time  1.516 ( 1.532)	Data  0.042 ( 0.045)	InnerLoop  0.633 ( 0.656)	Loss 5.9222e-01 (5.6661e-01)	Acc@1  77.91 ( 80.48)
The current update step is 8190
GPU_0_using curriculum 40 with window 40
Epoch: [273][20/30]	Time  1.513 ( 1.552)	Data  0.039 ( 0.051)	InnerLoop  0.636 ( 0.660)	Loss 4.9758e-01 (5.6905e-01)	Acc@1  83.23 ( 80.31)
The current update step is 8220
GPU_0_using curriculum 40 with window 40
Epoch: [274][20/30]	Time  1.636 ( 1.556)	Data  0.157 ( 0.069)	InnerLoop  0.639 ( 0.649)	Loss 5.0579e-01 (5.7608e-01)	Acc@1  82.50 ( 79.54)
The current update step is 8250
The current seed is 269169817901676951
The current lr is: 0.0015
Testing Results:
 *   Acc@1 77.500
 *   Acc@1 78.576
 *   Acc@1 77.553
 *   Acc@1 78.627
 *   Acc@1 77.605
 *   Acc@1 78.673
 *   Acc@1 73.013
 *   Acc@1 72.941
 *   Acc@1 72.395
 *   Acc@1 72.695
 *   Acc@1 72.421
 *   Acc@1 72.565
Training for 300 epoch: 75.25657894736841
Training for 600 epoch: 74.97368421052632
Training for 1000 epoch: 75.01315789473685
Training for 300 epoch: 75.75833333333333
Training for 600 epoch: 75.66125
Training for 1000 epoch: 75.61916666666667
[[75.25657894736841, 74.97368421052632, 75.01315789473685], [75.75833333333333, 75.66125, 75.61916666666667]]
train loss 0.6016909296035766, epoch 274, best loss 0.4521389428456624, best_epoch 234
GPU_0_using curriculum 40 with window 40
Epoch: [275][20/30]	Time  1.535 ( 1.553)	Data  0.038 ( 0.051)	InnerLoop  0.641 ( 0.661)	Loss 6.9270e-01 (5.5423e-01)	Acc@1  75.78 ( 80.72)
The current update step is 8280
GPU_0_using curriculum 40 with window 40
Epoch: [276][20/30]	Time  1.634 ( 1.556)	Data  0.156 ( 0.071)	InnerLoop  0.639 ( 0.646)	Loss 5.2646e-01 (5.4070e-01)	Acc@1  81.98 ( 81.24)
The current update step is 8310
GPU_0_using curriculum 40 with window 40
Epoch: [277][20/30]	Time  1.556 ( 1.555)	Data  0.045 ( 0.059)	InnerLoop  0.654 ( 0.655)	Loss 4.8832e-01 (5.7131e-01)	Acc@1  82.40 ( 80.18)
The current update step is 8340
GPU_0_using curriculum 40 with window 40
Epoch: [278][20/30]	Time  1.519 ( 1.548)	Data  0.038 ( 0.045)	InnerLoop  0.639 ( 0.664)	Loss 5.3361e-01 (5.4319e-01)	Acc@1  81.18 ( 81.06)
The current update step is 8370
GPU_0_using curriculum 40 with window 40
Epoch: [279][20/30]	Time  1.527 ( 1.550)	Data  0.039 ( 0.070)	InnerLoop  0.635 ( 0.642)	Loss 5.1063e-01 (5.4577e-01)	Acc@1  83.35 ( 80.93)
The current update step is 8400
The current seed is 6872801223796346422
The current lr is: 0.0015
Testing Results:
 *   Acc@1 74.618
 *   Acc@1 75.216
 *   Acc@1 74.908
 *   Acc@1 75.815
 *   Acc@1 75.421
 *   Acc@1 76.361
 *   Acc@1 70.066
 *   Acc@1 70.445
 *   Acc@1 69.895
 *   Acc@1 70.178
 *   Acc@1 70.750
 *   Acc@1 71.071
Training for 300 epoch: 72.34210526315789
Training for 600 epoch: 72.40131578947368
Training for 1000 epoch: 73.08552631578948
Training for 300 epoch: 72.83041666666666
Training for 600 epoch: 72.99666666666667
Training for 1000 epoch: 73.71583333333334
[[72.34210526315789, 72.40131578947368, 73.08552631578948], [72.83041666666666, 72.99666666666667, 73.71583333333334]]
train loss 0.9347435751914978, epoch 279, best loss 0.4521389428456624, best_epoch 234
GPU_0_using curriculum 40 with window 40
Epoch: [280][20/30]	Time  1.645 ( 1.544)	Data  0.038 ( 0.067)	InnerLoop  0.762 ( 0.647)	Loss 6.0583e-01 (5.7664e-01)	Acc@1  79.42 ( 80.11)
The current update step is 8430
GPU_0_using curriculum 40 with window 40
Epoch: [281][20/30]	Time  1.517 ( 1.540)	Data  0.037 ( 0.057)	InnerLoop  0.638 ( 0.653)	Loss 5.0905e-01 (5.8866e-01)	Acc@1  82.50 ( 79.45)
The current update step is 8460
GPU_0_using curriculum 40 with window 40
Epoch: [282][20/30]	Time  1.510 ( 1.540)	Data  0.038 ( 0.045)	InnerLoop  0.648 ( 0.665)	Loss 5.2466e-01 (5.5210e-01)	Acc@1  81.91 ( 81.10)
The current update step is 8490
GPU_0_using curriculum 40 with window 40
Epoch: [283][20/30]	Time  1.509 ( 1.538)	Data  0.039 ( 0.049)	InnerLoop  0.629 ( 0.659)	Loss 5.0905e-01 (5.1412e-01)	Acc@1  81.98 ( 82.21)
The current update step is 8520
GPU_0_using curriculum 40 with window 40
Epoch: [284][20/30]	Time  1.652 ( 1.558)	Data  0.161 ( 0.070)	InnerLoop  0.656 ( 0.654)	Loss 5.2398e-01 (5.4669e-01)	Acc@1  83.30 ( 81.04)
The current update step is 8550
The current seed is 16121852171985828928
The current lr is: 0.0015
Testing Results:
 *   Acc@1 58.447
 *   Acc@1 58.443
 *   Acc@1 53.539
 *   Acc@1 53.563
 *   Acc@1 52.882
 *   Acc@1 52.833
 *   Acc@1 64.974
 *   Acc@1 65.287
 *   Acc@1 64.895
 *   Acc@1 65.143
 *   Acc@1 65.658
 *   Acc@1 65.828
Training for 300 epoch: 61.71052631578947
Training for 600 epoch: 59.21710526315789
Training for 1000 epoch: 59.26973684210526
Training for 300 epoch: 61.864999999999995
Training for 600 epoch: 59.35333333333333
Training for 1000 epoch: 59.330416666666665
[[61.71052631578947, 59.21710526315789, 59.26973684210526], [61.864999999999995, 59.35333333333333, 59.330416666666665]]
train loss 0.8676431599934896, epoch 284, best loss 0.4521389428456624, best_epoch 234
GPU_0_using curriculum 40 with window 40
Epoch: [285][20/30]	Time  1.571 ( 1.559)	Data  0.039 ( 0.051)	InnerLoop  0.654 ( 0.669)	Loss 5.4479e-01 (5.3881e-01)	Acc@1  80.79 ( 81.45)
The current update step is 8580
GPU_0_using curriculum 40 with window 40
Epoch: [286][20/30]	Time  1.696 ( 1.568)	Data  0.163 ( 0.069)	InnerLoop  0.681 ( 0.659)	Loss 5.2558e-01 (5.5922e-01)	Acc@1  82.20 ( 80.47)
The current update step is 8610
GPU_0_using curriculum 40 with window 40
Epoch: [287][20/30]	Time  1.523 ( 1.564)	Data  0.040 ( 0.057)	InnerLoop  0.649 ( 0.667)	Loss 5.7180e-01 (5.2615e-01)	Acc@1  79.81 ( 82.15)
The current update step is 8640
GPU_0_using curriculum 40 with window 40
Epoch: [288][20/30]	Time  1.536 ( 1.565)	Data  0.040 ( 0.045)	InnerLoop  0.652 ( 0.677)	Loss 6.4326e-01 (5.5143e-01)	Acc@1  77.37 ( 80.82)
The current update step is 8670
GPU_0_using curriculum 40 with window 40
Epoch: [289][20/30]	Time  1.546 ( 1.567)	Data  0.041 ( 0.071)	InnerLoop  0.657 ( 0.655)	Loss 5.6207e-01 (5.3543e-01)	Acc@1  80.54 ( 81.45)
The current update step is 8700
The current seed is 9958415530836166789
The current lr is: 0.0015
Testing Results:
 *   Acc@1 62.289
 *   Acc@1 63.041
 *   Acc@1 62.921
 *   Acc@1 63.460
 *   Acc@1 63.776
 *   Acc@1 64.467
 *   Acc@1 74.684
 *   Acc@1 74.457
 *   Acc@1 74.658
 *   Acc@1 74.318
 *   Acc@1 74.461
 *   Acc@1 74.265
Training for 300 epoch: 68.48684210526316
Training for 600 epoch: 68.78947368421052
Training for 1000 epoch: 69.11842105263159
Training for 300 epoch: 68.74875
Training for 600 epoch: 68.88916666666667
Training for 1000 epoch: 69.36583333333334
[[68.48684210526316, 68.78947368421052, 69.11842105263159], [68.74875, 68.88916666666667, 69.36583333333334]]
train loss 0.7035385196050008, epoch 289, best loss 0.4521389428456624, best_epoch 234
GPU_0_using curriculum 40 with window 40
Epoch: [290][20/30]	Time  1.646 ( 1.554)	Data  0.038 ( 0.068)	InnerLoop  0.762 ( 0.646)	Loss 6.4398e-01 (5.2872e-01)	Acc@1  77.17 ( 81.72)
The current update step is 8730
GPU_0_using curriculum 40 with window 40
Epoch: [291][20/30]	Time  1.541 ( 1.551)	Data  0.038 ( 0.057)	InnerLoop  0.646 ( 0.653)	Loss 5.0848e-01 (5.3453e-01)	Acc@1  83.35 ( 81.69)
The current update step is 8760
GPU_0_using curriculum 40 with window 40
Epoch: [292][20/30]	Time  1.532 ( 1.557)	Data  0.040 ( 0.045)	InnerLoop  0.644 ( 0.668)	Loss 5.6530e-01 (5.3680e-01)	Acc@1  79.79 ( 81.61)
The current update step is 8790
GPU_0_using curriculum 40 with window 40
Epoch: [293][20/30]	Time  1.532 ( 1.549)	Data  0.039 ( 0.050)	InnerLoop  0.639 ( 0.658)	Loss 5.2324e-01 (5.6370e-01)	Acc@1  80.13 ( 79.95)
The current update step is 8820
GPU_0_using curriculum 40 with window 40
Epoch: [294][20/30]	Time  1.636 ( 1.561)	Data  0.158 ( 0.069)	InnerLoop  0.636 ( 0.651)	Loss 4.6202e-01 (5.3728e-01)	Acc@1  84.23 ( 81.15)
The current update step is 8850
The current seed is 5825611903327278687
The current lr is: 0.0015
Testing Results:
 *   Acc@1 66.237
 *   Acc@1 66.832
 *   Acc@1 66.737
 *   Acc@1 67.612
 *   Acc@1 66.868
 *   Acc@1 67.553
 *   Acc@1 73.618
 *   Acc@1 74.371
 *   Acc@1 74.355
 *   Acc@1 74.895
 *   Acc@1 74.224
 *   Acc@1 74.774
Training for 300 epoch: 69.92763157894737
Training for 600 epoch: 70.54605263157896
Training for 1000 epoch: 70.54605263157895
Training for 300 epoch: 70.60125
Training for 600 epoch: 71.25375
Training for 1000 epoch: 71.16375
[[69.92763157894737, 70.54605263157896, 70.54605263157895], [70.60125, 71.25375, 71.16375]]
train loss 0.5537528537114461, epoch 294, best loss 0.4521389428456624, best_epoch 294
GPU_0_using curriculum 40 with window 40
Epoch: [295][20/30]	Time  1.522 ( 1.547)	Data  0.041 ( 0.051)	InnerLoop  0.646 ( 0.660)	Loss 4.6829e-01 (4.9994e-01)	Acc@1  83.52 ( 82.39)
The current update step is 8880
GPU_0_using curriculum 40 with window 40
Epoch: [296][20/30]	Time  1.643 ( 1.552)	Data  0.162 ( 0.069)	InnerLoop  0.630 ( 0.646)	Loss 5.2295e-01 (5.5949e-01)	Acc@1  81.42 ( 80.29)
The current update step is 8910
GPU_0_using curriculum 40 with window 40
Epoch: [297][20/30]	Time  1.539 ( 1.547)	Data  0.040 ( 0.057)	InnerLoop  0.635 ( 0.652)	Loss 4.6911e-01 (5.8116e-01)	Acc@1  83.62 ( 79.77)
The current update step is 8940
GPU_0_using curriculum 40 with window 40
Epoch: [298][20/30]	Time  1.508 ( 1.549)	Data  0.037 ( 0.045)	InnerLoop  0.636 ( 0.665)	Loss 5.7205e-01 (5.3500e-01)	Acc@1  80.57 ( 81.32)
The current update step is 8970
GPU_0_using curriculum 40 with window 40
Epoch: [299][20/30]	Time  1.508 ( 1.544)	Data  0.038 ( 0.069)	InnerLoop  0.637 ( 0.639)	Loss 6.5903e-01 (5.4730e-01)	Acc@1  78.05 ( 80.75)
The current update step is 9000
The current seed is 9259658139720559593
The current lr is: 0.0015
Testing Results:
 *   Acc@1 75.263
 *   Acc@1 76.007
 *   Acc@1 75.092
 *   Acc@1 75.871
 *   Acc@1 75.053
 *   Acc@1 75.832
 *   Acc@1 79.145
 *   Acc@1 79.730
 *   Acc@1 79.368
 *   Acc@1 79.927
 *   Acc@1 79.539
 *   Acc@1 79.951
Training for 300 epoch: 77.20394736842104
Training for 600 epoch: 77.23026315789474
Training for 1000 epoch: 77.29605263157895
Training for 300 epoch: 77.86875
Training for 600 epoch: 77.89916666666667
Training for 1000 epoch: 77.89125
[[77.20394736842104, 77.23026315789474, 77.29605263157895], [77.86875, 77.89916666666667, 77.89125]]
train loss 0.4224886600335439, epoch 299, best loss 0.4224886600335439, best_epoch 299
GPU_0_using curriculum 40 with window 40
Epoch: [300][20/30]	Time  1.638 ( 1.553)	Data  0.044 ( 0.071)	InnerLoop  0.756 ( 0.645)	Loss 4.4997e-01 (5.6942e-01)	Acc@1  84.81 ( 80.18)
The current update step is 9030
GPU_0_using curriculum 40 with window 40
Epoch: [301][20/30]	Time  1.513 ( 1.551)	Data  0.037 ( 0.057)	InnerLoop  0.642 ( 0.655)	Loss 5.0822e-01 (5.3842e-01)	Acc@1  83.28 ( 81.47)
The current update step is 9060
GPU_0_using curriculum 40 with window 40
Epoch: [302][20/30]	Time  1.536 ( 1.545)	Data  0.038 ( 0.045)	InnerLoop  0.667 ( 0.666)	Loss 4.7930e-01 (5.2585e-01)	Acc@1  83.57 ( 81.66)
The current update step is 9090
GPU_0_using curriculum 40 with window 40
Epoch: [303][20/30]	Time  1.523 ( 1.541)	Data  0.039 ( 0.051)	InnerLoop  0.640 ( 0.657)	Loss 4.5479e-01 (5.6627e-01)	Acc@1  84.06 ( 80.11)
The current update step is 9120
GPU_0_using curriculum 40 with window 40
Epoch: [304][20/30]	Time  1.651 ( 1.562)	Data  0.166 ( 0.071)	InnerLoop  0.649 ( 0.653)	Loss 6.0630e-01 (5.2070e-01)	Acc@1  80.20 ( 81.82)
The current update step is 9150
The current seed is 6378759396637513154
The current lr is: 0.0015
Testing Results:
 *   Acc@1 68.421
 *   Acc@1 68.301
 *   Acc@1 68.171
 *   Acc@1 68.284
 *   Acc@1 68.250
 *   Acc@1 68.215
 *   Acc@1 77.316
 *   Acc@1 77.922
 *   Acc@1 76.013
 *   Acc@1 76.917
 *   Acc@1 75.934
 *   Acc@1 76.447
Training for 300 epoch: 72.86842105263158
Training for 600 epoch: 72.09210526315789
Training for 1000 epoch: 72.09210526315789
Training for 300 epoch: 73.11166666666666
Training for 600 epoch: 72.60041666666666
Training for 1000 epoch: 72.33083333333335
[[72.86842105263158, 72.09210526315789, 72.09210526315789], [73.11166666666666, 72.60041666666666, 72.33083333333335]]
train loss 0.5537511403083801, epoch 304, best loss 0.4224886600335439, best_epoch 299
GPU_0_using curriculum 40 with window 40
Epoch: [305][20/30]	Time  1.526 ( 1.553)	Data  0.037 ( 0.052)	InnerLoop  0.651 ( 0.664)	Loss 4.8453e-01 (5.2083e-01)	Acc@1  83.01 ( 81.54)
The current update step is 9180
GPU_0_using curriculum 40 with window 40
Epoch: [306][20/30]	Time  1.666 ( 1.557)	Data  0.167 ( 0.071)	InnerLoop  0.660 ( 0.651)	Loss 5.3269e-01 (5.4013e-01)	Acc@1  81.84 ( 80.92)
The current update step is 9210
GPU_0_using curriculum 40 with window 40
Epoch: [307][20/30]	Time  1.534 ( 1.580)	Data  0.039 ( 0.060)	InnerLoop  0.653 ( 0.672)	Loss 8.2482e-01 (5.6247e-01)	Acc@1  71.51 ( 80.36)
The current update step is 9240
GPU_0_using curriculum 40 with window 40
Epoch: [308][20/30]	Time  1.541 ( 1.559)	Data  0.038 ( 0.046)	InnerLoop  0.659 ( 0.671)	Loss 4.8493e-01 (5.1239e-01)	Acc@1  83.89 ( 82.59)
The current update step is 9270
GPU_0_using curriculum 40 with window 40
Epoch: [309][20/30]	Time  1.522 ( 1.571)	Data  0.042 ( 0.073)	InnerLoop  0.648 ( 0.655)	Loss 5.0109e-01 (5.5913e-01)	Acc@1  81.67 ( 80.74)
The current update step is 9300
The current seed is 2979381802305556308
The current lr is: 0.0015
Testing Results:
 *   Acc@1 70.618
 *   Acc@1 71.247
 *   Acc@1 70.066
 *   Acc@1 70.505
 *   Acc@1 69.868
 *   Acc@1 70.413
 *   Acc@1 76.934
 *   Acc@1 76.766
 *   Acc@1 75.434
 *   Acc@1 76.037
 *   Acc@1 75.855
 *   Acc@1 76.208
Training for 300 epoch: 73.77631578947368
Training for 600 epoch: 72.75
Training for 1000 epoch: 72.86184210526315
Training for 300 epoch: 74.00625
Training for 600 epoch: 73.27125
Training for 1000 epoch: 73.31083333333333
[[73.77631578947368, 72.75, 72.86184210526315], [74.00625, 73.27125, 73.31083333333333]]
train loss 0.5704019206682841, epoch 309, best loss 0.4224886600335439, best_epoch 299
GPU_0_using curriculum 40 with window 40
Epoch: [310][20/30]	Time  1.648 ( 1.561)	Data  0.036 ( 0.070)	InnerLoop  0.766 ( 0.649)	Loss 4.8389e-01 (5.4599e-01)	Acc@1  83.59 ( 81.03)
The current update step is 9330
GPU_0_using curriculum 40 with window 40
Epoch: [311][20/30]	Time  1.528 ( 1.559)	Data  0.038 ( 0.058)	InnerLoop  0.658 ( 0.660)	Loss 5.3575e-01 (5.5806e-01)	Acc@1  81.62 ( 80.63)
The current update step is 9360
GPU_0_using curriculum 40 with window 40
Epoch: [312][20/30]	Time  1.519 ( 1.556)	Data  0.042 ( 0.044)	InnerLoop  0.634 ( 0.672)	Loss 4.8521e-01 (5.8937e-01)	Acc@1  83.72 ( 79.08)
The current update step is 9390
GPU_0_using curriculum 40 with window 40
Epoch: [313][20/30]	Time  1.518 ( 1.543)	Data  0.039 ( 0.050)	InnerLoop  0.647 ( 0.655)	Loss 4.7810e-01 (5.2879e-01)	Acc@1  83.11 ( 81.76)
The current update step is 9420
GPU_0_using curriculum 40 with window 40
Epoch: [314][20/30]	Time  1.658 ( 1.549)	Data  0.157 ( 0.069)	InnerLoop  0.632 ( 0.642)	Loss 4.8138e-01 (5.2901e-01)	Acc@1  84.20 ( 81.85)
The current update step is 9450
The current seed is 7088989558846020163
The current lr is: 0.0015
Testing Results:
 *   Acc@1 67.868
 *   Acc@1 68.560
 *   Acc@1 65.882
 *   Acc@1 66.703
 *   Acc@1 63.908
 *   Acc@1 64.612
 *   Acc@1 55.434
 *   Acc@1 55.674
 *   Acc@1 55.829
 *   Acc@1 56.185
 *   Acc@1 56.158
 *   Acc@1 56.430
Training for 300 epoch: 61.651315789473685
Training for 600 epoch: 60.85526315789474
Training for 1000 epoch: 60.0328947368421
Training for 300 epoch: 62.11708333333333
Training for 600 epoch: 61.44375
Training for 1000 epoch: 60.521249999999995
[[61.651315789473685, 60.85526315789474, 60.0328947368421], [62.11708333333333, 61.44375, 60.521249999999995]]
train loss 1.7546068974812825, epoch 314, best loss 0.4224886600335439, best_epoch 299
GPU_0_using curriculum 40 with window 40
Epoch: [315][20/30]	Time  1.555 ( 1.553)	Data  0.036 ( 0.050)	InnerLoop  0.658 ( 0.661)	Loss 4.7135e-01 (5.3345e-01)	Acc@1  84.11 ( 81.49)
The current update step is 9480
GPU_0_using curriculum 40 with window 40
Epoch: [316][20/30]	Time  1.650 ( 1.562)	Data  0.156 ( 0.070)	InnerLoop  0.655 ( 0.654)	Loss 4.6690e-01 (5.1178e-01)	Acc@1  83.54 ( 82.24)
The current update step is 9510
GPU_0_using curriculum 40 with window 40
Epoch: [317][20/30]	Time  1.539 ( 1.547)	Data  0.037 ( 0.056)	InnerLoop  0.628 ( 0.651)	Loss 4.7888e-01 (5.3941e-01)	Acc@1  83.50 ( 81.28)
The current update step is 9540
GPU_0_using curriculum 40 with window 40
Epoch: [318][20/30]	Time  1.549 ( 1.568)	Data  0.042 ( 0.046)	InnerLoop  0.648 ( 0.675)	Loss 4.8644e-01 (5.2326e-01)	Acc@1  82.79 ( 82.05)
The current update step is 9570
GPU_0_using curriculum 40 with window 40
Epoch: [319][20/30]	Time  1.526 ( 1.549)	Data  0.040 ( 0.070)	InnerLoop  0.643 ( 0.641)	Loss 4.5660e-01 (5.2228e-01)	Acc@1  84.38 ( 81.98)
The current update step is 9600
The current seed is 2556350295028763324
The current lr is: 0.0015
Testing Results:
 *   Acc@1 68.816
 *   Acc@1 68.968
 *   Acc@1 67.579
 *   Acc@1 67.993
 *   Acc@1 67.316
 *   Acc@1 67.916
 *   Acc@1 69.053
 *   Acc@1 69.140
 *   Acc@1 69.513
 *   Acc@1 69.683
 *   Acc@1 69.632
 *   Acc@1 69.984
Training for 300 epoch: 68.93421052631578
Training for 600 epoch: 68.54605263157895
Training for 1000 epoch: 68.47368421052632
Training for 300 epoch: 69.05375000000001
Training for 600 epoch: 68.83833333333334
Training for 1000 epoch: 68.95
[[68.93421052631578, 68.54605263157895, 68.47368421052632], [69.05375000000001, 68.83833333333334, 68.95]]
train loss 0.7821631715774536, epoch 319, best loss 0.4224886600335439, best_epoch 299
GPU_0_using curriculum 40 with window 40
Epoch: [320][20/30]	Time  1.648 ( 1.549)	Data  0.041 ( 0.070)	InnerLoop  0.762 ( 0.645)	Loss 4.8614e-01 (5.3697e-01)	Acc@1  83.64 ( 81.53)
The current update step is 9630
GPU_0_using curriculum 40 with window 40
Epoch: [321][20/30]	Time  1.539 ( 1.552)	Data  0.043 ( 0.058)	InnerLoop  0.644 ( 0.653)	Loss 5.2392e-01 (5.1256e-01)	Acc@1  82.18 ( 82.24)
The current update step is 9660
GPU_0_using curriculum 40 with window 40
Epoch: [322][20/30]	Time  1.544 ( 1.548)	Data  0.051 ( 0.046)	InnerLoop  0.632 ( 0.661)	Loss 5.4889e-01 (5.0842e-01)	Acc@1  81.45 ( 82.34)
The current update step is 9690
GPU_0_using curriculum 40 with window 40
Epoch: [323][20/30]	Time  1.530 ( 1.556)	Data  0.041 ( 0.051)	InnerLoop  0.643 ( 0.663)	Loss 6.6648e-01 (5.4441e-01)	Acc@1  78.47 ( 81.34)
The current update step is 9720
GPU_0_using curriculum 40 with window 40
Epoch: [324][20/30]	Time  1.627 ( 1.558)	Data  0.158 ( 0.069)	InnerLoop  0.639 ( 0.646)	Loss 5.4343e-01 (5.1467e-01)	Acc@1  80.44 ( 81.87)
The current update step is 9750
The current seed is 3668325191225275502
The current lr is: 0.0015
Testing Results:
 *   Acc@1 70.224
 *   Acc@1 70.766
 *   Acc@1 70.000
 *   Acc@1 70.588
 *   Acc@1 70.053
 *   Acc@1 70.642
 *   Acc@1 69.645
 *   Acc@1 69.744
 *   Acc@1 70.421
 *   Acc@1 70.185
 *   Acc@1 71.684
 *   Acc@1 71.095
Training for 300 epoch: 69.93421052631578
Training for 600 epoch: 70.21052631578948
Training for 1000 epoch: 70.86842105263159
Training for 300 epoch: 70.255
Training for 600 epoch: 70.38666666666667
Training for 1000 epoch: 70.86833333333334
[[69.93421052631578, 70.21052631578948, 70.86842105263159], [70.255, 70.38666666666667, 70.86833333333334]]
train loss 0.6357132656415303, epoch 324, best loss 0.4224886600335439, best_epoch 299
GPU_0_using curriculum 40 with window 40
Epoch: [325][20/30]	Time  1.512 ( 1.559)	Data  0.039 ( 0.052)	InnerLoop  0.637 ( 0.666)	Loss 5.0761e-01 (5.2329e-01)	Acc@1  82.50 ( 81.85)
The current update step is 9780
GPU_0_using curriculum 40 with window 40
Epoch: [326][20/30]	Time  1.649 ( 1.562)	Data  0.159 ( 0.071)	InnerLoop  0.649 ( 0.650)	Loss 4.5914e-01 (5.0860e-01)	Acc@1  83.84 ( 82.09)
The current update step is 9810
GPU_0_using curriculum 40 with window 40
Epoch: [327][20/30]	Time  1.521 ( 1.569)	Data  0.037 ( 0.058)	InnerLoop  0.643 ( 0.664)	Loss 5.3051e-01 (5.6011e-01)	Acc@1  81.42 ( 80.53)
The current update step is 9840
GPU_0_using curriculum 40 with window 40
Epoch: [328][20/30]	Time  1.501 ( 1.547)	Data  0.037 ( 0.044)	InnerLoop  0.632 ( 0.664)	Loss 6.4501e-01 (5.8034e-01)	Acc@1  77.86 ( 79.41)
The current update step is 9870
GPU_0_using curriculum 40 with window 40
Epoch: [329][20/30]	Time  1.560 ( 1.540)	Data  0.039 ( 0.067)	InnerLoop  0.659 ( 0.635)	Loss 4.6970e-01 (5.2437e-01)	Acc@1  82.50 ( 81.82)
The current update step is 9900
The current seed is 11228644612778681610
The current lr is: 0.0015
Testing Results:
 *   Acc@1 65.092
 *   Acc@1 65.098
 *   Acc@1 64.579
 *   Acc@1 64.573
 *   Acc@1 64.618
 *   Acc@1 64.443
 *   Acc@1 63.408
 *   Acc@1 64.013
 *   Acc@1 64.855
 *   Acc@1 65.474
 *   Acc@1 65.461
 *   Acc@1 65.858
Training for 300 epoch: 64.25
Training for 600 epoch: 64.71710526315789
Training for 1000 epoch: 65.03947368421052
Training for 300 epoch: 64.55583333333334
Training for 600 epoch: 65.02375
Training for 1000 epoch: 65.15041666666667
[[64.25, 64.71710526315789, 65.03947368421052], [64.55583333333334, 65.02375, 65.15041666666667]]
train loss 0.9073313904126485, epoch 329, best loss 0.4224886600335439, best_epoch 299
GPU_0_using curriculum 40 with window 40
Epoch: [330][20/30]	Time  1.649 ( 1.550)	Data  0.036 ( 0.069)	InnerLoop  0.771 ( 0.644)	Loss 7.4352e-01 (5.4757e-01)	Acc@1  72.14 ( 81.09)
The current update step is 9930
GPU_0_using curriculum 40 with window 40
Epoch: [331][20/30]	Time  1.519 ( 1.546)	Data  0.040 ( 0.057)	InnerLoop  0.638 ( 0.652)	Loss 4.7140e-01 (5.3146e-01)	Acc@1  83.98 ( 81.41)
The current update step is 9960
GPU_0_using curriculum 40 with window 40
Epoch: [332][20/30]	Time  1.504 ( 1.535)	Data  0.041 ( 0.044)	InnerLoop  0.632 ( 0.658)	Loss 5.7672e-01 (5.2659e-01)	Acc@1  81.69 ( 81.71)
The current update step is 9990
GPU_0_using curriculum 40 with window 40
Epoch: [333][20/30]	Time  1.500 ( 1.537)	Data  0.037 ( 0.049)	InnerLoop  0.629 ( 0.651)	Loss 4.8627e-01 (5.5405e-01)	Acc@1  84.16 ( 80.33)
The current update step is 10020
GPU_0_using curriculum 40 with window 40
Epoch: [334][20/30]	Time  1.624 ( 1.533)	Data  0.151 ( 0.067)	InnerLoop  0.638 ( 0.635)	Loss 4.6872e-01 (5.1535e-01)	Acc@1  84.13 ( 82.19)
The current update step is 10050
The current seed is 5439882318402844600
The current lr is: 0.0015
Testing Results:
 *   Acc@1 79.605
 *   Acc@1 80.729
 *   Acc@1 80.118
 *   Acc@1 81.153
 *   Acc@1 80.329
 *   Acc@1 81.257
 *   Acc@1 74.816
 *   Acc@1 75.250
 *   Acc@1 74.947
 *   Acc@1 75.483
 *   Acc@1 60.053
 *   Acc@1 60.733
Training for 300 epoch: 77.21052631578948
Training for 600 epoch: 77.53289473684211
Training for 1000 epoch: 70.19078947368422
Training for 300 epoch: 77.98958333333334
Training for 600 epoch: 78.31791666666666
Training for 1000 epoch: 70.995
[[77.21052631578948, 77.53289473684211, 70.19078947368422], [77.98958333333334, 78.31791666666666, 70.995]]
train loss 0.9994872307459514, epoch 334, best loss 0.4224886600335439, best_epoch 299
GPU_0_using curriculum 40 with window 40
Epoch: [335][20/30]	Time  1.491 ( 1.532)	Data  0.034 ( 0.050)	InnerLoop  0.628 ( 0.650)	Loss 4.9527e-01 (5.2912e-01)	Acc@1  83.37 ( 81.47)
The current update step is 10080
GPU_0_using curriculum 40 with window 40
Epoch: [336][20/30]	Time  1.633 ( 1.542)	Data  0.158 ( 0.069)	InnerLoop  0.632 ( 0.640)	Loss 4.8979e-01 (5.4248e-01)	Acc@1  83.45 ( 81.20)
The current update step is 10110
GPU_0_using curriculum 40 with window 40
Epoch: [337][20/30]	Time  1.543 ( 1.558)	Data  0.041 ( 0.057)	InnerLoop  0.652 ( 0.657)	Loss 5.5719e-01 (5.4830e-01)	Acc@1  81.10 ( 81.42)
The current update step is 10140
GPU_0_using curriculum 40 with window 40
Epoch: [338][20/30]	Time  1.534 ( 1.558)	Data  0.037 ( 0.045)	InnerLoop  0.642 ( 0.668)	Loss 4.1273e-01 (5.1801e-01)	Acc@1  85.23 ( 82.25)
The current update step is 10170
GPU_0_using curriculum 40 with window 40
Epoch: [339][20/30]	Time  1.578 ( 1.578)	Data  0.048 ( 0.072)	InnerLoop  0.652 ( 0.654)	Loss 5.9308e-01 (5.1803e-01)	Acc@1  81.08 ( 81.96)
The current update step is 10200
The current seed is 17490207769389497583
The current lr is: 0.0015
Testing Results:
 *   Acc@1 62.303
 *   Acc@1 62.607
 *   Acc@1 64.092
 *   Acc@1 64.310
 *   Acc@1 64.039
 *   Acc@1 64.078
 *   Acc@1 77.329
 *   Acc@1 77.886
 *   Acc@1 78.079
 *   Acc@1 78.332
 *   Acc@1 78.171
 *   Acc@1 78.692
Training for 300 epoch: 69.81578947368422
Training for 600 epoch: 71.08552631578948
Training for 1000 epoch: 71.10526315789474
Training for 300 epoch: 70.24625
Training for 600 epoch: 71.32083333333333
Training for 1000 epoch: 71.38499999999999
[[69.81578947368422, 71.08552631578948, 71.10526315789474], [70.24625, 71.32083333333333, 71.38499999999999]]
train loss 0.4714749745051066, epoch 339, best loss 0.4224886600335439, best_epoch 299
GPU_0_using curriculum 40 with window 40
Epoch: [340][20/30]	Time  1.674 ( 1.584)	Data  0.046 ( 0.072)	InnerLoop  0.784 ( 0.665)	Loss 4.7365e-01 (5.2995e-01)	Acc@1  84.20 ( 81.70)
The current update step is 10230
GPU_0_using curriculum 40 with window 40
Epoch: [341][20/30]	Time  1.546 ( 1.575)	Data  0.038 ( 0.059)	InnerLoop  0.664 ( 0.672)	Loss 5.8825e-01 (5.3495e-01)	Acc@1  79.47 ( 81.32)
The current update step is 10260
GPU_0_using curriculum 40 with window 40
Epoch: [342][20/30]	Time  1.550 ( 1.575)	Data  0.045 ( 0.046)	InnerLoop  0.655 ( 0.684)	Loss 5.0696e-01 (4.9268e-01)	Acc@1  82.47 ( 82.88)
The current update step is 10290
GPU_0_using curriculum 40 with window 40
Epoch: [343][20/30]	Time  1.554 ( 1.575)	Data  0.040 ( 0.053)	InnerLoop  0.655 ( 0.674)	Loss 6.1503e-01 (5.5101e-01)	Acc@1  79.30 ( 80.79)
The current update step is 10320
GPU_0_using curriculum 40 with window 40
Epoch: [344][20/30]	Time  1.695 ( 1.585)	Data  0.160 ( 0.072)	InnerLoop  0.661 ( 0.665)	Loss 5.5948e-01 (5.2122e-01)	Acc@1  79.03 ( 82.03)
The current update step is 10350
The current seed is 4122990810617513152
The current lr is: 0.0015
Testing Results:
 *   Acc@1 74.211
 *   Acc@1 74.248
 *   Acc@1 74.145
 *   Acc@1 74.181
 *   Acc@1 74.947
 *   Acc@1 74.518
 *   Acc@1 71.474
 *   Acc@1 71.610
 *   Acc@1 70.513
 *   Acc@1 71.127
 *   Acc@1 70.566
 *   Acc@1 70.753
Training for 300 epoch: 72.84210526315789
Training for 600 epoch: 72.32894736842104
Training for 1000 epoch: 72.75657894736841
Training for 300 epoch: 72.92916666666667
Training for 600 epoch: 72.65416666666667
Training for 1000 epoch: 72.63583333333332
[[72.84210526315789, 72.32894736842104, 72.75657894736841], [72.92916666666667, 72.65416666666667, 72.63583333333332]]
train loss 0.8337947450955708, epoch 344, best loss 0.4224886600335439, best_epoch 299
GPU_0_using curriculum 40 with window 40
Epoch: [345][20/30]	Time  1.573 ( 1.580)	Data  0.038 ( 0.053)	InnerLoop  0.698 ( 0.681)	Loss 5.0465e-01 (5.3036e-01)	Acc@1  82.50 ( 81.64)
The current update step is 10380
GPU_0_using curriculum 40 with window 40
Epoch: [346][20/30]	Time  1.613 ( 1.542)	Data  0.151 ( 0.067)	InnerLoop  0.632 ( 0.647)	Loss 6.0477e-01 (5.4036e-01)	Acc@1  79.71 ( 81.40)
The current update step is 10410
GPU_0_using curriculum 40 with window 40
Epoch: [347][20/30]	Time  1.509 ( 1.536)	Data  0.036 ( 0.055)	InnerLoop  0.648 ( 0.651)	Loss 4.6001e-01 (5.2744e-01)	Acc@1  83.23 ( 81.66)
The current update step is 10440
GPU_0_using curriculum 40 with window 40
Epoch: [348][20/30]	Time  1.506 ( 1.535)	Data  0.039 ( 0.044)	InnerLoop  0.639 ( 0.663)	Loss 5.3208e-01 (5.3182e-01)	Acc@1  80.47 ( 81.36)
The current update step is 10470
GPU_0_using curriculum 40 with window 40
Epoch: [349][20/30]	Time  1.509 ( 1.539)	Data  0.038 ( 0.067)	InnerLoop  0.639 ( 0.638)	Loss 7.8675e-01 (5.5939e-01)	Acc@1  75.59 ( 80.92)
The current update step is 10500
The current seed is 17861716954726568356
The current lr is: 0.0015
Testing Results:
 *   Acc@1 46.632
 *   Acc@1 46.553
 *   Acc@1 55.158
 *   Acc@1 55.562
 *   Acc@1 60.605
 *   Acc@1 60.462
 *   Acc@1 67.724
 *   Acc@1 67.852
 *   Acc@1 59.500
 *   Acc@1 59.596
 *   Acc@1 60.395
 *   Acc@1 60.508
Training for 300 epoch: 57.17763157894737
Training for 600 epoch: 57.328947368421055
Training for 1000 epoch: 60.5
Training for 300 epoch: 57.2025
Training for 600 epoch: 57.579166666666666
Training for 1000 epoch: 60.48458333333333
[[57.17763157894737, 57.328947368421055, 60.5], [57.2025, 57.579166666666666, 60.48458333333333]]
train loss 1.4961049841562908, epoch 349, best loss 0.4224886600335439, best_epoch 299
GPU_0_using curriculum 40 with window 40
Epoch: [350][20/30]	Time  1.619 ( 1.547)	Data  0.039 ( 0.067)	InnerLoop  0.754 ( 0.646)	Loss 5.7797e-01 (5.3379e-01)	Acc@1  79.10 ( 81.58)
The current update step is 10530
GPU_0_using curriculum 40 with window 40
Epoch: [351][20/30]	Time  1.505 ( 1.540)	Data  0.036 ( 0.055)	InnerLoop  0.642 ( 0.654)	Loss 6.5492e-01 (5.6033e-01)	Acc@1  79.25 ( 80.78)
The current update step is 10560
GPU_0_using curriculum 40 with window 40
Epoch: [352][20/30]	Time  1.506 ( 1.540)	Data  0.040 ( 0.044)	InnerLoop  0.637 ( 0.666)	Loss 4.7464e-01 (5.2334e-01)	Acc@1  82.64 ( 81.95)
The current update step is 10590
GPU_0_using curriculum 40 with window 40
Epoch: [353][20/30]	Time  1.511 ( 1.532)	Data  0.040 ( 0.050)	InnerLoop  0.637 ( 0.652)	Loss 4.5158e-01 (5.1612e-01)	Acc@1  84.55 ( 82.08)
The current update step is 10620
GPU_0_using curriculum 40 with window 40
Epoch: [354][20/30]	Time  1.630 ( 1.539)	Data  0.156 ( 0.068)	InnerLoop  0.631 ( 0.641)	Loss 6.5563e-01 (5.6009e-01)	Acc@1  77.56 ( 80.26)
The current update step is 10650
The current seed is 8244756798413114482
The current lr is: 0.0015
Testing Results:
 *   Acc@1 58.026
 *   Acc@1 57.521
 *   Acc@1 58.816
 *   Acc@1 58.453
 *   Acc@1 59.487
 *   Acc@1 58.672
 *   Acc@1 67.118
 *   Acc@1 67.544
 *   Acc@1 67.737
 *   Acc@1 68.377
 *   Acc@1 68.355
 *   Acc@1 68.838
Training for 300 epoch: 62.57236842105263
Training for 600 epoch: 63.276315789473685
Training for 1000 epoch: 63.921052631578945
Training for 300 epoch: 62.5325
Training for 600 epoch: 63.415416666666665
Training for 1000 epoch: 63.754583333333336
[[62.57236842105263, 63.276315789473685, 63.921052631578945], [62.5325, 63.415416666666665, 63.754583333333336]]
train loss 1.1713237078348795, epoch 354, best loss 0.4224886600335439, best_epoch 299
GPU_0_using curriculum 40 with window 40
Epoch: [355][20/30]	Time  1.500 ( 1.536)	Data  0.038 ( 0.049)	InnerLoop  0.631 ( 0.654)	Loss 5.2841e-01 (5.6015e-01)	Acc@1  80.76 ( 80.67)
The current update step is 10680
GPU_0_using curriculum 40 with window 40
Epoch: [356][20/30]	Time  1.626 ( 1.538)	Data  0.156 ( 0.068)	InnerLoop  0.644 ( 0.642)	Loss 5.6703e-01 (5.1715e-01)	Acc@1  80.00 ( 82.28)
The current update step is 10710
GPU_0_using curriculum 40 with window 40
Epoch: [357][20/30]	Time  1.514 ( 1.534)	Data  0.039 ( 0.057)	InnerLoop  0.636 ( 0.647)	Loss 5.4480e-01 (5.4078e-01)	Acc@1  81.88 ( 81.22)
The current update step is 10740
GPU_0_using curriculum 40 with window 40
Epoch: [358][20/30]	Time  1.510 ( 1.535)	Data  0.040 ( 0.044)	InnerLoop  0.643 ( 0.662)	Loss 4.5252e-01 (5.4339e-01)	Acc@1  84.01 ( 81.60)
The current update step is 10770
GPU_0_using curriculum 40 with window 40
Epoch: [359][20/30]	Time  1.547 ( 1.549)	Data  0.041 ( 0.069)	InnerLoop  0.642 ( 0.637)	Loss 4.6561e-01 (5.2085e-01)	Acc@1  84.11 ( 81.67)
The current update step is 10800
The current seed is 2963264734740128827
The current lr is: 0.0015
Testing Results:
 *   Acc@1 72.829
 *   Acc@1 73.493
 *   Acc@1 72.737
 *   Acc@1 73.361
 *   Acc@1 71.539
 *   Acc@1 72.092
 *   Acc@1 72.066
 *   Acc@1 73.140
 *   Acc@1 70.855
 *   Acc@1 71.198
 *   Acc@1 70.684
 *   Acc@1 70.986
Training for 300 epoch: 72.44736842105263
Training for 600 epoch: 71.79605263157896
Training for 1000 epoch: 71.11184210526315
Training for 300 epoch: 73.31625
Training for 600 epoch: 72.27958333333333
Training for 1000 epoch: 71.53875
[[72.44736842105263, 71.79605263157896, 71.11184210526315], [73.31625, 72.27958333333333, 71.53875]]
train loss 0.9251940805753072, epoch 359, best loss 0.4224886600335439, best_epoch 359
GPU_0_using curriculum 40 with window 40
Epoch: [360][20/30]	Time  1.638 ( 1.558)	Data  0.037 ( 0.069)	InnerLoop  0.769 ( 0.649)	Loss 5.3820e-01 (5.2787e-01)	Acc@1  79.42 ( 81.62)
The current update step is 10830
GPU_0_using curriculum 40 with window 40
Epoch: [361][20/30]	Time  1.528 ( 1.550)	Data  0.040 ( 0.058)	InnerLoop  0.638 ( 0.652)	Loss 4.5983e-01 (5.1366e-01)	Acc@1  84.16 ( 82.25)
The current update step is 10860
GPU_0_using curriculum 40 with window 40
Epoch: [362][20/30]	Time  1.495 ( 1.542)	Data  0.041 ( 0.046)	InnerLoop  0.631 ( 0.664)	Loss 5.5230e-01 (5.1916e-01)	Acc@1  81.37 ( 82.21)
The current update step is 10890
GPU_0_using curriculum 40 with window 40
Epoch: [363][20/30]	Time  1.557 ( 1.572)	Data  0.044 ( 0.055)	InnerLoop  0.660 ( 0.672)	Loss 4.7848e-01 (5.1076e-01)	Acc@1  83.25 ( 82.38)
The current update step is 10920
GPU_0_using curriculum 40 with window 40
Epoch: [364][20/30]	Time  1.688 ( 1.607)	Data  0.165 ( 0.075)	InnerLoop  0.666 ( 0.676)	Loss 5.9003e-01 (5.1371e-01)	Acc@1  80.81 ( 82.65)
The current update step is 10950
The current seed is 2192456025306872791
The current lr is: 0.0015
Testing Results:
 *   Acc@1 44.645
 *   Acc@1 44.513
 *   Acc@1 56.092
 *   Acc@1 56.239
 *   Acc@1 56.553
 *   Acc@1 56.642
 *   Acc@1 64.605
 *   Acc@1 65.718
 *   Acc@1 65.961
 *   Acc@1 67.067
 *   Acc@1 66.447
 *   Acc@1 67.718
Training for 300 epoch: 54.625
Training for 600 epoch: 61.026315789473685
Training for 1000 epoch: 61.5
Training for 300 epoch: 55.11541666666667
Training for 600 epoch: 61.65291666666667
Training for 1000 epoch: 62.17958333333333
[[54.625, 61.026315789473685, 61.5], [55.11541666666667, 61.65291666666667, 62.17958333333333]]
train loss 0.9524657168070475, epoch 364, best loss 0.4224886600335439, best_epoch 359
GPU_0_using curriculum 40 with window 40
Epoch: [365][20/30]	Time  1.582 ( 1.600)	Data  0.046 ( 0.056)	InnerLoop  0.673 ( 0.687)	Loss 4.7699e-01 (5.2636e-01)	Acc@1  84.52 ( 81.84)
The current update step is 10980
GPU_0_using curriculum 40 with window 40
Epoch: [366][20/30]	Time  1.709 ( 1.609)	Data  0.171 ( 0.075)	InnerLoop  0.678 ( 0.678)	Loss 5.9106e-01 (5.2755e-01)	Acc@1  78.52 ( 81.93)
The current update step is 11010
GPU_0_using curriculum 40 with window 40
Epoch: [367][20/30]	Time  1.595 ( 1.606)	Data  0.048 ( 0.062)	InnerLoop  0.668 ( 0.686)	Loss 6.0126e-01 (5.4173e-01)	Acc@1  79.74 ( 81.23)
The current update step is 11040
GPU_0_using curriculum 40 with window 40
Epoch: [368][20/30]	Time  1.562 ( 1.600)	Data  0.040 ( 0.049)	InnerLoop  0.667 ( 0.696)	Loss 4.9841e-01 (5.3062e-01)	Acc@1  82.67 ( 81.94)
The current update step is 11070
GPU_0_using curriculum 40 with window 40
Epoch: [369][20/30]	Time  1.565 ( 1.602)	Data  0.045 ( 0.076)	InnerLoop  0.670 ( 0.669)	Loss 4.8350e-01 (5.6458e-01)	Acc@1  83.89 ( 80.80)
The current update step is 11100
The current seed is 1626475728261959798
The current lr is: 0.0015
Testing Results:
 *   Acc@1 64.408
 *   Acc@1 65.582
 *   Acc@1 64.882
 *   Acc@1 65.239
 *   Acc@1 65.539
 *   Acc@1 66.085
 *   Acc@1 69.184
 *   Acc@1 70.108
 *   Acc@1 69.342
 *   Acc@1 70.127
 *   Acc@1 69.842
 *   Acc@1 70.357
Training for 300 epoch: 66.79605263157896
Training for 600 epoch: 67.11184210526315
Training for 1000 epoch: 67.6907894736842
Training for 300 epoch: 67.845
Training for 600 epoch: 67.68291666666667
Training for 1000 epoch: 68.22083333333333
[[66.79605263157896, 67.11184210526315, 67.6907894736842], [67.845, 67.68291666666667, 68.22083333333333]]
train loss 0.8683897521018982, epoch 369, best loss 0.4224886600335439, best_epoch 359
GPU_0_using curriculum 40 with window 40
Epoch: [370][20/30]	Time  1.765 ( 1.655)	Data  0.047 ( 0.079)	InnerLoop  0.839 ( 0.702)	Loss 5.2351e-01 (5.3314e-01)	Acc@1  82.64 ( 81.84)
The current update step is 11130
GPU_0_using curriculum 40 with window 40
Epoch: [371][20/30]	Time  1.613 ( 1.649)	Data  0.044 ( 0.065)	InnerLoop  0.691 ( 0.709)	Loss 5.3940e-01 (5.1824e-01)	Acc@1  82.06 ( 82.27)
The current update step is 11160
GPU_0_using curriculum 40 with window 40
Epoch: [372][20/30]	Time  1.613 ( 1.648)	Data  0.041 ( 0.051)	InnerLoop  0.696 ( 0.722)	Loss 7.0210e-01 (5.4522e-01)	Acc@1  74.61 ( 81.09)
The current update step is 11190
GPU_0_using curriculum 40 with window 40
Epoch: [373][20/30]	Time  1.628 ( 1.650)	Data  0.050 ( 0.059)	InnerLoop  0.699 ( 0.716)	Loss 5.7430e-01 (5.4215e-01)	Acc@1  80.76 ( 81.37)
The current update step is 11220
GPU_0_using curriculum 40 with window 40
Epoch: [374][20/30]	Time  1.760 ( 1.664)	Data  0.177 ( 0.078)	InnerLoop  0.706 ( 0.706)	Loss 5.2985e-01 (5.5046e-01)	Acc@1  81.84 ( 81.31)
The current update step is 11250
The current seed is 5484320610837177674
The current lr is: 0.0015
Testing Results:
 *   Acc@1 66.342
 *   Acc@1 66.695
 *   Acc@1 69.316
 *   Acc@1 69.506
 *   Acc@1 69.211
 *   Acc@1 69.392
 *   Acc@1 68.421
 *   Acc@1 69.052
 *   Acc@1 69.789
 *   Acc@1 70.544
 *   Acc@1 70.026
 *   Acc@1 70.776
Training for 300 epoch: 67.38157894736841
Training for 600 epoch: 69.55263157894737
Training for 1000 epoch: 69.61842105263159
Training for 300 epoch: 67.87333333333333
Training for 600 epoch: 70.025
Training for 1000 epoch: 70.08416666666668
[[67.38157894736841, 69.55263157894737, 69.61842105263159], [67.87333333333333, 70.025, 70.08416666666668]]
train loss 0.7824914904594421, epoch 374, best loss 0.4224886600335439, best_epoch 359
GPU_0_using curriculum 40 with window 40
Epoch: [375][20/30]	Time  1.585 ( 1.647)	Data  0.043 ( 0.058)	InnerLoop  0.681 ( 0.712)	Loss 5.0914e-01 (5.3245e-01)	Acc@1  82.64 ( 81.72)
The current update step is 11280
GPU_0_using curriculum 40 with window 40
Epoch: [376][20/30]	Time  1.741 ( 1.666)	Data  0.181 ( 0.080)	InnerLoop  0.675 ( 0.704)	Loss 4.7383e-01 (5.2315e-01)	Acc@1  83.98 ( 82.00)
The current update step is 11310
GPU_0_using curriculum 40 with window 40
Epoch: [377][20/30]	Time  1.609 ( 1.663)	Data  0.044 ( 0.065)	InnerLoop  0.698 ( 0.715)	Loss 5.2465e-01 (5.3512e-01)	Acc@1  81.67 ( 81.45)
The current update step is 11340
GPU_0_using curriculum 40 with window 40
Epoch: [378][20/30]	Time  1.634 ( 1.657)	Data  0.045 ( 0.051)	InnerLoop  0.701 ( 0.727)	Loss 4.9068e-01 (5.1569e-01)	Acc@1  83.25 ( 82.25)
The current update step is 11370
GPU_0_using curriculum 40 with window 40
Epoch: [379][20/30]	Time  1.615 ( 1.653)	Data  0.046 ( 0.078)	InnerLoop  0.689 ( 0.698)	Loss 5.2441e-01 (5.2312e-01)	Acc@1  82.74 ( 81.84)
The current update step is 11400
The current seed is 1857863914901801170
The current lr is: 0.0015
Testing Results:
 *   Acc@1 72.776
 *   Acc@1 72.969
 *   Acc@1 73.724
 *   Acc@1 74.218
 *   Acc@1 74.066
 *   Acc@1 74.573
 *   Acc@1 67.961
 *   Acc@1 68.156
 *   Acc@1 70.382
 *   Acc@1 70.437
 *   Acc@1 71.684
 *   Acc@1 71.493
Training for 300 epoch: 70.36842105263159
Training for 600 epoch: 72.05263157894737
Training for 1000 epoch: 72.875
Training for 300 epoch: 70.5625
Training for 600 epoch: 72.32708333333333
Training for 1000 epoch: 73.03291666666667
[[70.36842105263159, 72.05263157894737, 72.875], [70.5625, 72.32708333333333, 73.03291666666667]]
train loss 0.9084814587593079, epoch 379, best loss 0.4224886600335439, best_epoch 359
GPU_0_using curriculum 40 with window 40
Epoch: [380][20/30]	Time  1.772 ( 1.639)	Data  0.050 ( 0.077)	InnerLoop  0.838 ( 0.692)	Loss 7.0710e-01 (5.1530e-01)	Acc@1  74.34 ( 82.23)
The current update step is 11430
GPU_0_using curriculum 40 with window 40
Epoch: [381][20/30]	Time  1.646 ( 1.657)	Data  0.048 ( 0.066)	InnerLoop  0.710 ( 0.712)	Loss 5.3090e-01 (4.9861e-01)	Acc@1  81.37 ( 82.76)
The current update step is 11460
GPU_0_using curriculum 40 with window 40
Epoch: [382][20/30]	Time  1.628 ( 1.658)	Data  0.046 ( 0.054)	InnerLoop  0.705 ( 0.727)	Loss 4.9628e-01 (4.9265e-01)	Acc@1  82.76 ( 83.21)
The current update step is 11490
GPU_0_using curriculum 40 with window 40
Epoch: [383][20/30]	Time  1.619 ( 1.659)	Data  0.044 ( 0.058)	InnerLoop  0.697 ( 0.722)	Loss 4.9642e-01 (4.9095e-01)	Acc@1  82.81 ( 82.88)
The current update step is 11520
GPU_0_using curriculum 40 with window 40
Epoch: [384][20/30]	Time  1.763 ( 1.664)	Data  0.183 ( 0.080)	InnerLoop  0.702 ( 0.705)	Loss 5.8860e-01 (5.0199e-01)	Acc@1  79.83 ( 82.73)
The current update step is 11550
The current seed is 11661721316299399955
The current lr is: 0.0015
Testing Results:
 *   Acc@1 57.947
 *   Acc@1 57.712
 *   Acc@1 58.579
 *   Acc@1 59.175
 *   Acc@1 57.921
 *   Acc@1 58.292
 *   Acc@1 69.934
 *   Acc@1 70.484
 *   Acc@1 70.355
 *   Acc@1 70.990
 *   Acc@1 70.053
 *   Acc@1 70.615
Training for 300 epoch: 63.94078947368421
Training for 600 epoch: 64.46710526315789
Training for 1000 epoch: 63.98684210526316
Training for 300 epoch: 64.09791666666666
Training for 600 epoch: 65.0825
Training for 1000 epoch: 64.45333333333333
[[63.94078947368421, 64.46710526315789, 63.98684210526316], [64.09791666666666, 65.0825, 64.45333333333333]]
train loss 0.8116631520589193, epoch 384, best loss 0.4224886600335439, best_epoch 359
GPU_0_using curriculum 40 with window 40
Epoch: [385][20/30]	Time  1.633 ( 1.664)	Data  0.048 ( 0.060)	InnerLoop  0.705 ( 0.722)	Loss 4.7338e-01 (5.1839e-01)	Acc@1  83.96 ( 81.90)
The current update step is 11580
GPU_0_using curriculum 40 with window 40
Epoch: [386][20/30]	Time  1.771 ( 1.672)	Data  0.181 ( 0.080)	InnerLoop  0.701 ( 0.709)	Loss 5.7563e-01 (4.9358e-01)	Acc@1  81.32 ( 83.21)
The current update step is 11610
GPU_0_using curriculum 40 with window 40
Epoch: [387][20/30]	Time  1.638 ( 1.670)	Data  0.045 ( 0.066)	InnerLoop  0.703 ( 0.720)	Loss 4.9187e-01 (5.0283e-01)	Acc@1  83.42 ( 82.60)
The current update step is 11640
GPU_0_using curriculum 40 with window 40
Epoch: [388][20/30]	Time  1.638 ( 1.665)	Data  0.046 ( 0.054)	InnerLoop  0.711 ( 0.731)	Loss 5.7967e-01 (5.2859e-01)	Acc@1  80.66 ( 81.91)
The current update step is 11670
GPU_0_using curriculum 40 with window 40
Epoch: [389][20/30]	Time  1.632 ( 1.648)	Data  0.051 ( 0.079)	InnerLoop  0.700 ( 0.691)	Loss 4.8221e-01 (5.2673e-01)	Acc@1  82.81 ( 81.60)
The current update step is 11700
The current seed is 11649962486796179238
The current lr is: 0.0015
Testing Results:
 *   Acc@1 72.474
 *   Acc@1 73.185
 *   Acc@1 70.592
 *   Acc@1 71.437
 *   Acc@1 70.447
 *   Acc@1 71.517
 *   Acc@1 67.408
 *   Acc@1 67.944
 *   Acc@1 69.250
 *   Acc@1 69.393
 *   Acc@1 69.868
 *   Acc@1 69.793
Training for 300 epoch: 69.94078947368422
Training for 600 epoch: 69.92105263157895
Training for 1000 epoch: 70.15789473684211
Training for 300 epoch: 70.56458333333333
Training for 600 epoch: 70.41499999999999
Training for 1000 epoch: 70.65541666666667
[[69.94078947368422, 69.92105263157895, 70.15789473684211], [70.56458333333333, 70.41499999999999, 70.65541666666667]]
train loss 0.7078494802474976, epoch 389, best loss 0.4224886600335439, best_epoch 359
GPU_0_using curriculum 40 with window 40
Epoch: [390][20/30]	Time  1.747 ( 1.663)	Data  0.040 ( 0.079)	InnerLoop  0.826 ( 0.703)	Loss 4.9507e-01 (5.2124e-01)	Acc@1  82.10 ( 81.44)
The current update step is 11730
GPU_0_using curriculum 40 with window 40
Epoch: [391][20/30]	Time  1.619 ( 1.644)	Data  0.046 ( 0.065)	InnerLoop  0.695 ( 0.704)	Loss 4.8521e-01 (5.2057e-01)	Acc@1  82.89 ( 81.66)
The current update step is 11760
GPU_0_using curriculum 40 with window 40
Epoch: [392][20/30]	Time  1.588 ( 1.653)	Data  0.046 ( 0.052)	InnerLoop  0.676 ( 0.722)	Loss 6.2882e-01 (5.3507e-01)	Acc@1  77.47 ( 81.27)
The current update step is 11790
GPU_0_using curriculum 40 with window 40
Epoch: [393][20/30]	Time  1.616 ( 1.635)	Data  0.046 ( 0.058)	InnerLoop  0.692 ( 0.706)	Loss 4.6673e-01 (5.4145e-01)	Acc@1  84.08 ( 81.21)
The current update step is 11820
GPU_0_using curriculum 40 with window 40
Epoch: [394][20/30]	Time  1.758 ( 1.664)	Data  0.179 ( 0.079)	InnerLoop  0.694 ( 0.705)	Loss 5.1977e-01 (5.0600e-01)	Acc@1  81.54 ( 82.40)
The current update step is 11850
The current seed is 13554151456400760021
The current lr is: 0.0015
Testing Results:
 *   Acc@1 58.237
 *   Acc@1 57.994
 *   Acc@1 56.316
 *   Acc@1 56.156
 *   Acc@1 56.224
 *   Acc@1 55.998
 *   Acc@1 67.605
 *   Acc@1 67.765
 *   Acc@1 67.487
 *   Acc@1 67.686
 *   Acc@1 67.803
 *   Acc@1 67.849
Training for 300 epoch: 62.921052631578945
Training for 600 epoch: 61.901315789473685
Training for 1000 epoch: 62.01315789473684
Training for 300 epoch: 62.87958333333333
Training for 600 epoch: 61.920833333333334
Training for 1000 epoch: 61.92375
[[62.921052631578945, 61.901315789473685, 62.01315789473684], [62.87958333333333, 61.920833333333334, 61.92375]]
train loss 0.8539284159342448, epoch 394, best loss 0.4224886600335439, best_epoch 359
GPU_0_using curriculum 40 with window 40
Epoch: [395][20/30]	Time  1.613 ( 1.656)	Data  0.045 ( 0.058)	InnerLoop  0.689 ( 0.717)	Loss 4.9640e-01 (5.2256e-01)	Acc@1  82.93 ( 81.89)
The current update step is 11880
GPU_0_using curriculum 40 with window 40
Epoch: [396][20/30]	Time  1.741 ( 1.658)	Data  0.172 ( 0.079)	InnerLoop  0.699 ( 0.698)	Loss 5.6436e-01 (5.1333e-01)	Acc@1  80.03 ( 82.27)
The current update step is 11910
GPU_0_using curriculum 40 with window 40
Epoch: [397][20/30]	Time  1.602 ( 1.617)	Data  0.045 ( 0.062)	InnerLoop  0.682 ( 0.691)	Loss 4.7169e-01 (5.0283e-01)	Acc@1  84.45 ( 82.81)
The current update step is 11940
GPU_0_using curriculum 40 with window 40
Epoch: [398][20/30]	Time  1.620 ( 1.638)	Data  0.046 ( 0.051)	InnerLoop  0.702 ( 0.715)	Loss 5.1164e-01 (5.1272e-01)	Acc@1  83.03 ( 82.67)
The current update step is 11970
GPU_0_using curriculum 40 with window 40
Epoch: [399][20/30]	Time  1.616 ( 1.654)	Data  0.047 ( 0.079)	InnerLoop  0.693 ( 0.697)	Loss 4.8017e-01 (5.2541e-01)	Acc@1  83.11 ( 81.92)
The current update step is 12000
The current seed is 3755138561985494538
The current lr is: 0.0015
Testing Results:
 *   Acc@1 72.500
 *   Acc@1 72.766
 *   Acc@1 72.605
 *   Acc@1 72.838
 *   Acc@1 72.092
 *   Acc@1 72.751
 *   Acc@1 67.342
 *   Acc@1 67.562
 *   Acc@1 66.882
 *   Acc@1 66.977
 *   Acc@1 66.605
 *   Acc@1 66.972
Training for 300 epoch: 69.92105263157895
Training for 600 epoch: 69.74342105263159
Training for 1000 epoch: 69.34868421052632
Training for 300 epoch: 70.16375
Training for 600 epoch: 69.9075
Training for 1000 epoch: 69.86125
[[69.92105263157895, 69.74342105263159, 69.34868421052632], [70.16375, 69.9075, 69.86125]]
train loss 0.9473656094868977, epoch 399, best loss 0.4224886600335439, best_epoch 359
GPU_0_using curriculum 40 with window 40
Epoch: [400][20/30]	Time  1.755 ( 1.663)	Data  0.049 ( 0.080)	InnerLoop  0.824 ( 0.703)	Loss 5.2325e-01 (4.9347e-01)	Acc@1  83.30 ( 82.86)
The current update step is 12030
GPU_0_using curriculum 40 with window 40
Epoch: [401][20/30]	Time  1.615 ( 1.638)	Data  0.055 ( 0.065)	InnerLoop  0.691 ( 0.701)	Loss 5.0498e-01 (4.9654e-01)	Acc@1  81.86 ( 82.86)
The current update step is 12060
GPU_0_using curriculum 40 with window 40
Epoch: [402][20/30]	Time  1.604 ( 1.651)	Data  0.042 ( 0.052)	InnerLoop  0.689 ( 0.721)	Loss 5.2379e-01 (5.3007e-01)	Acc@1  81.64 ( 81.49)
The current update step is 12090
GPU_0_using curriculum 40 with window 40
Epoch: [403][20/30]	Time  1.614 ( 1.637)	Data  0.049 ( 0.058)	InnerLoop  0.692 ( 0.707)	Loss 4.8408e-01 (5.1818e-01)	Acc@1  82.35 ( 82.05)
The current update step is 12120
GPU_0_using curriculum 40 with window 40
Epoch: [404][20/30]	Time  1.736 ( 1.645)	Data  0.174 ( 0.078)	InnerLoop  0.689 ( 0.694)	Loss 4.8198e-01 (4.9366e-01)	Acc@1  84.03 ( 83.09)
The current update step is 12150
The current seed is 16441547505583616392
The current lr is: 0.0015
Testing Results:
 *   Acc@1 48.592
 *   Acc@1 48.543
 *   Acc@1 49.750
 *   Acc@1 50.393
 *   Acc@1 50.711
 *   Acc@1 51.140
 *   Acc@1 70.803
 *   Acc@1 70.842
 *   Acc@1 69.224
 *   Acc@1 69.194
 *   Acc@1 70.500
 *   Acc@1 70.397
Training for 300 epoch: 59.69736842105263
Training for 600 epoch: 59.48684210526316
Training for 1000 epoch: 60.60526315789474
Training for 300 epoch: 59.6925
Training for 600 epoch: 59.793749999999996
Training for 1000 epoch: 60.76833333333333
[[59.69736842105263, 59.48684210526316, 60.60526315789474], [59.6925, 59.793749999999996, 60.76833333333333]]
train loss 0.7179515479087829, epoch 404, best loss 0.4224886600335439, best_epoch 359
GPU_0_using curriculum 40 with window 40
Epoch: [405][20/30]	Time  1.609 ( 1.630)	Data  0.045 ( 0.057)	InnerLoop  0.687 ( 0.705)	Loss 5.0510e-01 (5.3458e-01)	Acc@1  82.18 ( 81.58)
The current update step is 12180
GPU_0_using curriculum 40 with window 40
Epoch: [406][20/30]	Time  1.770 ( 1.661)	Data  0.183 ( 0.079)	InnerLoop  0.696 ( 0.702)	Loss 5.3128e-01 (5.0745e-01)	Acc@1  81.13 ( 82.43)
The current update step is 12210
GPU_0_using curriculum 40 with window 40
Epoch: [407][20/30]	Time  1.620 ( 1.653)	Data  0.048 ( 0.066)	InnerLoop  0.696 ( 0.708)	Loss 5.1403e-01 (5.1678e-01)	Acc@1  82.03 ( 82.14)
The current update step is 12240
GPU_0_using curriculum 40 with window 40
Epoch: [408][20/30]	Time  1.625 ( 1.650)	Data  0.042 ( 0.051)	InnerLoop  0.701 ( 0.720)	Loss 5.6717e-01 (5.2903e-01)	Acc@1  80.27 ( 81.66)
The current update step is 12270
GPU_0_using curriculum 40 with window 40
Epoch: [409][20/30]	Time  1.642 ( 1.630)	Data  0.051 ( 0.079)	InnerLoop  0.684 ( 0.679)	Loss 4.5032e-01 (5.0152e-01)	Acc@1  85.06 ( 82.56)
The current update step is 12300
The current seed is 8911798873833355012
The current lr is: 0.0015
Testing Results:
 *   Acc@1 76.224
 *   Acc@1 77.018
 *   Acc@1 76.961
 *   Acc@1 77.335
 *   Acc@1 76.184
 *   Acc@1 76.722
 *   Acc@1 74.408
 *   Acc@1 74.713
 *   Acc@1 74.895
 *   Acc@1 74.933
 *   Acc@1 74.513
 *   Acc@1 74.876
Training for 300 epoch: 75.31578947368422
Training for 600 epoch: 75.92763157894737
Training for 1000 epoch: 75.34868421052632
Training for 300 epoch: 75.86541666666668
Training for 600 epoch: 76.13374999999999
Training for 1000 epoch: 75.79875
[[75.31578947368422, 75.92763157894737, 75.34868421052632], [75.86541666666668, 76.13374999999999, 75.79875]]
train loss 0.7010336535135905, epoch 409, best loss 0.4224886600335439, best_epoch 359
GPU_0_using curriculum 40 with window 40
Epoch: [410][20/30]	Time  1.743 ( 1.657)	Data  0.046 ( 0.079)	InnerLoop  0.820 ( 0.699)	Loss 5.0791e-01 (5.0674e-01)	Acc@1  82.03 ( 82.52)
The current update step is 12330
GPU_0_using curriculum 40 with window 40
Epoch: [411][20/30]	Time  1.615 ( 1.645)	Data  0.046 ( 0.065)	InnerLoop  0.695 ( 0.706)	Loss 5.0658e-01 (5.0674e-01)	Acc@1  81.96 ( 82.27)
The current update step is 12360
GPU_0_using curriculum 40 with window 40
Epoch: [412][20/30]	Time  1.649 ( 1.650)	Data  0.043 ( 0.051)	InnerLoop  0.703 ( 0.722)	Loss 4.6543e-01 (5.0468e-01)	Acc@1  83.89 ( 82.85)
The current update step is 12390
GPU_0_using curriculum 40 with window 40
Epoch: [413][20/30]	Time  1.605 ( 1.628)	Data  0.040 ( 0.057)	InnerLoop  0.682 ( 0.703)	Loss 5.3245e-01 (5.0158e-01)	Acc@1  81.81 ( 82.77)
The current update step is 12420
GPU_0_using curriculum 40 with window 40
Epoch: [414][20/30]	Time  1.741 ( 1.654)	Data  0.180 ( 0.078)	InnerLoop  0.691 ( 0.698)	Loss 5.9697e-01 (5.1118e-01)	Acc@1  80.40 ( 82.33)
The current update step is 12450
The current seed is 5736476047290987426
The current lr is: 0.0015
Testing Results:
 *   Acc@1 76.355
 *   Acc@1 76.951
 *   Acc@1 76.211
 *   Acc@1 76.607
 *   Acc@1 76.039
 *   Acc@1 76.642
 *   Acc@1 79.671
 *   Acc@1 80.210
 *   Acc@1 79.447
 *   Acc@1 80.033
 *   Acc@1 79.105
 *   Acc@1 79.810
Training for 300 epoch: 78.01315789473685
Training for 600 epoch: 77.82894736842105
Training for 1000 epoch: 77.57236842105263
Training for 300 epoch: 78.58041666666666
Training for 600 epoch: 78.32
Training for 1000 epoch: 78.22625
[[78.01315789473685, 77.82894736842105, 77.57236842105263], [78.58041666666666, 78.32, 78.22625]]
train loss 0.40410459149678546, epoch 414, best loss 0.40410459149678546, best_epoch 414
GPU_0_using curriculum 40 with window 40
Epoch: [415][20/30]	Time  1.590 ( 1.645)	Data  0.041 ( 0.059)	InnerLoop  0.680 ( 0.711)	Loss 5.2472e-01 (5.2289e-01)	Acc@1  81.93 ( 82.05)
The current update step is 12480
GPU_0_using curriculum 40 with window 40
Epoch: [416][20/30]	Time  1.746 ( 1.655)	Data  0.177 ( 0.080)	InnerLoop  0.691 ( 0.699)	Loss 5.3618e-01 (5.2314e-01)	Acc@1  82.71 ( 82.28)
The current update step is 12510
GPU_0_using curriculum 40 with window 40
Epoch: [417][20/30]	Time  1.610 ( 1.647)	Data  0.048 ( 0.066)	InnerLoop  0.693 ( 0.707)	Loss 4.9315e-01 (5.0779e-01)	Acc@1  82.76 ( 82.83)
The current update step is 12540
GPU_0_using curriculum 40 with window 40
Epoch: [418][20/30]	Time  1.629 ( 1.664)	Data  0.048 ( 0.051)	InnerLoop  0.705 ( 0.730)	Loss 4.7916e-01 (5.0850e-01)	Acc@1  83.42 ( 82.78)
The current update step is 12570
GPU_0_using curriculum 40 with window 40
Epoch: [419][20/30]	Time  1.629 ( 1.668)	Data  0.047 ( 0.081)	InnerLoop  0.705 ( 0.702)	Loss 4.5206e-01 (5.0484e-01)	Acc@1  83.69 ( 83.13)
The current update step is 12600
The current seed is 4121654619030937781
The current lr is: 0.0015
Testing Results:
 *   Acc@1 77.461
 *   Acc@1 78.368
 *   Acc@1 55.553
 *   Acc@1 55.508
 *   Acc@1 55.132
 *   Acc@1 55.517
 *   Acc@1 76.013
 *   Acc@1 76.425
 *   Acc@1 76.329
 *   Acc@1 76.866
 *   Acc@1 76.316
 *   Acc@1 76.927
Training for 300 epoch: 76.73684210526315
Training for 600 epoch: 65.94078947368422
Training for 1000 epoch: 65.72368421052632
Training for 300 epoch: 77.39666666666668
Training for 600 epoch: 66.18708333333333
Training for 1000 epoch: 66.2225
[[76.73684210526315, 65.94078947368422, 65.72368421052632], [77.39666666666668, 66.18708333333333, 66.2225]]
train loss 0.6796043068250021, epoch 419, best loss 0.40410459149678546, best_epoch 414
GPU_0_using curriculum 40 with window 40
Epoch: [420][20/30]	Time  1.761 ( 1.661)	Data  0.048 ( 0.079)	InnerLoop  0.832 ( 0.705)	Loss 5.1155e-01 (4.9450e-01)	Acc@1  82.86 ( 82.89)
The current update step is 12630
GPU_0_using curriculum 40 with window 40
Epoch: [421][20/30]	Time  1.601 ( 1.637)	Data  0.049 ( 0.064)	InnerLoop  0.683 ( 0.702)	Loss 4.7241e-01 (4.9413e-01)	Acc@1  84.42 ( 82.88)
The current update step is 12660
GPU_0_using curriculum 40 with window 40
Epoch: [422][20/30]	Time  1.630 ( 1.655)	Data  0.051 ( 0.053)	InnerLoop  0.704 ( 0.725)	Loss 4.6196e-01 (4.8869e-01)	Acc@1  84.57 ( 83.00)
The current update step is 12690
GPU_0_using curriculum 40 with window 40
Epoch: [423][20/30]	Time  1.636 ( 1.662)	Data  0.047 ( 0.059)	InnerLoop  0.702 ( 0.722)	Loss 4.8607e-01 (4.9858e-01)	Acc@1  83.23 ( 82.60)
The current update step is 12720
GPU_0_using curriculum 40 with window 40
Epoch: [424][20/30]	Time  1.778 ( 1.664)	Data  0.181 ( 0.079)	InnerLoop  0.704 ( 0.706)	Loss 5.3796e-01 (4.8700e-01)	Acc@1  81.40 ( 83.06)
The current update step is 12750
The current seed is 4214421050540132342
The current lr is: 0.0015
Testing Results:
 *   Acc@1 68.513
 *   Acc@1 68.677
 *   Acc@1 69.553
 *   Acc@1 69.469
 *   Acc@1 70.039
 *   Acc@1 69.873
 *   Acc@1 47.447
 *   Acc@1 47.436
 *   Acc@1 60.329
 *   Acc@1 61.214
 *   Acc@1 59.105
 *   Acc@1 60.174
Training for 300 epoch: 57.98026315789473
Training for 600 epoch: 64.94078947368422
Training for 1000 epoch: 64.57236842105263
Training for 300 epoch: 58.05625
Training for 600 epoch: 65.34166666666667
Training for 1000 epoch: 65.02375
[[57.98026315789473, 64.94078947368422, 64.57236842105263], [58.05625, 65.34166666666667, 65.02375]]
train loss 1.1085730779647827, epoch 424, best loss 0.40410459149678546, best_epoch 414
GPU_0_using curriculum 40 with window 40
Epoch: [425][20/30]	Time  1.623 ( 1.652)	Data  0.043 ( 0.059)	InnerLoop  0.696 ( 0.714)	Loss 4.6291e-01 (5.0564e-01)	Acc@1  84.13 ( 82.75)
The current update step is 12780
GPU_0_using curriculum 40 with window 40
Epoch: [426][20/30]	Time  1.758 ( 1.660)	Data  0.184 ( 0.080)	InnerLoop  0.701 ( 0.705)	Loss 4.9127e-01 (5.0755e-01)	Acc@1  83.94 ( 82.71)
The current update step is 12810
GPU_0_using curriculum 40 with window 40
Epoch: [427][20/30]	Time  1.619 ( 1.651)	Data  0.046 ( 0.065)	InnerLoop  0.701 ( 0.709)	Loss 4.6554e-01 (5.1655e-01)	Acc@1  84.18 ( 82.36)
The current update step is 12840
GPU_0_using curriculum 40 with window 40
Epoch: [428][20/30]	Time  1.617 ( 1.656)	Data  0.041 ( 0.052)	InnerLoop  0.704 ( 0.726)	Loss 4.5425e-01 (4.8865e-01)	Acc@1  84.86 ( 83.33)
The current update step is 12870
GPU_0_using curriculum 40 with window 40
Epoch: [429][20/30]	Time  1.642 ( 1.658)	Data  0.049 ( 0.079)	InnerLoop  0.699 ( 0.699)	Loss 4.8389e-01 (5.0159e-01)	Acc@1  83.18 ( 82.64)
The current update step is 12900
The current seed is 3905425843307751441
The current lr is: 0.0015
Testing Results:
 *   Acc@1 67.645
 *   Acc@1 68.212
 *   Acc@1 67.592
 *   Acc@1 68.013
 *   Acc@1 66.447
 *   Acc@1 67.362
 *   Acc@1 69.053
 *   Acc@1 69.270
 *   Acc@1 72.566
 *   Acc@1 72.610
 *   Acc@1 72.316
 *   Acc@1 73.007
Training for 300 epoch: 68.34868421052632
Training for 600 epoch: 70.07894736842104
Training for 1000 epoch: 69.38157894736841
Training for 300 epoch: 68.74083333333334
Training for 600 epoch: 70.31166666666667
Training for 1000 epoch: 70.185
[[68.34868421052632, 70.07894736842104, 69.38157894736841], [68.74083333333334, 70.31166666666667, 70.185]]
train loss 0.7828520547866822, epoch 429, best loss 0.40410459149678546, best_epoch 414
GPU_0_using curriculum 40 with window 40
Epoch: [430][20/30]	Time  1.749 ( 1.655)	Data  0.047 ( 0.080)	InnerLoop  0.827 ( 0.699)	Loss 6.1047e-01 (4.9483e-01)	Acc@1  78.71 ( 82.66)
The current update step is 12930
GPU_0_using curriculum 40 with window 40
Epoch: [431][20/30]	Time  1.617 ( 1.654)	Data  0.042 ( 0.066)	InnerLoop  0.698 ( 0.711)	Loss 4.8638e-01 (4.9438e-01)	Acc@1  82.86 ( 82.95)
The current update step is 12960
GPU_0_using curriculum 40 with window 40
Epoch: [432][20/30]	Time  1.627 ( 1.656)	Data  0.049 ( 0.052)	InnerLoop  0.699 ( 0.726)	Loss 4.9263e-01 (5.1209e-01)	Acc@1  83.08 ( 82.29)
The current update step is 12990
GPU_0_using curriculum 40 with window 40
Epoch: [433][20/30]	Time  1.609 ( 1.652)	Data  0.047 ( 0.058)	InnerLoop  0.698 ( 0.717)	Loss 4.9348e-01 (5.1655e-01)	Acc@1  82.32 ( 81.87)
The current update step is 13020
GPU_0_using curriculum 40 with window 40
Epoch: [434][20/30]	Time  1.790 ( 1.651)	Data  0.179 ( 0.078)	InnerLoop  0.697 ( 0.698)	Loss 5.1575e-01 (5.0858e-01)	Acc@1  82.84 ( 82.53)
The current update step is 13050
The current seed is 17850030107133863542
The current lr is: 0.0015
Testing Results:
 *   Acc@1 71.237
 *   Acc@1 71.487
 *   Acc@1 64.789
 *   Acc@1 64.521
 *   Acc@1 63.763
 *   Acc@1 63.414
 *   Acc@1 43.092
 *   Acc@1 43.561
 *   Acc@1 44.026
 *   Acc@1 44.338
 *   Acc@1 44.197
 *   Acc@1 44.378
Training for 300 epoch: 57.164473684210535
Training for 600 epoch: 54.4078947368421
Training for 1000 epoch: 53.98026315789474
Training for 300 epoch: 57.524166666666666
Training for 600 epoch: 54.429583333333326
Training for 1000 epoch: 53.896249999999995
[[57.164473684210535, 54.4078947368421, 53.98026315789474], [57.524166666666666, 54.429583333333326, 53.896249999999995]]
train loss 1.8193645878473919, epoch 434, best loss 0.40410459149678546, best_epoch 414
GPU_0_using curriculum 40 with window 40
Epoch: [435][20/30]	Time  1.628 ( 1.654)	Data  0.043 ( 0.057)	InnerLoop  0.702 ( 0.719)	Loss 4.8591e-01 (5.1149e-01)	Acc@1  83.52 ( 82.70)
The current update step is 13080
GPU_0_using curriculum 40 with window 40
Epoch: [436][20/30]	Time  1.750 ( 1.659)	Data  0.175 ( 0.079)	InnerLoop  0.695 ( 0.702)	Loss 4.6989e-01 (5.2179e-01)	Acc@1  83.91 ( 82.11)
The current update step is 13110
GPU_0_using curriculum 40 with window 40
Epoch: [437][20/30]	Time  1.584 ( 1.654)	Data  0.046 ( 0.065)	InnerLoop  0.672 ( 0.711)	Loss 5.0257e-01 (4.9330e-01)	Acc@1  83.20 ( 83.45)
The current update step is 13140
GPU_0_using curriculum 40 with window 40
Epoch: [438][20/30]	Time  1.612 ( 1.654)	Data  0.046 ( 0.053)	InnerLoop  0.692 ( 0.724)	Loss 5.7718e-01 (5.1589e-01)	Acc@1  80.25 ( 82.14)
The current update step is 13170
GPU_0_using curriculum 40 with window 40
Epoch: [439][20/30]	Time  1.613 ( 1.652)	Data  0.048 ( 0.080)	InnerLoop  0.692 ( 0.695)	Loss 4.4638e-01 (4.9652e-01)	Acc@1  84.94 ( 83.23)
The current update step is 13200
The current seed is 7790238304440594574
The current lr is: 0.0015
Testing Results:
 *   Acc@1 55.382
 *   Acc@1 56.178
 *   Acc@1 70.618
 *   Acc@1 70.737
 *   Acc@1 70.671
 *   Acc@1 71.081
 *   Acc@1 70.250
 *   Acc@1 70.433
 *   Acc@1 51.711
 *   Acc@1 51.513
 *   Acc@1 57.645
 *   Acc@1 57.886
Training for 300 epoch: 62.815789473684205
Training for 600 epoch: 61.16447368421052
Training for 1000 epoch: 64.15789473684211
Training for 300 epoch: 63.30583333333334
Training for 600 epoch: 61.124583333333334
Training for 1000 epoch: 64.48333333333333
[[62.815789473684205, 61.16447368421052, 64.15789473684211], [63.30583333333334, 61.124583333333334, 64.48333333333333]]
train loss 1.635196627108256, epoch 439, best loss 0.40410459149678546, best_epoch 414
GPU_0_using curriculum 40 with window 40
Epoch: [440][20/30]	Time  1.754 ( 1.662)	Data  0.046 ( 0.080)	InnerLoop  0.838 ( 0.705)	Loss 4.9203e-01 (5.0202e-01)	Acc@1  83.54 ( 83.19)
The current update step is 13230
GPU_0_using curriculum 40 with window 40
Epoch: [441][20/30]	Time  1.593 ( 1.650)	Data  0.047 ( 0.065)	InnerLoop  0.683 ( 0.709)	Loss 5.5291e-01 (5.2602e-01)	Acc@1  81.03 ( 81.85)
The current update step is 13260
GPU_0_using curriculum 40 with window 40
Epoch: [442][20/30]	Time  1.624 ( 1.657)	Data  0.049 ( 0.053)	InnerLoop  0.701 ( 0.726)	Loss 6.3853e-01 (5.0180e-01)	Acc@1  77.83 ( 82.72)
The current update step is 13290
GPU_0_using curriculum 40 with window 40
Epoch: [443][20/30]	Time  1.600 ( 1.650)	Data  0.044 ( 0.059)	InnerLoop  0.694 ( 0.716)	Loss 5.1656e-01 (5.0388e-01)	Acc@1  83.20 ( 82.55)
The current update step is 13320
GPU_0_using curriculum 40 with window 40
Epoch: [444][20/30]	Time  1.759 ( 1.661)	Data  0.183 ( 0.080)	InnerLoop  0.695 ( 0.704)	Loss 5.0735e-01 (5.0966e-01)	Acc@1  83.42 ( 82.38)
The current update step is 13350
The current seed is 2496046123741767741
The current lr is: 0.0015
Testing Results:
 *   Acc@1 77.132
 *   Acc@1 78.303
 *   Acc@1 77.105
 *   Acc@1 77.833
 *   Acc@1 77.329
 *   Acc@1 77.661
 *   Acc@1 72.250
 *   Acc@1 72.177
 *   Acc@1 71.487
 *   Acc@1 71.750
 *   Acc@1 71.724
 *   Acc@1 71.523
Training for 300 epoch: 74.69078947368422
Training for 600 epoch: 74.29605263157896
Training for 1000 epoch: 74.52631578947368
Training for 300 epoch: 75.24041666666666
Training for 600 epoch: 74.79166666666666
Training for 1000 epoch: 74.59208333333333
[[74.69078947368422, 74.29605263157896, 74.52631578947368], [75.24041666666666, 74.79166666666666, 74.59208333333333]]
train loss 0.8354974789937337, epoch 444, best loss 0.40410459149678546, best_epoch 414
GPU_0_using curriculum 40 with window 40
Epoch: [445][20/30]	Time  1.595 ( 1.645)	Data  0.040 ( 0.058)	InnerLoop  0.686 ( 0.712)	Loss 4.9160e-01 (5.1278e-01)	Acc@1  82.67 ( 82.18)
The current update step is 13380
GPU_0_using curriculum 40 with window 40
Epoch: [446][20/30]	Time  1.771 ( 1.672)	Data  0.175 ( 0.081)	InnerLoop  0.702 ( 0.707)	Loss 5.8129e-01 (4.8307e-01)	Acc@1  79.96 ( 83.26)
The current update step is 13410
GPU_0_using curriculum 40 with window 40
Epoch: [447][20/30]	Time  1.624 ( 1.660)	Data  0.046 ( 0.067)	InnerLoop  0.694 ( 0.715)	Loss 5.7714e-01 (5.1996e-01)	Acc@1  81.30 ( 81.98)
The current update step is 13440
GPU_0_using curriculum 40 with window 40
Epoch: [448][20/30]	Time  1.641 ( 1.658)	Data  0.047 ( 0.053)	InnerLoop  0.701 ( 0.726)	Loss 4.7118e-01 (5.4254e-01)	Acc@1  83.40 ( 81.08)
The current update step is 13470
GPU_0_using curriculum 40 with window 40
Epoch: [449][20/30]	Time  1.625 ( 1.653)	Data  0.049 ( 0.081)	InnerLoop  0.694 ( 0.697)	Loss 5.4138e-01 (5.2915e-01)	Acc@1  81.76 ( 81.67)
The current update step is 13500
The current seed is 2147456135206521192
The current lr is: 0.0015
Testing Results:
 *   Acc@1 74.000
 *   Acc@1 74.185
 *   Acc@1 73.895
 *   Acc@1 74.142
 *   Acc@1 74.250
 *   Acc@1 74.266
 *   Acc@1 42.763
 *   Acc@1 42.871
 *   Acc@1 45.000
 *   Acc@1 45.897
 *   Acc@1 45.579
 *   Acc@1 46.056
Training for 300 epoch: 58.381578947368425
Training for 600 epoch: 59.44736842105263
Training for 1000 epoch: 59.91447368421053
Training for 300 epoch: 58.52791666666667
Training for 600 epoch: 60.01916666666666
Training for 1000 epoch: 60.16083333333333
[[58.381578947368425, 59.44736842105263, 59.91447368421053], [58.52791666666667, 60.01916666666666, 60.16083333333333]]
train loss 2.2005408238728843, epoch 449, best loss 0.40410459149678546, best_epoch 414
GPU_0_using curriculum 40 with window 40
Epoch: [450][20/30]	Time  1.759 ( 1.661)	Data  0.042 ( 0.079)	InnerLoop  0.832 ( 0.704)	Loss 7.3255e-01 (5.2852e-01)	Acc@1  76.88 ( 81.70)
The current update step is 13530
GPU_0_using curriculum 40 with window 40
Epoch: [451][20/30]	Time  1.648 ( 1.655)	Data  0.042 ( 0.065)	InnerLoop  0.704 ( 0.713)	Loss 5.6687e-01 (4.9907e-01)	Acc@1  80.81 ( 82.79)
The current update step is 13560
GPU_0_using curriculum 40 with window 40
Epoch: [452][20/30]	Time  1.626 ( 1.653)	Data  0.046 ( 0.052)	InnerLoop  0.701 ( 0.725)	Loss 6.5396e-01 (5.1453e-01)	Acc@1  77.83 ( 82.19)
The current update step is 13590
GPU_0_using curriculum 40 with window 40
Epoch: [453][20/30]	Time  1.625 ( 1.645)	Data  0.049 ( 0.059)	InnerLoop  0.700 ( 0.716)	Loss 5.1824e-01 (5.4696e-01)	Acc@1  81.57 ( 81.46)
The current update step is 13620
GPU_0_using curriculum 40 with window 40
Epoch: [454][20/30]	Time  1.781 ( 1.658)	Data  0.176 ( 0.078)	InnerLoop  0.704 ( 0.703)	Loss 4.3442e-01 (5.0412e-01)	Acc@1  84.99 ( 82.50)
The current update step is 13650
The current seed is 11619933804080154789
The current lr is: 0.0015
Testing Results:
 *   Acc@1 67.868
 *   Acc@1 68.756
 *   Acc@1 74.868
 *   Acc@1 76.007
 *   Acc@1 74.908
 *   Acc@1 76.092
 *   Acc@1 58.263
 *   Acc@1 59.059
 *   Acc@1 64.039
 *   Acc@1 64.457
 *   Acc@1 63.566
 *   Acc@1 64.320
Training for 300 epoch: 63.065789473684205
Training for 600 epoch: 69.45394736842104
Training for 1000 epoch: 69.23684210526316
Training for 300 epoch: 63.9075
Training for 600 epoch: 70.23249999999999
Training for 1000 epoch: 70.20583333333333
[[63.065789473684205, 69.45394736842104, 69.23684210526316], [63.9075, 70.23249999999999, 70.20583333333333]]
train loss 1.0735582984288534, epoch 454, best loss 0.40410459149678546, best_epoch 414
GPU_0_using curriculum 40 with window 40
Epoch: [455][20/30]	Time  1.611 ( 1.653)	Data  0.043 ( 0.060)	InnerLoop  0.689 ( 0.715)	Loss 4.7652e-01 (5.0056e-01)	Acc@1  83.67 ( 82.89)
The current update step is 13680
GPU_0_using curriculum 40 with window 40
Epoch: [456][20/30]	Time  1.747 ( 1.648)	Data  0.176 ( 0.078)	InnerLoop  0.688 ( 0.695)	Loss 6.8083e-01 (5.2395e-01)	Acc@1  74.56 ( 81.67)
The current update step is 13710
GPU_0_using curriculum 40 with window 40
Epoch: [457][20/30]	Time  1.631 ( 1.653)	Data  0.042 ( 0.065)	InnerLoop  0.704 ( 0.709)	Loss 4.9619e-01 (5.3391e-01)	Acc@1  81.45 ( 81.51)
The current update step is 13740
GPU_0_using curriculum 40 with window 40
Epoch: [458][20/30]	Time  1.614 ( 1.633)	Data  0.045 ( 0.050)	InnerLoop  0.687 ( 0.711)	Loss 4.6772e-01 (5.0798e-01)	Acc@1  83.62 ( 82.36)
The current update step is 13770
GPU_0_using curriculum 40 with window 40
Epoch: [459][20/30]	Time  1.627 ( 1.662)	Data  0.050 ( 0.080)	InnerLoop  0.692 ( 0.700)	Loss 4.6895e-01 (5.4456e-01)	Acc@1  83.89 ( 81.04)
The current update step is 13800
The current seed is 1563702727485154672
The current lr is: 0.0015
Testing Results:
 *   Acc@1 75.303
 *   Acc@1 76.089
 *   Acc@1 75.474
 *   Acc@1 76.176
 *   Acc@1 74.789
 *   Acc@1 75.940
 *   Acc@1 61.895
 *   Acc@1 61.628
 *   Acc@1 61.947
 *   Acc@1 62.013
 *   Acc@1 62.132
 *   Acc@1 62.246
Training for 300 epoch: 68.59868421052632
Training for 600 epoch: 68.71052631578948
Training for 1000 epoch: 68.46052631578947
Training for 300 epoch: 68.85875
Training for 600 epoch: 69.09416666666667
Training for 1000 epoch: 69.09291666666667
[[68.59868421052632, 68.71052631578948, 68.46052631578947], [68.85875, 69.09416666666667, 69.09291666666667]]
train loss 1.4148837141036987, epoch 459, best loss 0.40410459149678546, best_epoch 414
GPU_0_using curriculum 40 with window 40
Epoch: [460][20/30]	Time  1.723 ( 1.665)	Data  0.039 ( 0.079)	InnerLoop  0.809 ( 0.702)	Loss 4.9407e-01 (5.0170e-01)	Acc@1  83.45 ( 82.98)
The current update step is 13830
GPU_0_using curriculum 40 with window 40
Epoch: [461][20/30]	Time  1.632 ( 1.653)	Data  0.051 ( 0.064)	InnerLoop  0.691 ( 0.708)	Loss 4.9299e-01 (5.1921e-01)	Acc@1  82.52 ( 82.14)
The current update step is 13860
GPU_0_using curriculum 40 with window 40
Epoch: [462][20/30]	Time  1.599 ( 1.629)	Data  0.042 ( 0.050)	InnerLoop  0.684 ( 0.710)	Loss 4.7766e-01 (5.0110e-01)	Acc@1  83.64 ( 82.82)
The current update step is 13890
GPU_0_using curriculum 40 with window 40
Epoch: [463][20/30]	Time  1.640 ( 1.658)	Data  0.047 ( 0.059)	InnerLoop  0.707 ( 0.718)	Loss 4.6742e-01 (4.9249e-01)	Acc@1  84.47 ( 83.08)
The current update step is 13920
GPU_0_using curriculum 40 with window 40
Epoch: [464][20/30]	Time  1.761 ( 1.660)	Data  0.182 ( 0.079)	InnerLoop  0.700 ( 0.701)	Loss 5.4010e-01 (5.1780e-01)	Acc@1  81.49 ( 82.22)
The current update step is 13950
The current seed is 14585117165614873341
The current lr is: 0.0015
Testing Results:
 *   Acc@1 77.816
 *   Acc@1 77.850
 *   Acc@1 76.934
 *   Acc@1 77.244
 *   Acc@1 76.039
 *   Acc@1 76.583
 *   Acc@1 61.789
 *   Acc@1 61.339
 *   Acc@1 62.079
 *   Acc@1 62.428
 *   Acc@1 62.092
 *   Acc@1 62.488
Training for 300 epoch: 69.80263157894737
Training for 600 epoch: 69.50657894736842
Training for 1000 epoch: 69.0657894736842
Training for 300 epoch: 69.59458333333333
Training for 600 epoch: 69.83625
Training for 1000 epoch: 69.53583333333333
[[69.80263157894737, 69.50657894736842, 69.0657894736842], [69.59458333333333, 69.83625, 69.53583333333333]]
train loss 1.2762330684661864, epoch 464, best loss 0.40410459149678546, best_epoch 414
GPU_0_using curriculum 40 with window 40
Epoch: [465][20/30]	Time  1.615 ( 1.652)	Data  0.048 ( 0.059)	InnerLoop  0.695 ( 0.716)	Loss 5.0837e-01 (4.8712e-01)	Acc@1  82.08 ( 83.39)
The current update step is 13980
GPU_0_using curriculum 40 with window 40
Epoch: [466][20/30]	Time  1.722 ( 1.649)	Data  0.171 ( 0.078)	InnerLoop  0.681 ( 0.695)	Loss 4.4972e-01 (5.1646e-01)	Acc@1  84.35 ( 82.16)
The current update step is 14010
GPU_0_using curriculum 40 with window 40
Epoch: [467][20/30]	Time  1.597 ( 1.645)	Data  0.042 ( 0.065)	InnerLoop  0.686 ( 0.705)	Loss 4.8924e-01 (4.9152e-01)	Acc@1  82.81 ( 83.06)
The current update step is 14040
GPU_0_using curriculum 40 with window 40
Epoch: [468][20/30]	Time  1.604 ( 1.648)	Data  0.046 ( 0.051)	InnerLoop  0.683 ( 0.719)	Loss 4.8576e-01 (5.1102e-01)	Acc@1  83.33 ( 82.32)
The current update step is 14070
GPU_0_using curriculum 40 with window 40
Epoch: [469][20/30]	Time  1.613 ( 1.653)	Data  0.044 ( 0.079)	InnerLoop  0.690 ( 0.692)	Loss 5.5014e-01 (4.8995e-01)	Acc@1  81.49 ( 83.27)
The current update step is 14100
The current seed is 3385392409272377406
The current lr is: 0.0015
Testing Results:
 *   Acc@1 77.487
 *   Acc@1 78.118
 *   Acc@1 78.342
 *   Acc@1 78.562
 *   Acc@1 77.868
 *   Acc@1 78.780
 *   Acc@1 77.539
 *   Acc@1 78.106
 *   Acc@1 76.921
 *   Acc@1 77.293
 *   Acc@1 77.079
 *   Acc@1 77.683
Training for 300 epoch: 77.51315789473685
Training for 600 epoch: 77.63157894736841
Training for 1000 epoch: 77.47368421052632
Training for 300 epoch: 78.11208333333335
Training for 600 epoch: 77.92791666666668
Training for 1000 epoch: 78.23125
[[77.51315789473685, 77.63157894736841, 77.47368421052632], [78.11208333333335, 77.92791666666668, 78.23125]]
train loss 0.6106016194025675, epoch 469, best loss 0.40410459149678546, best_epoch 414
GPU_0_using curriculum 40 with window 40
Epoch: [470][20/30]	Time  1.721 ( 1.636)	Data  0.044 ( 0.076)	InnerLoop  0.811 ( 0.689)	Loss 4.3187e-01 (4.7875e-01)	Acc@1  85.55 ( 83.64)
The current update step is 14130
GPU_0_using curriculum 40 with window 40
Epoch: [471][20/30]	Time  1.631 ( 1.651)	Data  0.048 ( 0.065)	InnerLoop  0.699 ( 0.706)	Loss 4.5539e-01 (5.0421e-01)	Acc@1  83.30 ( 82.61)
The current update step is 14160
GPU_0_using curriculum 40 with window 40
Epoch: [472][20/30]	Time  1.634 ( 1.643)	Data  0.044 ( 0.051)	InnerLoop  0.702 ( 0.715)	Loss 4.8336e-01 (4.9917e-01)	Acc@1  83.20 ( 82.36)
The current update step is 14190
GPU_0_using curriculum 40 with window 40
Epoch: [473][20/30]	Time  1.630 ( 1.648)	Data  0.048 ( 0.058)	InnerLoop  0.699 ( 0.713)	Loss 5.4092e-01 (4.6753e-01)	Acc@1  83.76 ( 84.08)
The current update step is 14220
GPU_0_using curriculum 40 with window 40
Epoch: [474][20/30]	Time  1.756 ( 1.663)	Data  0.175 ( 0.079)	InnerLoop  0.699 ( 0.701)	Loss 5.5808e-01 (4.7464e-01)	Acc@1  79.93 ( 83.84)
The current update step is 14250
The current seed is 5604664772721442165
The current lr is: 0.0015
Testing Results:
 *   Acc@1 73.803
 *   Acc@1 74.207
 *   Acc@1 72.724
 *   Acc@1 73.407
 *   Acc@1 71.895
 *   Acc@1 72.847
 *   Acc@1 61.526
 *   Acc@1 62.389
 *   Acc@1 63.553
 *   Acc@1 63.930
 *   Acc@1 64.184
 *   Acc@1 64.064
Training for 300 epoch: 67.66447368421052
Training for 600 epoch: 68.13815789473685
Training for 1000 epoch: 68.03947368421052
Training for 300 epoch: 68.29791666666667
Training for 600 epoch: 68.66833333333334
Training for 1000 epoch: 68.45583333333333
[[67.66447368421052, 68.13815789473685, 68.03947368421052], [68.29791666666667, 68.66833333333334, 68.45583333333333]]
train loss 1.2022732744852702, epoch 474, best loss 0.40410459149678546, best_epoch 474
GPU_0_using curriculum 40 with window 40
Epoch: [475][20/30]	Time  1.662 ( 1.661)	Data  0.044 ( 0.058)	InnerLoop  0.693 ( 0.717)	Loss 4.6443e-01 (4.9343e-01)	Acc@1  84.06 ( 83.08)
The current update step is 14280
GPU_0_using curriculum 40 with window 40
Epoch: [476][20/30]	Time  1.749 ( 1.662)	Data  0.171 ( 0.079)	InnerLoop  0.698 ( 0.700)	Loss 4.5831e-01 (4.9858e-01)	Acc@1  84.86 ( 82.91)
The current update step is 14310
GPU_0_using curriculum 40 with window 40
Epoch: [477][20/30]	Time  1.614 ( 1.652)	Data  0.040 ( 0.065)	InnerLoop  0.694 ( 0.708)	Loss 4.8323e-01 (5.1294e-01)	Acc@1  84.08 ( 82.01)
The current update step is 14340
GPU_0_using curriculum 40 with window 40
Epoch: [478][20/30]	Time  1.615 ( 1.647)	Data  0.050 ( 0.052)	InnerLoop  0.696 ( 0.720)	Loss 4.7491e-01 (4.9300e-01)	Acc@1  85.03 ( 82.87)
The current update step is 14370
GPU_0_using curriculum 40 with window 40
Epoch: [479][20/30]	Time  1.633 ( 1.636)	Data  0.051 ( 0.078)	InnerLoop  0.697 ( 0.687)	Loss 5.5861e-01 (4.7657e-01)	Acc@1  79.69 ( 83.42)
The current update step is 14400
The current seed is 1175178753533839245
The current lr is: 0.0015
Testing Results:
 *   Acc@1 78.118
 *   Acc@1 78.513
 *   Acc@1 64.145
 *   Acc@1 64.522
 *   Acc@1 67.842
 *   Acc@1 68.902
 *   Acc@1 65.105
 *   Acc@1 65.930
 *   Acc@1 66.408
 *   Acc@1 67.207
 *   Acc@1 66.921
 *   Acc@1 67.692
Training for 300 epoch: 71.61184210526315
Training for 600 epoch: 65.27631578947368
Training for 1000 epoch: 67.38157894736841
Training for 300 epoch: 72.22125
Training for 600 epoch: 65.86458333333333
Training for 1000 epoch: 68.29708333333333
[[71.61184210526315, 65.27631578947368, 67.38157894736841], [72.22125, 65.86458333333333, 68.29708333333333]]
train loss 0.9446871441841126, epoch 479, best loss 0.40410459149678546, best_epoch 474
GPU_0_using curriculum 40 with window 40
Epoch: [480][20/30]	Time  1.771 ( 1.667)	Data  0.047 ( 0.079)	InnerLoop  0.842 ( 0.708)	Loss 5.0875e-01 (5.2198e-01)	Acc@1  81.69 ( 82.02)
The current update step is 14430
GPU_0_using curriculum 40 with window 40
Epoch: [481][20/30]	Time  1.654 ( 1.657)	Data  0.042 ( 0.064)	InnerLoop  0.709 ( 0.712)	Loss 4.8305e-01 (4.9210e-01)	Acc@1  83.13 ( 82.98)
The current update step is 14460
GPU_0_using curriculum 40 with window 40
Epoch: [482][20/30]	Time  1.630 ( 1.664)	Data  0.050 ( 0.054)	InnerLoop  0.700 ( 0.730)	Loss 4.5107e-01 (5.0918e-01)	Acc@1  84.79 ( 82.44)
The current update step is 14490
GPU_0_using curriculum 40 with window 40
Epoch: [483][20/30]	Time  1.622 ( 1.659)	Data  0.042 ( 0.060)	InnerLoop  0.697 ( 0.724)	Loss 5.6240e-01 (4.9926e-01)	Acc@1  80.79 ( 82.90)
The current update step is 14520
GPU_0_using curriculum 40 with window 40
Epoch: [484][20/30]	Time  1.754 ( 1.658)	Data  0.176 ( 0.079)	InnerLoop  0.699 ( 0.703)	Loss 4.6272e-01 (4.9478e-01)	Acc@1  83.81 ( 83.07)
The current update step is 14550
The current seed is 9260069018342699206
The current lr is: 0.0015
Testing Results:
 *   Acc@1 64.947
 *   Acc@1 65.548
 *   Acc@1 66.000
 *   Acc@1 65.881
 *   Acc@1 65.474
 *   Acc@1 65.862
 *   Acc@1 76.513
 *   Acc@1 77.091
 *   Acc@1 48.237
 *   Acc@1 47.680
 *   Acc@1 55.816
 *   Acc@1 55.678
Training for 300 epoch: 70.73026315789474
Training for 600 epoch: 57.118421052631575
Training for 1000 epoch: 60.64473684210526
Training for 300 epoch: 71.31958333333333
Training for 600 epoch: 56.78041666666667
Training for 1000 epoch: 60.76958333333333
[[70.73026315789474, 57.118421052631575, 60.64473684210526], [71.31958333333333, 56.78041666666667, 60.76958333333333]]
train loss 1.4201319803237915, epoch 484, best loss 0.40410459149678546, best_epoch 474
GPU_0_using curriculum 40 with window 40
Epoch: [485][20/30]	Time  1.631 ( 1.657)	Data  0.045 ( 0.057)	InnerLoop  0.700 ( 0.720)	Loss 5.2842e-01 (4.7852e-01)	Acc@1  82.03 ( 83.57)
The current update step is 14580
GPU_0_using curriculum 40 with window 40
Epoch: [486][20/30]	Time  1.754 ( 1.663)	Data  0.182 ( 0.079)	InnerLoop  0.691 ( 0.703)	Loss 5.0913e-01 (4.8177e-01)	Acc@1  82.28 ( 83.32)
The current update step is 14610
GPU_0_using curriculum 40 with window 40
Epoch: [487][20/30]	Time  1.636 ( 1.652)	Data  0.042 ( 0.065)	InnerLoop  0.710 ( 0.708)	Loss 4.9706e-01 (4.7916e-01)	Acc@1  83.23 ( 83.65)
The current update step is 14640
GPU_0_using curriculum 40 with window 40
Epoch: [488][20/30]	Time  1.623 ( 1.656)	Data  0.047 ( 0.052)	InnerLoop  0.694 ( 0.720)	Loss 4.3921e-01 (5.0554e-01)	Acc@1  85.69 ( 82.65)
The current update step is 14670
GPU_0_using curriculum 40 with window 40
Epoch: [489][20/30]	Time  1.630 ( 1.656)	Data  0.046 ( 0.079)	InnerLoop  0.692 ( 0.697)	Loss 4.3513e-01 (4.9390e-01)	Acc@1  84.91 ( 83.19)
The current update step is 14700
The current seed is 8853207513928440915
The current lr is: 0.0015
Testing Results:
 *   Acc@1 70.526
 *   Acc@1 70.972
 *   Acc@1 71.000
 *   Acc@1 71.455
 *   Acc@1 70.895
 *   Acc@1 71.464
 *   Acc@1 73.092
 *   Acc@1 73.377
 *   Acc@1 72.434
 *   Acc@1 72.855
 *   Acc@1 73.197
 *   Acc@1 73.185
Training for 300 epoch: 71.80921052631578
Training for 600 epoch: 71.71710526315789
Training for 1000 epoch: 72.04605263157895
Training for 300 epoch: 72.17458333333333
Training for 600 epoch: 72.155
Training for 1000 epoch: 72.32458333333334
[[71.80921052631578, 71.71710526315789, 72.04605263157895], [72.17458333333333, 72.155, 72.32458333333334]]
train loss 0.753030256207784, epoch 489, best loss 0.40410459149678546, best_epoch 474
GPU_0_using curriculum 40 with window 40
Epoch: [490][20/30]	Time  1.741 ( 1.651)	Data  0.041 ( 0.078)	InnerLoop  0.818 ( 0.696)	Loss 5.0014e-01 (5.0292e-01)	Acc@1  83.45 ( 82.60)
The current update step is 14730
GPU_0_using curriculum 40 with window 40
Epoch: [491][20/30]	Time  1.624 ( 1.660)	Data  0.042 ( 0.066)	InnerLoop  0.701 ( 0.712)	Loss 4.8265e-01 (4.9991e-01)	Acc@1  84.13 ( 82.68)
The current update step is 14760
GPU_0_using curriculum 40 with window 40
Epoch: [492][20/30]	Time  1.616 ( 1.652)	Data  0.043 ( 0.051)	InnerLoop  0.699 ( 0.722)	Loss 4.7184e-01 (4.9508e-01)	Acc@1  83.40 ( 83.00)
The current update step is 14790
GPU_0_using curriculum 40 with window 40
Epoch: [493][20/30]	Time  1.632 ( 1.655)	Data  0.050 ( 0.058)	InnerLoop  0.694 ( 0.716)	Loss 4.7616e-01 (5.0935e-01)	Acc@1  83.76 ( 82.67)
The current update step is 14820
GPU_0_using curriculum 40 with window 40
Epoch: [494][20/30]	Time  1.764 ( 1.667)	Data  0.182 ( 0.080)	InnerLoop  0.691 ( 0.707)	Loss 5.0847e-01 (4.9975e-01)	Acc@1  82.81 ( 82.88)
The current update step is 14850
The current seed is 12040800254697587222
The current lr is: 0.0015
Testing Results:
 *   Acc@1 70.224
 *   Acc@1 70.302
 *   Acc@1 69.461
 *   Acc@1 70.097
 *   Acc@1 69.987
 *   Acc@1 70.282
 *   Acc@1 63.763
 *   Acc@1 63.372
 *   Acc@1 60.763
 *   Acc@1 60.191
 *   Acc@1 60.513
 *   Acc@1 60.440
Training for 300 epoch: 66.99342105263158
Training for 600 epoch: 65.11184210526316
Training for 1000 epoch: 65.25
Training for 300 epoch: 66.83666666666667
Training for 600 epoch: 65.14416666666666
Training for 1000 epoch: 65.36083333333333
[[66.99342105263158, 65.11184210526316, 65.25], [66.83666666666667, 65.14416666666666, 65.36083333333333]]
train loss 1.040199690246582, epoch 494, best loss 0.40410459149678546, best_epoch 474
GPU_0_using curriculum 40 with window 40
Epoch: [495][20/30]	Time  1.627 ( 1.643)	Data  0.048 ( 0.057)	InnerLoop  0.696 ( 0.710)	Loss 5.4271e-01 (5.1396e-01)	Acc@1  81.84 ( 82.57)
The current update step is 14880
GPU_0_using curriculum 40 with window 40
Epoch: [496][20/30]	Time  1.752 ( 1.649)	Data  0.179 ( 0.079)	InnerLoop  0.694 ( 0.695)	Loss 5.1034e-01 (4.9926e-01)	Acc@1  82.20 ( 82.98)
The current update step is 14910
GPU_0_using curriculum 40 with window 40
Epoch: [497][20/30]	Time  1.628 ( 1.652)	Data  0.047 ( 0.065)	InnerLoop  0.704 ( 0.707)	Loss 4.4497e-01 (4.7493e-01)	Acc@1  84.64 ( 83.63)
The current update step is 14940
GPU_0_using curriculum 40 with window 40
Epoch: [498][20/30]	Time  1.634 ( 1.660)	Data  0.047 ( 0.052)	InnerLoop  0.701 ( 0.725)	Loss 4.6522e-01 (4.8837e-01)	Acc@1  83.84 ( 83.04)
The current update step is 14970
GPU_0_using curriculum 40 with window 40
Epoch: [499][20/30]	Time  1.634 ( 1.657)	Data  0.050 ( 0.080)	InnerLoop  0.696 ( 0.696)	Loss 4.5266e-01 (4.8073e-01)	Acc@1  84.62 ( 83.40)
The current update step is 15000
The current seed is 3260338626998090957
The current lr is: 0.0015
Testing Results:
 *   Acc@1 64.250
 *   Acc@1 64.932
 *   Acc@1 67.539
 *   Acc@1 68.408
 *   Acc@1 67.868
 *   Acc@1 68.775
 *   Acc@1 65.197
 *   Acc@1 64.913
 *   Acc@1 64.618
 *   Acc@1 64.362
 *   Acc@1 64.934
 *   Acc@1 64.823
Training for 300 epoch: 64.72368421052632
Training for 600 epoch: 66.07894736842104
Training for 1000 epoch: 66.40131578947368
Training for 300 epoch: 64.9225
Training for 600 epoch: 66.38499999999999
Training for 1000 epoch: 66.79875000000001
[[64.72368421052632, 66.07894736842104, 66.40131578947368], [64.9225, 66.38499999999999, 66.79875000000001]]
train loss 1.2100338944117228, epoch 499, best loss 0.40410459149678546, best_epoch 474
GPU_0_using curriculum 40 with window 40
Epoch: [500][20/30]	Time  1.760 ( 1.664)	Data  0.053 ( 0.080)	InnerLoop  0.827 ( 0.705)	Loss 4.6379e-01 (4.7588e-01)	Acc@1  84.16 ( 83.38)
The current update step is 15030
GPU_0_using curriculum 40 with window 40
Epoch: [501][20/30]	Time  1.635 ( 1.644)	Data  0.046 ( 0.065)	InnerLoop  0.694 ( 0.704)	Loss 4.7759e-01 (4.7284e-01)	Acc@1  83.18 ( 83.48)
The current update step is 15060
GPU_0_using curriculum 40 with window 40
Epoch: [502][20/30]	Time  1.621 ( 1.644)	Data  0.044 ( 0.051)	InnerLoop  0.697 ( 0.717)	Loss 4.5391e-01 (4.9149e-01)	Acc@1  84.28 ( 83.15)
The current update step is 15090
GPU_0_using curriculum 40 with window 40
Epoch: [503][20/30]	Time  1.614 ( 1.642)	Data  0.047 ( 0.057)	InnerLoop  0.687 ( 0.709)	Loss 4.6340e-01 (4.8457e-01)	Acc@1  84.11 ( 83.36)
The current update step is 15120
GPU_0_using curriculum 40 with window 40
Epoch: [504][20/30]	Time  1.760 ( 1.666)	Data  0.180 ( 0.079)	InnerLoop  0.695 ( 0.705)	Loss 5.2751e-01 (4.9536e-01)	Acc@1  82.84 ( 83.12)
The current update step is 15150
The current seed is 15086131555796245721
The current lr is: 0.0015
Testing Results:
 *   Acc@1 66.105
 *   Acc@1 66.790
 *   Acc@1 68.197
 *   Acc@1 68.532
 *   Acc@1 68.355
 *   Acc@1 69.013
 *   Acc@1 59.158
 *   Acc@1 59.266
 *   Acc@1 61.158
 *   Acc@1 61.501
 *   Acc@1 61.724
 *   Acc@1 62.685
Training for 300 epoch: 62.631578947368425
Training for 600 epoch: 64.67763157894737
Training for 1000 epoch: 65.03947368421052
Training for 300 epoch: 63.02791666666667
Training for 600 epoch: 65.01666666666667
Training for 1000 epoch: 65.84875
[[62.631578947368425, 64.67763157894737, 65.03947368421052], [63.02791666666667, 65.01666666666667, 65.84875]]
train loss 1.1075560489654541, epoch 504, best loss 0.40410459149678546, best_epoch 474
GPU_0_using curriculum 40 with window 40
Epoch: [505][20/30]	Time  1.643 ( 1.664)	Data  0.046 ( 0.058)	InnerLoop  0.703 ( 0.722)	Loss 4.9153e-01 (4.7390e-01)	Acc@1  83.35 ( 83.65)
The current update step is 15180
GPU_0_using curriculum 40 with window 40
Epoch: [506][20/30]	Time  1.762 ( 1.678)	Data  0.179 ( 0.080)	InnerLoop  0.703 ( 0.711)	Loss 4.9047e-01 (4.8733e-01)	Acc@1  82.86 ( 83.10)
The current update step is 15210
GPU_0_using curriculum 40 with window 40
Epoch: [507][20/30]	Time  1.637 ( 1.660)	Data  0.053 ( 0.066)	InnerLoop  0.702 ( 0.713)	Loss 4.9866e-01 (4.9454e-01)	Acc@1  81.27 ( 82.93)
The current update step is 15240
GPU_0_using curriculum 40 with window 40
Epoch: [508][20/30]	Time  1.642 ( 1.654)	Data  0.048 ( 0.052)	InnerLoop  0.707 ( 0.724)	Loss 4.4748e-01 (4.8931e-01)	Acc@1  84.67 ( 83.02)
The current update step is 15270
GPU_0_using curriculum 40 with window 40
Epoch: [509][20/30]	Time  1.635 ( 1.665)	Data  0.043 ( 0.079)	InnerLoop  0.698 ( 0.703)	Loss 4.8283e-01 (4.9955e-01)	Acc@1  83.33 ( 82.71)
The current update step is 15300
The current seed is 13778597576649295366
The current lr is: 0.0015
Testing Results:
 *   Acc@1 70.250
 *   Acc@1 70.365
 *   Acc@1 53.474
 *   Acc@1 54.080
 *   Acc@1 44.197
 *   Acc@1 44.834
 *   Acc@1 64.000
 *   Acc@1 65.026
 *   Acc@1 65.539
 *   Acc@1 66.121
 *   Acc@1 64.803
 *   Acc@1 65.670
Training for 300 epoch: 67.125
Training for 600 epoch: 59.50657894736842
Training for 1000 epoch: 54.5
Training for 300 epoch: 67.69541666666666
Training for 600 epoch: 60.10041666666667
Training for 1000 epoch: 55.25208333333333
[[67.125, 59.50657894736842, 54.5], [67.69541666666666, 60.10041666666667, 55.25208333333333]]
train loss 1.2075289101918538, epoch 509, best loss 0.40410459149678546, best_epoch 474
GPU_0_using curriculum 40 with window 40
Epoch: [510][20/30]	Time  1.739 ( 1.658)	Data  0.040 ( 0.078)	InnerLoop  0.820 ( 0.703)	Loss 4.5165e-01 (5.0092e-01)	Acc@1  84.30 ( 82.57)
The current update step is 15330
GPU_0_using curriculum 40 with window 40
Epoch: [511][20/30]	Time  1.634 ( 1.665)	Data  0.053 ( 0.066)	InnerLoop  0.694 ( 0.717)	Loss 4.6789e-01 (5.0432e-01)	Acc@1  82.98 ( 82.45)
The current update step is 15360
GPU_0_using curriculum 40 with window 40
Epoch: [512][20/30]	Time  1.605 ( 1.656)	Data  0.042 ( 0.050)	InnerLoop  0.678 ( 0.726)	Loss 6.2092e-01 (5.2269e-01)	Acc@1  78.74 ( 81.66)
The current update step is 15390
GPU_0_using curriculum 40 with window 40
Epoch: [513][20/30]	Time  1.646 ( 1.667)	Data  0.049 ( 0.059)	InnerLoop  0.704 ( 0.725)	Loss 7.6186e-01 (5.1998e-01)	Acc@1  74.56 ( 81.89)
The current update step is 15420
GPU_0_using curriculum 40 with window 40
Epoch: [514][20/30]	Time  1.762 ( 1.667)	Data  0.179 ( 0.079)	InnerLoop  0.697 ( 0.708)	Loss 7.6972e-01 (5.4652e-01)	Acc@1  71.83 ( 81.01)
The current update step is 15450
The current seed is 15061782922218879212
The current lr is: 0.0015
Testing Results:
 *   Acc@1 51.289
 *   Acc@1 51.867
 *   Acc@1 69.724
 *   Acc@1 69.686
 *   Acc@1 70.000
 *   Acc@1 69.957
 *   Acc@1 73.224
 *   Acc@1 73.135
 *   Acc@1 74.697
 *   Acc@1 74.564
 *   Acc@1 75.039
 *   Acc@1 74.798
Training for 300 epoch: 62.256578947368425
Training for 600 epoch: 72.21052631578948
Training for 1000 epoch: 72.51973684210526
Training for 300 epoch: 62.50125
Training for 600 epoch: 72.125
Training for 1000 epoch: 72.3775
[[62.256578947368425, 72.21052631578948, 72.51973684210526], [62.50125, 72.125, 72.3775]]
train loss 0.8062103726704916, epoch 514, best loss 0.40410459149678546, best_epoch 474
GPU_0_using curriculum 40 with window 40
Epoch: [515][20/30]	Time  1.632 ( 1.665)	Data  0.046 ( 0.058)	InnerLoop  0.700 ( 0.725)	Loss 4.6780e-01 (5.0781e-01)	Acc@1  84.47 ( 82.26)
The current update step is 15480
GPU_0_using curriculum 40 with window 40
Epoch: [516][20/30]	Time  1.762 ( 1.660)	Data  0.185 ( 0.080)	InnerLoop  0.698 ( 0.701)	Loss 4.3478e-01 (4.9493e-01)	Acc@1  84.79 ( 82.83)
The current update step is 15510
GPU_0_using curriculum 40 with window 40
Epoch: [517][20/30]	Time  1.620 ( 1.656)	Data  0.042 ( 0.065)	InnerLoop  0.703 ( 0.710)	Loss 5.4914e-01 (5.0060e-01)	Acc@1  80.35 ( 82.81)
The current update step is 15540
GPU_0_using curriculum 40 with window 40
Epoch: [518][20/30]	Time  1.585 ( 1.638)	Data  0.040 ( 0.050)	InnerLoop  0.669 ( 0.714)	Loss 4.8606e-01 (5.2124e-01)	Acc@1  83.01 ( 82.11)
The current update step is 15570
GPU_0_using curriculum 40 with window 40
Epoch: [519][20/30]	Time  1.640 ( 1.655)	Data  0.049 ( 0.078)	InnerLoop  0.691 ( 0.696)	Loss 4.6966e-01 (4.9094e-01)	Acc@1  83.96 ( 83.21)
The current update step is 15600
The current seed is 17590544287946335739
The current lr is: 0.0015
Testing Results:
 *   Acc@1 62.645
 *   Acc@1 63.333
 *   Acc@1 62.776
 *   Acc@1 63.380
 *   Acc@1 62.882
 *   Acc@1 63.379
 *   Acc@1 72.579
 *   Acc@1 73.157
 *   Acc@1 74.118
 *   Acc@1 75.045
 *   Acc@1 74.079
 *   Acc@1 75.266
Training for 300 epoch: 67.61184210526315
Training for 600 epoch: 68.44736842105263
Training for 1000 epoch: 68.48026315789474
Training for 300 epoch: 68.24541666666667
Training for 600 epoch: 69.2125
Training for 1000 epoch: 69.3225
[[67.61184210526315, 68.44736842105263, 68.48026315789474], [68.24541666666667, 69.2125, 69.3225]]
train loss 0.7343265452067057, epoch 519, best loss 0.40410459149678546, best_epoch 474
GPU_0_using curriculum 40 with window 40
Epoch: [520][20/30]	Time  1.764 ( 1.665)	Data  0.046 ( 0.079)	InnerLoop  0.833 ( 0.704)	Loss 6.3568e-01 (5.0828e-01)	Acc@1  78.47 ( 82.48)
The current update step is 15630
GPU_0_using curriculum 40 with window 40
Epoch: [521][20/30]	Time  1.610 ( 1.656)	Data  0.042 ( 0.064)	InnerLoop  0.693 ( 0.710)	Loss 5.0287e-01 (5.1835e-01)	Acc@1  82.54 ( 82.07)
The current update step is 15660
GPU_0_using curriculum 40 with window 40
Epoch: [522][20/30]	Time  1.628 ( 1.648)	Data  0.046 ( 0.050)	InnerLoop  0.704 ( 0.720)	Loss 4.6080e-01 (4.9535e-01)	Acc@1  83.37 ( 82.83)
The current update step is 15690
GPU_0_using curriculum 40 with window 40
Epoch: [523][20/30]	Time  1.628 ( 1.654)	Data  0.050 ( 0.058)	InnerLoop  0.698 ( 0.715)	Loss 4.8100e-01 (5.0479e-01)	Acc@1  82.59 ( 82.23)
The current update step is 15720
GPU_0_using curriculum 40 with window 40
Epoch: [524][20/30]	Time  1.749 ( 1.662)	Data  0.178 ( 0.079)	InnerLoop  0.696 ( 0.702)	Loss 5.0536e-01 (4.9448e-01)	Acc@1  83.06 ( 82.85)
The current update step is 15750
The current seed is 15870016870102659043
The current lr is: 0.0015
Testing Results:
 *   Acc@1 65.671
 *   Acc@1 65.749
 *   Acc@1 58.395
 *   Acc@1 57.300
 *   Acc@1 60.303
 *   Acc@1 59.243
 *   Acc@1 68.789
 *   Acc@1 69.188
 *   Acc@1 69.224
 *   Acc@1 69.585
 *   Acc@1 69.368
 *   Acc@1 69.845
Training for 300 epoch: 67.23026315789474
Training for 600 epoch: 63.80921052631579
Training for 1000 epoch: 64.83552631578948
Training for 300 epoch: 67.46833333333333
Training for 600 epoch: 63.442499999999995
Training for 1000 epoch: 64.54416666666667
[[67.23026315789474, 63.80921052631579, 64.83552631578948], [67.46833333333333, 63.442499999999995, 64.54416666666667]]
train loss 1.0323731932322184, epoch 524, best loss 0.40410459149678546, best_epoch 474
GPU_0_using curriculum 40 with window 40
Epoch: [525][20/30]	Time  1.625 ( 1.649)	Data  0.043 ( 0.059)	InnerLoop  0.698 ( 0.711)	Loss 5.6158e-01 (5.0616e-01)	Acc@1  79.79 ( 82.62)
The current update step is 15780
GPU_0_using curriculum 40 with window 40
Epoch: [526][20/30]	Time  1.756 ( 1.657)	Data  0.172 ( 0.077)	InnerLoop  0.684 ( 0.698)	Loss 4.5784e-01 (4.8336e-01)	Acc@1  84.59 ( 83.33)
The current update step is 15810
GPU_0_using curriculum 40 with window 40
Epoch: [527][20/30]	Time  1.613 ( 1.649)	Data  0.043 ( 0.065)	InnerLoop  0.693 ( 0.706)	Loss 4.7257e-01 (4.8916e-01)	Acc@1  83.40 ( 83.39)
The current update step is 15840
GPU_0_using curriculum 40 with window 40
Epoch: [528][20/30]	Time  1.626 ( 1.652)	Data  0.043 ( 0.052)	InnerLoop  0.691 ( 0.721)	Loss 5.0159e-01 (4.9208e-01)	Acc@1  83.72 ( 82.94)
The current update step is 15870
GPU_0_using curriculum 40 with window 40
Epoch: [529][20/30]	Time  1.622 ( 1.658)	Data  0.041 ( 0.080)	InnerLoop  0.705 ( 0.696)	Loss 5.1146e-01 (4.9680e-01)	Acc@1  82.67 ( 82.63)
The current update step is 15900
The current seed is 10103903830438776940
The current lr is: 0.0015
Testing Results:
 *   Acc@1 74.118
 *   Acc@1 74.368
 *   Acc@1 74.776
 *   Acc@1 75.222
 *   Acc@1 74.868
 *   Acc@1 75.409
 *   Acc@1 68.355
 *   Acc@1 69.198
 *   Acc@1 70.303
 *   Acc@1 70.993
 *   Acc@1 70.434
 *   Acc@1 71.265
Training for 300 epoch: 71.23684210526315
Training for 600 epoch: 72.53947368421052
Training for 1000 epoch: 72.65131578947368
Training for 300 epoch: 71.7825
Training for 600 epoch: 73.1075
Training for 1000 epoch: 73.33708333333334
[[71.23684210526315, 72.53947368421052, 72.65131578947368], [71.7825, 73.1075, 73.33708333333334]]
train loss 1.105403263727824, epoch 529, best loss 0.40410459149678546, best_epoch 474
GPU_0_using curriculum 40 with window 40
Epoch: [530][20/30]	Time  1.716 ( 1.645)	Data  0.042 ( 0.078)	InnerLoop  0.801 ( 0.692)	Loss 5.8296e-01 (4.9896e-01)	Acc@1  81.01 ( 82.99)
The current update step is 15930
GPU_0_using curriculum 40 with window 40
Epoch: [531][20/30]	Time  1.615 ( 1.649)	Data  0.045 ( 0.064)	InnerLoop  0.691 ( 0.707)	Loss 4.8887e-01 (5.0864e-01)	Acc@1  83.86 ( 82.84)
The current update step is 15960
GPU_0_using curriculum 40 with window 40
Epoch: [532][20/30]	Time  1.612 ( 1.649)	Data  0.042 ( 0.050)	InnerLoop  0.697 ( 0.723)	Loss 4.5127e-01 (4.9002e-01)	Acc@1  84.45 ( 83.07)
The current update step is 15990
GPU_0_using curriculum 40 with window 40
Epoch: [533][20/30]	Time  1.616 ( 1.654)	Data  0.047 ( 0.058)	InnerLoop  0.694 ( 0.717)	Loss 4.6017e-01 (5.0157e-01)	Acc@1  84.91 ( 82.34)
The current update step is 16020
GPU_0_using curriculum 40 with window 40
Epoch: [534][20/30]	Time  1.759 ( 1.659)	Data  0.181 ( 0.079)	InnerLoop  0.696 ( 0.701)	Loss 4.3431e-01 (4.8583e-01)	Acc@1  85.57 ( 83.49)
The current update step is 16050
The current seed is 8564160936804520507
The current lr is: 0.0015
Testing Results:
 *   Acc@1 54.526
 *   Acc@1 55.108
 *   Acc@1 49.224
 *   Acc@1 49.426
 *   Acc@1 36.118
 *   Acc@1 35.562
 *   Acc@1 78.145
 *   Acc@1 78.221
 *   Acc@1 77.079
 *   Acc@1 77.333
 *   Acc@1 76.421
 *   Acc@1 76.813
Training for 300 epoch: 66.33552631578948
Training for 600 epoch: 63.151315789473685
Training for 1000 epoch: 56.26973684210526
Training for 300 epoch: 66.66458333333333
Training for 600 epoch: 63.37958333333333
Training for 1000 epoch: 56.187916666666666
[[66.33552631578948, 63.151315789473685, 56.26973684210526], [66.66458333333333, 63.37958333333333, 56.187916666666666]]
train loss 0.6256388590494791, epoch 534, best loss 0.40410459149678546, best_epoch 534
GPU_0_using curriculum 40 with window 40
Epoch: [535][20/30]	Time  1.600 ( 1.651)	Data  0.043 ( 0.057)	InnerLoop  0.688 ( 0.715)	Loss 4.6487e-01 (5.0250e-01)	Acc@1  84.28 ( 82.66)
The current update step is 16080
GPU_0_using curriculum 40 with window 40
Epoch: [536][20/30]	Time  1.766 ( 1.665)	Data  0.181 ( 0.079)	InnerLoop  0.703 ( 0.705)	Loss 4.7512e-01 (4.9664e-01)	Acc@1  83.69 ( 82.87)
The current update step is 16110
GPU_0_using curriculum 40 with window 40
Epoch: [537][20/30]	Time  1.629 ( 1.662)	Data  0.044 ( 0.066)	InnerLoop  0.704 ( 0.713)	Loss 5.2284e-01 (4.8604e-01)	Acc@1  82.06 ( 83.13)
The current update step is 16140
GPU_0_using curriculum 40 with window 40
Epoch: [538][20/30]	Time  1.658 ( 1.663)	Data  0.045 ( 0.051)	InnerLoop  0.707 ( 0.731)	Loss 4.7161e-01 (4.7486e-01)	Acc@1  83.79 ( 83.46)
The current update step is 16170
GPU_0_using curriculum 40 with window 40
Epoch: [539][20/30]	Time  1.615 ( 1.646)	Data  0.044 ( 0.078)	InnerLoop  0.695 ( 0.697)	Loss 4.8902e-01 (4.8813e-01)	Acc@1  81.15 ( 82.95)
The current update step is 16200
The current seed is 5709091439333837363
The current lr is: 0.0015
Testing Results:
 *   Acc@1 63.487
 *   Acc@1 63.938
 *   Acc@1 69.250
 *   Acc@1 69.641
 *   Acc@1 69.395
 *   Acc@1 69.785
 *   Acc@1 74.000
 *   Acc@1 74.918
 *   Acc@1 73.026
 *   Acc@1 73.922
 *   Acc@1 73.224
 *   Acc@1 73.505
Training for 300 epoch: 68.74342105263158
Training for 600 epoch: 71.13815789473685
Training for 1000 epoch: 71.30921052631578
Training for 300 epoch: 69.42833333333334
Training for 600 epoch: 71.78166666666667
Training for 1000 epoch: 71.645
[[68.74342105263158, 71.13815789473685, 71.30921052631578], [69.42833333333334, 71.78166666666667, 71.645]]
train loss 0.656726271311442, epoch 539, best loss 0.40410459149678546, best_epoch 534
GPU_0_using curriculum 40 with window 40
Epoch: [540][20/30]	Time  1.766 ( 1.666)	Data  0.046 ( 0.080)	InnerLoop  0.836 ( 0.705)	Loss 4.6850e-01 (4.9123e-01)	Acc@1  82.57 ( 83.16)
The current update step is 16230
GPU_0_using curriculum 40 with window 40
Epoch: [541][20/30]	Time  1.622 ( 1.655)	Data  0.043 ( 0.066)	InnerLoop  0.700 ( 0.713)	Loss 4.8591e-01 (4.9036e-01)	Acc@1  83.96 ( 82.84)
The current update step is 16260
GPU_0_using curriculum 40 with window 40
Epoch: [542][20/30]	Time  1.597 ( 1.649)	Data  0.049 ( 0.053)	InnerLoop  0.687 ( 0.721)	Loss 5.0219e-01 (5.0132e-01)	Acc@1  82.28 ( 82.42)
The current update step is 16290
GPU_0_using curriculum 40 with window 40
Epoch: [543][20/30]	Time  1.631 ( 1.657)	Data  0.047 ( 0.059)	InnerLoop  0.704 ( 0.720)	Loss 4.8594e-01 (4.9394e-01)	Acc@1  83.25 ( 82.74)
The current update step is 16320
GPU_0_using curriculum 40 with window 40
Epoch: [544][20/30]	Time  1.755 ( 1.658)	Data  0.185 ( 0.079)	InnerLoop  0.691 ( 0.703)	Loss 4.1888e-01 (4.8880e-01)	Acc@1  85.96 ( 83.08)
The current update step is 16350
The current seed is 13136838194799622775
The current lr is: 0.0015
Testing Results:
 *   Acc@1 65.645
 *   Acc@1 65.772
 *   Acc@1 65.671
 *   Acc@1 65.772
 *   Acc@1 70.118
 *   Acc@1 69.888
 *   Acc@1 43.053
 *   Acc@1 42.833
 *   Acc@1 46.526
 *   Acc@1 46.886
 *   Acc@1 50.579
 *   Acc@1 50.718
Training for 300 epoch: 54.348684210526315
Training for 600 epoch: 56.098684210526315
Training for 1000 epoch: 60.348684210526315
Training for 300 epoch: 54.30291666666666
Training for 600 epoch: 56.329166666666666
Training for 1000 epoch: 60.30291666666667
[[54.348684210526315, 56.098684210526315, 60.348684210526315], [54.30291666666666, 56.329166666666666, 60.30291666666667]]
train loss 1.5632938453674317, epoch 544, best loss 0.40410459149678546, best_epoch 534
GPU_0_using curriculum 40 with window 40
Epoch: [545][20/30]	Time  1.557 ( 1.586)	Data  0.039 ( 0.054)	InnerLoop  0.656 ( 0.680)	Loss 4.3097e-01 (4.8428e-01)	Acc@1  85.33 ( 83.15)
The current update step is 16380
GPU_0_using curriculum 40 with window 40
Epoch: [546][20/30]	Time  1.685 ( 1.593)	Data  0.165 ( 0.074)	InnerLoop  0.673 ( 0.667)	Loss 5.0630e-01 (5.1156e-01)	Acc@1  82.20 ( 82.32)
The current update step is 16410
GPU_0_using curriculum 40 with window 40
Epoch: [547][20/30]	Time  1.558 ( 1.580)	Data  0.045 ( 0.060)	InnerLoop  0.657 ( 0.671)	Loss 6.4497e-01 (5.2632e-01)	Acc@1  78.37 ( 81.74)
The current update step is 16440
GPU_0_using curriculum 40 with window 40
Epoch: [548][20/30]	Time  1.553 ( 1.570)	Data  0.041 ( 0.047)	InnerLoop  0.661 ( 0.680)	Loss 4.7900e-01 (5.1307e-01)	Acc@1  83.03 ( 81.95)
The current update step is 16470
GPU_0_using curriculum 40 with window 40
Epoch: [549][20/30]	Time  1.561 ( 1.582)	Data  0.043 ( 0.075)	InnerLoop  0.662 ( 0.656)	Loss 4.4991e-01 (5.1091e-01)	Acc@1  84.20 ( 82.23)
The current update step is 16500
The current seed is 15553714261939561515
The current lr is: 0.0015
Testing Results:
 *   Acc@1 64.395
 *   Acc@1 64.634
 *   Acc@1 66.697
 *   Acc@1 66.566
 *   Acc@1 67.447
 *   Acc@1 67.685
 *   Acc@1 60.618
 *   Acc@1 60.288
 *   Acc@1 55.724
 *   Acc@1 56.428
 *   Acc@1 52.645
 *   Acc@1 53.046
Training for 300 epoch: 62.506578947368425
Training for 600 epoch: 61.21052631578947
Training for 1000 epoch: 60.046052631578945
Training for 300 epoch: 62.46125000000001
Training for 600 epoch: 61.49666666666667
Training for 1000 epoch: 60.36541666666667
[[62.506578947368425, 61.21052631578947, 60.046052631578945], [62.46125000000001, 61.49666666666667, 60.36541666666667]]
train loss 1.3144897666931152, epoch 549, best loss 0.40410459149678546, best_epoch 534
GPU_0_using curriculum 40 with window 40
Epoch: [550][20/30]	Time  1.690 ( 1.588)	Data  0.044 ( 0.074)	InnerLoop  0.789 ( 0.665)	Loss 4.8320e-01 (5.0292e-01)	Acc@1  83.74 ( 82.63)
The current update step is 16530
GPU_0_using curriculum 40 with window 40
Epoch: [551][20/30]	Time  1.545 ( 1.573)	Data  0.040 ( 0.060)	InnerLoop  0.660 ( 0.666)	Loss 4.8069e-01 (5.1528e-01)	Acc@1  83.64 ( 82.32)
The current update step is 16560
GPU_0_using curriculum 40 with window 40
Epoch: [552][20/30]	Time  1.544 ( 1.572)	Data  0.040 ( 0.048)	InnerLoop  0.653 ( 0.679)	Loss 7.4298e-01 (5.1226e-01)	Acc@1  76.22 ( 82.55)
The current update step is 16590
GPU_0_using curriculum 40 with window 40
Epoch: [553][20/30]	Time  1.540 ( 1.560)	Data  0.042 ( 0.052)	InnerLoop  0.650 ( 0.670)	Loss 4.5782e-01 (4.8745e-01)	Acc@1  84.18 ( 83.27)
The current update step is 16620
GPU_0_using curriculum 40 with window 40
Epoch: [554][20/30]	Time  1.623 ( 1.551)	Data  0.157 ( 0.070)	InnerLoop  0.640 ( 0.646)	Loss 4.8552e-01 (5.0810e-01)	Acc@1  83.13 ( 82.75)
The current update step is 16650
The current seed is 6027255245127933720
The current lr is: 0.0015
Testing Results:
 *   Acc@1 59.329
 *   Acc@1 60.529
 *   Acc@1 61.987
 *   Acc@1 62.385
 *   Acc@1 62.447
 *   Acc@1 63.097
 *   Acc@1 75.605
 *   Acc@1 76.180
 *   Acc@1 75.566
 *   Acc@1 76.307
 *   Acc@1 76.000
 *   Acc@1 76.511
Training for 300 epoch: 67.46710526315789
Training for 600 epoch: 68.77631578947368
Training for 1000 epoch: 69.22368421052632
Training for 300 epoch: 68.35458333333334
Training for 600 epoch: 69.34583333333333
Training for 1000 epoch: 69.80375000000001
[[67.46710526315789, 68.77631578947368, 69.22368421052632], [68.35458333333334, 69.34583333333333, 69.80375000000001]]
train loss 0.5258618846257528, epoch 554, best loss 0.40410459149678546, best_epoch 534
GPU_0_using curriculum 40 with window 40
Epoch: [555][20/30]	Time  1.518 ( 1.532)	Data  0.038 ( 0.050)	InnerLoop  0.630 ( 0.649)	Loss 5.1221e-01 (5.1294e-01)	Acc@1  81.01 ( 82.06)
The current update step is 16680
GPU_0_using curriculum 40 with window 40
Epoch: [556][20/30]	Time  1.648 ( 1.542)	Data  0.165 ( 0.068)	InnerLoop  0.648 ( 0.639)	Loss 4.8546e-01 (5.0287e-01)	Acc@1  83.30 ( 82.83)
The current update step is 16710
GPU_0_using curriculum 40 with window 40
Epoch: [557][20/30]	Time  1.502 ( 1.533)	Data  0.040 ( 0.055)	InnerLoop  0.632 ( 0.645)	Loss 4.4794e-01 (4.8637e-01)	Acc@1  84.62 ( 83.27)
The current update step is 16740
GPU_0_using curriculum 40 with window 40
Epoch: [558][20/30]	Time  1.511 ( 1.529)	Data  0.037 ( 0.043)	InnerLoop  0.630 ( 0.657)	Loss 5.8922e-01 (5.0337e-01)	Acc@1  79.08 ( 82.47)
The current update step is 16770
GPU_0_using curriculum 40 with window 40
Epoch: [559][20/30]	Time  1.509 ( 1.542)	Data  0.041 ( 0.069)	InnerLoop  0.631 ( 0.636)	Loss 5.8256e-01 (5.0754e-01)	Acc@1  79.37 ( 82.13)
The current update step is 16800
The current seed is 12061536218484377827
The current lr is: 0.0015
Testing Results:
 *   Acc@1 63.461
 *   Acc@1 64.222
 *   Acc@1 66.711
 *   Acc@1 67.312
 *   Acc@1 66.395
 *   Acc@1 66.891
 *   Acc@1 59.289
 *   Acc@1 59.467
 *   Acc@1 59.921
 *   Acc@1 59.998
 *   Acc@1 61.171
 *   Acc@1 60.556
Training for 300 epoch: 61.375
Training for 600 epoch: 63.31578947368421
Training for 1000 epoch: 63.7828947368421
Training for 300 epoch: 61.84458333333333
Training for 600 epoch: 63.65541666666667
Training for 1000 epoch: 63.72333333333333
[[61.375, 63.31578947368421, 63.7828947368421], [61.84458333333333, 63.65541666666667, 63.72333333333333]]
train loss 1.1205123155593872, epoch 559, best loss 0.40410459149678546, best_epoch 534
GPU_0_using curriculum 40 with window 40
Epoch: [560][20/30]	Time  1.619 ( 1.542)	Data  0.040 ( 0.068)	InnerLoop  0.748 ( 0.640)	Loss 5.5003e-01 (5.0379e-01)	Acc@1  80.64 ( 82.30)
The current update step is 16830
GPU_0_using curriculum 40 with window 40
Epoch: [561][20/30]	Time  1.497 ( 1.529)	Data  0.039 ( 0.056)	InnerLoop  0.635 ( 0.646)	Loss 4.9830e-01 (5.1036e-01)	Acc@1  81.93 ( 82.00)
The current update step is 16860
GPU_0_using curriculum 40 with window 40
Epoch: [562][20/30]	Time  1.514 ( 1.535)	Data  0.036 ( 0.043)	InnerLoop  0.637 ( 0.660)	Loss 5.4903e-01 (5.0109e-01)	Acc@1  81.25 ( 82.65)
The current update step is 16890
GPU_0_using curriculum 40 with window 40
Epoch: [563][20/30]	Time  1.495 ( 1.527)	Data  0.038 ( 0.049)	InnerLoop  0.633 ( 0.649)	Loss 5.6999e-01 (4.8912e-01)	Acc@1  80.00 ( 83.17)
The current update step is 16920
GPU_0_using curriculum 40 with window 40
Epoch: [564][20/30]	Time  1.641 ( 1.538)	Data  0.152 ( 0.068)	InnerLoop  0.643 ( 0.638)	Loss 5.1216e-01 (4.8820e-01)	Acc@1  81.93 ( 83.19)
The current update step is 16950
The current seed is 6281035093253063253
The current lr is: 0.0015
Testing Results:
 *   Acc@1 67.618
 *   Acc@1 67.846
 *   Acc@1 61.184
 *   Acc@1 61.421
 *   Acc@1 61.158
 *   Acc@1 61.776
 *   Acc@1 70.368
 *   Acc@1 71.048
 *   Acc@1 72.237
 *   Acc@1 73.257
 *   Acc@1 72.645
 *   Acc@1 73.617
Training for 300 epoch: 68.99342105263158
Training for 600 epoch: 66.71052631578948
Training for 1000 epoch: 66.90131578947368
Training for 300 epoch: 69.44708333333332
Training for 600 epoch: 67.33916666666667
Training for 1000 epoch: 67.69624999999999
[[68.99342105263158, 66.71052631578948, 66.90131578947368], [69.44708333333332, 67.33916666666667, 67.69624999999999]]
train loss 0.6623057172775269, epoch 564, best loss 0.40410459149678546, best_epoch 534
GPU_0_using curriculum 40 with window 40
Epoch: [565][20/30]	Time  1.515 ( 1.535)	Data  0.038 ( 0.050)	InnerLoop  0.632 ( 0.655)	Loss 4.7216e-01 (4.9670e-01)	Acc@1  83.57 ( 83.00)
The current update step is 16980
GPU_0_using curriculum 40 with window 40
Epoch: [566][20/30]	Time  1.632 ( 1.541)	Data  0.159 ( 0.068)	InnerLoop  0.632 ( 0.640)	Loss 4.7531e-01 (4.7782e-01)	Acc@1  83.64 ( 83.40)
The current update step is 17010
GPU_0_using curriculum 40 with window 40
Epoch: [567][20/30]	Time  1.502 ( 1.529)	Data  0.038 ( 0.056)	InnerLoop  0.637 ( 0.646)	Loss 4.9271e-01 (4.9006e-01)	Acc@1  83.42 ( 83.07)
The current update step is 17040
GPU_0_using curriculum 40 with window 40
Epoch: [568][20/30]	Time  1.506 ( 1.528)	Data  0.038 ( 0.044)	InnerLoop  0.626 ( 0.657)	Loss 4.8664e-01 (4.8339e-01)	Acc@1  84.08 ( 83.37)
The current update step is 17070
GPU_0_using curriculum 40 with window 40
Epoch: [569][20/30]	Time  1.514 ( 1.533)	Data  0.040 ( 0.067)	InnerLoop  0.635 ( 0.633)	Loss 5.3617e-01 (4.7753e-01)	Acc@1  80.03 ( 83.32)
The current update step is 17100
The current seed is 14755678139311643224
The current lr is: 0.0015
Testing Results:
 *   Acc@1 78.671
 *   Acc@1 79.218
 *   Acc@1 78.355
 *   Acc@1 78.979
 *   Acc@1 78.158
 *   Acc@1 78.599
 *   Acc@1 78.934
 *   Acc@1 79.967
 *   Acc@1 66.447
 *   Acc@1 66.998
 *   Acc@1 66.816
 *   Acc@1 67.222
Training for 300 epoch: 78.80263157894737
Training for 600 epoch: 72.40131578947368
Training for 1000 epoch: 72.48684210526315
Training for 300 epoch: 79.59208333333333
Training for 600 epoch: 72.98833333333334
Training for 1000 epoch: 72.91041666666666
[[78.80263157894737, 72.40131578947368, 72.48684210526315], [79.59208333333333, 72.98833333333334, 72.91041666666666]]
train loss 1.0373955852508545, epoch 569, best loss 0.40410459149678546, best_epoch 534
GPU_0_using curriculum 40 with window 40
Epoch: [570][20/30]	Time  1.603 ( 1.534)	Data  0.040 ( 0.068)	InnerLoop  0.742 ( 0.637)	Loss 5.2716e-01 (5.1703e-01)	Acc@1  82.57 ( 82.25)
The current update step is 17130
GPU_0_using curriculum 40 with window 40
Epoch: [571][20/30]	Time  1.499 ( 1.527)	Data  0.038 ( 0.056)	InnerLoop  0.632 ( 0.642)	Loss 5.0274e-01 (4.7164e-01)	Acc@1  83.59 ( 83.69)
The current update step is 17160
GPU_0_using curriculum 40 with window 40
Epoch: [572][20/30]	Time  1.507 ( 1.528)	Data  0.042 ( 0.044)	InnerLoop  0.637 ( 0.658)	Loss 5.0029e-01 (5.0111e-01)	Acc@1  82.81 ( 82.50)
The current update step is 17190
GPU_0_using curriculum 40 with window 40
Epoch: [573][20/30]	Time  1.500 ( 1.530)	Data  0.039 ( 0.050)	InnerLoop  0.640 ( 0.649)	Loss 4.7265e-01 (5.0080e-01)	Acc@1  84.16 ( 82.72)
The current update step is 17220
GPU_0_using curriculum 40 with window 40
Epoch: [574][20/30]	Time  1.639 ( 1.534)	Data  0.156 ( 0.068)	InnerLoop  0.640 ( 0.639)	Loss 5.3144e-01 (4.8455e-01)	Acc@1  81.37 ( 83.03)
The current update step is 17250
The current seed is 17045964289848981697
The current lr is: 0.0015
Testing Results:
 *   Acc@1 71.697
 *   Acc@1 71.674
 *   Acc@1 73.579
 *   Acc@1 73.420
 *   Acc@1 74.316
 *   Acc@1 74.280
 *   Acc@1 73.592
 *   Acc@1 73.292
 *   Acc@1 76.618
 *   Acc@1 76.980
 *   Acc@1 76.382
 *   Acc@1 76.675
Training for 300 epoch: 72.64473684210526
Training for 600 epoch: 75.09868421052632
Training for 1000 epoch: 75.34868421052632
Training for 300 epoch: 72.48291666666667
Training for 600 epoch: 75.2
Training for 1000 epoch: 75.47749999999999
[[72.64473684210526, 75.09868421052632, 75.34868421052632], [72.48291666666667, 75.2, 75.47749999999999]]
train loss 0.6615871037483215, epoch 574, best loss 0.40410459149678546, best_epoch 534
GPU_0_using curriculum 40 with window 40
Epoch: [575][20/30]	Time  1.492 ( 1.529)	Data  0.040 ( 0.049)	InnerLoop  0.632 ( 0.649)	Loss 4.9166e-01 (4.9461e-01)	Acc@1  83.25 ( 82.84)
The current update step is 17280
GPU_0_using curriculum 40 with window 40
Epoch: [576][20/30]	Time  1.612 ( 1.537)	Data  0.156 ( 0.069)	InnerLoop  0.629 ( 0.639)	Loss 4.6033e-01 (4.8959e-01)	Acc@1  83.81 ( 82.96)
The current update step is 17310
GPU_0_using curriculum 40 with window 40
Epoch: [577][20/30]	Time  1.503 ( 1.529)	Data  0.039 ( 0.055)	InnerLoop  0.639 ( 0.643)	Loss 4.4894e-01 (4.8473e-01)	Acc@1  84.89 ( 83.23)
The current update step is 17340
GPU_0_using curriculum 40 with window 40
Epoch: [578][20/30]	Time  1.500 ( 1.527)	Data  0.037 ( 0.043)	InnerLoop  0.638 ( 0.657)	Loss 5.2068e-01 (4.8297e-01)	Acc@1  82.10 ( 83.14)
The current update step is 17370
GPU_0_using curriculum 40 with window 40
Epoch: [579][20/30]	Time  1.522 ( 1.531)	Data  0.037 ( 0.069)	InnerLoop  0.632 ( 0.632)	Loss 5.2383e-01 (5.1131e-01)	Acc@1  80.71 ( 81.96)
The current update step is 17400
The current seed is 7603377182327303190
The current lr is: 0.0015
Testing Results:
 *   Acc@1 62.053
 *   Acc@1 62.383
 *   Acc@1 73.829
 *   Acc@1 74.695
 *   Acc@1 74.276
 *   Acc@1 74.648
 *   Acc@1 56.776
 *   Acc@1 56.788
 *   Acc@1 56.526
 *   Acc@1 56.792
 *   Acc@1 57.039
 *   Acc@1 57.161
Training for 300 epoch: 59.41447368421053
Training for 600 epoch: 65.17763157894737
Training for 1000 epoch: 65.65789473684211
Training for 300 epoch: 59.58541666666667
Training for 600 epoch: 65.74333333333333
Training for 1000 epoch: 65.90458333333333
[[59.41447368421053, 65.17763157894737, 65.65789473684211], [59.58541666666667, 65.74333333333333, 65.90458333333333]]
train loss 1.2522130700429281, epoch 579, best loss 0.40410459149678546, best_epoch 534
GPU_0_using curriculum 40 with window 40
Epoch: [580][20/30]	Time  1.615 ( 1.535)	Data  0.036 ( 0.068)	InnerLoop  0.757 ( 0.638)	Loss 4.6009e-01 (4.9968e-01)	Acc@1  83.47 ( 82.72)
The current update step is 17430
GPU_0_using curriculum 40 with window 40
Epoch: [581][20/30]	Time  1.491 ( 1.530)	Data  0.037 ( 0.056)	InnerLoop  0.627 ( 0.645)	Loss 4.6121e-01 (5.0484e-01)	Acc@1  83.72 ( 82.28)
The current update step is 17460
GPU_0_using curriculum 40 with window 40
Epoch: [582][20/30]	Time  1.534 ( 1.532)	Data  0.039 ( 0.044)	InnerLoop  0.630 ( 0.657)	Loss 5.2207e-01 (5.0280e-01)	Acc@1  83.06 ( 82.19)
The current update step is 17490
GPU_0_using curriculum 40 with window 40
Epoch: [583][20/30]	Time  1.516 ( 1.530)	Data  0.038 ( 0.050)	InnerLoop  0.654 ( 0.651)	Loss 4.5398e-01 (5.0690e-01)	Acc@1  84.47 ( 82.16)
The current update step is 17520
GPU_0_using curriculum 40 with window 40
Epoch: [584][20/30]	Time  1.640 ( 1.532)	Data  0.154 ( 0.068)	InnerLoop  0.649 ( 0.637)	Loss 5.0171e-01 (4.8692e-01)	Acc@1  83.25 ( 83.01)
The current update step is 17550
The current seed is 2517764882939884298
The current lr is: 0.0015
Testing Results:
 *   Acc@1 62.197
 *   Acc@1 62.421
 *   Acc@1 65.934
 *   Acc@1 66.094
 *   Acc@1 67.487
 *   Acc@1 67.795
 *   Acc@1 65.105
 *   Acc@1 65.315
 *   Acc@1 66.461
 *   Acc@1 66.302
 *   Acc@1 67.237
 *   Acc@1 67.083
Training for 300 epoch: 63.651315789473685
Training for 600 epoch: 66.19736842105263
Training for 1000 epoch: 67.36184210526316
Training for 300 epoch: 63.867916666666666
Training for 600 epoch: 66.19833333333332
Training for 1000 epoch: 67.43916666666667
[[63.651315789473685, 66.19736842105263, 67.36184210526316], [63.867916666666666, 66.19833333333332, 67.43916666666667]]
train loss 0.7985691692988078, epoch 584, best loss 0.40410459149678546, best_epoch 534
GPU_0_using curriculum 40 with window 40
Epoch: [585][20/30]	Time  1.498 ( 1.530)	Data  0.037 ( 0.050)	InnerLoop  0.634 ( 0.651)	Loss 4.3611e-01 (5.4396e-01)	Acc@1  84.89 ( 80.90)
The current update step is 17580
GPU_0_using curriculum 40 with window 40
Epoch: [586][20/30]	Time  1.631 ( 1.532)	Data  0.163 ( 0.068)	InnerLoop  0.627 ( 0.637)	Loss 5.3164e-01 (5.0258e-01)	Acc@1  81.54 ( 82.94)
The current update step is 17610
GPU_0_using curriculum 40 with window 40
Epoch: [587][20/30]	Time  1.500 ( 1.530)	Data  0.039 ( 0.056)	InnerLoop  0.633 ( 0.644)	Loss 4.7936e-01 (5.0702e-01)	Acc@1  84.28 ( 82.41)
The current update step is 17640
GPU_0_using curriculum 40 with window 40
Epoch: [588][20/30]	Time  1.514 ( 1.532)	Data  0.036 ( 0.043)	InnerLoop  0.628 ( 0.655)	Loss 4.7767e-01 (4.9742e-01)	Acc@1  82.93 ( 82.66)
The current update step is 17670
GPU_0_using curriculum 40 with window 40
Epoch: [589][20/30]	Time  1.486 ( 1.524)	Data  0.040 ( 0.067)	InnerLoop  0.626 ( 0.630)	Loss 5.0825e-01 (4.8545e-01)	Acc@1  81.79 ( 83.34)
The current update step is 17700
The current seed is 9448644461863843543
The current lr is: 0.0015
Testing Results:
 *   Acc@1 50.224
 *   Acc@1 50.079
 *   Acc@1 51.421
 *   Acc@1 52.172
 *   Acc@1 51.026
 *   Acc@1 51.142
 *   Acc@1 79.868
 *   Acc@1 80.551
 *   Acc@1 80.408
 *   Acc@1 80.632
 *   Acc@1 80.118
 *   Acc@1 80.760
Training for 300 epoch: 65.04605263157895
Training for 600 epoch: 65.91447368421052
Training for 1000 epoch: 65.57236842105263
Training for 300 epoch: 65.315
Training for 600 epoch: 66.40208333333334
Training for 1000 epoch: 65.95083333333334
[[65.04605263157895, 65.91447368421052, 65.57236842105263], [65.315, 66.40208333333334, 65.95083333333334]]
train loss 0.3927976068019867, epoch 589, best loss 0.3927976068019867, best_epoch 589
GPU_0_using curriculum 40 with window 40
Epoch: [590][20/30]	Time  1.639 ( 1.537)	Data  0.043 ( 0.069)	InnerLoop  0.751 ( 0.639)	Loss 4.6350e-01 (4.8696e-01)	Acc@1  83.89 ( 83.09)
The current update step is 17730
GPU_0_using curriculum 40 with window 40
Epoch: [591][20/30]	Time  1.520 ( 1.525)	Data  0.041 ( 0.055)	InnerLoop  0.633 ( 0.644)	Loss 5.0565e-01 (4.8564e-01)	Acc@1  82.74 ( 83.14)
The current update step is 17760
GPU_0_using curriculum 40 with window 40
Epoch: [592][20/30]	Time  1.503 ( 1.530)	Data  0.041 ( 0.044)	InnerLoop  0.629 ( 0.658)	Loss 5.2793e-01 (5.0785e-01)	Acc@1  82.52 ( 82.05)
The current update step is 17790
GPU_0_using curriculum 40 with window 40
Epoch: [593][20/30]	Time  1.495 ( 1.524)	Data  0.038 ( 0.049)	InnerLoop  0.637 ( 0.651)	Loss 4.6581e-01 (4.9180e-01)	Acc@1  83.86 ( 83.03)
The current update step is 17820
GPU_0_using curriculum 40 with window 40
Epoch: [594][20/30]	Time  1.618 ( 1.534)	Data  0.156 ( 0.068)	InnerLoop  0.636 ( 0.637)	Loss 4.5763e-01 (4.9545e-01)	Acc@1  83.94 ( 82.72)
The current update step is 17850
The current seed is 8630147929119122693
The current lr is: 0.0015
Testing Results:
 *   Acc@1 64.724
 *   Acc@1 65.389
 *   Acc@1 65.697
 *   Acc@1 65.814
 *   Acc@1 64.500
 *   Acc@1 65.433
 *   Acc@1 66.329
 *   Acc@1 66.458
 *   Acc@1 56.816
 *   Acc@1 57.137
 *   Acc@1 64.961
 *   Acc@1 65.487
Training for 300 epoch: 65.52631578947368
Training for 600 epoch: 61.256578947368425
Training for 1000 epoch: 64.73026315789474
Training for 300 epoch: 65.92375
Training for 600 epoch: 61.47541666666666
Training for 1000 epoch: 65.46041666666667
[[65.52631578947368, 61.256578947368425, 64.73026315789474], [65.92375, 61.47541666666666, 65.46041666666667]]
train loss 1.2048061485926311, epoch 594, best loss 0.3927976068019867, best_epoch 589
GPU_0_using curriculum 40 with window 40
Epoch: [595][20/30]	Time  1.495 ( 1.523)	Data  0.036 ( 0.048)	InnerLoop  0.640 ( 0.648)	Loss 4.6987e-01 (4.7102e-01)	Acc@1  83.84 ( 83.76)
The current update step is 17880
GPU_0_using curriculum 40 with window 40
Epoch: [596][20/30]	Time  1.607 ( 1.532)	Data  0.153 ( 0.067)	InnerLoop  0.630 ( 0.634)	Loss 6.9127e-01 (5.1250e-01)	Acc@1  71.68 ( 82.14)
The current update step is 17910
GPU_0_using curriculum 40 with window 40
Epoch: [597][20/30]	Time  1.507 ( 1.524)	Data  0.036 ( 0.055)	InnerLoop  0.629 ( 0.642)	Loss 4.4798e-01 (4.8662e-01)	Acc@1  83.59 ( 83.04)
The current update step is 17940
GPU_0_using curriculum 40 with window 40
Epoch: [598][20/30]	Time  1.491 ( 1.521)	Data  0.038 ( 0.043)	InnerLoop  0.626 ( 0.652)	Loss 5.3898e-01 (4.9829e-01)	Acc@1  81.20 ( 82.87)
The current update step is 17970
GPU_0_using curriculum 40 with window 40
Epoch: [599][20/30]	Time  1.504 ( 1.526)	Data  0.039 ( 0.068)	InnerLoop  0.632 ( 0.631)	Loss 4.8008e-01 (5.1115e-01)	Acc@1  84.08 ( 82.27)
The current update step is 18000
The current seed is 14469752631891283317
The current lr is: 0.0015
Testing Results:
 *   Acc@1 79.263
 *   Acc@1 79.751
 *   Acc@1 78.342
 *   Acc@1 79.290
 *   Acc@1 77.632
 *   Acc@1 78.927
 *   Acc@1 47.829
 *   Acc@1 48.278
 *   Acc@1 68.316
 *   Acc@1 68.752
 *   Acc@1 67.895
 *   Acc@1 68.931
Training for 300 epoch: 63.546052631578945
Training for 600 epoch: 73.32894736842104
Training for 1000 epoch: 72.76315789473685
Training for 300 epoch: 64.01458333333333
Training for 600 epoch: 74.02083333333334
Training for 1000 epoch: 73.92916666666667
[[63.546052631578945, 73.32894736842104, 72.76315789473685], [64.01458333333333, 74.02083333333334, 73.92916666666667]]
train loss 0.5241513427416483, epoch 599, best loss 0.3927976068019867, best_epoch 589
=== Final results:
{'acc': 78.80263157894737, 'test': [78.80263157894737, 72.40131578947368, 72.48684210526315], 'train': [78.80263157894737, 72.40131578947368, 72.48684210526315], 'ind': 0, 'epoch': 570, 'data': array([[ 0.10273182,  0.33977407, -0.17671183, ...,  0.35528064,
         0.013692  ,  0.03561344],
       [-0.08659467, -0.3058161 ,  0.05406353, ..., -0.1723926 ,
         0.16985177,  0.07360204],
       [-0.03521769,  0.11560431, -0.01484583, ..., -0.07543737,
        -0.20155685,  0.01961635],
       ...,
       [-0.05014465, -0.18772547, -0.17134982, ..., -0.05414044,
         0.32759908,  0.06551427],
       [-0.4447511 ,  0.01529299, -0.04852896, ...,  0.28421733,
         0.19340724,  0.0785622 ],
       [ 0.12073418, -0.00721053, -0.12309484, ...,  0.01215709,
         0.31924027,  0.43914956]], shape=(200, 768), dtype=float32)}
