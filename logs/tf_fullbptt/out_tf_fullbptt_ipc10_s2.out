Torch Seed Specified with rank: 0
Dataset: agnews_emb
Dataset Path: ./scripts
Namespace(seed=0, mp_distributed=False, world_size=1, rank=0, dist_url='tcp://224.66.41.62:23456', dist_backend='nccl', workers=0, gpu=None, root='./scripts', dataset='agnews_emb', arch='text_transformer', width=256, lr=0.001, inner_optim='Adam', outer_optim='Adam', inner_lr=0.001, label_lr_scale=1, num_per_class=10, batch_per_class=5, task_sampler_nc=4, window=40, minwindow=0, totwindow=40, num_train_eval=4, train_y=False, batch_size=4096, eps=1e-08, wd=0, test_freq=5, print_freq=20, start_epoch=0, epochs=200, ddtype='standard', cctype=0, zca=False, wandb=False, clip_coef=0.9, fname='out_tf_fullbptt_ipc10_s2', out_dir='./checkpoints', name='agnews_tf_fullbptt_s2', comp_aug=False, comp_aug_real=False, syn_strategy='none', real_strategy='none', ckptname='none', limit_train=False, load_ckpt=False, complete_random=False, boost_dd=False, boost_init_from='none', boost_beta=1.0, stage=2, distributed=False, data_root='./scripts/agnews_emb')
==> Preparing data..
None None
Dataset: number of classes: 4
Training set size: 120000
Image size: channel 1, height 768, width 1
Synthetic images, not_single False, keys []
==> Building model..
Initialized data with size, x: torch.Size([40, 768]), y:torch.Size([40])
TextTransformer(
  (input_proj): Linear(in_features=192, out_features=256, bias=True)
  (encoder): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=1024, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=1024, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (cls_head): Linear(in_features=256, out_features=4, bias=True)
)
use data parallel only
GPU_0_using curriculum 40 with window 40
Epoch: [0][20/30]	Time  1.584 ( 1.637)	Data  0.043 ( 0.057)	InnerLoop  0.661 ( 0.688)	Loss 2.3867e+00 (3.8216e+00)	Acc@1  41.19 ( 30.93)
The current update step is 30
GPU_0_using curriculum 40 with window 40
Epoch: [1][20/30]	Time  1.597 ( 1.611)	Data  0.047 ( 0.068)	InnerLoop  0.647 ( 0.655)	Loss 2.1362e+00 (2.0127e+00)	Acc@1  40.41 ( 44.54)
The current update step is 60
GPU_0_using curriculum 40 with window 40
Epoch: [2][20/30]	Time  1.684 ( 1.590)	Data  0.040 ( 0.072)	InnerLoop  0.760 ( 0.644)	Loss 1.3543e+00 (1.6514e+00)	Acc@1  56.40 ( 48.03)
The current update step is 90
GPU_0_using curriculum 40 with window 40
Epoch: [3][20/30]	Time  1.593 ( 1.593)	Data  0.040 ( 0.055)	InnerLoop  0.654 ( 0.658)	Loss 1.3950e+00 (1.3496e+00)	Acc@1  50.56 ( 52.15)
The current update step is 120
GPU_0_using curriculum 40 with window 40
Epoch: [4][20/30]	Time  1.551 ( 1.591)	Data  0.041 ( 0.061)	InnerLoop  0.638 ( 0.650)	Loss 1.3809e+00 (1.2036e+00)	Acc@1  47.02 ( 58.06)
The current update step is 150
The current seed is 5875932352992004529
The current lr is: 0.001
Testing Results:
 *   Acc@1 65.355
 *   Acc@1 65.484
 *   Acc@1 63.197
 *   Acc@1 62.997
 *   Acc@1 62.329
 *   Acc@1 62.257
 *   Acc@1 60.605
 *   Acc@1 60.429
 *   Acc@1 56.263
 *   Acc@1 56.258
 *   Acc@1 48.724
 *   Acc@1 49.251
 *   Acc@1 49.237
 *   Acc@1 48.737
 *   Acc@1 51.895
 *   Acc@1 51.340
 *   Acc@1 62.197
 *   Acc@1 62.068
 *   Acc@1 63.395
 *   Acc@1 63.214
 *   Acc@1 63.487
 *   Acc@1 63.421
 *   Acc@1 62.224
 *   Acc@1 61.691
 *   Acc@1 55.724
 *   Acc@1 55.206
 *   Acc@1 55.592
 *   Acc@1 55.362
 *   Acc@1 54.461
 *   Acc@1 54.138
 *   Acc@1 53.500
 *   Acc@1 52.913
Training for 300 epoch: 59.88486842105263
Training for 600 epoch: 57.72697368421053
Training for 1000 epoch: 57.37828947368421
Training for 3000 epoch: 57.055921052631575
Training for 300 epoch: 59.75375
Training for 600 epoch: 57.706041666666664
Training for 1000 epoch: 57.138125
Training for 3000 epoch: 56.593333333333334
[[59.88486842105263, 57.72697368421053, 57.37828947368421, 57.055921052631575], [59.75375, 57.706041666666664, 57.138125, 56.593333333333334]]
train loss 0.556937716515859, epoch 4, best loss 0.556937716515859, best_epoch 4
GPU_0_using curriculum 40 with window 40
Epoch: [5][20/30]	Time  1.554 ( 1.558)	Data  0.040 ( 0.063)	InnerLoop  0.628 ( 0.638)	Loss 1.0660e+00 (1.3121e+00)	Acc@1  62.52 ( 54.79)
The current update step is 180
GPU_0_using curriculum 40 with window 40
Epoch: [6][20/30]	Time  1.523 ( 1.558)	Data  0.038 ( 0.071)	InnerLoop  0.625 ( 0.628)	Loss 9.1369e-01 (1.0651e+00)	Acc@1  67.33 ( 59.80)
The current update step is 210
GPU_0_using curriculum 40 with window 40
Epoch: [7][20/30]	Time  1.507 ( 1.544)	Data  0.042 ( 0.064)	InnerLoop  0.621 ( 0.630)	Loss 7.0470e-01 (1.0966e+00)	Acc@1  74.44 ( 60.17)
The current update step is 240
GPU_0_using curriculum 40 with window 40
Epoch: [8][20/30]	Time  1.497 ( 1.540)	Data  0.040 ( 0.064)	InnerLoop  0.615 ( 0.626)	Loss 8.6476e-01 (9.3047e-01)	Acc@1  64.38 ( 64.33)
The current update step is 270
GPU_0_using curriculum 40 with window 40
Epoch: [9][20/30]	Time  1.497 ( 1.519)	Data  0.040 ( 0.057)	InnerLoop  0.610 ( 0.629)	Loss 8.7002e-01 (8.6964e-01)	Acc@1  67.16 ( 67.99)
The current update step is 300
The current seed is 9404640462810159147
The current lr is: 0.001
Testing Results:
 *   Acc@1 68.342
 *   Acc@1 68.799
 *   Acc@1 65.855
 *   Acc@1 65.547
 *   Acc@1 63.184
 *   Acc@1 63.057
 *   Acc@1 62.079
 *   Acc@1 62.270
 *   Acc@1 70.592
 *   Acc@1 70.854
 *   Acc@1 70.329
 *   Acc@1 70.834
 *   Acc@1 69.789
 *   Acc@1 70.447
 *   Acc@1 68.605
 *   Acc@1 69.294
 *   Acc@1 63.171
 *   Acc@1 63.618
 *   Acc@1 59.382
 *   Acc@1 59.573
 *   Acc@1 56.934
 *   Acc@1 57.277
 *   Acc@1 54.250
 *   Acc@1 54.312
 *   Acc@1 69.132
 *   Acc@1 69.541
 *   Acc@1 68.434
 *   Acc@1 69.188
 *   Acc@1 68.461
 *   Acc@1 69.048
 *   Acc@1 69.066
 *   Acc@1 69.455
Training for 300 epoch: 67.8092105263158
Training for 600 epoch: 66.0
Training for 1000 epoch: 64.59210526315789
Training for 3000 epoch: 63.5
Training for 300 epoch: 68.203125
Training for 600 epoch: 66.285625
Training for 1000 epoch: 64.95708333333333
Training for 3000 epoch: 63.83270833333333
[[67.8092105263158, 66.0, 64.59210526315789, 63.5], [68.203125, 66.285625, 64.95708333333333, 63.83270833333333]]
train loss 0.23112021917502085, epoch 9, best loss 0.23112021917502085, best_epoch 9
GPU_0_using curriculum 40 with window 40
Epoch: [10][20/30]	Time  1.519 ( 1.521)	Data  0.040 ( 0.062)	InnerLoop  0.656 ( 0.627)	Loss 9.5794e-01 (9.8047e-01)	Acc@1  62.30 ( 63.79)
The current update step is 330
GPU_0_using curriculum 40 with window 40
Epoch: [11][20/30]	Time  1.474 ( 1.517)	Data  0.043 ( 0.070)	InnerLoop  0.612 ( 0.613)	Loss 1.0191e+00 (8.9510e-01)	Acc@1  55.30 ( 66.53)
The current update step is 360
GPU_0_using curriculum 40 with window 40
Epoch: [12][20/30]	Time  1.469 ( 1.528)	Data  0.040 ( 0.066)	InnerLoop  0.609 ( 0.626)	Loss 8.3258e-01 (8.5227e-01)	Acc@1  66.89 ( 67.53)
The current update step is 390
GPU_0_using curriculum 40 with window 40
Epoch: [13][20/30]	Time  1.500 ( 1.527)	Data  0.038 ( 0.063)	InnerLoop  0.609 ( 0.622)	Loss 6.7765e-01 (8.2005e-01)	Acc@1  75.73 ( 68.67)
The current update step is 420
GPU_0_using curriculum 40 with window 40
Epoch: [14][20/30]	Time  1.474 ( 1.514)	Data  0.039 ( 0.057)	InnerLoop  0.606 ( 0.627)	Loss 7.6567e-01 (7.6576e-01)	Acc@1  70.02 ( 71.90)
The current update step is 450
The current seed is 17043402275558832647
The current lr is: 0.001
Testing Results:
 *   Acc@1 64.066
 *   Acc@1 64.363
 *   Acc@1 64.447
 *   Acc@1 64.662
 *   Acc@1 66.013
 *   Acc@1 66.090
 *   Acc@1 70.158
 *   Acc@1 70.484
 *   Acc@1 47.829
 *   Acc@1 48.188
 *   Acc@1 47.934
 *   Acc@1 47.998
 *   Acc@1 47.513
 *   Acc@1 47.476
 *   Acc@1 47.237
 *   Acc@1 47.177
 *   Acc@1 57.987
 *   Acc@1 58.239
 *   Acc@1 56.053
 *   Acc@1 56.450
 *   Acc@1 56.605
 *   Acc@1 56.921
 *   Acc@1 58.895
 *   Acc@1 59.587
 *   Acc@1 50.842
 *   Acc@1 51.506
 *   Acc@1 51.553
 *   Acc@1 51.828
 *   Acc@1 52.461
 *   Acc@1 52.509
 *   Acc@1 53.026
 *   Acc@1 53.145
Training for 300 epoch: 55.180921052631575
Training for 600 epoch: 54.99671052631579
Training for 1000 epoch: 55.64802631578947
Training for 3000 epoch: 57.328947368421055
Training for 300 epoch: 55.57395833333333
Training for 600 epoch: 55.23458333333333
Training for 1000 epoch: 55.748958333333334
Training for 3000 epoch: 57.598125
[[55.180921052631575, 54.99671052631579, 55.64802631578947, 57.328947368421055], [55.57395833333333, 55.23458333333333, 55.748958333333334, 57.598125]]
train loss 0.5592572927792867, epoch 14, best loss 0.23112021917502085, best_epoch 9
GPU_0_using curriculum 40 with window 40
Epoch: [15][20/30]	Time  1.489 ( 1.523)	Data  0.039 ( 0.064)	InnerLoop  0.608 ( 0.627)	Loss 1.4164e+00 (8.8110e-01)	Acc@1  56.27 ( 67.71)
The current update step is 480
GPU_0_using curriculum 40 with window 40
Epoch: [16][20/30]	Time  1.491 ( 1.509)	Data  0.040 ( 0.070)	InnerLoop  0.611 ( 0.612)	Loss 7.5875e-01 (8.2522e-01)	Acc@1  71.36 ( 68.83)
The current update step is 510
GPU_0_using curriculum 40 with window 40
Epoch: [17][20/30]	Time  1.487 ( 1.520)	Data  0.038 ( 0.064)	InnerLoop  0.616 ( 0.625)	Loss 1.1376e+00 (7.6453e-01)	Acc@1  59.11 ( 71.07)
The current update step is 540
GPU_0_using curriculum 40 with window 40
Epoch: [18][20/30]	Time  1.567 ( 1.515)	Data  0.040 ( 0.064)	InnerLoop  0.603 ( 0.619)	Loss 8.0952e-01 (8.1142e-01)	Acc@1  71.02 ( 70.72)
The current update step is 570
GPU_0_using curriculum 40 with window 40
Epoch: [19][20/30]	Time  1.488 ( 1.516)	Data  0.039 ( 0.057)	InnerLoop  0.609 ( 0.622)	Loss 7.4172e-01 (7.9896e-01)	Acc@1  69.70 ( 70.83)
The current update step is 600
The current seed is 17813499996531843874
The current lr is: 0.001
Testing Results:
 *   Acc@1 72.487
 *   Acc@1 72.879
 *   Acc@1 69.974
 *   Acc@1 70.338
 *   Acc@1 68.908
 *   Acc@1 69.715
 *   Acc@1 70.816
 *   Acc@1 71.134
 *   Acc@1 70.039
 *   Acc@1 70.257
 *   Acc@1 69.539
 *   Acc@1 69.335
 *   Acc@1 69.618
 *   Acc@1 69.258
 *   Acc@1 71.039
 *   Acc@1 71.243
 *   Acc@1 63.053
 *   Acc@1 63.383
 *   Acc@1 62.053
 *   Acc@1 62.403
 *   Acc@1 59.303
 *   Acc@1 59.256
 *   Acc@1 54.079
 *   Acc@1 54.227
 *   Acc@1 77.132
 *   Acc@1 77.494
 *   Acc@1 77.382
 *   Acc@1 77.505
 *   Acc@1 77.250
 *   Acc@1 77.546
 *   Acc@1 77.197
 *   Acc@1 77.649
Training for 300 epoch: 70.67763157894737
Training for 600 epoch: 69.73684210526315
Training for 1000 epoch: 68.76973684210526
Training for 3000 epoch: 68.28289473684211
Training for 300 epoch: 71.00354166666666
Training for 600 epoch: 69.89541666666668
Training for 1000 epoch: 68.94375000000001
Training for 3000 epoch: 68.56333333333333
[[70.67763157894737, 69.73684210526315, 68.76973684210526, 68.28289473684211], [71.00354166666666, 69.89541666666668, 68.94375000000001, 68.56333333333333]]
train loss 0.22992272667090097, epoch 19, best loss 0.22992272667090097, best_epoch 19
GPU_0_using curriculum 40 with window 40
Epoch: [20][20/30]	Time  1.485 ( 1.515)	Data  0.039 ( 0.063)	InnerLoop  0.605 ( 0.622)	Loss 7.5033e-01 (8.0859e-01)	Acc@1  73.78 ( 71.62)
The current update step is 630
GPU_0_using curriculum 40 with window 40
Epoch: [21][20/30]	Time  1.481 ( 1.508)	Data  0.038 ( 0.070)	InnerLoop  0.612 ( 0.607)	Loss 1.0934e+00 (8.0244e-01)	Acc@1  61.77 ( 70.18)
The current update step is 660
GPU_0_using curriculum 40 with window 40
Epoch: [22][20/30]	Time  1.493 ( 1.511)	Data  0.040 ( 0.065)	InnerLoop  0.606 ( 0.617)	Loss 8.1595e-01 (7.5070e-01)	Acc@1  68.26 ( 72.04)
The current update step is 690
GPU_0_using curriculum 40 with window 40
Epoch: [23][20/30]	Time  1.478 ( 1.516)	Data  0.038 ( 0.063)	InnerLoop  0.616 ( 0.620)	Loss 7.9741e-01 (7.7963e-01)	Acc@1  71.46 ( 71.88)
The current update step is 720
GPU_0_using curriculum 40 with window 40
Epoch: [24][20/30]	Time  1.492 ( 1.509)	Data  0.039 ( 0.056)	InnerLoop  0.619 ( 0.620)	Loss 7.1610e-01 (8.0620e-01)	Acc@1  73.93 ( 70.89)
The current update step is 750
The current seed is 18028451323104661579
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.329
 *   Acc@1 76.688
 *   Acc@1 77.066
 *   Acc@1 77.002
 *   Acc@1 76.079
 *   Acc@1 76.830
 *   Acc@1 76.079
 *   Acc@1 76.316
 *   Acc@1 74.434
 *   Acc@1 74.542
 *   Acc@1 73.197
 *   Acc@1 72.846
 *   Acc@1 71.592
 *   Acc@1 71.149
 *   Acc@1 67.026
 *   Acc@1 66.942
 *   Acc@1 66.342
 *   Acc@1 66.213
 *   Acc@1 65.539
 *   Acc@1 66.067
 *   Acc@1 67.750
 *   Acc@1 67.421
 *   Acc@1 70.158
 *   Acc@1 70.296
 *   Acc@1 66.303
 *   Acc@1 66.206
 *   Acc@1 66.105
 *   Acc@1 65.787
 *   Acc@1 64.921
 *   Acc@1 65.310
 *   Acc@1 63.737
 *   Acc@1 63.529
Training for 300 epoch: 70.85197368421052
Training for 600 epoch: 70.47697368421052
Training for 1000 epoch: 70.08552631578948
Training for 3000 epoch: 69.25
Training for 300 epoch: 70.91187500000001
Training for 600 epoch: 70.425625
Training for 1000 epoch: 70.17750000000001
Training for 3000 epoch: 69.270625
[[70.85197368421052, 70.47697368421052, 70.08552631578948, 69.25], [70.91187500000001, 70.425625, 70.17750000000001, 69.270625]]
train loss 0.29857485478719076, epoch 24, best loss 0.22992272667090097, best_epoch 19
GPU_0_using curriculum 40 with window 40
Epoch: [25][20/30]	Time  1.484 ( 1.517)	Data  0.040 ( 0.063)	InnerLoop  0.614 ( 0.626)	Loss 7.4419e-01 (7.1807e-01)	Acc@1  72.00 ( 73.63)
The current update step is 780
GPU_0_using curriculum 40 with window 40
Epoch: [26][20/30]	Time  1.496 ( 1.514)	Data  0.046 ( 0.071)	InnerLoop  0.616 ( 0.614)	Loss 8.8909e-01 (8.0752e-01)	Acc@1  64.16 ( 69.78)
The current update step is 810
GPU_0_using curriculum 40 with window 40
Epoch: [27][20/30]	Time  1.486 ( 1.511)	Data  0.040 ( 0.063)	InnerLoop  0.618 ( 0.620)	Loss 5.9964e-01 (7.9441e-01)	Acc@1  77.83 ( 70.25)
The current update step is 840
GPU_0_using curriculum 40 with window 40
Epoch: [28][20/30]	Time  1.475 ( 1.514)	Data  0.039 ( 0.064)	InnerLoop  0.607 ( 0.621)	Loss 7.4188e-01 (8.5287e-01)	Acc@1  70.80 ( 69.75)
The current update step is 870
GPU_0_using curriculum 40 with window 40
Epoch: [29][20/30]	Time  1.500 ( 1.518)	Data  0.038 ( 0.057)	InnerLoop  0.610 ( 0.629)	Loss 5.8208e-01 (7.7980e-01)	Acc@1  79.74 ( 72.16)
The current update step is 900
The current seed is 8204894147718479663
The current lr is: 0.001
Testing Results:
 *   Acc@1 68.329
 *   Acc@1 68.304
 *   Acc@1 67.487
 *   Acc@1 67.708
 *   Acc@1 67.408
 *   Acc@1 67.450
 *   Acc@1 61.632
 *   Acc@1 61.307
 *   Acc@1 64.184
 *   Acc@1 64.245
 *   Acc@1 58.408
 *   Acc@1 58.459
 *   Acc@1 55.987
 *   Acc@1 55.865
 *   Acc@1 55.224
 *   Acc@1 54.751
 *   Acc@1 63.013
 *   Acc@1 62.279
 *   Acc@1 62.039
 *   Acc@1 61.798
 *   Acc@1 62.145
 *   Acc@1 62.189
 *   Acc@1 63.237
 *   Acc@1 63.432
 *   Acc@1 74.987
 *   Acc@1 75.041
 *   Acc@1 73.079
 *   Acc@1 73.237
 *   Acc@1 71.355
 *   Acc@1 71.159
 *   Acc@1 69.605
 *   Acc@1 69.682
Training for 300 epoch: 67.62828947368422
Training for 600 epoch: 65.2532894736842
Training for 1000 epoch: 64.22368421052632
Training for 3000 epoch: 62.42434210526316
Training for 300 epoch: 67.46729166666667
Training for 600 epoch: 65.300625
Training for 1000 epoch: 64.16583333333332
Training for 3000 epoch: 62.29270833333334
[[67.62828947368422, 65.2532894736842, 64.22368421052632, 62.42434210526316], [67.46729166666667, 65.300625, 64.16583333333332, 62.29270833333334]]
train loss 0.2103849159558614, epoch 29, best loss 0.2103849159558614, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [30][20/30]	Time  1.491 ( 1.517)	Data  0.040 ( 0.064)	InnerLoop  0.616 ( 0.624)	Loss 1.1811e+00 (8.3846e-01)	Acc@1  63.18 ( 70.44)
The current update step is 930
GPU_0_using curriculum 40 with window 40
Epoch: [31][20/30]	Time  1.500 ( 1.521)	Data  0.040 ( 0.069)	InnerLoop  0.621 ( 0.617)	Loss 6.0413e-01 (7.6919e-01)	Acc@1  77.42 ( 71.31)
The current update step is 960
GPU_0_using curriculum 40 with window 40
Epoch: [32][20/30]	Time  1.474 ( 1.519)	Data  0.038 ( 0.064)	InnerLoop  0.610 ( 0.618)	Loss 9.5435e-01 (7.9883e-01)	Acc@1  65.55 ( 71.38)
The current update step is 990
GPU_0_using curriculum 40 with window 40
Epoch: [33][20/30]	Time  1.490 ( 1.512)	Data  0.037 ( 0.064)	InnerLoop  0.614 ( 0.618)	Loss 8.2470e-01 (7.6231e-01)	Acc@1  68.31 ( 71.58)
The current update step is 1020
GPU_0_using curriculum 40 with window 40
Epoch: [34][20/30]	Time  1.471 ( 1.511)	Data  0.039 ( 0.056)	InnerLoop  0.608 ( 0.623)	Loss 8.3276e-01 (8.6279e-01)	Acc@1  69.26 ( 68.80)
The current update step is 1050
The current seed is 12183358280117851575
The current lr is: 0.001
Testing Results:
 *   Acc@1 74.382
 *   Acc@1 75.236
 *   Acc@1 68.487
 *   Acc@1 69.003
 *   Acc@1 66.355
 *   Acc@1 66.908
 *   Acc@1 63.566
 *   Acc@1 64.038
 *   Acc@1 54.105
 *   Acc@1 53.869
 *   Acc@1 56.132
 *   Acc@1 56.458
 *   Acc@1 59.053
 *   Acc@1 59.412
 *   Acc@1 60.711
 *   Acc@1 60.508
 *   Acc@1 66.803
 *   Acc@1 67.068
 *   Acc@1 64.947
 *   Acc@1 65.541
 *   Acc@1 66.474
 *   Acc@1 66.882
 *   Acc@1 69.197
 *   Acc@1 69.833
 *   Acc@1 69.342
 *   Acc@1 70.261
 *   Acc@1 69.329
 *   Acc@1 70.126
 *   Acc@1 69.868
 *   Acc@1 70.646
 *   Acc@1 70.513
 *   Acc@1 71.081
Training for 300 epoch: 66.15789473684211
Training for 600 epoch: 64.72368421052632
Training for 1000 epoch: 65.4375
Training for 3000 epoch: 65.99671052631578
Training for 300 epoch: 66.60854166666667
Training for 600 epoch: 65.28208333333333
Training for 1000 epoch: 65.96208333333333
Training for 3000 epoch: 66.365
[[66.15789473684211, 64.72368421052632, 65.4375, 65.99671052631578], [66.60854166666667, 65.28208333333333, 65.96208333333333, 66.365]]
train loss 0.22150952935218812, epoch 34, best loss 0.2103849159558614, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [35][20/30]	Time  1.479 ( 1.520)	Data  0.039 ( 0.063)	InnerLoop  0.613 ( 0.624)	Loss 1.0042e+00 (9.2377e-01)	Acc@1  62.57 ( 66.76)
The current update step is 1080
GPU_0_using curriculum 40 with window 40
Epoch: [36][20/30]	Time  1.479 ( 1.509)	Data  0.036 ( 0.069)	InnerLoop  0.611 ( 0.610)	Loss 8.1605e-01 (7.8339e-01)	Acc@1  68.68 ( 71.82)
The current update step is 1110
GPU_0_using curriculum 40 with window 40
Epoch: [37][20/30]	Time  1.469 ( 1.509)	Data  0.040 ( 0.064)	InnerLoop  0.605 ( 0.616)	Loss 9.1463e-01 (7.8867e-01)	Acc@1  64.55 ( 70.19)
The current update step is 1140
GPU_0_using curriculum 40 with window 40
Epoch: [38][20/30]	Time  1.485 ( 1.508)	Data  0.042 ( 0.063)	InnerLoop  0.604 ( 0.614)	Loss 6.0006e-01 (7.7212e-01)	Acc@1  79.30 ( 71.37)
The current update step is 1170
GPU_0_using curriculum 40 with window 40
Epoch: [39][20/30]	Time  1.481 ( 1.506)	Data  0.041 ( 0.057)	InnerLoop  0.612 ( 0.622)	Loss 6.8136e-01 (7.7316e-01)	Acc@1  75.78 ( 72.89)
The current update step is 1200
The current seed is 11317678015732549255
The current lr is: 0.001
Testing Results:
 *   Acc@1 75.171
 *   Acc@1 75.423
 *   Acc@1 71.145
 *   Acc@1 71.461
 *   Acc@1 69.737
 *   Acc@1 69.335
 *   Acc@1 67.079
 *   Acc@1 66.879
 *   Acc@1 71.789
 *   Acc@1 72.640
 *   Acc@1 71.566
 *   Acc@1 71.802
 *   Acc@1 70.658
 *   Acc@1 71.354
 *   Acc@1 69.474
 *   Acc@1 70.223
 *   Acc@1 71.171
 *   Acc@1 71.181
 *   Acc@1 67.842
 *   Acc@1 68.053
 *   Acc@1 66.921
 *   Acc@1 67.389
 *   Acc@1 65.303
 *   Acc@1 66.022
 *   Acc@1 70.829
 *   Acc@1 70.959
 *   Acc@1 61.408
 *   Acc@1 61.779
 *   Acc@1 62.158
 *   Acc@1 62.758
 *   Acc@1 67.395
 *   Acc@1 68.331
Training for 300 epoch: 72.24013157894737
Training for 600 epoch: 67.99013157894737
Training for 1000 epoch: 67.36842105263158
Training for 3000 epoch: 67.3125
Training for 300 epoch: 72.55083333333333
Training for 600 epoch: 68.27395833333333
Training for 1000 epoch: 67.70916666666666
Training for 3000 epoch: 67.86395833333333
[[72.24013157894737, 67.99013157894737, 67.36842105263158, 67.3125], [72.55083333333333, 68.27395833333333, 67.70916666666666, 67.86395833333333]]
train loss 0.2294084101041158, epoch 39, best loss 0.2103849159558614, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [40][20/30]	Time  1.507 ( 1.520)	Data  0.049 ( 0.064)	InnerLoop  0.617 ( 0.626)	Loss 6.3432e-01 (7.6480e-01)	Acc@1  78.52 ( 72.49)
The current update step is 1230
GPU_0_using curriculum 40 with window 40
Epoch: [41][20/30]	Time  1.482 ( 1.514)	Data  0.039 ( 0.070)	InnerLoop  0.615 ( 0.614)	Loss 7.1559e-01 (7.4868e-01)	Acc@1  73.02 ( 73.19)
The current update step is 1260
GPU_0_using curriculum 40 with window 40
Epoch: [42][20/30]	Time  1.487 ( 1.508)	Data  0.039 ( 0.064)	InnerLoop  0.621 ( 0.617)	Loss 6.1614e-01 (6.8111e-01)	Acc@1  77.47 ( 75.28)
The current update step is 1290
GPU_0_using curriculum 40 with window 40
Epoch: [43][20/30]	Time  1.485 ( 1.516)	Data  0.042 ( 0.064)	InnerLoop  0.608 ( 0.619)	Loss 6.4086e-01 (7.4312e-01)	Acc@1  78.20 ( 73.38)
The current update step is 1320
GPU_0_using curriculum 40 with window 40
Epoch: [44][20/30]	Time  1.511 ( 1.513)	Data  0.040 ( 0.057)	InnerLoop  0.620 ( 0.626)	Loss 6.1613e-01 (7.6664e-01)	Acc@1  75.46 ( 73.59)
The current update step is 1350
The current seed is 5186140581600209212
The current lr is: 0.001
Testing Results:
 *   Acc@1 61.118
 *   Acc@1 61.874
 *   Acc@1 59.224
 *   Acc@1 59.657
 *   Acc@1 54.947
 *   Acc@1 55.121
 *   Acc@1 51.197
 *   Acc@1 51.591
 *   Acc@1 57.684
 *   Acc@1 57.906
 *   Acc@1 54.882
 *   Acc@1 55.399
 *   Acc@1 54.158
 *   Acc@1 54.608
 *   Acc@1 54.355
 *   Acc@1 54.928
 *   Acc@1 63.987
 *   Acc@1 63.773
 *   Acc@1 63.145
 *   Acc@1 63.729
 *   Acc@1 65.092
 *   Acc@1 65.357
 *   Acc@1 65.803
 *   Acc@1 65.743
 *   Acc@1 56.974
 *   Acc@1 57.472
 *   Acc@1 55.197
 *   Acc@1 55.505
 *   Acc@1 54.553
 *   Acc@1 55.392
 *   Acc@1 55.224
 *   Acc@1 55.801
Training for 300 epoch: 59.940789473684205
Training for 600 epoch: 58.11184210526316
Training for 1000 epoch: 57.1875
Training for 3000 epoch: 56.64473684210526
Training for 300 epoch: 60.25604166666667
Training for 600 epoch: 58.5725
Training for 1000 epoch: 57.61937499999999
Training for 3000 epoch: 57.01562500000001
[[59.940789473684205, 58.11184210526316, 57.1875, 56.64473684210526], [60.25604166666667, 58.5725, 57.61937499999999, 57.01562500000001]]
train loss 0.3916973431587219, epoch 44, best loss 0.2103849159558614, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [45][20/30]	Time  1.494 ( 1.524)	Data  0.042 ( 0.065)	InnerLoop  0.616 ( 0.628)	Loss 5.7242e-01 (7.7524e-01)	Acc@1  79.57 ( 71.75)
The current update step is 1380
GPU_0_using curriculum 40 with window 40
Epoch: [46][20/30]	Time  1.474 ( 1.513)	Data  0.038 ( 0.070)	InnerLoop  0.609 ( 0.611)	Loss 8.3797e-01 (6.6995e-01)	Acc@1  68.75 ( 74.81)
The current update step is 1410
GPU_0_using curriculum 40 with window 40
Epoch: [47][20/30]	Time  1.488 ( 1.512)	Data  0.040 ( 0.065)	InnerLoop  0.611 ( 0.619)	Loss 7.5340e-01 (7.3255e-01)	Acc@1  73.61 ( 72.46)
The current update step is 1440
GPU_0_using curriculum 40 with window 40
Epoch: [48][20/30]	Time  1.474 ( 1.510)	Data  0.041 ( 0.063)	InnerLoop  0.608 ( 0.619)	Loss 8.9328e-01 (7.4482e-01)	Acc@1  70.75 ( 73.35)
The current update step is 1470
GPU_0_using curriculum 40 with window 40
Epoch: [49][20/30]	Time  1.489 ( 1.511)	Data  0.044 ( 0.058)	InnerLoop  0.614 ( 0.625)	Loss 5.6886e-01 (6.5180e-01)	Acc@1  81.27 ( 76.28)
The current update step is 1500
The current seed is 3011017439755131578
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.868
 *   Acc@1 72.049
 *   Acc@1 70.421
 *   Acc@1 70.749
 *   Acc@1 71.461
 *   Acc@1 71.479
 *   Acc@1 73.263
 *   Acc@1 73.350
 *   Acc@1 71.132
 *   Acc@1 71.460
 *   Acc@1 68.566
 *   Acc@1 69.153
 *   Acc@1 69.263
 *   Acc@1 70.122
 *   Acc@1 71.289
 *   Acc@1 72.030
 *   Acc@1 66.421
 *   Acc@1 66.531
 *   Acc@1 68.592
 *   Acc@1 68.188
 *   Acc@1 68.671
 *   Acc@1 68.499
 *   Acc@1 72.368
 *   Acc@1 72.245
 *   Acc@1 77.513
 *   Acc@1 78.016
 *   Acc@1 68.184
 *   Acc@1 68.999
 *   Acc@1 62.618
 *   Acc@1 63.253
 *   Acc@1 60.566
 *   Acc@1 60.986
Training for 300 epoch: 71.73355263157895
Training for 600 epoch: 68.9407894736842
Training for 1000 epoch: 68.0032894736842
Training for 3000 epoch: 69.37171052631578
Training for 300 epoch: 72.01395833333333
Training for 600 epoch: 69.27208333333334
Training for 1000 epoch: 68.33833333333334
Training for 3000 epoch: 69.65270833333334
[[71.73355263157895, 68.9407894736842, 68.0032894736842, 69.37171052631578], [72.01395833333333, 69.27208333333334, 68.33833333333334, 69.65270833333334]]
train loss 0.31227215321858726, epoch 49, best loss 0.2103849159558614, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [50][20/30]	Time  1.489 ( 1.518)	Data  0.040 ( 0.063)	InnerLoop  0.613 ( 0.625)	Loss 6.8670e-01 (7.2126e-01)	Acc@1  73.29 ( 73.27)
The current update step is 1530
GPU_0_using curriculum 40 with window 40
Epoch: [51][20/30]	Time  1.503 ( 1.511)	Data  0.040 ( 0.071)	InnerLoop  0.612 ( 0.611)	Loss 6.6972e-01 (8.0230e-01)	Acc@1  74.32 ( 71.38)
The current update step is 1560
GPU_0_using curriculum 40 with window 40
Epoch: [52][20/30]	Time  1.480 ( 1.516)	Data  0.044 ( 0.065)	InnerLoop  0.614 ( 0.622)	Loss 6.1842e-01 (6.4215e-01)	Acc@1  77.66 ( 76.91)
The current update step is 1590
GPU_0_using curriculum 40 with window 40
Epoch: [53][20/30]	Time  1.479 ( 1.514)	Data  0.043 ( 0.064)	InnerLoop  0.610 ( 0.620)	Loss 6.2203e-01 (7.2282e-01)	Acc@1  78.83 ( 73.47)
The current update step is 1620
GPU_0_using curriculum 40 with window 40
Epoch: [54][20/30]	Time  1.479 ( 1.514)	Data  0.039 ( 0.057)	InnerLoop  0.615 ( 0.628)	Loss 8.2700e-01 (7.3599e-01)	Acc@1  68.53 ( 73.49)
The current update step is 1650
The current seed is 7509491645235092229
The current lr is: 0.001
Testing Results:
 *   Acc@1 66.750
 *   Acc@1 66.523
 *   Acc@1 53.421
 *   Acc@1 53.788
 *   Acc@1 52.342
 *   Acc@1 52.583
 *   Acc@1 54.303
 *   Acc@1 54.166
 *   Acc@1 72.184
 *   Acc@1 72.612
 *   Acc@1 72.592
 *   Acc@1 72.878
 *   Acc@1 73.579
 *   Acc@1 73.821
 *   Acc@1 73.316
 *   Acc@1 73.558
 *   Acc@1 78.145
 *   Acc@1 78.606
 *   Acc@1 77.921
 *   Acc@1 78.317
 *   Acc@1 77.947
 *   Acc@1 78.038
 *   Acc@1 76.632
 *   Acc@1 76.948
 *   Acc@1 67.171
 *   Acc@1 67.667
 *   Acc@1 66.868
 *   Acc@1 67.616
 *   Acc@1 67.276
 *   Acc@1 67.499
 *   Acc@1 65.829
 *   Acc@1 66.504
Training for 300 epoch: 71.0625
Training for 600 epoch: 67.70065789473684
Training for 1000 epoch: 67.78618421052632
Training for 3000 epoch: 67.51973684210526
Training for 300 epoch: 71.351875
Training for 600 epoch: 68.14999999999999
Training for 1000 epoch: 67.98541666666667
Training for 3000 epoch: 67.79416666666667
[[71.0625, 67.70065789473684, 67.78618421052632, 67.51973684210526], [71.351875, 68.14999999999999, 67.98541666666667, 67.79416666666667]]
train loss 0.25526589334805805, epoch 54, best loss 0.2103849159558614, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [55][20/30]	Time  1.481 ( 1.520)	Data  0.039 ( 0.063)	InnerLoop  0.613 ( 0.624)	Loss 6.5171e-01 (6.7173e-01)	Acc@1  76.17 ( 75.52)
The current update step is 1680
GPU_0_using curriculum 40 with window 40
Epoch: [56][20/30]	Time  1.493 ( 1.512)	Data  0.042 ( 0.069)	InnerLoop  0.624 ( 0.613)	Loss 6.9765e-01 (6.6921e-01)	Acc@1  76.27 ( 76.34)
The current update step is 1710
GPU_0_using curriculum 40 with window 40
Epoch: [57][20/30]	Time  1.513 ( 1.512)	Data  0.040 ( 0.064)	InnerLoop  0.605 ( 0.617)	Loss 9.2633e-01 (7.3938e-01)	Acc@1  69.17 ( 72.87)
The current update step is 1740
GPU_0_using curriculum 40 with window 40
Epoch: [58][20/30]	Time  1.469 ( 1.517)	Data  0.039 ( 0.064)	InnerLoop  0.607 ( 0.621)	Loss 6.3064e-01 (7.0162e-01)	Acc@1  76.00 ( 74.38)
The current update step is 1770
GPU_0_using curriculum 40 with window 40
Epoch: [59][20/30]	Time  1.475 ( 1.523)	Data  0.039 ( 0.057)	InnerLoop  0.611 ( 0.628)	Loss 5.7874e-01 (7.0848e-01)	Acc@1  78.05 ( 73.51)
The current update step is 1800
The current seed is 8927596895329672058
The current lr is: 0.001
Testing Results:
 *   Acc@1 75.724
 *   Acc@1 75.968
 *   Acc@1 75.447
 *   Acc@1 75.842
 *   Acc@1 75.013
 *   Acc@1 75.616
 *   Acc@1 75.895
 *   Acc@1 76.157
 *   Acc@1 72.842
 *   Acc@1 72.597
 *   Acc@1 73.566
 *   Acc@1 73.504
 *   Acc@1 73.316
 *   Acc@1 73.367
 *   Acc@1 72.724
 *   Acc@1 72.850
 *   Acc@1 76.434
 *   Acc@1 77.176
 *   Acc@1 75.658
 *   Acc@1 76.410
 *   Acc@1 74.737
 *   Acc@1 75.542
 *   Acc@1 74.645
 *   Acc@1 74.637
 *   Acc@1 72.961
 *   Acc@1 73.233
 *   Acc@1 73.447
 *   Acc@1 73.175
 *   Acc@1 72.908
 *   Acc@1 73.377
 *   Acc@1 73.276
 *   Acc@1 73.932
Training for 300 epoch: 74.49013157894737
Training for 600 epoch: 74.52960526315789
Training for 1000 epoch: 73.99342105263159
Training for 3000 epoch: 74.13486842105263
Training for 300 epoch: 74.74354166666667
Training for 600 epoch: 74.73270833333333
Training for 1000 epoch: 74.47520833333333
Training for 3000 epoch: 74.39375
[[74.49013157894737, 74.52960526315789, 73.99342105263159, 74.13486842105263], [74.74354166666667, 74.73270833333333, 74.47520833333333, 74.39375]]
train loss 0.22415845925807953, epoch 59, best loss 0.2103849159558614, best_epoch 29
GPU_0_using curriculum 40 with window 40
Epoch: [60][20/30]	Time  1.481 ( 1.518)	Data  0.038 ( 0.062)	InnerLoop  0.618 ( 0.626)	Loss 7.2780e-01 (7.2937e-01)	Acc@1  75.07 ( 73.28)
The current update step is 1830
GPU_0_using curriculum 40 with window 40
Epoch: [61][20/30]	Time  1.496 ( 1.513)	Data  0.041 ( 0.070)	InnerLoop  0.618 ( 0.613)	Loss 6.4255e-01 (7.1341e-01)	Acc@1  75.51 ( 74.67)
The current update step is 1860
GPU_0_using curriculum 40 with window 40
Epoch: [62][20/30]	Time  1.499 ( 1.515)	Data  0.039 ( 0.065)	InnerLoop  0.624 ( 0.620)	Loss 5.7396e-01 (6.8637e-01)	Acc@1  79.91 ( 76.32)
The current update step is 1890
GPU_0_using curriculum 40 with window 40
Epoch: [63][20/30]	Time  1.499 ( 1.522)	Data  0.044 ( 0.065)	InnerLoop  0.609 ( 0.622)	Loss 1.0561e+00 (7.1923e-01)	Acc@1  61.89 ( 74.22)
The current update step is 1920
GPU_0_using curriculum 40 with window 40
Epoch: [64][20/30]	Time  1.481 ( 1.508)	Data  0.039 ( 0.057)	InnerLoop  0.614 ( 0.623)	Loss 7.1715e-01 (7.1263e-01)	Acc@1  74.15 ( 73.89)
The current update step is 1950
The current seed is 2435274771497564426
The current lr is: 0.001
Testing Results:
 *   Acc@1 57.434
 *   Acc@1 58.038
 *   Acc@1 57.013
 *   Acc@1 57.101
 *   Acc@1 56.658
 *   Acc@1 56.483
 *   Acc@1 54.461
 *   Acc@1 54.928
 *   Acc@1 67.487
 *   Acc@1 68.087
 *   Acc@1 66.145
 *   Acc@1 66.743
 *   Acc@1 66.539
 *   Acc@1 66.949
 *   Acc@1 67.908
 *   Acc@1 68.472
 *   Acc@1 69.882
 *   Acc@1 69.591
 *   Acc@1 69.382
 *   Acc@1 69.620
 *   Acc@1 69.921
 *   Acc@1 69.971
 *   Acc@1 70.342
 *   Acc@1 70.459
 *   Acc@1 70.553
 *   Acc@1 70.566
 *   Acc@1 70.053
 *   Acc@1 70.324
 *   Acc@1 70.605
 *   Acc@1 70.919
 *   Acc@1 71.408
 *   Acc@1 71.650
Training for 300 epoch: 66.3388157894737
Training for 600 epoch: 65.64802631578948
Training for 1000 epoch: 65.93092105263158
Training for 3000 epoch: 66.02960526315789
Training for 300 epoch: 66.57041666666666
Training for 600 epoch: 65.94708333333334
Training for 1000 epoch: 66.080625
Training for 3000 epoch: 66.37708333333333
[[66.3388157894737, 65.64802631578948, 65.93092105263158, 66.02960526315789], [66.57041666666666, 65.94708333333334, 66.080625, 66.37708333333333]]
train loss 0.20243011213938394, epoch 64, best loss 0.20243011213938394, best_epoch 64
GPU_0_using curriculum 40 with window 40
Epoch: [65][20/30]	Time  1.500 ( 1.515)	Data  0.039 ( 0.062)	InnerLoop  0.614 ( 0.621)	Loss 7.8618e-01 (7.3616e-01)	Acc@1  71.75 ( 72.46)
The current update step is 1980
GPU_0_using curriculum 40 with window 40
Epoch: [66][20/30]	Time  1.468 ( 1.511)	Data  0.038 ( 0.070)	InnerLoop  0.610 ( 0.613)	Loss 7.3028e-01 (8.0630e-01)	Acc@1  74.24 ( 70.96)
The current update step is 2010
GPU_0_using curriculum 40 with window 40
Epoch: [67][20/30]	Time  1.485 ( 1.520)	Data  0.037 ( 0.064)	InnerLoop  0.610 ( 0.616)	Loss 6.9727e-01 (7.2272e-01)	Acc@1  76.68 ( 73.31)
The current update step is 2040
GPU_0_using curriculum 40 with window 40
Epoch: [68][20/30]	Time  1.467 ( 1.515)	Data  0.038 ( 0.063)	InnerLoop  0.604 ( 0.619)	Loss 7.3677e-01 (7.1451e-01)	Acc@1  74.49 ( 73.38)
The current update step is 2070
GPU_0_using curriculum 40 with window 40
Epoch: [69][20/30]	Time  1.498 ( 1.514)	Data  0.039 ( 0.058)	InnerLoop  0.617 ( 0.625)	Loss 8.6251e-01 (7.4471e-01)	Acc@1  63.40 ( 72.66)
The current update step is 2100
The current seed is 1355233096225972509
The current lr is: 0.001
Testing Results:
 *   Acc@1 67.408
 *   Acc@1 67.824
 *   Acc@1 67.039
 *   Acc@1 68.017
 *   Acc@1 67.487
 *   Acc@1 68.322
 *   Acc@1 64.526
 *   Acc@1 65.588
 *   Acc@1 64.658
 *   Acc@1 64.945
 *   Acc@1 65.211
 *   Acc@1 65.118
 *   Acc@1 67.816
 *   Acc@1 67.603
 *   Acc@1 74.184
 *   Acc@1 73.912
 *   Acc@1 69.553
 *   Acc@1 70.207
 *   Acc@1 68.211
 *   Acc@1 68.306
 *   Acc@1 66.013
 *   Acc@1 66.002
 *   Acc@1 63.474
 *   Acc@1 63.556
 *   Acc@1 63.921
 *   Acc@1 63.636
 *   Acc@1 61.145
 *   Acc@1 60.723
 *   Acc@1 59.316
 *   Acc@1 59.088
 *   Acc@1 60.000
 *   Acc@1 59.735
Training for 300 epoch: 66.38486842105263
Training for 600 epoch: 65.40131578947368
Training for 1000 epoch: 65.15789473684211
Training for 3000 epoch: 65.54605263157895
Training for 300 epoch: 66.65291666666666
Training for 600 epoch: 65.54083333333334
Training for 1000 epoch: 65.25395833333333
Training for 3000 epoch: 65.69770833333334
[[66.38486842105263, 65.40131578947368, 65.15789473684211, 65.54605263157895], [66.65291666666666, 65.54083333333334, 65.25395833333333, 65.69770833333334]]
train loss 0.34407734786669414, epoch 69, best loss 0.20243011213938394, best_epoch 64
GPU_0_using curriculum 40 with window 40
Epoch: [70][20/30]	Time  1.469 ( 1.515)	Data  0.038 ( 0.063)	InnerLoop  0.606 ( 0.625)	Loss 8.1943e-01 (8.4338e-01)	Acc@1  72.27 ( 68.19)
The current update step is 2130
GPU_0_using curriculum 40 with window 40
Epoch: [71][20/30]	Time  1.479 ( 1.511)	Data  0.039 ( 0.069)	InnerLoop  0.607 ( 0.612)	Loss 6.2621e-01 (8.2059e-01)	Acc@1  76.29 ( 70.10)
The current update step is 2160
GPU_0_using curriculum 40 with window 40
Epoch: [72][20/30]	Time  1.498 ( 1.506)	Data  0.043 ( 0.064)	InnerLoop  0.625 ( 0.618)	Loss 5.9852e-01 (7.5449e-01)	Acc@1  77.05 ( 72.34)
The current update step is 2190
GPU_0_using curriculum 40 with window 40
Epoch: [73][20/30]	Time  1.476 ( 1.507)	Data  0.043 ( 0.064)	InnerLoop  0.612 ( 0.616)	Loss 8.8178e-01 (8.2299e-01)	Acc@1  63.11 ( 69.06)
The current update step is 2220
GPU_0_using curriculum 40 with window 40
Epoch: [74][20/30]	Time  1.490 ( 1.511)	Data  0.041 ( 0.057)	InnerLoop  0.613 ( 0.625)	Loss 8.3460e-01 (7.3065e-01)	Acc@1  70.21 ( 72.71)
The current update step is 2250
The current seed is 15978673541550418382
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.000
 *   Acc@1 75.924
 *   Acc@1 73.763
 *   Acc@1 73.832
 *   Acc@1 73.566
 *   Acc@1 73.532
 *   Acc@1 72.039
 *   Acc@1 72.121
 *   Acc@1 74.671
 *   Acc@1 74.782
 *   Acc@1 72.408
 *   Acc@1 73.474
 *   Acc@1 71.658
 *   Acc@1 72.204
 *   Acc@1 69.816
 *   Acc@1 70.719
 *   Acc@1 69.342
 *   Acc@1 69.099
 *   Acc@1 67.921
 *   Acc@1 68.123
 *   Acc@1 66.842
 *   Acc@1 66.876
 *   Acc@1 63.211
 *   Acc@1 63.431
 *   Acc@1 66.526
 *   Acc@1 66.938
 *   Acc@1 66.763
 *   Acc@1 67.437
 *   Acc@1 67.395
 *   Acc@1 67.859
 *   Acc@1 67.526
 *   Acc@1 68.132
Training for 300 epoch: 71.63486842105263
Training for 600 epoch: 70.21381578947368
Training for 1000 epoch: 69.86513157894737
Training for 3000 epoch: 68.14802631578948
Training for 300 epoch: 71.68604166666665
Training for 600 epoch: 70.71645833333334
Training for 1000 epoch: 70.11791666666667
Training for 3000 epoch: 68.60062500000001
[[71.63486842105263, 70.21381578947368, 69.86513157894737, 68.14802631578948], [71.68604166666665, 70.71645833333334, 70.11791666666667, 68.60062500000001]]
train loss 0.24814425270557403, epoch 74, best loss 0.20243011213938394, best_epoch 64
GPU_0_using curriculum 40 with window 40
Epoch: [75][20/30]	Time  1.463 ( 1.512)	Data  0.038 ( 0.062)	InnerLoop  0.606 ( 0.623)	Loss 7.9098e-01 (7.8179e-01)	Acc@1  65.45 ( 71.66)
The current update step is 2280
GPU_0_using curriculum 40 with window 40
Epoch: [76][20/30]	Time  1.476 ( 1.507)	Data  0.040 ( 0.069)	InnerLoop  0.609 ( 0.611)	Loss 7.5431e-01 (7.2483e-01)	Acc@1  73.75 ( 73.67)
The current update step is 2310
GPU_0_using curriculum 40 with window 40
Epoch: [77][20/30]	Time  1.494 ( 1.510)	Data  0.039 ( 0.063)	InnerLoop  0.625 ( 0.617)	Loss 5.7427e-01 (7.3773e-01)	Acc@1  78.32 ( 74.03)
The current update step is 2340
GPU_0_using curriculum 40 with window 40
Epoch: [78][20/30]	Time  1.472 ( 1.506)	Data  0.042 ( 0.064)	InnerLoop  0.605 ( 0.613)	Loss 6.1757e-01 (7.0398e-01)	Acc@1  77.22 ( 73.55)
The current update step is 2370
GPU_0_using curriculum 40 with window 40
Epoch: [79][20/30]	Time  1.499 ( 1.505)	Data  0.046 ( 0.058)	InnerLoop  0.621 ( 0.624)	Loss 6.8893e-01 (7.9081e-01)	Acc@1  73.90 ( 71.48)
The current update step is 2400
The current seed is 8732122445552750408
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.118
 *   Acc@1 76.546
 *   Acc@1 75.105
 *   Acc@1 75.186
 *   Acc@1 74.197
 *   Acc@1 74.432
 *   Acc@1 74.645
 *   Acc@1 74.673
 *   Acc@1 64.671
 *   Acc@1 65.502
 *   Acc@1 62.237
 *   Acc@1 62.532
 *   Acc@1 60.868
 *   Acc@1 60.914
 *   Acc@1 60.934
 *   Acc@1 61.614
 *   Acc@1 77.632
 *   Acc@1 78.412
 *   Acc@1 75.118
 *   Acc@1 76.171
 *   Acc@1 74.500
 *   Acc@1 74.887
 *   Acc@1 73.250
 *   Acc@1 73.962
 *   Acc@1 56.750
 *   Acc@1 57.903
 *   Acc@1 58.408
 *   Acc@1 59.567
 *   Acc@1 57.263
 *   Acc@1 58.177
 *   Acc@1 57.500
 *   Acc@1 57.674
Training for 300 epoch: 68.79276315789474
Training for 600 epoch: 67.71710526315789
Training for 1000 epoch: 66.70723684210526
Training for 3000 epoch: 66.58223684210526
Training for 300 epoch: 69.59104166666667
Training for 600 epoch: 68.36375
Training for 1000 epoch: 67.10229166666667
Training for 3000 epoch: 66.98083333333334
[[68.79276315789474, 67.71710526315789, 66.70723684210526, 66.58223684210526], [69.59104166666667, 68.36375, 67.10229166666667, 66.98083333333334]]
train loss 0.31718817836443586, epoch 79, best loss 0.20243011213938394, best_epoch 64
GPU_0_using curriculum 40 with window 40
Epoch: [80][20/30]	Time  1.474 ( 1.519)	Data  0.042 ( 0.063)	InnerLoop  0.612 ( 0.627)	Loss 8.8800e-01 (8.3581e-01)	Acc@1  68.77 ( 69.39)
The current update step is 2430
GPU_0_using curriculum 40 with window 40
Epoch: [81][20/30]	Time  1.462 ( 1.503)	Data  0.039 ( 0.069)	InnerLoop  0.603 ( 0.610)	Loss 6.5115e-01 (7.4012e-01)	Acc@1  76.39 ( 72.60)
The current update step is 2460
GPU_0_using curriculum 40 with window 40
Epoch: [82][20/30]	Time  1.467 ( 1.509)	Data  0.038 ( 0.063)	InnerLoop  0.612 ( 0.617)	Loss 6.6660e-01 (7.2518e-01)	Acc@1  77.08 ( 74.09)
The current update step is 2490
GPU_0_using curriculum 40 with window 40
Epoch: [83][20/30]	Time  1.480 ( 1.507)	Data  0.037 ( 0.064)	InnerLoop  0.609 ( 0.619)	Loss 5.6651e-01 (6.7472e-01)	Acc@1  80.10 ( 75.73)
The current update step is 2520
GPU_0_using curriculum 40 with window 40
Epoch: [84][20/30]	Time  1.481 ( 1.516)	Data  0.040 ( 0.057)	InnerLoop  0.614 ( 0.630)	Loss 6.9196e-01 (7.3083e-01)	Acc@1  72.66 ( 72.80)
The current update step is 2550
The current seed is 10032935874989988888
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.566
 *   Acc@1 76.780
 *   Acc@1 76.737
 *   Acc@1 77.056
 *   Acc@1 77.132
 *   Acc@1 77.180
 *   Acc@1 77.197
 *   Acc@1 77.864
 *   Acc@1 71.132
 *   Acc@1 71.599
 *   Acc@1 71.447
 *   Acc@1 72.055
 *   Acc@1 71.816
 *   Acc@1 72.455
 *   Acc@1 73.618
 *   Acc@1 74.339
 *   Acc@1 74.974
 *   Acc@1 75.282
 *   Acc@1 70.132
 *   Acc@1 71.099
 *   Acc@1 70.882
 *   Acc@1 71.549
 *   Acc@1 73.105
 *   Acc@1 73.963
 *   Acc@1 70.566
 *   Acc@1 71.091
 *   Acc@1 71.632
 *   Acc@1 71.202
 *   Acc@1 70.895
 *   Acc@1 71.503
 *   Acc@1 72.053
 *   Acc@1 72.651
Training for 300 epoch: 73.3092105263158
Training for 600 epoch: 72.48684210526316
Training for 1000 epoch: 72.68092105263158
Training for 3000 epoch: 73.99342105263159
Training for 300 epoch: 73.688125
Training for 600 epoch: 72.85291666666667
Training for 1000 epoch: 73.171875
Training for 3000 epoch: 74.704375
[[73.3092105263158, 72.48684210526316, 72.68092105263158, 73.99342105263159], [73.688125, 72.85291666666667, 73.171875, 74.704375]]
train loss 0.1925978762547175, epoch 84, best loss 0.1925978762547175, best_epoch 84
GPU_0_using curriculum 40 with window 40
Epoch: [85][20/30]	Time  1.492 ( 1.512)	Data  0.039 ( 0.063)	InnerLoop  0.610 ( 0.622)	Loss 6.9982e-01 (6.7445e-01)	Acc@1  73.83 ( 74.29)
The current update step is 2580
GPU_0_using curriculum 40 with window 40
Epoch: [86][20/30]	Time  1.486 ( 1.512)	Data  0.039 ( 0.070)	InnerLoop  0.613 ( 0.614)	Loss 7.0016e-01 (7.3217e-01)	Acc@1  73.36 ( 73.13)
The current update step is 2610
GPU_0_using curriculum 40 with window 40
Epoch: [87][20/30]	Time  1.469 ( 1.508)	Data  0.040 ( 0.063)	InnerLoop  0.607 ( 0.618)	Loss 5.9587e-01 (7.0274e-01)	Acc@1  78.98 ( 74.48)
The current update step is 2640
GPU_0_using curriculum 40 with window 40
Epoch: [88][20/30]	Time  1.474 ( 1.510)	Data  0.040 ( 0.063)	InnerLoop  0.610 ( 0.618)	Loss 8.8080e-01 (7.2812e-01)	Acc@1  65.87 ( 73.11)
The current update step is 2670
GPU_0_using curriculum 40 with window 40
Epoch: [89][20/30]	Time  1.500 ( 1.512)	Data  0.040 ( 0.057)	InnerLoop  0.617 ( 0.623)	Loss 7.1332e-01 (7.9992e-01)	Acc@1  70.73 ( 71.46)
The current update step is 2700
The current seed is 12704565356689709345
The current lr is: 0.001
Testing Results:
 *   Acc@1 78.487
 *   Acc@1 78.412
 *   Acc@1 78.013
 *   Acc@1 77.872
 *   Acc@1 77.263
 *   Acc@1 76.938
 *   Acc@1 76.592
 *   Acc@1 76.285
 *   Acc@1 75.921
 *   Acc@1 75.806
 *   Acc@1 74.934
 *   Acc@1 75.430
 *   Acc@1 75.013
 *   Acc@1 75.197
 *   Acc@1 74.184
 *   Acc@1 74.463
 *   Acc@1 70.684
 *   Acc@1 71.204
 *   Acc@1 70.250
 *   Acc@1 70.739
 *   Acc@1 69.789
 *   Acc@1 70.383
 *   Acc@1 66.316
 *   Acc@1 66.707
 *   Acc@1 77.855
 *   Acc@1 78.354
 *   Acc@1 77.250
 *   Acc@1 77.987
 *   Acc@1 76.737
 *   Acc@1 77.493
 *   Acc@1 74.934
 *   Acc@1 75.952
Training for 300 epoch: 75.73684210526316
Training for 600 epoch: 75.11184210526315
Training for 1000 epoch: 74.70065789473684
Training for 3000 epoch: 73.00657894736842
Training for 300 epoch: 75.94395833333334
Training for 600 epoch: 75.50708333333334
Training for 1000 epoch: 75.00270833333333
Training for 3000 epoch: 73.35145833333333
[[75.73684210526316, 75.11184210526315, 74.70065789473684, 73.00657894736842], [75.94395833333334, 75.50708333333334, 75.00270833333333, 73.35145833333333]]
train loss 0.17559806438287098, epoch 89, best loss 0.17559806438287098, best_epoch 89
GPU_0_using curriculum 40 with window 40
Epoch: [90][20/30]	Time  1.488 ( 1.523)	Data  0.043 ( 0.064)	InnerLoop  0.621 ( 0.631)	Loss 1.0122e+00 (7.4569e-01)	Acc@1  53.32 ( 72.67)
The current update step is 2730
GPU_0_using curriculum 40 with window 40
Epoch: [91][20/30]	Time  1.467 ( 1.510)	Data  0.039 ( 0.069)	InnerLoop  0.608 ( 0.614)	Loss 8.4962e-01 (7.3264e-01)	Acc@1  70.24 ( 73.44)
The current update step is 2760
GPU_0_using curriculum 40 with window 40
Epoch: [92][20/30]	Time  1.504 ( 1.519)	Data  0.042 ( 0.065)	InnerLoop  0.609 ( 0.623)	Loss 6.5815e-01 (6.9683e-01)	Acc@1  75.12 ( 74.66)
The current update step is 2790
GPU_0_using curriculum 40 with window 40
Epoch: [93][20/30]	Time  1.510 ( 1.522)	Data  0.040 ( 0.064)	InnerLoop  0.631 ( 0.625)	Loss 9.1475e-01 (8.3642e-01)	Acc@1  64.43 ( 69.42)
The current update step is 2820
GPU_0_using curriculum 40 with window 40
Epoch: [94][20/30]	Time  1.505 ( 1.514)	Data  0.040 ( 0.057)	InnerLoop  0.637 ( 0.628)	Loss 8.5172e-01 (7.0190e-01)	Acc@1  66.36 ( 73.68)
The current update step is 2850
The current seed is 1278621292308696801
The current lr is: 0.001
Testing Results:
 *   Acc@1 73.921
 *   Acc@1 73.849
 *   Acc@1 73.882
 *   Acc@1 73.726
 *   Acc@1 72.079
 *   Acc@1 72.205
 *   Acc@1 71.197
 *   Acc@1 71.411
 *   Acc@1 79.789
 *   Acc@1 79.622
 *   Acc@1 79.053
 *   Acc@1 78.982
 *   Acc@1 78.461
 *   Acc@1 78.297
 *   Acc@1 77.355
 *   Acc@1 77.121
 *   Acc@1 73.842
 *   Acc@1 73.938
 *   Acc@1 69.500
 *   Acc@1 70.282
 *   Acc@1 68.855
 *   Acc@1 69.469
 *   Acc@1 68.368
 *   Acc@1 68.681
 *   Acc@1 76.474
 *   Acc@1 76.652
 *   Acc@1 74.237
 *   Acc@1 74.737
 *   Acc@1 72.382
 *   Acc@1 72.399
 *   Acc@1 67.763
 *   Acc@1 67.970
Training for 300 epoch: 76.00657894736842
Training for 600 epoch: 74.16776315789474
Training for 1000 epoch: 72.94407894736842
Training for 3000 epoch: 71.17105263157895
Training for 300 epoch: 76.01520833333333
Training for 600 epoch: 74.43166666666666
Training for 1000 epoch: 73.0925
Training for 3000 epoch: 71.295625
[[76.00657894736842, 74.16776315789474, 72.94407894736842, 71.17105263157895], [76.01520833333333, 74.43166666666666, 73.0925, 71.295625]]
train loss 0.2270672983090083, epoch 94, best loss 0.17559806438287098, best_epoch 89
GPU_0_using curriculum 40 with window 40
Epoch: [95][20/30]	Time  1.470 ( 1.520)	Data  0.038 ( 0.063)	InnerLoop  0.607 ( 0.624)	Loss 7.7464e-01 (7.1678e-01)	Acc@1  72.14 ( 73.76)
The current update step is 2880
GPU_0_using curriculum 40 with window 40
Epoch: [96][20/30]	Time  1.481 ( 1.504)	Data  0.040 ( 0.068)	InnerLoop  0.616 ( 0.610)	Loss 6.1500e-01 (6.6316e-01)	Acc@1  76.25 ( 74.91)
The current update step is 2910
GPU_0_using curriculum 40 with window 40
Epoch: [97][20/30]	Time  1.500 ( 1.517)	Data  0.042 ( 0.064)	InnerLoop  0.617 ( 0.620)	Loss 5.8063e-01 (6.6977e-01)	Acc@1  80.03 ( 75.11)
The current update step is 2940
GPU_0_using curriculum 40 with window 40
Epoch: [98][20/30]	Time  1.471 ( 1.517)	Data  0.038 ( 0.063)	InnerLoop  0.611 ( 0.622)	Loss 9.9246e-01 (8.0349e-01)	Acc@1  66.82 ( 71.05)
The current update step is 2970
GPU_0_using curriculum 40 with window 40
Epoch: [99][20/30]	Time  1.477 ( 1.506)	Data  0.039 ( 0.057)	InnerLoop  0.612 ( 0.622)	Loss 6.0568e-01 (7.5959e-01)	Acc@1  77.39 ( 71.84)
The current update step is 3000
The current seed is 2024152991485589277
The current lr is: 0.001
Testing Results:
 *   Acc@1 75.658
 *   Acc@1 75.931
 *   Acc@1 73.671
 *   Acc@1 73.527
 *   Acc@1 70.447
 *   Acc@1 71.317
 *   Acc@1 67.776
 *   Acc@1 68.351
 *   Acc@1 74.118
 *   Acc@1 74.748
 *   Acc@1 74.211
 *   Acc@1 74.631
 *   Acc@1 72.750
 *   Acc@1 73.123
 *   Acc@1 70.776
 *   Acc@1 71.198
 *   Acc@1 66.829
 *   Acc@1 66.889
 *   Acc@1 66.974
 *   Acc@1 66.954
 *   Acc@1 65.895
 *   Acc@1 66.033
 *   Acc@1 64.750
 *   Acc@1 65.031
 *   Acc@1 71.316
 *   Acc@1 71.251
 *   Acc@1 65.500
 *   Acc@1 66.176
 *   Acc@1 64.105
 *   Acc@1 63.818
 *   Acc@1 64.355
 *   Acc@1 64.250
Training for 300 epoch: 71.98026315789474
Training for 600 epoch: 70.08881578947368
Training for 1000 epoch: 68.29934210526315
Training for 3000 epoch: 66.91447368421052
Training for 300 epoch: 72.20458333333333
Training for 600 epoch: 70.321875
Training for 1000 epoch: 68.57270833333334
Training for 3000 epoch: 67.20729166666666
[[71.98026315789474, 70.08881578947368, 68.29934210526315, 66.91447368421052], [72.20458333333333, 70.321875, 68.57270833333334, 67.20729166666666]]
train loss 0.21247245298226675, epoch 99, best loss 0.17559806438287098, best_epoch 89
GPU_0_using curriculum 40 with window 40
Epoch: [100][20/30]	Time  1.473 ( 1.518)	Data  0.038 ( 0.063)	InnerLoop  0.608 ( 0.626)	Loss 6.4248e-01 (7.5444e-01)	Acc@1  75.46 ( 72.29)
The current update step is 3030
GPU_0_using curriculum 40 with window 40
Epoch: [101][20/30]	Time  1.481 ( 1.509)	Data  0.038 ( 0.071)	InnerLoop  0.611 ( 0.612)	Loss 5.6932e-01 (7.3664e-01)	Acc@1  78.88 ( 72.39)
The current update step is 3060
GPU_0_using curriculum 40 with window 40
Epoch: [102][20/30]	Time  1.474 ( 1.509)	Data  0.040 ( 0.064)	InnerLoop  0.609 ( 0.618)	Loss 6.7320e-01 (7.0359e-01)	Acc@1  74.34 ( 73.91)
The current update step is 3090
GPU_0_using curriculum 40 with window 40
Epoch: [103][20/30]	Time  1.487 ( 1.508)	Data  0.041 ( 0.063)	InnerLoop  0.614 ( 0.618)	Loss 7.8580e-01 (6.8039e-01)	Acc@1  70.97 ( 74.39)
The current update step is 3120
GPU_0_using curriculum 40 with window 40
Epoch: [104][20/30]	Time  1.480 ( 1.510)	Data  0.042 ( 0.059)	InnerLoop  0.611 ( 0.623)	Loss 5.2450e-01 (6.4872e-01)	Acc@1  80.25 ( 75.77)
The current update step is 3150
The current seed is 7803215149648645635
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.961
 *   Acc@1 69.763
 *   Acc@1 67.789
 *   Acc@1 68.075
 *   Acc@1 67.513
 *   Acc@1 67.467
 *   Acc@1 66.829
 *   Acc@1 66.724
 *   Acc@1 60.513
 *   Acc@1 60.244
 *   Acc@1 56.092
 *   Acc@1 56.299
 *   Acc@1 55.026
 *   Acc@1 54.977
 *   Acc@1 56.789
 *   Acc@1 57.267
 *   Acc@1 73.803
 *   Acc@1 73.831
 *   Acc@1 74.184
 *   Acc@1 74.293
 *   Acc@1 72.724
 *   Acc@1 72.601
 *   Acc@1 71.539
 *   Acc@1 71.718
 *   Acc@1 76.145
 *   Acc@1 75.876
 *   Acc@1 72.184
 *   Acc@1 71.895
 *   Acc@1 71.329
 *   Acc@1 71.017
 *   Acc@1 70.316
 *   Acc@1 70.255
Training for 300 epoch: 70.10526315789474
Training for 600 epoch: 67.5625
Training for 1000 epoch: 66.64802631578947
Training for 3000 epoch: 66.36842105263158
Training for 300 epoch: 69.92854166666666
Training for 600 epoch: 67.640625
Training for 1000 epoch: 66.51541666666667
Training for 3000 epoch: 66.49125
[[70.10526315789474, 67.5625, 66.64802631578947, 66.36842105263158], [69.92854166666666, 67.640625, 66.51541666666667, 66.49125]]
train loss 0.18815271612803142, epoch 104, best loss 0.17559806438287098, best_epoch 89
GPU_0_using curriculum 40 with window 40
Epoch: [105][20/30]	Time  1.485 ( 1.516)	Data  0.038 ( 0.063)	InnerLoop  0.610 ( 0.623)	Loss 8.3955e-01 (7.2401e-01)	Acc@1  67.70 ( 72.57)
The current update step is 3180
GPU_0_using curriculum 40 with window 40
Epoch: [106][20/30]	Time  1.476 ( 1.510)	Data  0.039 ( 0.069)	InnerLoop  0.610 ( 0.612)	Loss 6.4442e-01 (7.1152e-01)	Acc@1  76.39 ( 73.92)
The current update step is 3210
GPU_0_using curriculum 40 with window 40
Epoch: [107][20/30]	Time  1.491 ( 1.516)	Data  0.043 ( 0.065)	InnerLoop  0.620 ( 0.619)	Loss 7.7339e-01 (7.4168e-01)	Acc@1  68.82 ( 71.95)
The current update step is 3240
GPU_0_using curriculum 40 with window 40
Epoch: [108][20/30]	Time  1.484 ( 1.511)	Data  0.038 ( 0.064)	InnerLoop  0.608 ( 0.618)	Loss 5.4468e-01 (7.1892e-01)	Acc@1  79.39 ( 74.08)
The current update step is 3270
GPU_0_using curriculum 40 with window 40
Epoch: [109][20/30]	Time  1.494 ( 1.511)	Data  0.041 ( 0.057)	InnerLoop  0.620 ( 0.624)	Loss 6.6762e-01 (6.7847e-01)	Acc@1  71.75 ( 75.13)
The current update step is 3300
The current seed is 11365626105622607903
The current lr is: 0.001
Testing Results:
 *   Acc@1 76.776
 *   Acc@1 77.013
 *   Acc@1 77.711
 *   Acc@1 77.518
 *   Acc@1 77.250
 *   Acc@1 77.536
 *   Acc@1 74.947
 *   Acc@1 75.156
 *   Acc@1 77.895
 *   Acc@1 78.507
 *   Acc@1 74.618
 *   Acc@1 75.238
 *   Acc@1 73.355
 *   Acc@1 73.862
 *   Acc@1 72.566
 *   Acc@1 73.162
 *   Acc@1 80.184
 *   Acc@1 80.060
 *   Acc@1 77.224
 *   Acc@1 77.387
 *   Acc@1 75.868
 *   Acc@1 76.579
 *   Acc@1 75.382
 *   Acc@1 76.441
 *   Acc@1 74.789
 *   Acc@1 75.103
 *   Acc@1 72.961
 *   Acc@1 73.435
 *   Acc@1 72.697
 *   Acc@1 72.604
 *   Acc@1 70.539
 *   Acc@1 70.589
Training for 300 epoch: 77.41118421052632
Training for 600 epoch: 75.6282894736842
Training for 1000 epoch: 74.79276315789474
Training for 3000 epoch: 73.35855263157895
Training for 300 epoch: 77.67083333333333
Training for 600 epoch: 75.89458333333333
Training for 1000 epoch: 75.14541666666666
Training for 3000 epoch: 73.83687499999999
[[77.41118421052632, 75.6282894736842, 74.79276315789474, 73.35855263157895], [77.67083333333333, 75.89458333333333, 75.14541666666666, 73.83687499999999]]
train loss 0.21934069209893545, epoch 109, best loss 0.17559806438287098, best_epoch 89
GPU_0_using curriculum 40 with window 40
Epoch: [110][20/30]	Time  1.490 ( 1.519)	Data  0.043 ( 0.063)	InnerLoop  0.616 ( 0.626)	Loss 8.7908e-01 (6.6806e-01)	Acc@1  65.67 ( 74.80)
The current update step is 3330
GPU_0_using curriculum 40 with window 40
Epoch: [111][20/30]	Time  1.484 ( 1.517)	Data  0.042 ( 0.071)	InnerLoop  0.613 ( 0.615)	Loss 6.2818e-01 (6.5136e-01)	Acc@1  78.34 ( 76.30)
The current update step is 3360
GPU_0_using curriculum 40 with window 40
Epoch: [112][20/30]	Time  1.499 ( 1.510)	Data  0.051 ( 0.065)	InnerLoop  0.608 ( 0.617)	Loss 7.3912e-01 (8.2363e-01)	Acc@1  68.65 ( 69.99)
The current update step is 3390
GPU_0_using curriculum 40 with window 40
Epoch: [113][20/30]	Time  1.478 ( 1.511)	Data  0.040 ( 0.065)	InnerLoop  0.610 ( 0.617)	Loss 6.3846e-01 (6.8766e-01)	Acc@1  75.15 ( 75.19)
The current update step is 3420
GPU_0_using curriculum 40 with window 40
Epoch: [114][20/30]	Time  1.480 ( 1.521)	Data  0.039 ( 0.059)	InnerLoop  0.614 ( 0.628)	Loss 1.0137e+00 (7.4782e-01)	Acc@1  67.29 ( 73.41)
The current update step is 3450
The current seed is 14889093382181786416
The current lr is: 0.001
Testing Results:
 *   Acc@1 78.303
 *   Acc@1 79.198
 *   Acc@1 76.421
 *   Acc@1 77.097
 *   Acc@1 74.763
 *   Acc@1 75.120
 *   Acc@1 70.289
 *   Acc@1 71.036
 *   Acc@1 78.092
 *   Acc@1 78.405
 *   Acc@1 73.697
 *   Acc@1 73.888
 *   Acc@1 71.539
 *   Acc@1 71.677
 *   Acc@1 71.684
 *   Acc@1 71.969
 *   Acc@1 67.618
 *   Acc@1 68.355
 *   Acc@1 69.329
 *   Acc@1 69.692
 *   Acc@1 71.632
 *   Acc@1 71.770
 *   Acc@1 72.329
 *   Acc@1 72.771
 *   Acc@1 72.447
 *   Acc@1 73.106
 *   Acc@1 68.118
 *   Acc@1 68.948
 *   Acc@1 68.816
 *   Acc@1 69.654
 *   Acc@1 71.171
 *   Acc@1 71.813
Training for 300 epoch: 74.11513157894737
Training for 600 epoch: 71.89144736842104
Training for 1000 epoch: 71.6875
Training for 3000 epoch: 71.36842105263158
Training for 300 epoch: 74.76583333333335
Training for 600 epoch: 72.40625
Training for 1000 epoch: 72.05520833333333
Training for 3000 epoch: 71.89729166666666
[[74.11513157894737, 71.89144736842104, 71.6875, 71.36842105263158], [74.76583333333335, 72.40625, 72.05520833333333, 71.89729166666666]]
train loss 0.1948200184504191, epoch 114, best loss 0.17559806438287098, best_epoch 89
GPU_0_using curriculum 40 with window 40
Epoch: [115][20/30]	Time  1.502 ( 1.521)	Data  0.042 ( 0.064)	InnerLoop  0.611 ( 0.626)	Loss 8.8565e-01 (7.2993e-01)	Acc@1  64.72 ( 73.09)
The current update step is 3480
GPU_0_using curriculum 40 with window 40
Epoch: [116][20/30]	Time  1.486 ( 1.516)	Data  0.041 ( 0.071)	InnerLoop  0.614 ( 0.613)	Loss 5.5713e-01 (7.7277e-01)	Acc@1  78.34 ( 72.98)
The current update step is 3510
GPU_0_using curriculum 40 with window 40
Epoch: [117][20/30]	Time  1.488 ( 1.517)	Data  0.040 ( 0.065)	InnerLoop  0.613 ( 0.619)	Loss 6.0339e-01 (7.0139e-01)	Acc@1  76.59 ( 73.34)
The current update step is 3540
GPU_0_using curriculum 40 with window 40
Epoch: [118][20/30]	Time  1.475 ( 1.513)	Data  0.038 ( 0.065)	InnerLoop  0.609 ( 0.619)	Loss 5.6738e-01 (7.6500e-01)	Acc@1  77.81 ( 71.24)
The current update step is 3570
GPU_0_using curriculum 40 with window 40
Epoch: [119][20/30]	Time  1.484 ( 1.509)	Data  0.040 ( 0.058)	InnerLoop  0.617 ( 0.623)	Loss 6.2617e-01 (7.1535e-01)	Acc@1  75.44 ( 73.18)
The current update step is 3600
The current seed is 11502750797995034814
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.592
 *   Acc@1 70.610
 *   Acc@1 62.724
 *   Acc@1 63.352
 *   Acc@1 61.934
 *   Acc@1 62.422
 *   Acc@1 64.276
 *   Acc@1 64.644
 *   Acc@1 68.224
 *   Acc@1 68.278
 *   Acc@1 67.276
 *   Acc@1 67.314
 *   Acc@1 64.316
 *   Acc@1 64.897
 *   Acc@1 59.658
 *   Acc@1 60.251
 *   Acc@1 75.447
 *   Acc@1 75.943
 *   Acc@1 73.987
 *   Acc@1 73.968
 *   Acc@1 71.816
 *   Acc@1 71.913
 *   Acc@1 65.079
 *   Acc@1 65.289
 *   Acc@1 76.711
 *   Acc@1 77.268
 *   Acc@1 75.039
 *   Acc@1 75.648
 *   Acc@1 69.763
 *   Acc@1 70.468
 *   Acc@1 61.329
 *   Acc@1 61.558
Training for 300 epoch: 72.49342105263159
Training for 600 epoch: 69.75657894736842
Training for 1000 epoch: 66.95723684210526
Training for 3000 epoch: 62.585526315789465
Training for 300 epoch: 73.02499999999999
Training for 600 epoch: 70.07062499999999
Training for 1000 epoch: 67.42520833333333
Training for 3000 epoch: 62.935625
[[72.49342105263159, 69.75657894736842, 66.95723684210526, 62.585526315789465], [73.02499999999999, 70.07062499999999, 67.42520833333333, 62.935625]]
train loss 0.24986354077657064, epoch 119, best loss 0.17559806438287098, best_epoch 89
GPU_0_using curriculum 40 with window 40
Epoch: [120][20/30]	Time  1.480 ( 1.515)	Data  0.041 ( 0.063)	InnerLoop  0.613 ( 0.626)	Loss 7.5040e-01 (6.4242e-01)	Acc@1  74.56 ( 75.89)
The current update step is 3630
GPU_0_using curriculum 40 with window 40
Epoch: [121][20/30]	Time  1.488 ( 1.510)	Data  0.039 ( 0.069)	InnerLoop  0.612 ( 0.612)	Loss 6.2539e-01 (6.8827e-01)	Acc@1  78.61 ( 74.60)
The current update step is 3660
GPU_0_using curriculum 40 with window 40
Epoch: [122][20/30]	Time  1.492 ( 1.511)	Data  0.040 ( 0.064)	InnerLoop  0.609 ( 0.619)	Loss 5.3578e-01 (6.3387e-01)	Acc@1  80.35 ( 76.27)
The current update step is 3690
GPU_0_using curriculum 40 with window 40
Epoch: [123][20/30]	Time  1.523 ( 1.513)	Data  0.040 ( 0.064)	InnerLoop  0.620 ( 0.620)	Loss 5.4910e-01 (6.8304e-01)	Acc@1  80.13 ( 74.72)
The current update step is 3720
GPU_0_using curriculum 40 with window 40
Epoch: [124][20/30]	Time  1.494 ( 1.512)	Data  0.039 ( 0.058)	InnerLoop  0.606 ( 0.624)	Loss 6.8669e-01 (7.3027e-01)	Acc@1  73.22 ( 73.25)
The current update step is 3750
The current seed is 17731998569303052028
The current lr is: 0.001
Testing Results:
 *   Acc@1 58.276
 *   Acc@1 58.287
 *   Acc@1 57.803
 *   Acc@1 57.273
 *   Acc@1 56.974
 *   Acc@1 57.165
 *   Acc@1 60.145
 *   Acc@1 60.417
 *   Acc@1 70.000
 *   Acc@1 70.312
 *   Acc@1 71.487
 *   Acc@1 71.652
 *   Acc@1 71.789
 *   Acc@1 71.944
 *   Acc@1 73.053
 *   Acc@1 72.583
 *   Acc@1 72.039
 *   Acc@1 72.409
 *   Acc@1 69.526
 *   Acc@1 70.103
 *   Acc@1 69.461
 *   Acc@1 69.602
 *   Acc@1 69.066
 *   Acc@1 69.288
 *   Acc@1 80.447
 *   Acc@1 80.847
 *   Acc@1 80.026
 *   Acc@1 80.779
 *   Acc@1 79.158
 *   Acc@1 80.335
 *   Acc@1 77.789
 *   Acc@1 78.582
Training for 300 epoch: 70.19078947368422
Training for 600 epoch: 69.71052631578948
Training for 1000 epoch: 69.34539473684211
Training for 3000 epoch: 70.01315789473684
Training for 300 epoch: 70.46375
Training for 600 epoch: 69.95145833333333
Training for 1000 epoch: 69.76145833333332
Training for 3000 epoch: 70.2175
[[70.19078947368422, 69.71052631578948, 69.34539473684211, 70.01315789473684], [70.46375, 69.95145833333333, 69.76145833333332, 70.2175]]
train loss 0.16694394240379334, epoch 124, best loss 0.16694394240379334, best_epoch 124
GPU_0_using curriculum 40 with window 40
Epoch: [125][20/30]	Time  1.479 ( 1.517)	Data  0.040 ( 0.063)	InnerLoop  0.612 ( 0.624)	Loss 5.6784e-01 (6.3813e-01)	Acc@1  79.79 ( 76.63)
The current update step is 3780
GPU_0_using curriculum 40 with window 40
Epoch: [126][20/30]	Time  1.474 ( 1.510)	Data  0.038 ( 0.069)	InnerLoop  0.607 ( 0.611)	Loss 6.3860e-01 (7.1654e-01)	Acc@1  75.98 ( 73.83)
The current update step is 3810
GPU_0_using curriculum 40 with window 40
Epoch: [127][20/30]	Time  1.478 ( 1.511)	Data  0.040 ( 0.064)	InnerLoop  0.609 ( 0.618)	Loss 6.6282e-01 (6.4078e-01)	Acc@1  76.27 ( 76.76)
The current update step is 3840
GPU_0_using curriculum 40 with window 40
Epoch: [128][20/30]	Time  1.474 ( 1.507)	Data  0.039 ( 0.063)	InnerLoop  0.609 ( 0.617)	Loss 7.7720e-01 (6.9267e-01)	Acc@1  71.04 ( 73.83)
The current update step is 3870
GPU_0_using curriculum 40 with window 40
Epoch: [129][20/30]	Time  1.485 ( 1.513)	Data  0.040 ( 0.058)	InnerLoop  0.609 ( 0.625)	Loss 7.2215e-01 (6.8825e-01)	Acc@1  69.56 ( 74.15)
The current update step is 3900
The current seed is 16765505201657327044
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.539
 *   Acc@1 70.032
 *   Acc@1 70.026
 *   Acc@1 70.223
 *   Acc@1 69.066
 *   Acc@1 69.540
 *   Acc@1 68.842
 *   Acc@1 69.962
 *   Acc@1 72.026
 *   Acc@1 71.462
 *   Acc@1 70.184
 *   Acc@1 70.103
 *   Acc@1 68.132
 *   Acc@1 68.263
 *   Acc@1 68.658
 *   Acc@1 68.301
 *   Acc@1 68.487
 *   Acc@1 68.647
 *   Acc@1 69.092
 *   Acc@1 69.078
 *   Acc@1 67.868
 *   Acc@1 68.329
 *   Acc@1 67.355
 *   Acc@1 67.491
 *   Acc@1 75.250
 *   Acc@1 75.531
 *   Acc@1 74.513
 *   Acc@1 74.845
 *   Acc@1 73.211
 *   Acc@1 73.693
 *   Acc@1 69.579
 *   Acc@1 69.769
Training for 300 epoch: 71.32565789473685
Training for 600 epoch: 70.95394736842105
Training for 1000 epoch: 69.56907894736842
Training for 3000 epoch: 68.60855263157895
Training for 300 epoch: 71.418125
Training for 600 epoch: 71.06229166666665
Training for 1000 epoch: 69.95645833333333
Training for 3000 epoch: 68.880625
[[71.32565789473685, 70.95394736842105, 69.56907894736842, 68.60855263157895], [71.418125, 71.06229166666665, 69.95645833333333, 68.880625]]
train loss 0.23133997134367626, epoch 129, best loss 0.16694394240379334, best_epoch 124
GPU_0_using curriculum 40 with window 40
Epoch: [130][20/30]	Time  1.482 ( 1.521)	Data  0.040 ( 0.063)	InnerLoop  0.615 ( 0.625)	Loss 7.3975e-01 (7.1661e-01)	Acc@1  72.12 ( 73.18)
The current update step is 3930
GPU_0_using curriculum 40 with window 40
Epoch: [131][20/30]	Time  1.487 ( 1.514)	Data  0.038 ( 0.070)	InnerLoop  0.616 ( 0.615)	Loss 6.1382e-01 (6.8125e-01)	Acc@1  78.03 ( 75.08)
The current update step is 3960
GPU_0_using curriculum 40 with window 40
Epoch: [132][20/30]	Time  1.482 ( 1.513)	Data  0.044 ( 0.065)	InnerLoop  0.611 ( 0.619)	Loss 6.0727e-01 (6.7321e-01)	Acc@1  77.66 ( 75.10)
The current update step is 3990
GPU_0_using curriculum 40 with window 40
Epoch: [133][20/30]	Time  1.474 ( 1.510)	Data  0.039 ( 0.062)	InnerLoop  0.607 ( 0.617)	Loss 7.2986e-01 (6.4465e-01)	Acc@1  72.97 ( 76.30)
The current update step is 4020
GPU_0_using curriculum 40 with window 40
Epoch: [134][20/30]	Time  1.477 ( 1.513)	Data  0.040 ( 0.057)	InnerLoop  0.610 ( 0.623)	Loss 5.5200e-01 (6.6342e-01)	Acc@1  81.01 ( 75.95)
The current update step is 4050
The current seed is 14742736533392318927
The current lr is: 0.001
Testing Results:
 *   Acc@1 69.368
 *   Acc@1 69.963
 *   Acc@1 66.500
 *   Acc@1 66.815
 *   Acc@1 65.842
 *   Acc@1 66.287
 *   Acc@1 65.829
 *   Acc@1 66.235
 *   Acc@1 57.276
 *   Acc@1 57.261
 *   Acc@1 53.895
 *   Acc@1 53.736
 *   Acc@1 52.368
 *   Acc@1 52.517
 *   Acc@1 53.816
 *   Acc@1 53.920
 *   Acc@1 75.934
 *   Acc@1 76.235
 *   Acc@1 73.855
 *   Acc@1 74.224
 *   Acc@1 72.355
 *   Acc@1 73.143
 *   Acc@1 70.961
 *   Acc@1 71.330
 *   Acc@1 75.395
 *   Acc@1 76.168
 *   Acc@1 72.776
 *   Acc@1 72.748
 *   Acc@1 70.855
 *   Acc@1 71.618
 *   Acc@1 70.408
 *   Acc@1 70.240
Training for 300 epoch: 69.49342105263158
Training for 600 epoch: 66.75657894736842
Training for 1000 epoch: 65.35526315789474
Training for 3000 epoch: 65.25328947368422
Training for 300 epoch: 69.90666666666667
Training for 600 epoch: 66.88083333333333
Training for 1000 epoch: 65.89125
Training for 3000 epoch: 65.43125
[[69.49342105263158, 66.75657894736842, 65.35526315789474, 65.25328947368422], [69.90666666666667, 66.88083333333333, 65.89125, 65.43125]]
train loss 0.20464960734049478, epoch 134, best loss 0.16694394240379334, best_epoch 124
GPU_0_using curriculum 40 with window 40
Epoch: [135][20/30]	Time  1.482 ( 1.519)	Data  0.039 ( 0.063)	InnerLoop  0.609 ( 0.625)	Loss 1.0172e+00 (6.9724e-01)	Acc@1  61.50 ( 73.83)
The current update step is 4080
GPU_0_using curriculum 40 with window 40
Epoch: [136][20/30]	Time  1.487 ( 1.509)	Data  0.039 ( 0.069)	InnerLoop  0.619 ( 0.610)	Loss 6.4137e-01 (7.1938e-01)	Acc@1  75.76 ( 73.31)
The current update step is 4110
GPU_0_using curriculum 40 with window 40
Epoch: [137][20/30]	Time  1.491 ( 1.516)	Data  0.038 ( 0.064)	InnerLoop  0.620 ( 0.619)	Loss 6.7655e-01 (6.8670e-01)	Acc@1  75.27 ( 74.57)
The current update step is 4140
GPU_0_using curriculum 40 with window 40
Epoch: [138][20/30]	Time  1.510 ( 1.514)	Data  0.041 ( 0.064)	InnerLoop  0.610 ( 0.617)	Loss 5.6290e-01 (7.6258e-01)	Acc@1  79.52 ( 71.42)
The current update step is 4170
GPU_0_using curriculum 40 with window 40
Epoch: [139][20/30]	Time  1.485 ( 1.508)	Data  0.040 ( 0.057)	InnerLoop  0.611 ( 0.624)	Loss 5.7008e-01 (7.1623e-01)	Acc@1  80.22 ( 73.06)
The current update step is 4200
The current seed is 2755799664764194489
The current lr is: 0.001
Testing Results:
 *   Acc@1 72.118
 *   Acc@1 72.296
 *   Acc@1 69.434
 *   Acc@1 69.853
 *   Acc@1 68.474
 *   Acc@1 68.872
 *   Acc@1 68.961
 *   Acc@1 69.690
 *   Acc@1 72.895
 *   Acc@1 72.859
 *   Acc@1 69.789
 *   Acc@1 69.884
 *   Acc@1 68.237
 *   Acc@1 67.875
 *   Acc@1 64.553
 *   Acc@1 64.767
 *   Acc@1 75.579
 *   Acc@1 75.357
 *   Acc@1 74.171
 *   Acc@1 74.319
 *   Acc@1 72.961
 *   Acc@1 73.373
 *   Acc@1 70.724
 *   Acc@1 71.366
 *   Acc@1 78.158
 *   Acc@1 78.434
 *   Acc@1 78.092
 *   Acc@1 78.162
 *   Acc@1 77.500
 *   Acc@1 77.810
 *   Acc@1 76.500
 *   Acc@1 76.758
Training for 300 epoch: 74.6875
Training for 600 epoch: 72.87171052631578
Training for 1000 epoch: 71.79276315789474
Training for 3000 epoch: 70.1842105263158
Training for 300 epoch: 74.73645833333333
Training for 600 epoch: 73.054375
Training for 1000 epoch: 71.98229166666667
Training for 3000 epoch: 70.64541666666666
[[74.6875, 72.87171052631578, 71.79276315789474, 70.1842105263158], [74.73645833333333, 73.054375, 71.98229166666667, 70.64541666666666]]
train loss 0.16660270546277364, epoch 139, best loss 0.16660270546277364, best_epoch 139
GPU_0_using curriculum 40 with window 40
Epoch: [140][20/30]	Time  1.495 ( 1.519)	Data  0.043 ( 0.063)	InnerLoop  0.617 ( 0.626)	Loss 6.8962e-01 (7.7054e-01)	Acc@1  74.32 ( 72.93)
The current update step is 4230
GPU_0_using curriculum 40 with window 40
Epoch: [141][20/30]	Time  1.469 ( 1.511)	Data  0.038 ( 0.071)	InnerLoop  0.605 ( 0.612)	Loss 7.4771e-01 (6.8251e-01)	Acc@1  72.63 ( 74.78)
The current update step is 4260
GPU_0_using curriculum 40 with window 40
Epoch: [142][20/30]	Time  1.495 ( 1.508)	Data  0.038 ( 0.065)	InnerLoop  0.631 ( 0.618)	Loss 6.3368e-01 (6.6356e-01)	Acc@1  77.08 ( 76.15)
The current update step is 4290
GPU_0_using curriculum 40 with window 40
Epoch: [143][20/30]	Time  1.490 ( 1.508)	Data  0.038 ( 0.063)	InnerLoop  0.609 ( 0.617)	Loss 5.7615e-01 (7.2622e-01)	Acc@1  79.03 ( 73.81)
The current update step is 4320
GPU_0_using curriculum 40 with window 40
Epoch: [144][20/30]	Time  1.481 ( 1.509)	Data  0.038 ( 0.057)	InnerLoop  0.615 ( 0.623)	Loss 5.5135e-01 (6.5497e-01)	Acc@1  79.47 ( 75.46)
The current update step is 4350
The current seed is 10840696287537508770
The current lr is: 0.001
Testing Results:
 *   Acc@1 64.421
 *   Acc@1 64.311
 *   Acc@1 66.382
 *   Acc@1 66.202
 *   Acc@1 65.605
 *   Acc@1 65.677
 *   Acc@1 62.789
 *   Acc@1 63.471
 *   Acc@1 69.658
 *   Acc@1 69.738
 *   Acc@1 67.697
 *   Acc@1 67.708
 *   Acc@1 66.566
 *   Acc@1 66.741
 *   Acc@1 66.118
 *   Acc@1 66.377
 *   Acc@1 72.276
 *   Acc@1 72.965
 *   Acc@1 70.447
 *   Acc@1 70.892
 *   Acc@1 69.750
 *   Acc@1 69.888
 *   Acc@1 69.882
 *   Acc@1 70.267
 *   Acc@1 54.921
 *   Acc@1 55.438
 *   Acc@1 54.447
 *   Acc@1 54.458
 *   Acc@1 54.697
 *   Acc@1 54.869
 *   Acc@1 57.079
 *   Acc@1 57.749
Training for 300 epoch: 65.31907894736842
Training for 600 epoch: 64.74342105263158
Training for 1000 epoch: 64.15460526315789
Training for 3000 epoch: 63.96710526315789
Training for 300 epoch: 65.613125
Training for 600 epoch: 64.815
Training for 1000 epoch: 64.29354166666667
Training for 3000 epoch: 64.46625
[[65.31907894736842, 64.74342105263158, 64.15460526315789, 63.96710526315789], [65.613125, 64.815, 64.29354166666667, 64.46625]]
train loss 0.30717242724100746, epoch 144, best loss 0.16660270546277364, best_epoch 139
GPU_0_using curriculum 40 with window 40
Epoch: [145][20/30]	Time  1.487 ( 1.518)	Data  0.048 ( 0.064)	InnerLoop  0.612 ( 0.626)	Loss 6.1379e-01 (7.0916e-01)	Acc@1  78.81 ( 73.46)
The current update step is 4380
GPU_0_using curriculum 40 with window 40
Epoch: [146][20/30]	Time  1.481 ( 1.510)	Data  0.040 ( 0.069)	InnerLoop  0.612 ( 0.614)	Loss 7.1580e-01 (6.5811e-01)	Acc@1  68.87 ( 75.44)
The current update step is 4410
GPU_0_using curriculum 40 with window 40
Epoch: [147][20/30]	Time  1.492 ( 1.512)	Data  0.039 ( 0.064)	InnerLoop  0.625 ( 0.620)	Loss 5.9237e-01 (7.0216e-01)	Acc@1  77.00 ( 73.91)
The current update step is 4440
GPU_0_using curriculum 40 with window 40
Epoch: [148][20/30]	Time  1.483 ( 1.509)	Data  0.040 ( 0.063)	InnerLoop  0.615 ( 0.619)	Loss 7.1220e-01 (6.5253e-01)	Acc@1  72.36 ( 75.38)
The current update step is 4470
GPU_0_using curriculum 40 with window 40
Epoch: [149][20/30]	Time  1.483 ( 1.513)	Data  0.046 ( 0.058)	InnerLoop  0.609 ( 0.624)	Loss 1.0386e+00 (7.1477e-01)	Acc@1  56.96 ( 73.27)
The current update step is 4500
The current seed is 13579739963714641490
The current lr is: 0.001
Testing Results:
 *   Acc@1 58.447
 *   Acc@1 58.668
 *   Acc@1 56.618
 *   Acc@1 57.182
 *   Acc@1 56.329
 *   Acc@1 56.748
 *   Acc@1 58.092
 *   Acc@1 57.702
 *   Acc@1 74.776
 *   Acc@1 74.689
 *   Acc@1 73.276
 *   Acc@1 73.439
 *   Acc@1 72.882
 *   Acc@1 73.131
 *   Acc@1 72.961
 *   Acc@1 73.502
 *   Acc@1 79.539
 *   Acc@1 80.058
 *   Acc@1 75.539
 *   Acc@1 75.718
 *   Acc@1 73.579
 *   Acc@1 73.248
 *   Acc@1 70.961
 *   Acc@1 70.763
 *   Acc@1 63.724
 *   Acc@1 64.220
 *   Acc@1 62.816
 *   Acc@1 63.413
 *   Acc@1 61.329
 *   Acc@1 61.697
 *   Acc@1 57.671
 *   Acc@1 58.350
Training for 300 epoch: 69.12171052631578
Training for 600 epoch: 67.0625
Training for 1000 epoch: 66.02960526315789
Training for 3000 epoch: 64.92105263157895
Training for 300 epoch: 69.40875
Training for 600 epoch: 67.43791666666667
Training for 1000 epoch: 66.20583333333333
Training for 3000 epoch: 65.07895833333333
[[69.12171052631578, 67.0625, 66.02960526315789, 64.92105263157895], [69.40875, 67.43791666666667, 66.20583333333333, 65.07895833333333]]
train loss 0.382768554798762, epoch 149, best loss 0.16660270546277364, best_epoch 139
GPU_0_using curriculum 40 with window 40
Epoch: [150][20/30]	Time  1.495 ( 1.517)	Data  0.038 ( 0.064)	InnerLoop  0.614 ( 0.625)	Loss 5.6520e-01 (7.1343e-01)	Acc@1  79.54 ( 73.77)
The current update step is 4530
GPU_0_using curriculum 40 with window 40
Epoch: [151][20/30]	Time  1.484 ( 1.511)	Data  0.039 ( 0.070)	InnerLoop  0.608 ( 0.612)	Loss 6.3252e-01 (7.3809e-01)	Acc@1  77.49 ( 72.55)
The current update step is 4560
GPU_0_using curriculum 40 with window 40
Epoch: [152][20/30]	Time  1.475 ( 1.510)	Data  0.040 ( 0.064)	InnerLoop  0.608 ( 0.619)	Loss 5.3422e-01 (7.1360e-01)	Acc@1  81.27 ( 74.27)
The current update step is 4590
GPU_0_using curriculum 40 with window 40
Epoch: [153][20/30]	Time  1.481 ( 1.507)	Data  0.038 ( 0.064)	InnerLoop  0.617 ( 0.618)	Loss 6.9517e-01 (7.2916e-01)	Acc@1  73.56 ( 73.84)
The current update step is 4620
GPU_0_using curriculum 40 with window 40
Epoch: [154][20/30]	Time  1.475 ( 1.515)	Data  0.040 ( 0.059)	InnerLoop  0.608 ( 0.627)	Loss 9.4896e-01 (7.1232e-01)	Acc@1  63.11 ( 73.47)
The current update step is 4650
The current seed is 10010484373201951401
The current lr is: 0.001
Testing Results:
 *   Acc@1 70.579
 *   Acc@1 71.334
 *   Acc@1 72.237
 *   Acc@1 72.669
 *   Acc@1 72.434
 *   Acc@1 72.797
 *   Acc@1 74.158
 *   Acc@1 75.308
 *   Acc@1 79.921
 *   Acc@1 80.264
 *   Acc@1 78.908
 *   Acc@1 78.198
 *   Acc@1 77.421
 *   Acc@1 77.597
 *   Acc@1 76.539
 *   Acc@1 76.850
 *   Acc@1 72.684
 *   Acc@1 72.653
 *   Acc@1 59.618
 *   Acc@1 60.288
 *   Acc@1 58.632
 *   Acc@1 58.966
 *   Acc@1 59.566
 *   Acc@1 59.932
 *   Acc@1 77.461
 *   Acc@1 77.571
 *   Acc@1 75.000
 *   Acc@1 75.032
 *   Acc@1 73.526
 *   Acc@1 74.208
 *   Acc@1 74.316
 *   Acc@1 74.978
Training for 300 epoch: 75.16118421052632
Training for 600 epoch: 71.44078947368422
Training for 1000 epoch: 70.5032894736842
Training for 3000 epoch: 71.14473684210526
Training for 300 epoch: 75.455625
Training for 600 epoch: 71.546875
Training for 1000 epoch: 70.89208333333333
Training for 3000 epoch: 71.76729166666667
[[75.16118421052632, 71.44078947368422, 70.5032894736842, 71.14473684210526], [75.455625, 71.546875, 70.89208333333333, 71.76729166666667]]
train loss 0.18223854780991872, epoch 154, best loss 0.16660270546277364, best_epoch 139
GPU_0_using curriculum 40 with window 40
Epoch: [155][20/30]	Time  1.480 ( 1.509)	Data  0.039 ( 0.064)	InnerLoop  0.610 ( 0.620)	Loss 6.2105e-01 (6.8833e-01)	Acc@1  79.20 ( 74.77)
The current update step is 4680
GPU_0_using curriculum 40 with window 40
Epoch: [156][20/30]	Time  1.465 ( 1.502)	Data  0.036 ( 0.069)	InnerLoop  0.603 ( 0.608)	Loss 7.0796e-01 (7.4810e-01)	Acc@1  72.78 ( 73.18)
The current update step is 4710
GPU_0_using curriculum 40 with window 40
Epoch: [157][20/30]	Time  1.477 ( 1.510)	Data  0.039 ( 0.065)	InnerLoop  0.606 ( 0.617)	Loss 5.7166e-01 (7.1520e-01)	Acc@1  78.08 ( 73.48)
The current update step is 4740
GPU_0_using curriculum 40 with window 40
Epoch: [158][20/30]	Time  1.472 ( 1.503)	Data  0.039 ( 0.063)	InnerLoop  0.611 ( 0.615)	Loss 9.6304e-01 (7.2178e-01)	Acc@1  64.28 ( 73.09)
The current update step is 4770
GPU_0_using curriculum 40 with window 40
Epoch: [159][20/30]	Time  1.479 ( 1.507)	Data  0.040 ( 0.056)	InnerLoop  0.609 ( 0.624)	Loss 6.7404e-01 (6.7791e-01)	Acc@1  75.49 ( 75.03)
The current update step is 4800
The current seed is 16117266440491075169
The current lr is: 0.001
Testing Results:
 *   Acc@1 72.618
 *   Acc@1 73.136
 *   Acc@1 72.750
 *   Acc@1 73.543
 *   Acc@1 69.513
 *   Acc@1 70.128
 *   Acc@1 68.079
 *   Acc@1 67.958
 *   Acc@1 79.329
 *   Acc@1 79.517
 *   Acc@1 78.632
 *   Acc@1 79.177
 *   Acc@1 78.316
 *   Acc@1 78.711
 *   Acc@1 77.684
 *   Acc@1 78.010
 *   Acc@1 80.645
 *   Acc@1 80.770
 *   Acc@1 78.263
 *   Acc@1 78.484
 *   Acc@1 74.461
 *   Acc@1 74.471
 *   Acc@1 73.158
 *   Acc@1 72.947
 *   Acc@1 77.605
 *   Acc@1 78.169
 *   Acc@1 78.000
 *   Acc@1 78.065
 *   Acc@1 76.263
 *   Acc@1 76.728
 *   Acc@1 75.342
 *   Acc@1 75.626
Training for 300 epoch: 77.54934210526315
Training for 600 epoch: 76.91118421052632
Training for 1000 epoch: 74.63815789473684
Training for 3000 epoch: 73.56578947368422
Training for 300 epoch: 77.89791666666667
Training for 600 epoch: 77.31708333333333
Training for 1000 epoch: 75.00958333333332
Training for 3000 epoch: 73.63520833333334
[[77.54934210526315, 76.91118421052632, 74.63815789473684, 73.56578947368422], [77.89791666666667, 77.31708333333333, 75.00958333333332, 73.63520833333334]]
train loss 0.18314590551058452, epoch 159, best loss 0.16660270546277364, best_epoch 139
GPU_0_using curriculum 40 with window 40
Epoch: [160][20/30]	Time  1.493 ( 1.519)	Data  0.047 ( 0.064)	InnerLoop  0.616 ( 0.626)	Loss 7.3481e-01 (7.0690e-01)	Acc@1  69.29 ( 73.75)
The current update step is 4830
GPU_0_using curriculum 40 with window 40
Epoch: [161][20/30]	Time  1.486 ( 1.510)	Data  0.039 ( 0.070)	InnerLoop  0.613 ( 0.611)	Loss 7.8369e-01 (6.9088e-01)	Acc@1  67.92 ( 74.54)
The current update step is 4860
GPU_0_using curriculum 40 with window 40
Epoch: [162][20/30]	Time  1.481 ( 1.516)	Data  0.041 ( 0.063)	InnerLoop  0.609 ( 0.618)	Loss 7.0610e-01 (6.7508e-01)	Acc@1  74.34 ( 75.21)
The current update step is 4890
GPU_0_using curriculum 40 with window 40
Epoch: [163][20/30]	Time  1.489 ( 1.511)	Data  0.040 ( 0.063)	InnerLoop  0.611 ( 0.618)	Loss 6.8060e-01 (6.4591e-01)	Acc@1  76.73 ( 76.44)
The current update step is 4920
GPU_0_using curriculum 40 with window 40
Epoch: [164][20/30]	Time  1.490 ( 1.512)	Data  0.039 ( 0.058)	InnerLoop  0.615 ( 0.624)	Loss 6.2220e-01 (7.0400e-01)	Acc@1  76.27 ( 74.94)
The current update step is 4950
The current seed is 16369947056727246765
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.658
 *   Acc@1 78.577
 *   Acc@1 76.566
 *   Acc@1 77.338
 *   Acc@1 76.447
 *   Acc@1 77.042
 *   Acc@1 74.882
 *   Acc@1 75.609
 *   Acc@1 76.908
 *   Acc@1 77.778
 *   Acc@1 73.974
 *   Acc@1 74.672
 *   Acc@1 73.118
 *   Acc@1 73.500
 *   Acc@1 71.289
 *   Acc@1 71.638
 *   Acc@1 74.461
 *   Acc@1 74.580
 *   Acc@1 72.026
 *   Acc@1 72.272
 *   Acc@1 71.921
 *   Acc@1 72.625
 *   Acc@1 76.053
 *   Acc@1 76.364
 *   Acc@1 78.842
 *   Acc@1 79.241
 *   Acc@1 77.711
 *   Acc@1 77.835
 *   Acc@1 76.961
 *   Acc@1 77.257
 *   Acc@1 75.342
 *   Acc@1 76.147
Training for 300 epoch: 76.96710526315789
Training for 600 epoch: 75.06907894736842
Training for 1000 epoch: 74.61184210526316
Training for 3000 epoch: 74.39144736842105
Training for 300 epoch: 77.54395833333334
Training for 600 epoch: 75.52916666666665
Training for 1000 epoch: 75.10583333333334
Training for 3000 epoch: 74.93958333333333
[[76.96710526315789, 75.06907894736842, 74.61184210526316, 74.39144736842105], [77.54395833333334, 75.52916666666665, 75.10583333333334, 74.93958333333333]]
train loss 0.1985632666826248, epoch 164, best loss 0.16660270546277364, best_epoch 139
GPU_0_using curriculum 40 with window 40
Epoch: [165][20/30]	Time  1.482 ( 1.514)	Data  0.038 ( 0.063)	InnerLoop  0.614 ( 0.623)	Loss 7.5884e-01 (6.4804e-01)	Acc@1  69.41 ( 75.86)
The current update step is 4980
GPU_0_using curriculum 40 with window 40
Epoch: [166][20/30]	Time  1.478 ( 1.509)	Data  0.039 ( 0.070)	InnerLoop  0.610 ( 0.612)	Loss 5.9334e-01 (6.8478e-01)	Acc@1  76.56 ( 75.10)
The current update step is 5010
GPU_0_using curriculum 40 with window 40
Epoch: [167][20/30]	Time  1.470 ( 1.511)	Data  0.038 ( 0.064)	InnerLoop  0.607 ( 0.620)	Loss 6.1708e-01 (6.3539e-01)	Acc@1  77.78 ( 76.38)
The current update step is 5040
GPU_0_using curriculum 40 with window 40
Epoch: [168][20/30]	Time  1.515 ( 1.518)	Data  0.041 ( 0.065)	InnerLoop  0.625 ( 0.620)	Loss 5.9898e-01 (6.5359e-01)	Acc@1  76.42 ( 74.96)
The current update step is 5070
GPU_0_using curriculum 40 with window 40
Epoch: [169][20/30]	Time  1.499 ( 1.518)	Data  0.038 ( 0.058)	InnerLoop  0.617 ( 0.628)	Loss 7.3616e-01 (6.3350e-01)	Acc@1  67.80 ( 76.50)
The current update step is 5100
The current seed is 15715118054779946349
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.316
 *   Acc@1 77.990
 *   Acc@1 75.026
 *   Acc@1 76.171
 *   Acc@1 74.158
 *   Acc@1 74.567
 *   Acc@1 72.368
 *   Acc@1 73.168
 *   Acc@1 67.013
 *   Acc@1 67.133
 *   Acc@1 63.000
 *   Acc@1 63.033
 *   Acc@1 62.605
 *   Acc@1 63.056
 *   Acc@1 63.842
 *   Acc@1 63.742
 *   Acc@1 70.342
 *   Acc@1 70.944
 *   Acc@1 68.263
 *   Acc@1 68.710
 *   Acc@1 66.487
 *   Acc@1 66.836
 *   Acc@1 62.724
 *   Acc@1 63.343
 *   Acc@1 73.408
 *   Acc@1 73.632
 *   Acc@1 71.276
 *   Acc@1 71.281
 *   Acc@1 68.882
 *   Acc@1 69.036
 *   Acc@1 65.579
 *   Acc@1 66.014
Training for 300 epoch: 72.01973684210526
Training for 600 epoch: 69.39144736842105
Training for 1000 epoch: 68.03289473684211
Training for 3000 epoch: 66.1282894736842
Training for 300 epoch: 72.425
Training for 600 epoch: 69.79874999999998
Training for 1000 epoch: 68.37354166666665
Training for 3000 epoch: 66.56666666666666
[[72.01973684210526, 69.39144736842105, 68.03289473684211, 66.1282894736842], [72.425, 69.79874999999998, 68.37354166666665, 66.56666666666666]]
train loss 0.2584076956272125, epoch 169, best loss 0.16660270546277364, best_epoch 139
GPU_0_using curriculum 40 with window 40
Epoch: [170][20/30]	Time  1.502 ( 1.513)	Data  0.039 ( 0.063)	InnerLoop  0.614 ( 0.621)	Loss 6.1963e-01 (7.3024e-01)	Acc@1  78.39 ( 74.37)
The current update step is 5130
GPU_0_using curriculum 40 with window 40
Epoch: [171][20/30]	Time  1.487 ( 1.508)	Data  0.037 ( 0.070)	InnerLoop  0.612 ( 0.611)	Loss 7.6627e-01 (7.8948e-01)	Acc@1  71.53 ( 70.75)
The current update step is 5160
GPU_0_using curriculum 40 with window 40
Epoch: [172][20/30]	Time  1.486 ( 1.504)	Data  0.040 ( 0.063)	InnerLoop  0.616 ( 0.616)	Loss 6.8468e-01 (7.1451e-01)	Acc@1  72.80 ( 73.95)
The current update step is 5190
GPU_0_using curriculum 40 with window 40
Epoch: [173][20/30]	Time  1.469 ( 1.513)	Data  0.038 ( 0.064)	InnerLoop  0.611 ( 0.620)	Loss 6.5634e-01 (7.4802e-01)	Acc@1  75.95 ( 72.40)
The current update step is 5220
GPU_0_using curriculum 40 with window 40
Epoch: [174][20/30]	Time  1.490 ( 1.512)	Data  0.040 ( 0.058)	InnerLoop  0.614 ( 0.627)	Loss 7.8023e-01 (6.8321e-01)	Acc@1  69.87 ( 74.45)
The current update step is 5250
The current seed is 5667797623849856883
The current lr is: 0.001
Testing Results:
 *   Acc@1 64.461
 *   Acc@1 64.478
 *   Acc@1 61.211
 *   Acc@1 61.446
 *   Acc@1 60.921
 *   Acc@1 60.655
 *   Acc@1 57.145
 *   Acc@1 57.430
 *   Acc@1 78.987
 *   Acc@1 79.071
 *   Acc@1 77.289
 *   Acc@1 77.308
 *   Acc@1 75.908
 *   Acc@1 76.035
 *   Acc@1 75.171
 *   Acc@1 75.213
 *   Acc@1 77.566
 *   Acc@1 78.026
 *   Acc@1 77.237
 *   Acc@1 77.068
 *   Acc@1 76.579
 *   Acc@1 76.772
 *   Acc@1 75.724
 *   Acc@1 75.759
 *   Acc@1 78.276
 *   Acc@1 78.760
 *   Acc@1 76.632
 *   Acc@1 77.056
 *   Acc@1 76.105
 *   Acc@1 76.537
 *   Acc@1 75.513
 *   Acc@1 75.965
Training for 300 epoch: 74.82236842105264
Training for 600 epoch: 73.0921052631579
Training for 1000 epoch: 72.3782894736842
Training for 3000 epoch: 70.88815789473684
Training for 300 epoch: 75.08354166666668
Training for 600 epoch: 73.21958333333333
Training for 1000 epoch: 72.49979166666665
Training for 3000 epoch: 71.09166666666667
[[74.82236842105264, 73.0921052631579, 72.3782894736842, 70.88815789473684], [75.08354166666668, 73.21958333333333, 72.49979166666665, 71.09166666666667]]
train loss 0.17009817542235056, epoch 174, best loss 0.16660270546277364, best_epoch 139
GPU_0_using curriculum 40 with window 40
Epoch: [175][20/30]	Time  1.479 ( 1.515)	Data  0.039 ( 0.063)	InnerLoop  0.610 ( 0.624)	Loss 9.1642e-01 (6.6289e-01)	Acc@1  69.29 ( 75.11)
The current update step is 5280
GPU_0_using curriculum 40 with window 40
Epoch: [176][20/30]	Time  1.468 ( 1.503)	Data  0.041 ( 0.070)	InnerLoop  0.603 ( 0.609)	Loss 6.1276e-01 (7.1200e-01)	Acc@1  78.49 ( 73.47)
The current update step is 5310
GPU_0_using curriculum 40 with window 40
Epoch: [177][20/30]	Time  1.473 ( 1.509)	Data  0.038 ( 0.065)	InnerLoop  0.607 ( 0.618)	Loss 6.5143e-01 (7.0440e-01)	Acc@1  73.85 ( 73.59)
The current update step is 5340
GPU_0_using curriculum 40 with window 40
Epoch: [178][20/30]	Time  1.486 ( 1.516)	Data  0.042 ( 0.064)	InnerLoop  0.612 ( 0.620)	Loss 6.0906e-01 (6.9512e-01)	Acc@1  78.54 ( 74.51)
The current update step is 5370
GPU_0_using curriculum 40 with window 40
Epoch: [179][20/30]	Time  1.476 ( 1.512)	Data  0.039 ( 0.057)	InnerLoop  0.614 ( 0.627)	Loss 6.0726e-01 (6.4608e-01)	Acc@1  79.08 ( 76.31)
The current update step is 5400
The current seed is 13255557730639825750
The current lr is: 0.001
Testing Results:
 *   Acc@1 78.303
 *   Acc@1 78.302
 *   Acc@1 75.829
 *   Acc@1 76.113
 *   Acc@1 74.789
 *   Acc@1 74.784
 *   Acc@1 73.461
 *   Acc@1 73.628
 *   Acc@1 65.750
 *   Acc@1 66.381
 *   Acc@1 63.158
 *   Acc@1 63.760
 *   Acc@1 61.500
 *   Acc@1 62.347
 *   Acc@1 57.197
 *   Acc@1 57.888
 *   Acc@1 73.382
 *   Acc@1 73.883
 *   Acc@1 73.934
 *   Acc@1 74.286
 *   Acc@1 73.211
 *   Acc@1 74.029
 *   Acc@1 72.158
 *   Acc@1 72.297
 *   Acc@1 76.461
 *   Acc@1 76.945
 *   Acc@1 76.145
 *   Acc@1 76.310
 *   Acc@1 76.145
 *   Acc@1 76.235
 *   Acc@1 75.316
 *   Acc@1 75.513
Training for 300 epoch: 73.47368421052632
Training for 600 epoch: 72.26644736842105
Training for 1000 epoch: 71.41118421052632
Training for 3000 epoch: 69.53289473684211
Training for 300 epoch: 73.87791666666666
Training for 600 epoch: 72.61729166666666
Training for 1000 epoch: 71.84875
Training for 3000 epoch: 69.831875
[[73.47368421052632, 72.26644736842105, 71.41118421052632, 69.53289473684211], [73.87791666666666, 72.61729166666666, 71.84875, 69.831875]]
train loss 0.1765816490570704, epoch 179, best loss 0.16660270546277364, best_epoch 139
GPU_0_using curriculum 40 with window 40
Epoch: [180][20/30]	Time  1.491 ( 1.518)	Data  0.041 ( 0.063)	InnerLoop  0.616 ( 0.623)	Loss 8.7446e-01 (6.6665e-01)	Acc@1  70.24 ( 75.67)
The current update step is 5430
GPU_0_using curriculum 40 with window 40
Epoch: [181][20/30]	Time  1.492 ( 1.514)	Data  0.038 ( 0.069)	InnerLoop  0.630 ( 0.614)	Loss 6.1888e-01 (6.9458e-01)	Acc@1  73.66 ( 74.30)
The current update step is 5460
GPU_0_using curriculum 40 with window 40
Epoch: [182][20/30]	Time  1.493 ( 1.510)	Data  0.037 ( 0.063)	InnerLoop  0.614 ( 0.620)	Loss 5.3206e-01 (6.5810e-01)	Acc@1  80.71 ( 75.64)
The current update step is 5490
GPU_0_using curriculum 40 with window 40
Epoch: [183][20/30]	Time  1.464 ( 1.512)	Data  0.037 ( 0.063)	InnerLoop  0.606 ( 0.616)	Loss 5.8688e-01 (7.3821e-01)	Acc@1  78.47 ( 73.18)
The current update step is 5520
GPU_0_using curriculum 40 with window 40
Epoch: [184][20/30]	Time  1.469 ( 1.507)	Data  0.039 ( 0.057)	InnerLoop  0.611 ( 0.623)	Loss 6.4388e-01 (6.5968e-01)	Acc@1  71.75 ( 75.07)
The current update step is 5550
The current seed is 3006849359627394283
The current lr is: 0.001
Testing Results:
 *   Acc@1 66.724
 *   Acc@1 67.177
 *   Acc@1 62.632
 *   Acc@1 62.685
 *   Acc@1 61.803
 *   Acc@1 62.596
 *   Acc@1 63.079
 *   Acc@1 63.562
 *   Acc@1 75.342
 *   Acc@1 75.529
 *   Acc@1 75.855
 *   Acc@1 75.824
 *   Acc@1 76.303
 *   Acc@1 76.201
 *   Acc@1 74.368
 *   Acc@1 74.737
 *   Acc@1 77.829
 *   Acc@1 78.563
 *   Acc@1 77.842
 *   Acc@1 78.415
 *   Acc@1 76.474
 *   Acc@1 76.808
 *   Acc@1 75.250
 *   Acc@1 75.380
 *   Acc@1 74.500
 *   Acc@1 74.491
 *   Acc@1 71.632
 *   Acc@1 71.859
 *   Acc@1 70.408
 *   Acc@1 70.502
 *   Acc@1 68.289
 *   Acc@1 68.449
Training for 300 epoch: 73.59868421052632
Training for 600 epoch: 71.99013157894737
Training for 1000 epoch: 71.24671052631578
Training for 3000 epoch: 70.24671052631578
Training for 300 epoch: 73.94020833333333
Training for 600 epoch: 72.19583333333334
Training for 1000 epoch: 71.526875
Training for 3000 epoch: 70.531875
[[73.59868421052632, 71.99013157894737, 71.24671052631578, 70.24671052631578], [73.94020833333333, 72.19583333333334, 71.526875, 70.531875]]
train loss 0.21310577443440756, epoch 184, best loss 0.16660270546277364, best_epoch 139
GPU_0_using curriculum 40 with window 40
Epoch: [185][20/30]	Time  1.497 ( 1.525)	Data  0.040 ( 0.063)	InnerLoop  0.628 ( 0.628)	Loss 5.5199e-01 (6.4791e-01)	Acc@1  79.10 ( 75.88)
The current update step is 5580
GPU_0_using curriculum 40 with window 40
Epoch: [186][20/30]	Time  1.481 ( 1.514)	Data  0.040 ( 0.070)	InnerLoop  0.611 ( 0.614)	Loss 6.2130e-01 (7.0464e-01)	Acc@1  77.42 ( 73.25)
The current update step is 5610
GPU_0_using curriculum 40 with window 40
Epoch: [187][20/30]	Time  1.478 ( 1.519)	Data  0.040 ( 0.065)	InnerLoop  0.614 ( 0.621)	Loss 7.0432e-01 (6.7458e-01)	Acc@1  71.63 ( 74.55)
The current update step is 5640
GPU_0_using curriculum 40 with window 40
Epoch: [188][20/30]	Time  1.479 ( 1.510)	Data  0.038 ( 0.063)	InnerLoop  0.617 ( 0.617)	Loss 6.2652e-01 (6.5692e-01)	Acc@1  77.25 ( 75.41)
The current update step is 5670
GPU_0_using curriculum 40 with window 40
Epoch: [189][20/30]	Time  1.477 ( 1.513)	Data  0.039 ( 0.057)	InnerLoop  0.610 ( 0.625)	Loss 8.6592e-01 (6.5790e-01)	Acc@1  68.75 ( 75.66)
The current update step is 5700
The current seed is 7242887906881106277
The current lr is: 0.001
Testing Results:
 *   Acc@1 71.658
 *   Acc@1 71.433
 *   Acc@1 72.513
 *   Acc@1 72.285
 *   Acc@1 73.355
 *   Acc@1 73.464
 *   Acc@1 73.697
 *   Acc@1 74.369
 *   Acc@1 77.908
 *   Acc@1 78.186
 *   Acc@1 74.211
 *   Acc@1 74.024
 *   Acc@1 72.592
 *   Acc@1 72.667
 *   Acc@1 71.882
 *   Acc@1 72.695
 *   Acc@1 80.487
 *   Acc@1 80.531
 *   Acc@1 79.158
 *   Acc@1 79.313
 *   Acc@1 78.105
 *   Acc@1 78.064
 *   Acc@1 76.789
 *   Acc@1 76.762
 *   Acc@1 78.355
 *   Acc@1 78.476
 *   Acc@1 78.526
 *   Acc@1 78.415
 *   Acc@1 77.789
 *   Acc@1 78.004
 *   Acc@1 77.066
 *   Acc@1 76.693
Training for 300 epoch: 77.10197368421053
Training for 600 epoch: 76.10197368421052
Training for 1000 epoch: 75.46052631578948
Training for 3000 epoch: 74.85855263157895
Training for 300 epoch: 77.15625
Training for 600 epoch: 76.009375
Training for 1000 epoch: 75.54979166666666
Training for 3000 epoch: 75.12979166666666
[[77.10197368421053, 76.10197368421052, 75.46052631578948, 74.85855263157895], [77.15625, 76.009375, 75.54979166666666, 75.12979166666666]]
train loss 0.168621320605278, epoch 189, best loss 0.16660270546277364, best_epoch 139
GPU_0_using curriculum 40 with window 40
Epoch: [190][20/30]	Time  1.482 ( 1.515)	Data  0.038 ( 0.063)	InnerLoop  0.612 ( 0.625)	Loss 6.4555e-01 (6.9539e-01)	Acc@1  73.49 ( 74.72)
The current update step is 5730
GPU_0_using curriculum 40 with window 40
Epoch: [191][20/30]	Time  1.481 ( 1.507)	Data  0.038 ( 0.069)	InnerLoop  0.613 ( 0.610)	Loss 9.5282e-01 (7.0532e-01)	Acc@1  72.41 ( 74.38)
The current update step is 5760
GPU_0_using curriculum 40 with window 40
Epoch: [192][20/30]	Time  1.472 ( 1.506)	Data  0.039 ( 0.063)	InnerLoop  0.609 ( 0.615)	Loss 6.1171e-01 (7.1525e-01)	Acc@1  77.47 ( 74.22)
The current update step is 5790
GPU_0_using curriculum 40 with window 40
Epoch: [193][20/30]	Time  1.475 ( 1.505)	Data  0.043 ( 0.063)	InnerLoop  0.612 ( 0.616)	Loss 5.2051e-01 (6.4919e-01)	Acc@1  81.35 ( 76.52)
The current update step is 5820
GPU_0_using curriculum 40 with window 40
Epoch: [194][20/30]	Time  1.499 ( 1.513)	Data  0.038 ( 0.057)	InnerLoop  0.618 ( 0.623)	Loss 6.9350e-01 (6.5744e-01)	Acc@1  74.41 ( 75.59)
The current update step is 5850
The current seed is 10213002890005281861
The current lr is: 0.001
Testing Results:
 *   Acc@1 78.605
 *   Acc@1 78.632
 *   Acc@1 79.118
 *   Acc@1 79.081
 *   Acc@1 78.171
 *   Acc@1 78.452
 *   Acc@1 75.184
 *   Acc@1 74.588
 *   Acc@1 78.474
 *   Acc@1 78.248
 *   Acc@1 77.961
 *   Acc@1 77.638
 *   Acc@1 75.921
 *   Acc@1 75.968
 *   Acc@1 73.539
 *   Acc@1 73.779
 *   Acc@1 78.316
 *   Acc@1 78.203
 *   Acc@1 75.934
 *   Acc@1 76.221
 *   Acc@1 76.500
 *   Acc@1 76.636
 *   Acc@1 75.105
 *   Acc@1 75.610
 *   Acc@1 73.342
 *   Acc@1 73.987
 *   Acc@1 74.882
 *   Acc@1 75.323
 *   Acc@1 72.447
 *   Acc@1 73.440
 *   Acc@1 68.263
 *   Acc@1 68.627
Training for 300 epoch: 77.18421052631578
Training for 600 epoch: 76.97368421052632
Training for 1000 epoch: 75.75986842105263
Training for 3000 epoch: 73.02302631578947
Training for 300 epoch: 77.26708333333333
Training for 600 epoch: 77.06541666666666
Training for 1000 epoch: 76.12375
Training for 3000 epoch: 73.15125
[[77.18421052631578, 76.97368421052632, 75.75986842105263, 73.02302631578947], [77.26708333333333, 77.06541666666666, 76.12375, 73.15125]]
train loss 0.28587422739664714, epoch 194, best loss 0.16660270546277364, best_epoch 139
GPU_0_using curriculum 40 with window 40
Epoch: [195][20/30]	Time  1.540 ( 1.518)	Data  0.039 ( 0.063)	InnerLoop  0.619 ( 0.624)	Loss 6.7763e-01 (6.4684e-01)	Acc@1  72.27 ( 75.71)
The current update step is 5880
GPU_0_using curriculum 40 with window 40
Epoch: [196][20/30]	Time  1.499 ( 1.512)	Data  0.041 ( 0.069)	InnerLoop  0.634 ( 0.614)	Loss 5.7371e-01 (6.5915e-01)	Acc@1  79.15 ( 75.68)
The current update step is 5910
GPU_0_using curriculum 40 with window 40
Epoch: [197][20/30]	Time  1.481 ( 1.510)	Data  0.038 ( 0.064)	InnerLoop  0.614 ( 0.617)	Loss 7.4912e-01 (6.2644e-01)	Acc@1  72.49 ( 76.50)
The current update step is 5940
GPU_0_using curriculum 40 with window 40
Epoch: [198][20/30]	Time  1.475 ( 1.505)	Data  0.044 ( 0.063)	InnerLoop  0.607 ( 0.617)	Loss 1.0214e+00 (7.1757e-01)	Acc@1  60.08 ( 73.17)
The current update step is 5970
GPU_0_using curriculum 40 with window 40
Epoch: [199][20/30]	Time  1.498 ( 1.508)	Data  0.040 ( 0.057)	InnerLoop  0.618 ( 0.623)	Loss 7.7125e-01 (6.8359e-01)	Acc@1  72.12 ( 74.61)
The current update step is 6000
The current seed is 15367590098599743547
The current lr is: 0.001
Testing Results:
 *   Acc@1 77.750
 *   Acc@1 77.631
 *   Acc@1 75.263
 *   Acc@1 75.587
 *   Acc@1 74.329
 *   Acc@1 74.590
 *   Acc@1 73.039
 *   Acc@1 73.491
 *   Acc@1 79.474
 *   Acc@1 79.975
 *   Acc@1 78.697
 *   Acc@1 79.387
 *   Acc@1 78.487
 *   Acc@1 79.353
 *   Acc@1 77.474
 *   Acc@1 77.917
 *   Acc@1 76.421
 *   Acc@1 76.800
 *   Acc@1 75.105
 *   Acc@1 75.835
 *   Acc@1 74.632
 *   Acc@1 75.059
 *   Acc@1 72.947
 *   Acc@1 73.468
 *   Acc@1 77.605
 *   Acc@1 78.105
 *   Acc@1 75.882
 *   Acc@1 76.227
 *   Acc@1 76.803
 *   Acc@1 77.228
 *   Acc@1 77.987
 *   Acc@1 78.721
Training for 300 epoch: 77.8125
Training for 600 epoch: 76.23684210526316
Training for 1000 epoch: 76.0625
Training for 3000 epoch: 75.36184210526315
Training for 300 epoch: 78.12770833333333
Training for 600 epoch: 76.75875
Training for 1000 epoch: 76.5575
Training for 3000 epoch: 75.89895833333333
[[77.8125, 76.23684210526316, 76.0625, 75.36184210526315], [78.12770833333333, 76.75875, 76.5575, 75.89895833333333]]
train loss 0.16854745604197185, epoch 199, best loss 0.16660270546277364, best_epoch 199
=== Final results:
{'acc': 77.8125, 'test': [77.8125, 76.23684210526316, 76.0625, 75.36184210526315], 'train': [77.8125, 76.23684210526316, 76.0625, 75.36184210526315], 'ind': 0, 'epoch': 200, 'data': array([[-0.09187082, -0.10342127,  0.00279413, ...,  0.08389717,
        -0.01932401, -0.0291351 ],
       [ 0.02614325,  0.05545193,  0.01382256, ..., -0.01141397,
         0.04736703, -0.01480443],
       [-0.09770861,  0.0501905 , -0.10421175, ..., -0.01736734,
         0.11624404, -0.04507739],
       ...,
       [ 0.08286856,  0.1159281 ,  0.01739794, ..., -0.01972594,
         0.02798114, -0.02218051],
       [-0.11050437, -0.00272845, -0.12990485, ..., -0.05763245,
         0.0047489 ,  0.06122823],
       [-0.02087834, -0.07924145, -0.00611749, ..., -0.09638313,
         0.02296004, -0.01695061]], shape=(40, 768), dtype=float32)}
